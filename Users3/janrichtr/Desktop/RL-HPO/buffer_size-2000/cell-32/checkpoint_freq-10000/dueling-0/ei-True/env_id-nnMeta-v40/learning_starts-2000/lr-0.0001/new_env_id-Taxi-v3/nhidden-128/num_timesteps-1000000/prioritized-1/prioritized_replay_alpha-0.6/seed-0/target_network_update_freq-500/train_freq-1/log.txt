Logging to /Users/janrichtr/Desktop/RL-HPO/buffer_size-2000/cell-32/checkpoint_freq-10000/dueling-0/ei-True/env_id-nnMeta-v40/learning_starts-2000/lr-0.0001/new_env_id-Taxi-v3/nhidden-128/num_timesteps-1000000/prioritized-1/prioritized_replay_alpha-0.6/seed-0/target_network_update_freq-500/train_freq-1/
Loaded model from /Users/janrichtr/Desktop/RL-HPO/buffer_size-2000/cell-32/checkpoint_freq-10000/dueling-0/ei-True/env_id-nnMeta-v40/learning_starts-2000/lr-0.0001/new_env_id-Taxi-v3/nhidden-128/num_timesteps-1000000/prioritized-1/prioritized_replay_alpha-0.6/seed-0/target_network_update_freq-500/train_freq-1/model
--------------------------------------
| % time spent exploring  | 99       |
| episodes                | 100      |
| lives                   | 100      |
| mean 100 episode ei     | 4.95     |
| mean 100 episode length | 10       |
| mean 100 episode reward | 0.551    |
| most_used_dataset       | 0        |
| number_of_used          | 20       |
| q_t                     | nan      |
| steps                   | 890      |
| td_erros                | nan      |
--------------------------------------
--------------------------------------
| % time spent exploring  | 99       |
| episodes                | 200      |
| lives                   | 200      |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 10.2     |
| mean 100 episode reward | -0.154   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | nan      |
| steps                   | 1814     |
| td_erros                | nan      |
--------------------------------------
--------------------------------------
| % time spent exploring  | 99       |
| episodes                | 300      |
| lives                   | 300      |
| mean 100 episode ei     | 4.91     |
| mean 100 episode length | 10.4     |
| mean 100 episode reward | 0.557    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | nan      |
| steps                   | 2751     |
| td_erros                | nan      |
--------------------------------------
--------------------------------------
| % time spent exploring  | 99       |
| episodes                | 400      |
| lives                   | 400      |
| mean 100 episode ei     | 4.76     |
| mean 100 episode length | 10.1     |
| mean 100 episode reward | 0.466    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | nan      |
| steps                   | 3656     |
| td_erros                | nan      |
--------------------------------------
--------------------------------------
| % time spent exploring  | 99       |
| episodes                | 500      |
| lives                   | 500      |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 9.82     |
| mean 100 episode reward | -0.0872  |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | nan      |
| steps                   | 4538     |
| td_erros                | nan      |
--------------------------------------
--------------------------------------
| % time spent exploring  | 98       |
| episodes                | 600      |
| lives                   | 600      |
| mean 100 episode ei     | 4.75     |
| mean 100 episode length | 9.93     |
| mean 100 episode reward | 0.048    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5211   |
| steps                   | 5431     |
| td_erros                | 0.1427   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 98       |
| episodes                | 700      |
| lives                   | 700      |
| mean 100 episode ei     | 4.51     |
| mean 100 episode length | 9.96     |
| mean 100 episode reward | 0.295    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7891   |
| steps                   | 6327     |
| td_erros                | 0.2985   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 98       |
| episodes                | 800      |
| lives                   | 800      |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 10.2     |
| mean 100 episode reward | -0.267   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3508   |
| steps                   | 7244     |
| td_erros                | 0.4542   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 98       |
| episodes                | 900      |
| lives                   | 900      |
| mean 100 episode ei     | 4.76     |
| mean 100 episode length | 10       |
| mean 100 episode reward | -0.186   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.8582   |
| steps                   | 8148     |
| td_erros                | 0.6393   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 98       |
| episodes                | 1000     |
| lives                   | 1000     |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 9.79     |
| mean 100 episode reward | 0.608    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.3992   |
| steps                   | 9027     |
| td_erros                | 0.8107   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 98       |
| episodes                | 1100     |
| lives                   | 1100     |
| mean 100 episode ei     | 4.73     |
| mean 100 episode length | 10.1     |
| mean 100 episode reward | 0.313    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.9674   |
| steps                   | 9933     |
| td_erros                | 0.9968   |
--------------------------------------
Saving model due to mean reward increase: None -> 0.1516
--------------------------------------
| % time spent exploring  | 97       |
| episodes                | 1200     |
| lives                   | 1200     |
| mean 100 episode ei     | 4.48     |
| mean 100 episode length | 9.15     |
| mean 100 episode reward | -0.111   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 6.2047   |
| steps                   | 10748    |
| td_erros                | 1.1019   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 97       |
| episodes                | 1300     |
| lives                   | 1300     |
| mean 100 episode ei     | 4.45     |
| mean 100 episode length | 9.67     |
| mean 100 episode reward | 0.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 6.2967   |
| steps                   | 11615    |
| td_erros                | 1.1895   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 97       |
| episodes                | 1400     |
| lives                   | 1400     |
| mean 100 episode ei     | 4.4      |
| mean 100 episode length | 9.38     |
| mean 100 episode reward | 0.008    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 6.5133   |
| steps                   | 12453    |
| td_erros                | 1.2603   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 97       |
| episodes                | 1500     |
| lives                   | 1500     |
| mean 100 episode ei     | 4.42     |
| mean 100 episode length | 9.47     |
| mean 100 episode reward | 0.417    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 6.7391   |
| steps                   | 13300    |
| td_erros                | 1.3857   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 97       |
| episodes                | 1600     |
| lives                   | 1600     |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 9.18     |
| mean 100 episode reward | -0.0222  |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 6.8087   |
| steps                   | 14118    |
| td_erros                | 1.4793   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 97       |
| episodes                | 1700     |
| lives                   | 1700     |
| mean 100 episode ei     | 5.18     |
| mean 100 episode length | 10       |
| mean 100 episode reward | 0.379    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 6.6914   |
| steps                   | 15022    |
| td_erros                | 1.401    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 96       |
| episodes                | 1800     |
| lives                   | 1800     |
| mean 100 episode ei     | 5.04     |
| mean 100 episode length | 10.5     |
| mean 100 episode reward | 0.0471   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 6.5933   |
| steps                   | 15975    |
| td_erros                | 1.3361   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 96       |
| episodes                | 1900     |
| lives                   | 1900     |
| mean 100 episode ei     | 4.52     |
| mean 100 episode length | 10       |
| mean 100 episode reward | 0.062    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 6.5256   |
| steps                   | 16878    |
| td_erros                | 1.2023   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 96       |
| episodes                | 2000     |
| lives                   | 2000     |
| mean 100 episode ei     | 4.42     |
| mean 100 episode length | 9.08     |
| mean 100 episode reward | 0.0378   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 6.4478   |
| steps                   | 17686    |
| td_erros                | 1.2019   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 96       |
| episodes                | 2100     |
| lives                   | 2100     |
| mean 100 episode ei     | 4.79     |
| mean 100 episode length | 9.85     |
| mean 100 episode reward | 0.552    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 6.3623   |
| steps                   | 18571    |
| td_erros                | 1.173    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 96       |
| episodes                | 2200     |
| lives                   | 2200     |
| mean 100 episode ei     | 4.35     |
| mean 100 episode length | 9.39     |
| mean 100 episode reward | 0.0289   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 6.4355   |
| steps                   | 19410    |
| td_erros                | 1.1695   |
--------------------------------------
Saving model due to mean reward increase: 0.1516 -> 0.3725
Saving model due to running mean reward increase: 0.1386 -> 0.3725
--------------------------------------
| % time spent exploring  | 95       |
| episodes                | 2300     |
| lives                   | 2300     |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 9.44     |
| mean 100 episode reward | 0.343    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 6.4644   |
| steps                   | 20254    |
| td_erros                | 1.1596   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 95       |
| episodes                | 2400     |
| lives                   | 2400     |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 9.23     |
| mean 100 episode reward | 0.898    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 6.4916   |
| steps                   | 21077    |
| td_erros                | 1.1793   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 95       |
| episodes                | 2500     |
| lives                   | 2500     |
| mean 100 episode ei     | 4.61     |
| mean 100 episode length | 9.61     |
| mean 100 episode reward | 0.449    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 6.5312   |
| steps                   | 21938    |
| td_erros                | 1.2398   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 95       |
| episodes                | 2600     |
| lives                   | 2600     |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 9.24     |
| mean 100 episode reward | 0.292    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 6.4666   |
| steps                   | 22762    |
| td_erros                | 1.2404   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 95       |
| episodes                | 2700     |
| lives                   | 2700     |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 9.62     |
| mean 100 episode reward | 0.285    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 6.4677   |
| steps                   | 23624    |
| td_erros                | 1.2497   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 95       |
| episodes                | 2800     |
| lives                   | 2800     |
| mean 100 episode ei     | 4.89     |
| mean 100 episode length | 9.92     |
| mean 100 episode reward | -0.0917  |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 6.3687   |
| steps                   | 24516    |
| td_erros                | 1.1546   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 94       |
| episodes                | 2900     |
| lives                   | 2900     |
| mean 100 episode ei     | 4.74     |
| mean 100 episode length | 10       |
| mean 100 episode reward | 0.756    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 6.2047   |
| steps                   | 25420    |
| td_erros                | 1.0572   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 94       |
| episodes                | 3000     |
| lives                   | 3000     |
| mean 100 episode ei     | 4.72     |
| mean 100 episode length | 9.58     |
| mean 100 episode reward | 0.149    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 6.0975   |
| steps                   | 26278    |
| td_erros                | 1.0186   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 94       |
| episodes                | 3100     |
| lives                   | 3100     |
| mean 100 episode ei     | 4.62     |
| mean 100 episode length | 9.41     |
| mean 100 episode reward | 0.605    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.9788   |
| steps                   | 27119    |
| td_erros                | 1.0221   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 94       |
| episodes                | 3200     |
| lives                   | 3200     |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 10.2     |
| mean 100 episode reward | 0.0119   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.8834   |
| steps                   | 28039    |
| td_erros                | 0.9501   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 94       |
| episodes                | 3300     |
| lives                   | 3300     |
| mean 100 episode ei     | 4.94     |
| mean 100 episode length | 9.8      |
| mean 100 episode reward | 0.653    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.8645   |
| steps                   | 28919    |
| td_erros                | 0.9297   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 94       |
| episodes                | 3400     |
| lives                   | 3400     |
| mean 100 episode ei     | 4.47     |
| mean 100 episode length | 9.48     |
| mean 100 episode reward | 0.406    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.8548   |
| steps                   | 29767    |
| td_erros                | 0.9469   |
--------------------------------------
Saving model due to mean reward increase: 0.3725 -> 0.6828
Saving model due to running mean reward increase: 0.3816 -> 0.6828
--------------------------------------
| % time spent exploring  | 93       |
| episodes                | 3500     |
| lives                   | 3500     |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 9.62     |
| mean 100 episode reward | 0.338    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.8093   |
| steps                   | 30629    |
| td_erros                | 0.9612   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 93       |
| episodes                | 3600     |
| lives                   | 3600     |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 9.83     |
| mean 100 episode reward | 0.143    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.7332   |
| steps                   | 31512    |
| td_erros                | 0.9023   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 93       |
| episodes                | 3700     |
| lives                   | 3700     |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 9.28     |
| mean 100 episode reward | 0.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.6134   |
| steps                   | 32340    |
| td_erros                | 0.8484   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 93       |
| episodes                | 3800     |
| lives                   | 3800     |
| mean 100 episode ei     | 4.78     |
| mean 100 episode length | 9.6      |
| mean 100 episode reward | 0.885    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.6226   |
| steps                   | 33200    |
| td_erros                | 0.8233   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 93       |
| episodes                | 3900     |
| lives                   | 3900     |
| mean 100 episode ei     | 4.8      |
| mean 100 episode length | 9.83     |
| mean 100 episode reward | 0.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.5461   |
| steps                   | 34083    |
| td_erros                | 0.812    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 93       |
| episodes                | 4000     |
| lives                   | 4000     |
| mean 100 episode ei     | 4.47     |
| mean 100 episode length | 9.78     |
| mean 100 episode reward | -0.0879  |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.469    |
| steps                   | 34961    |
| td_erros                | 0.7748   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 92       |
| episodes                | 4100     |
| lives                   | 4100     |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 9.43     |
| mean 100 episode reward | 0.843    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.3698   |
| steps                   | 35804    |
| td_erros                | 0.7308   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 92       |
| episodes                | 4200     |
| lives                   | 4200     |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 9.94     |
| mean 100 episode reward | 0.254    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.2795   |
| steps                   | 36698    |
| td_erros                | 0.6784   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 92       |
| episodes                | 4300     |
| lives                   | 4300     |
| mean 100 episode ei     | 4.46     |
| mean 100 episode length | 8.75     |
| mean 100 episode reward | 0.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.2576   |
| steps                   | 37473    |
| td_erros                | 0.6677   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 92       |
| episodes                | 4400     |
| lives                   | 4400     |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 9.67     |
| mean 100 episode reward | 0.474    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.3507   |
| steps                   | 38340    |
| td_erros                | 0.7006   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 92       |
| episodes                | 4500     |
| lives                   | 4500     |
| mean 100 episode ei     | 4.43     |
| mean 100 episode length | 8.9      |
| mean 100 episode reward | 1.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.3763   |
| steps                   | 39130    |
| td_erros                | 0.6947   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 92       |
| episodes                | 4600     |
| lives                   | 4600     |
| mean 100 episode ei     | 4.45     |
| mean 100 episode length | 9.28     |
| mean 100 episode reward | 0.513    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.4274   |
| steps                   | 39958    |
| td_erros                | 0.7212   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 91       |
| episodes                | 4700     |
| lives                   | 4700     |
| mean 100 episode ei     | 4.46     |
| mean 100 episode length | 9.53     |
| mean 100 episode reward | 0.452    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.3155   |
| steps                   | 40811    |
| td_erros                | 0.6714   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 91       |
| episodes                | 4800     |
| lives                   | 4800     |
| mean 100 episode ei     | 5.09     |
| mean 100 episode length | 9.29     |
| mean 100 episode reward | 0.801    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.2237   |
| steps                   | 41640    |
| td_erros                | 0.6196   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 91       |
| episodes                | 4900     |
| lives                   | 4900     |
| mean 100 episode ei     | 4.99     |
| mean 100 episode length | 9.57     |
| mean 100 episode reward | 0.951    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.1722   |
| steps                   | 42497    |
| td_erros                | 0.6113   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 91       |
| episodes                | 5000     |
| lives                   | 5000     |
| mean 100 episode ei     | 5.37     |
| mean 100 episode length | 10       |
| mean 100 episode reward | 1.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.1672   |
| steps                   | 43399    |
| td_erros                | 0.6069   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 91       |
| episodes                | 5100     |
| lives                   | 5100     |
| mean 100 episode ei     | 4.43     |
| mean 100 episode length | 9.19     |
| mean 100 episode reward | 0.683    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.3006   |
| steps                   | 44218    |
| td_erros                | 0.6572   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 91       |
| episodes                | 5200     |
| lives                   | 5200     |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 9.21     |
| mean 100 episode reward | 0.522    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.2995   |
| steps                   | 45039    |
| td_erros                | 0.6628   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 90       |
| episodes                | 5300     |
| lives                   | 5300     |
| mean 100 episode ei     | 4.43     |
| mean 100 episode length | 9.24     |
| mean 100 episode reward | 0.911    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.3983   |
| steps                   | 45863    |
| td_erros                | 0.7355   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 90       |
| episodes                | 5400     |
| lives                   | 5400     |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 9.63     |
| mean 100 episode reward | 0.505    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.482    |
| steps                   | 46726    |
| td_erros                | 0.7941   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 90       |
| episodes                | 5500     |
| lives                   | 5500     |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 9.25     |
| mean 100 episode reward | 0.805    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.4571   |
| steps                   | 47551    |
| td_erros                | 0.8006   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 90       |
| episodes                | 5600     |
| lives                   | 5600     |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 9.37     |
| mean 100 episode reward | 0.563    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.3426   |
| steps                   | 48388    |
| td_erros                | 0.7972   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 90       |
| episodes                | 5700     |
| lives                   | 5700     |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 8.86     |
| mean 100 episode reward | 0.445    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.2495   |
| steps                   | 49174    |
| td_erros                | 0.7809   |
--------------------------------------
Saving model due to running mean reward increase: 0.5163 -> 0.5831
--------------------------------------
| % time spent exploring  | 90       |
| episodes                | 5800     |
| lives                   | 5800     |
| mean 100 episode ei     | 4.36     |
| mean 100 episode length | 9.37     |
| mean 100 episode reward | 0.646    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.1495   |
| steps                   | 50011    |
| td_erros                | 0.7618   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 89       |
| episodes                | 5900     |
| lives                   | 5900     |
| mean 100 episode ei     | 5.01     |
| mean 100 episode length | 10.1     |
| mean 100 episode reward | 0.832    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.0392   |
| steps                   | 50920    |
| td_erros                | 0.6796   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 89       |
| episodes                | 6000     |
| lives                   | 6000     |
| mean 100 episode ei     | 4.94     |
| mean 100 episode length | 9.88     |
| mean 100 episode reward | 0.846    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.9315   |
| steps                   | 51808    |
| td_erros                | 0.6686   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 89       |
| episodes                | 6100     |
| lives                   | 6100     |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 8.73     |
| mean 100 episode reward | 0.368    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.8389   |
| steps                   | 52581    |
| td_erros                | 0.6016   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 89       |
| episodes                | 6200     |
| lives                   | 6200     |
| mean 100 episode ei     | 4.76     |
| mean 100 episode length | 9.92     |
| mean 100 episode reward | 0.218    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.8141   |
| steps                   | 53473    |
| td_erros                | 0.5603   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 89       |
| episodes                | 6300     |
| lives                   | 6300     |
| mean 100 episode ei     | 4.62     |
| mean 100 episode length | 9.45     |
| mean 100 episode reward | 0.449    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.8301   |
| steps                   | 54318    |
| td_erros                | 0.5407   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 89       |
| episodes                | 6400     |
| lives                   | 6400     |
| mean 100 episode ei     | 4.78     |
| mean 100 episode length | 9.37     |
| mean 100 episode reward | 1.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.7806   |
| steps                   | 55155    |
| td_erros                | 0.5187   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 88       |
| episodes                | 6500     |
| lives                   | 6500     |
| mean 100 episode ei     | 4.72     |
| mean 100 episode length | 9.59     |
| mean 100 episode reward | 1.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.9318   |
| steps                   | 56014    |
| td_erros                | 0.5904   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 88       |
| episodes                | 6600     |
| lives                   | 6600     |
| mean 100 episode ei     | 4.95     |
| mean 100 episode length | 9.33     |
| mean 100 episode reward | 1.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.9258   |
| steps                   | 56847    |
| td_erros                | 0.5982   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 88       |
| episodes                | 6700     |
| lives                   | 6700     |
| mean 100 episode ei     | 4.41     |
| mean 100 episode length | 8.58     |
| mean 100 episode reward | 1.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.8272   |
| steps                   | 57605    |
| td_erros                | 0.5805   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 88       |
| episodes                | 6800     |
| lives                   | 6800     |
| mean 100 episode ei     | 4.74     |
| mean 100 episode length | 9.41     |
| mean 100 episode reward | 0.962    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.7568   |
| steps                   | 58446    |
| td_erros                | 0.5421   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 88       |
| episodes                | 6900     |
| lives                   | 6900     |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 8.91     |
| mean 100 episode reward | 0.533    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.6813   |
| steps                   | 59237    |
| td_erros                | 0.5767   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 88       |
| episodes                | 7000     |
| lives                   | 7000     |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 8.19     |
| mean 100 episode reward | 1.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.5644   |
| steps                   | 59956    |
| td_erros                | 0.517    |
--------------------------------------
Saving model due to mean reward increase: 0.6828 -> 1.2445
Saving model due to running mean reward increase: 0.6671 -> 1.2445
--------------------------------------
| % time spent exploring  | 87       |
| episodes                | 7100     |
| lives                   | 7100     |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 9.14     |
| mean 100 episode reward | 1.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.4831   |
| steps                   | 60770    |
| td_erros                | 0.5417   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 87       |
| episodes                | 7200     |
| lives                   | 7200     |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 8.77     |
| mean 100 episode reward | 1.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.4216   |
| steps                   | 61547    |
| td_erros                | 0.5138   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 87       |
| episodes                | 7300     |
| lives                   | 7300     |
| mean 100 episode ei     | 4.39     |
| mean 100 episode length | 9.49     |
| mean 100 episode reward | 0.836    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.4019   |
| steps                   | 62396    |
| td_erros                | 0.5092   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 87       |
| episodes                | 7400     |
| lives                   | 7400     |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 9.32     |
| mean 100 episode reward | 1.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2981   |
| steps                   | 63228    |
| td_erros                | 0.4661   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 87       |
| episodes                | 7500     |
| lives                   | 7500     |
| mean 100 episode ei     | 4.88     |
| mean 100 episode length | 9.33     |
| mean 100 episode reward | 1.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2203   |
| steps                   | 64061    |
| td_erros                | 0.423    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 87       |
| episodes                | 7600     |
| lives                   | 7600     |
| mean 100 episode ei     | 5.19     |
| mean 100 episode length | 9.75     |
| mean 100 episode reward | 0.571    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.214    |
| steps                   | 64936    |
| td_erros                | 0.4439   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 86       |
| episodes                | 7700     |
| lives                   | 7700     |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 9.07     |
| mean 100 episode reward | 0.713    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2691   |
| steps                   | 65743    |
| td_erros                | 0.4099   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 86       |
| episodes                | 7800     |
| lives                   | 7800     |
| mean 100 episode ei     | 4.89     |
| mean 100 episode length | 8.78     |
| mean 100 episode reward | 1.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3186   |
| steps                   | 66521    |
| td_erros                | 0.4287   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 86       |
| episodes                | 7900     |
| lives                   | 7900     |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 9.13     |
| mean 100 episode reward | 1.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.5435   |
| steps                   | 67334    |
| td_erros                | 0.4691   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 86       |
| episodes                | 8000     |
| lives                   | 8000     |
| mean 100 episode ei     | 4.91     |
| mean 100 episode length | 9.23     |
| mean 100 episode reward | 1.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.6499   |
| steps                   | 68157    |
| td_erros                | 0.471    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 86       |
| episodes                | 8100     |
| lives                   | 8100     |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 8.59     |
| mean 100 episode reward | 1.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.7644   |
| steps                   | 68916    |
| td_erros                | 0.475    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 86       |
| episodes                | 8200     |
| lives                   | 8200     |
| mean 100 episode ei     | 4.69     |
| mean 100 episode length | 8.85     |
| mean 100 episode reward | 1.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.863    |
| steps                   | 69701    |
| td_erros                | 0.5374   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 86       |
| episodes                | 8300     |
| lives                   | 8300     |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 9.16     |
| mean 100 episode reward | 0.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.8248   |
| steps                   | 70517    |
| td_erros                | 0.5756   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 85       |
| episodes                | 8400     |
| lives                   | 8400     |
| mean 100 episode ei     | 4.7      |
| mean 100 episode length | 9.34     |
| mean 100 episode reward | 0.856    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.7561   |
| steps                   | 71351    |
| td_erros                | 0.5975   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 85       |
| episodes                | 8500     |
| lives                   | 8500     |
| mean 100 episode ei     | 4.79     |
| mean 100 episode length | 9.02     |
| mean 100 episode reward | 1.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.6337   |
| steps                   | 72153    |
| td_erros                | 0.5391   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 85       |
| episodes                | 8600     |
| lives                   | 8600     |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 9.32     |
| mean 100 episode reward | 0.703    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.5738   |
| steps                   | 72985    |
| td_erros                | 0.5338   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 85       |
| episodes                | 8700     |
| lives                   | 8700     |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 8.92     |
| mean 100 episode reward | 0.854    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.4332   |
| steps                   | 73777    |
| td_erros                | 0.4951   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 85       |
| episodes                | 8800     |
| lives                   | 8800     |
| mean 100 episode ei     | 4.71     |
| mean 100 episode length | 8.69     |
| mean 100 episode reward | 1.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.4955   |
| steps                   | 74546    |
| td_erros                | 0.5142   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 85       |
| episodes                | 8900     |
| lives                   | 8900     |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 8.86     |
| mean 100 episode reward | 1.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.4762   |
| steps                   | 75332    |
| td_erros                | 0.5182   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 9000     |
| lives                   | 9000     |
| mean 100 episode ei     | 4.73     |
| mean 100 episode length | 9.55     |
| mean 100 episode reward | 1.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3156   |
| steps                   | 76187    |
| td_erros                | 0.4215   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 9100     |
| lives                   | 9100     |
| mean 100 episode ei     | 4.8      |
| mean 100 episode length | 9.45     |
| mean 100 episode reward | 1        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1766   |
| steps                   | 77032    |
| td_erros                | 0.3887   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 9200     |
| lives                   | 9200     |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 9.6      |
| mean 100 episode reward | 1.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2231   |
| steps                   | 77892    |
| td_erros                | 0.4185   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 9300     |
| lives                   | 9300     |
| mean 100 episode ei     | 5.1      |
| mean 100 episode length | 9.72     |
| mean 100 episode reward | 1.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2183   |
| steps                   | 78764    |
| td_erros                | 0.4516   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 9400     |
| lives                   | 9400     |
| mean 100 episode ei     | 5.36     |
| mean 100 episode length | 9.59     |
| mean 100 episode reward | 0.904    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2812   |
| steps                   | 79623    |
| td_erros                | 0.4407   |
--------------------------------------
Saving model due to mean reward increase: 1.2445 -> 1.3977
Saving model due to running mean reward increase: 1.0752 -> 1.3977
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 9500     |
| lives                   | 9500     |
| mean 100 episode ei     | 4.74     |
| mean 100 episode length | 8.81     |
| mean 100 episode reward | 1.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3956   |
| steps                   | 80404    |
| td_erros                | 0.4476   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 83       |
| episodes                | 9600     |
| lives                   | 9600     |
| mean 100 episode ei     | 4.71     |
| mean 100 episode length | 9.68     |
| mean 100 episode reward | 1.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.4868   |
| steps                   | 81272    |
| td_erros                | 0.4663   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 83       |
| episodes                | 9700     |
| lives                   | 9700     |
| mean 100 episode ei     | 4.24     |
| mean 100 episode length | 8.54     |
| mean 100 episode reward | 1.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.5337   |
| steps                   | 82026    |
| td_erros                | 0.4804   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 83       |
| episodes                | 9800     |
| lives                   | 9800     |
| mean 100 episode ei     | 4.45     |
| mean 100 episode length | 8.41     |
| mean 100 episode reward | 1.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.626    |
| steps                   | 82767    |
| td_erros                | 0.5439   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 83       |
| episodes                | 9900     |
| lives                   | 9900     |
| mean 100 episode ei     | 4.95     |
| mean 100 episode length | 8.97     |
| mean 100 episode reward | 1.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.7396   |
| steps                   | 83564    |
| td_erros                | 0.5895   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 83       |
| episodes                | 10000    |
| lives                   | 10000    |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 8.56     |
| mean 100 episode reward | 0.972    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.7099   |
| steps                   | 84320    |
| td_erros                | 0.5901   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 83       |
| episodes                | 10100    |
| lives                   | 10100    |
| mean 100 episode ei     | 4.62     |
| mean 100 episode length | 8.83     |
| mean 100 episode reward | 1.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.6476   |
| steps                   | 85103    |
| td_erros                | 0.6193   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 10200    |
| lives                   | 10200    |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 8.65     |
| mean 100 episode reward | 1.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.5111   |
| steps                   | 85868    |
| td_erros                | 0.5504   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 10300    |
| lives                   | 10300    |
| mean 100 episode ei     | 4.35     |
| mean 100 episode length | 8.45     |
| mean 100 episode reward | 1.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.5407   |
| steps                   | 86613    |
| td_erros                | 0.603    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 10400    |
| lives                   | 10400    |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 8.35     |
| mean 100 episode reward | 1.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.5146   |
| steps                   | 87348    |
| td_erros                | 0.6295   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 10500    |
| lives                   | 10500    |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 8.87     |
| mean 100 episode reward | 1.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.4354   |
| steps                   | 88135    |
| td_erros                | 0.5844   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 10600    |
| lives                   | 10600    |
| mean 100 episode ei     | 4.41     |
| mean 100 episode length | 8.98     |
| mean 100 episode reward | 0.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2816   |
| steps                   | 88933    |
| td_erros                | 0.5101   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 10700    |
| lives                   | 10700    |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 8.63     |
| mean 100 episode reward | 0.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1886   |
| steps                   | 89696    |
| td_erros                | 0.47     |
--------------------------------------
Saving model due to running mean reward increase: 0.2612 -> 1.276
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 10800    |
| lives                   | 10800    |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 8.83     |
| mean 100 episode reward | 1.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0809   |
| steps                   | 90479    |
| td_erros                | 0.4078   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 10900    |
| lives                   | 10900    |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 7.85     |
| mean 100 episode reward | 1.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0903   |
| steps                   | 91164    |
| td_erros                | 0.4112   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 11000    |
| lives                   | 11000    |
| mean 100 episode ei     | 4.52     |
| mean 100 episode length | 8.07     |
| mean 100 episode reward | 1.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1277   |
| steps                   | 91871    |
| td_erros                | 0.4244   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 11100    |
| lives                   | 11100    |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 9.1      |
| mean 100 episode reward | 1.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.15     |
| steps                   | 92681    |
| td_erros                | 0.4284   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 11200    |
| lives                   | 11200    |
| mean 100 episode ei     | 4.41     |
| mean 100 episode length | 8.29     |
| mean 100 episode reward | 1.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1051   |
| steps                   | 93410    |
| td_erros                | 0.3968   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 11300    |
| lives                   | 11300    |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 8.9      |
| mean 100 episode reward | 1.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.097    |
| steps                   | 94200    |
| td_erros                | 0.4096   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 11400    |
| lives                   | 11400    |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 8.76     |
| mean 100 episode reward | 1.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0666   |
| steps                   | 94976    |
| td_erros                | 0.4037   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 11500    |
| lives                   | 11500    |
| mean 100 episode ei     | 3.83     |
| mean 100 episode length | 7.98     |
| mean 100 episode reward | 1.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0532   |
| steps                   | 95674    |
| td_erros                | 0.4336   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 80       |
| episodes                | 11600    |
| lives                   | 11600    |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 8.91     |
| mean 100 episode reward | 1.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0185   |
| steps                   | 96465    |
| td_erros                | 0.4191   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 80       |
| episodes                | 11700    |
| lives                   | 11700    |
| mean 100 episode ei     | 4.72     |
| mean 100 episode length | 9.13     |
| mean 100 episode reward | 1.69     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0064   |
| steps                   | 97278    |
| td_erros                | 0.4191   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 80       |
| episodes                | 11800    |
| lives                   | 11800    |
| mean 100 episode ei     | 4.96     |
| mean 100 episode length | 9.02     |
| mean 100 episode reward | 2.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9172   |
| steps                   | 98080    |
| td_erros                | 0.3965   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 80       |
| episodes                | 11900    |
| lives                   | 11900    |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 8.45     |
| mean 100 episode reward | 1.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9062   |
| steps                   | 98825    |
| td_erros                | 0.3913   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 80       |
| episodes                | 12000    |
| lives                   | 12000    |
| mean 100 episode ei     | 5.35     |
| mean 100 episode length | 9.36     |
| mean 100 episode reward | 1.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9557   |
| steps                   | 99661    |
| td_erros                | 0.4263   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 80       |
| episodes                | 12100    |
| lives                   | 12100    |
| mean 100 episode ei     | 4.72     |
| mean 100 episode length | 8.47     |
| mean 100 episode reward | 1.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9794   |
| steps                   | 100408   |
| td_erros                | 0.4142   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 79       |
| episodes                | 12200    |
| lives                   | 12200    |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 8.47     |
| mean 100 episode reward | 1.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0071   |
| steps                   | 101155   |
| td_erros                | 0.4331   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 79       |
| episodes                | 12300    |
| lives                   | 12300    |
| mean 100 episode ei     | 4.61     |
| mean 100 episode length | 8.64     |
| mean 100 episode reward | 1.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.079    |
| steps                   | 101919   |
| td_erros                | 0.4238   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 79       |
| episodes                | 12400    |
| lives                   | 12400    |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 8.74     |
| mean 100 episode reward | 1.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1516   |
| steps                   | 102693   |
| td_erros                | 0.4369   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 79       |
| episodes                | 12500    |
| lives                   | 12500    |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 8.36     |
| mean 100 episode reward | 1.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2163   |
| steps                   | 103429   |
| td_erros                | 0.464    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 79       |
| episodes                | 12600    |
| lives                   | 12600    |
| mean 100 episode ei     | 4.39     |
| mean 100 episode length | 8.94     |
| mean 100 episode reward | 1.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1129   |
| steps                   | 104223   |
| td_erros                | 0.4415   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 79       |
| episodes                | 12700    |
| lives                   | 12700    |
| mean 100 episode ei     | 4.4      |
| mean 100 episode length | 8.79     |
| mean 100 episode reward | 1.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1009   |
| steps                   | 105002   |
| td_erros                | 0.4272   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 79       |
| episodes                | 12800    |
| lives                   | 12800    |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 7.96     |
| mean 100 episode reward | 1.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0521   |
| steps                   | 105698   |
| td_erros                | 0.4156   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 12900    |
| lives                   | 12900    |
| mean 100 episode ei     | 4.9      |
| mean 100 episode length | 8.98     |
| mean 100 episode reward | 1.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0143   |
| steps                   | 106496   |
| td_erros                | 0.4275   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 13000    |
| lives                   | 13000    |
| mean 100 episode ei     | 4.9      |
| mean 100 episode length | 9.02     |
| mean 100 episode reward | 1.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9771   |
| steps                   | 107298   |
| td_erros                | 0.3585   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 13100    |
| lives                   | 13100    |
| mean 100 episode ei     | 4.35     |
| mean 100 episode length | 9.01     |
| mean 100 episode reward | 0.721    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9525   |
| steps                   | 108099   |
| td_erros                | 0.3735   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 13200    |
| lives                   | 13200    |
| mean 100 episode ei     | 4.76     |
| mean 100 episode length | 8.98     |
| mean 100 episode reward | 1.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9011   |
| steps                   | 108897   |
| td_erros                | 0.3318   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 13300    |
| lives                   | 13300    |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 8        |
| mean 100 episode reward | 2.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9083   |
| steps                   | 109597   |
| td_erros                | 0.3112   |
--------------------------------------
Saving model due to mean reward increase: 1.3977 -> 2.0987
Saving model due to running mean reward increase: 2.0589 -> 2.0987
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 13400    |
| lives                   | 13400    |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 8.04     |
| mean 100 episode reward | 1.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8995   |
| steps                   | 110301   |
| td_erros                | 0.2883   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 13500    |
| lives                   | 13500    |
| mean 100 episode ei     | 4.77     |
| mean 100 episode length | 8.6      |
| mean 100 episode reward | 1.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8759   |
| steps                   | 111061   |
| td_erros                | 0.2923   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 77       |
| episodes                | 13600    |
| lives                   | 13600    |
| mean 100 episode ei     | 4.43     |
| mean 100 episode length | 8.58     |
| mean 100 episode reward | 1.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8099   |
| steps                   | 111819   |
| td_erros                | 0.2464   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 77       |
| episodes                | 13700    |
| lives                   | 13700    |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 7.73     |
| mean 100 episode reward | 2.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8303   |
| steps                   | 112492   |
| td_erros                | 0.3022   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 77       |
| episodes                | 13800    |
| lives                   | 13800    |
| mean 100 episode ei     | 5.1      |
| mean 100 episode length | 8.98     |
| mean 100 episode reward | 2.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8109   |
| steps                   | 113290   |
| td_erros                | 0.2502   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 77       |
| episodes                | 13900    |
| lives                   | 13900    |
| mean 100 episode ei     | 4.61     |
| mean 100 episode length | 8.51     |
| mean 100 episode reward | 2.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8544   |
| steps                   | 114041   |
| td_erros                | 0.3131   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 77       |
| episodes                | 14000    |
| lives                   | 14000    |
| mean 100 episode ei     | 4.7      |
| mean 100 episode length | 8.75     |
| mean 100 episode reward | 1.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9372   |
| steps                   | 114816   |
| td_erros                | 0.3469   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 77       |
| episodes                | 14100    |
| lives                   | 14100    |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 8.65     |
| mean 100 episode reward | 1.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9755   |
| steps                   | 115581   |
| td_erros                | 0.3846   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 14200    |
| lives                   | 14200    |
| mean 100 episode ei     | 5        |
| mean 100 episode length | 9.38     |
| mean 100 episode reward | 1.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0143   |
| steps                   | 116419   |
| td_erros                | 0.4009   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 14300    |
| lives                   | 14300    |
| mean 100 episode ei     | 4.36     |
| mean 100 episode length | 8.49     |
| mean 100 episode reward | 1.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1199   |
| steps                   | 117168   |
| td_erros                | 0.4148   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 14400    |
| lives                   | 14400    |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 8.49     |
| mean 100 episode reward | 1.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.134    |
| steps                   | 117917   |
| td_erros                | 0.4315   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 14500    |
| lives                   | 14500    |
| mean 100 episode ei     | 4.46     |
| mean 100 episode length | 8.32     |
| mean 100 episode reward | 1.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0632   |
| steps                   | 118649   |
| td_erros                | 0.4407   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 14600    |
| lives                   | 14600    |
| mean 100 episode ei     | 4.84     |
| mean 100 episode length | 8.67     |
| mean 100 episode reward | 1.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0927   |
| steps                   | 119416   |
| td_erros                | 0.4577   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 14700    |
| lives                   | 14700    |
| mean 100 episode ei     | 5.02     |
| mean 100 episode length | 9.02     |
| mean 100 episode reward | 1.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0443   |
| steps                   | 120218   |
| td_erros                | 0.4337   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 14800    |
| lives                   | 14800    |
| mean 100 episode ei     | 4.71     |
| mean 100 episode length | 8.6      |
| mean 100 episode reward | 1.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0718   |
| steps                   | 120978   |
| td_erros                | 0.4352   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 14900    |
| lives                   | 14900    |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 8.34     |
| mean 100 episode reward | 1.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1713   |
| steps                   | 121712   |
| td_erros                | 0.4643   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 15000    |
| lives                   | 15000    |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 8.5      |
| mean 100 episode reward | 1.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1419   |
| steps                   | 122462   |
| td_erros                | 0.4575   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 15100    |
| lives                   | 15100    |
| mean 100 episode ei     | 4.7      |
| mean 100 episode length | 8.74     |
| mean 100 episode reward | 1.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1384   |
| steps                   | 123236   |
| td_erros                | 0.4301   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 15200    |
| lives                   | 15200    |
| mean 100 episode ei     | 4.83     |
| mean 100 episode length | 8.55     |
| mean 100 episode reward | 1.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0786   |
| steps                   | 123991   |
| td_erros                | 0.3987   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 15300    |
| lives                   | 15300    |
| mean 100 episode ei     | 4.23     |
| mean 100 episode length | 8.52     |
| mean 100 episode reward | 1.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0546   |
| steps                   | 124743   |
| td_erros                | 0.3871   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 15400    |
| lives                   | 15400    |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 8.88     |
| mean 100 episode reward | 1.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9717   |
| steps                   | 125531   |
| td_erros                | 0.332    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 15500    |
| lives                   | 15500    |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 7.83     |
| mean 100 episode reward | 1.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8766   |
| steps                   | 126214   |
| td_erros                | 0.3482   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 15600    |
| lives                   | 15600    |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 8.04     |
| mean 100 episode reward | 2.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8095   |
| steps                   | 126918   |
| td_erros                | 0.3369   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 15700    |
| lives                   | 15700    |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 8.39     |
| mean 100 episode reward | 2.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6957   |
| steps                   | 127657   |
| td_erros                | 0.2731   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 15800    |
| lives                   | 15800    |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 8.52     |
| mean 100 episode reward | 1.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6172   |
| steps                   | 128409   |
| td_erros                | 0.2918   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 15900    |
| lives                   | 15900    |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 8.2      |
| mean 100 episode reward | 1.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5885   |
| steps                   | 129129   |
| td_erros                | 0.2698   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 16000    |
| lives                   | 16000    |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 7.86     |
| mean 100 episode reward | 2        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5889   |
| steps                   | 129815   |
| td_erros                | 0.2911   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 16100    |
| lives                   | 16100    |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 8.14     |
| mean 100 episode reward | 1.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6032   |
| steps                   | 130529   |
| td_erros                | 0.3182   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 16200    |
| lives                   | 16200    |
| mean 100 episode ei     | 4.84     |
| mean 100 episode length | 8.4      |
| mean 100 episode reward | 1.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5999   |
| steps                   | 131269   |
| td_erros                | 0.3415   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 16300    |
| lives                   | 16300    |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 8.56     |
| mean 100 episode reward | 1        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6174   |
| steps                   | 132025   |
| td_erros                | 0.3544   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 16400    |
| lives                   | 16400    |
| mean 100 episode ei     | 4.43     |
| mean 100 episode length | 8.79     |
| mean 100 episode reward | 1.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6096   |
| steps                   | 132804   |
| td_erros                | 0.331    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 16500    |
| lives                   | 16500    |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 8.51     |
| mean 100 episode reward | 2.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6414   |
| steps                   | 133555   |
| td_erros                | 0.3241   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 16600    |
| lives                   | 16600    |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 8.5      |
| mean 100 episode reward | 1.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6009   |
| steps                   | 134305   |
| td_erros                | 0.2989   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 16700    |
| lives                   | 16700    |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 7.88     |
| mean 100 episode reward | 1.96     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5428   |
| steps                   | 134993   |
| td_erros                | 0.2731   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 16800    |
| lives                   | 16800    |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 8.44     |
| mean 100 episode reward | 1.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6209   |
| steps                   | 135737   |
| td_erros                | 0.2973   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 16900    |
| lives                   | 16900    |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 7.44     |
| mean 100 episode reward | 1.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6739   |
| steps                   | 136381   |
| td_erros                | 0.3323   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 17000    |
| lives                   | 17000    |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 7.97     |
| mean 100 episode reward | 1.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6806   |
| steps                   | 137078   |
| td_erros                | 0.3589   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 17100    |
| lives                   | 17100    |
| mean 100 episode ei     | 4.52     |
| mean 100 episode length | 8.54     |
| mean 100 episode reward | 1.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6126   |
| steps                   | 137832   |
| td_erros                | 0.3441   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 17200    |
| lives                   | 17200    |
| mean 100 episode ei     | 4.39     |
| mean 100 episode length | 8.28     |
| mean 100 episode reward | 1.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6154   |
| steps                   | 138560   |
| td_erros                | 0.3357   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 17300    |
| lives                   | 17300    |
| mean 100 episode ei     | 4.76     |
| mean 100 episode length | 8.82     |
| mean 100 episode reward | 1.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5786   |
| steps                   | 139342   |
| td_erros                | 0.3227   |
--------------------------------------
Saving model due to running mean reward increase: 1.4194 -> 1.9114
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 17400    |
| lives                   | 17400    |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 8.4      |
| mean 100 episode reward | 1.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5755   |
| steps                   | 140082   |
| td_erros                | 0.2808   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 17500    |
| lives                   | 17500    |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 7.8      |
| mean 100 episode reward | 1.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7028   |
| steps                   | 140762   |
| td_erros                | 0.3347   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 17600    |
| lives                   | 17600    |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 7.98     |
| mean 100 episode reward | 2.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.65     |
| steps                   | 141460   |
| td_erros                | 0.3167   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 17700    |
| lives                   | 17700    |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 7.87     |
| mean 100 episode reward | 1.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5516   |
| steps                   | 142147   |
| td_erros                | 0.2667   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 17800    |
| lives                   | 17800    |
| mean 100 episode ei     | 4.48     |
| mean 100 episode length | 8.36     |
| mean 100 episode reward | 2.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5041   |
| steps                   | 142883   |
| td_erros                | 0.2685   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 17900    |
| lives                   | 17900    |
| mean 100 episode ei     | 4.47     |
| mean 100 episode length | 8.5      |
| mean 100 episode reward | 2.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.45     |
| steps                   | 143633   |
| td_erros                | 0.2571   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 18000    |
| lives                   | 18000    |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 8.01     |
| mean 100 episode reward | 1.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4749   |
| steps                   | 144334   |
| td_erros                | 0.2428   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 18100    |
| lives                   | 18100    |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 7.72     |
| mean 100 episode reward | 2.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4828   |
| steps                   | 145006   |
| td_erros                | 0.282    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 18200    |
| lives                   | 18200    |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 8.33     |
| mean 100 episode reward | 1.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4972   |
| steps                   | 145739   |
| td_erros                | 0.2772   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 18300    |
| lives                   | 18300    |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 7.95     |
| mean 100 episode reward | 1.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5073   |
| steps                   | 146434   |
| td_erros                | 0.3137   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 18400    |
| lives                   | 18400    |
| mean 100 episode ei     | 4.52     |
| mean 100 episode length | 8.04     |
| mean 100 episode reward | 2.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5348   |
| steps                   | 147138   |
| td_erros                | 0.323    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 18500    |
| lives                   | 18500    |
| mean 100 episode ei     | 4.72     |
| mean 100 episode length | 8.23     |
| mean 100 episode reward | 1.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5766   |
| steps                   | 147861   |
| td_erros                | 0.341    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 18600    |
| lives                   | 18600    |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 8.37     |
| mean 100 episode reward | 1.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6132   |
| steps                   | 148598   |
| td_erros                | 0.3498   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 18700    |
| lives                   | 18700    |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 8.12     |
| mean 100 episode reward | 1.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6566   |
| steps                   | 149310   |
| td_erros                | 0.3875   |
--------------------------------------
Saving model due to running mean reward increase: 1.4591 -> 1.7428
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 18800    |
| lives                   | 18800    |
| mean 100 episode ei     | 4.51     |
| mean 100 episode length | 8.35     |
| mean 100 episode reward | 1.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7342   |
| steps                   | 150045   |
| td_erros                | 0.4307   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 18900    |
| lives                   | 18900    |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 7.93     |
| mean 100 episode reward | 1.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8288   |
| steps                   | 150738   |
| td_erros                | 0.4342   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 19000    |
| lives                   | 19000    |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 7.99     |
| mean 100 episode reward | 1.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8567   |
| steps                   | 151437   |
| td_erros                | 0.4972   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 19100    |
| lives                   | 19100    |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 7.45     |
| mean 100 episode reward | 2.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8383   |
| steps                   | 152082   |
| td_erros                | 0.5099   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 19200    |
| lives                   | 19200    |
| mean 100 episode ei     | 4.45     |
| mean 100 episode length | 7.91     |
| mean 100 episode reward | 2.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8624   |
| steps                   | 152773   |
| td_erros                | 0.5028   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 19300    |
| lives                   | 19300    |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 7.95     |
| mean 100 episode reward | 1.69     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8276   |
| steps                   | 153468   |
| td_erros                | 0.5009   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 19400    |
| lives                   | 19400    |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 7.56     |
| mean 100 episode reward | 2.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7678   |
| steps                   | 154124   |
| td_erros                | 0.4858   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 19500    |
| lives                   | 19500    |
| mean 100 episode ei     | 5.13     |
| mean 100 episode length | 9.02     |
| mean 100 episode reward | 2.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.641    |
| steps                   | 154926   |
| td_erros                | 0.4384   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 19600    |
| lives                   | 19600    |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 7.84     |
| mean 100 episode reward | 1.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5623   |
| steps                   | 155610   |
| td_erros                | 0.3785   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 19700    |
| lives                   | 19700    |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 7.79     |
| mean 100 episode reward | 1.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4697   |
| steps                   | 156289   |
| td_erros                | 0.322    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 19800    |
| lives                   | 19800    |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 8.04     |
| mean 100 episode reward | 2.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3809   |
| steps                   | 156993   |
| td_erros                | 0.2981   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 19900    |
| lives                   | 19900    |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 7.74     |
| mean 100 episode reward | 2.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3173   |
| steps                   | 157667   |
| td_erros                | 0.3043   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 20000    |
| lives                   | 20000    |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 7.84     |
| mean 100 episode reward | 1.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2788   |
| steps                   | 158351   |
| td_erros                | 0.3055   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 20100    |
| lives                   | 20100    |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 8.3      |
| mean 100 episode reward | 1.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.28     |
| steps                   | 159081   |
| td_erros                | 0.3028   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 20200    |
| lives                   | 20200    |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 7.48     |
| mean 100 episode reward | 1.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3264   |
| steps                   | 159729   |
| td_erros                | 0.3303   |
--------------------------------------
Saving model due to mean reward increase: 2.0987 -> 2.4446
Saving model due to running mean reward increase: 1.479 -> 2.4446
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 20300    |
| lives                   | 20300    |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 6.84     |
| mean 100 episode reward | 2.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.365    |
| steps                   | 160313   |
| td_erros                | 0.3581   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 20400    |
| lives                   | 20400    |
| mean 100 episode ei     | 4.49     |
| mean 100 episode length | 8        |
| mean 100 episode reward | 2.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4005   |
| steps                   | 161013   |
| td_erros                | 0.3743   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 20500    |
| lives                   | 20500    |
| mean 100 episode ei     | 4.81     |
| mean 100 episode length | 8.12     |
| mean 100 episode reward | 2.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3078   |
| steps                   | 161725   |
| td_erros                | 0.2926   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 20600    |
| lives                   | 20600    |
| mean 100 episode ei     | 4.33     |
| mean 100 episode length | 8.05     |
| mean 100 episode reward | 1.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2433   |
| steps                   | 162430   |
| td_erros                | 0.263    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 20700    |
| lives                   | 20700    |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 8.44     |
| mean 100 episode reward | 1.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2473   |
| steps                   | 163174   |
| td_erros                | 0.2091   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 20800    |
| lives                   | 20800    |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 8.15     |
| mean 100 episode reward | 2.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2427   |
| steps                   | 163889   |
| td_erros                | 0.2273   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 20900    |
| lives                   | 20900    |
| mean 100 episode ei     | 4.46     |
| mean 100 episode length | 8.12     |
| mean 100 episode reward | 2.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3412   |
| steps                   | 164601   |
| td_erros                | 0.2723   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 21000    |
| lives                   | 21000    |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 7.9      |
| mean 100 episode reward | 1.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4805   |
| steps                   | 165291   |
| td_erros                | 0.3168   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 21100    |
| lives                   | 21100    |
| mean 100 episode ei     | 3.67     |
| mean 100 episode length | 7.61     |
| mean 100 episode reward | 1.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5411   |
| steps                   | 165952   |
| td_erros                | 0.3465   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 21200    |
| lives                   | 21200    |
| mean 100 episode ei     | 4.42     |
| mean 100 episode length | 8.04     |
| mean 100 episode reward | 1.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6151   |
| steps                   | 166656   |
| td_erros                | 0.3932   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 21300    |
| lives                   | 21300    |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 7.92     |
| mean 100 episode reward | 2.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6034   |
| steps                   | 167348   |
| td_erros                | 0.4213   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 21400    |
| lives                   | 21400    |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 7.99     |
| mean 100 episode reward | 2.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5738   |
| steps                   | 168047   |
| td_erros                | 0.4218   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 21500    |
| lives                   | 21500    |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 8.47     |
| mean 100 episode reward | 2.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.566    |
| steps                   | 168794   |
| td_erros                | 0.3961   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 21600    |
| lives                   | 21600    |
| mean 100 episode ei     | 4.46     |
| mean 100 episode length | 8.07     |
| mean 100 episode reward | 2.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.576    |
| steps                   | 169501   |
| td_erros                | 0.37     |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 21700    |
| lives                   | 21700    |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 7.69     |
| mean 100 episode reward | 1.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5523   |
| steps                   | 170170   |
| td_erros                | 0.3734   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 21800    |
| lives                   | 21800    |
| mean 100 episode ei     | 4.24     |
| mean 100 episode length | 7.59     |
| mean 100 episode reward | 2.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4949   |
| steps                   | 170829   |
| td_erros                | 0.3672   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 21900    |
| lives                   | 21900    |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 7.48     |
| mean 100 episode reward | 1.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.516    |
| steps                   | 171477   |
| td_erros                | 0.3658   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 22000    |
| lives                   | 22000    |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 7.92     |
| mean 100 episode reward | 2.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4818   |
| steps                   | 172169   |
| td_erros                | 0.3389   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 22100    |
| lives                   | 22100    |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 7.44     |
| mean 100 episode reward | 1.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4758   |
| steps                   | 172813   |
| td_erros                | 0.2981   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 22200    |
| lives                   | 22200    |
| mean 100 episode ei     | 4.88     |
| mean 100 episode length | 8.76     |
| mean 100 episode reward | 1.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4367   |
| steps                   | 173589   |
| td_erros                | 0.2763   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 22300    |
| lives                   | 22300    |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 7.79     |
| mean 100 episode reward | 2.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4119   |
| steps                   | 174268   |
| td_erros                | 0.2756   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 22400    |
| lives                   | 22400    |
| mean 100 episode ei     | 4.49     |
| mean 100 episode length | 7.85     |
| mean 100 episode reward | 2.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4114   |
| steps                   | 174953   |
| td_erros                | 0.2711   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 22500    |
| lives                   | 22500    |
| mean 100 episode ei     | 3.8      |
| mean 100 episode length | 7.64     |
| mean 100 episode reward | 2.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4205   |
| steps                   | 175617   |
| td_erros                | 0.2907   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 22600    |
| lives                   | 22600    |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 8.39     |
| mean 100 episode reward | 2.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4363   |
| steps                   | 176356   |
| td_erros                | 0.2942   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 22700    |
| lives                   | 22700    |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 7.51     |
| mean 100 episode reward | 2.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4728   |
| steps                   | 177007   |
| td_erros                | 0.2765   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 22800    |
| lives                   | 22800    |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 8.03     |
| mean 100 episode reward | 1.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4547   |
| steps                   | 177710   |
| td_erros                | 0.296    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 22900    |
| lives                   | 22900    |
| mean 100 episode ei     | 4.7      |
| mean 100 episode length | 8.81     |
| mean 100 episode reward | 2.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4709   |
| steps                   | 178491   |
| td_erros                | 0.2757   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 23000    |
| lives                   | 23000    |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 7.64     |
| mean 100 episode reward | 2.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5062   |
| steps                   | 179155   |
| td_erros                | 0.3026   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 23100    |
| lives                   | 23100    |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 7.33     |
| mean 100 episode reward | 2.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5241   |
| steps                   | 179788   |
| td_erros                | 0.3085   |
--------------------------------------
Saving model due to running mean reward increase: 2.2403 -> 2.3021
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 23200    |
| lives                   | 23200    |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 7.51     |
| mean 100 episode reward | 1.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4917   |
| steps                   | 180439   |
| td_erros                | 0.2991   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 23300    |
| lives                   | 23300    |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 7.87     |
| mean 100 episode reward | 1.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.411    |
| steps                   | 181126   |
| td_erros                | 0.2461   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 23400    |
| lives                   | 23400    |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 7.88     |
| mean 100 episode reward | 1.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3276   |
| steps                   | 181814   |
| td_erros                | 0.2198   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 23500    |
| lives                   | 23500    |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 7.75     |
| mean 100 episode reward | 2.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2659   |
| steps                   | 182489   |
| td_erros                | 0.21     |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 23600    |
| lives                   | 23600    |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 8.55     |
| mean 100 episode reward | 2.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1841   |
| steps                   | 183244   |
| td_erros                | 0.189    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 23700    |
| lives                   | 23700    |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 7.48     |
| mean 100 episode reward | 2.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1317   |
| steps                   | 183892   |
| td_erros                | 0.1642   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 23800    |
| lives                   | 23800    |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 7.94     |
| mean 100 episode reward | 2.69     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0549   |
| steps                   | 184586   |
| td_erros                | 0.1237   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 23900    |
| lives                   | 23900    |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 6.52     |
| mean 100 episode reward | 2.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0106   |
| steps                   | 185138   |
| td_erros                | 0.1196   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 24000    |
| lives                   | 24000    |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 6.96     |
| mean 100 episode reward | 2.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0334   |
| steps                   | 185734   |
| td_erros                | 0.1523   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 24100    |
| lives                   | 24100    |
| mean 100 episode ei     | 5.11     |
| mean 100 episode length | 8.2      |
| mean 100 episode reward | 1.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0776   |
| steps                   | 186454   |
| td_erros                | 0.1736   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 24200    |
| lives                   | 24200    |
| mean 100 episode ei     | 4.77     |
| mean 100 episode length | 8.15     |
| mean 100 episode reward | 1.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1956   |
| steps                   | 187169   |
| td_erros                | 0.1739   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 24300    |
| lives                   | 24300    |
| mean 100 episode ei     | 3.52     |
| mean 100 episode length | 6.93     |
| mean 100 episode reward | 2.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3086   |
| steps                   | 187762   |
| td_erros                | 0.2365   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 24400    |
| lives                   | 24400    |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 7.98     |
| mean 100 episode reward | 1.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4103   |
| steps                   | 188460   |
| td_erros                | 0.2635   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 24500    |
| lives                   | 24500    |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 7.61     |
| mean 100 episode reward | 2.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4609   |
| steps                   | 189121   |
| td_erros                | 0.2808   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 24600    |
| lives                   | 24600    |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 8.31     |
| mean 100 episode reward | 1.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4294   |
| steps                   | 189852   |
| td_erros                | 0.2764   |
--------------------------------------
Saving model due to running mean reward increase: 1.979 -> 2.0202
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 24700    |
| lives                   | 24700    |
| mean 100 episode ei     | 3.67     |
| mean 100 episode length | 7.66     |
| mean 100 episode reward | 1.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3619   |
| steps                   | 190518   |
| td_erros                | 0.2189   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 24800    |
| lives                   | 24800    |
| mean 100 episode ei     | 3.68     |
| mean 100 episode length | 7.93     |
| mean 100 episode reward | 1.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2552   |
| steps                   | 191211   |
| td_erros                | 0.1827   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 24900    |
| lives                   | 24900    |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 7.71     |
| mean 100 episode reward | 2.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1441   |
| steps                   | 191882   |
| td_erros                | 0.1654   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 25000    |
| lives                   | 25000    |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 7.76     |
| mean 100 episode reward | 2.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0922   |
| steps                   | 192558   |
| td_erros                | 0.1434   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 25100    |
| lives                   | 25100    |
| mean 100 episode ei     | 3.15     |
| mean 100 episode length | 6.26     |
| mean 100 episode reward | 2.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0271   |
| steps                   | 193084   |
| td_erros                | 0.1379   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 25200    |
| lives                   | 25200    |
| mean 100 episode ei     | 3.66     |
| mean 100 episode length | 7.01     |
| mean 100 episode reward | 2.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0124   |
| steps                   | 193685   |
| td_erros                | 0.1681   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 25300    |
| lives                   | 25300    |
| mean 100 episode ei     | 3.64     |
| mean 100 episode length | 7.13     |
| mean 100 episode reward | 2.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9515   |
| steps                   | 194298   |
| td_erros                | 0.1656   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 25400    |
| lives                   | 25400    |
| mean 100 episode ei     | 4.23     |
| mean 100 episode length | 8.01     |
| mean 100 episode reward | 2.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8868   |
| steps                   | 194999   |
| td_erros                | 0.1376   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 25500    |
| lives                   | 25500    |
| mean 100 episode ei     | 4.33     |
| mean 100 episode length | 7.99     |
| mean 100 episode reward | 1.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.843    |
| steps                   | 195698   |
| td_erros                | 0.0885   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 25600    |
| lives                   | 25600    |
| mean 100 episode ei     | 5.02     |
| mean 100 episode length | 8.04     |
| mean 100 episode reward | 2.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.825    |
| steps                   | 196402   |
| td_erros                | 0.076    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 25700    |
| lives                   | 25700    |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 7.79     |
| mean 100 episode reward | 2.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8272   |
| steps                   | 197081   |
| td_erros                | 0.0637   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 25800    |
| lives                   | 25800    |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 7.89     |
| mean 100 episode reward | 1.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8559   |
| steps                   | 197770   |
| td_erros                | 0.0728   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 25900    |
| lives                   | 25900    |
| mean 100 episode ei     | 4.45     |
| mean 100 episode length | 7.86     |
| mean 100 episode reward | 1.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8428   |
| steps                   | 198456   |
| td_erros                | 0.0433   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 26000    |
| lives                   | 26000    |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 8.12     |
| mean 100 episode reward | 1.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8402   |
| steps                   | 199168   |
| td_erros                | 0.0356   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 26100    |
| lives                   | 26100    |
| mean 100 episode ei     | 3.55     |
| mean 100 episode length | 7.28     |
| mean 100 episode reward | 2.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8964   |
| steps                   | 199796   |
| td_erros                | 0.042    |
--------------------------------------
Saving model due to mean reward increase: 2.4446 -> 2.4852
Saving model due to running mean reward increase: 1.8688 -> 2.4852
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 26200    |
| lives                   | 26200    |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 7.53     |
| mean 100 episode reward | 2.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.921    |
| steps                   | 200449   |
| td_erros                | 0.0853   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 26300    |
| lives                   | 26300    |
| mean 100 episode ei     | 3.57     |
| mean 100 episode length | 7.29     |
| mean 100 episode reward | 1.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9498   |
| steps                   | 201078   |
| td_erros                | 0.0886   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 26400    |
| lives                   | 26400    |
| mean 100 episode ei     | 3.54     |
| mean 100 episode length | 6.82     |
| mean 100 episode reward | 2.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9836   |
| steps                   | 201660   |
| td_erros                | 0.1471   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 26500    |
| lives                   | 26500    |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 7.53     |
| mean 100 episode reward | 2.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9365   |
| steps                   | 202313   |
| td_erros                | 0.1134   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 26600    |
| lives                   | 26600    |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 7.33     |
| mean 100 episode reward | 2.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9409   |
| steps                   | 202946   |
| td_erros                | 0.1586   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 26700    |
| lives                   | 26700    |
| mean 100 episode ei     | 4.49     |
| mean 100 episode length | 7.44     |
| mean 100 episode reward | 2.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9533   |
| steps                   | 203590   |
| td_erros                | 0.1526   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 26800    |
| lives                   | 26800    |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 7.26     |
| mean 100 episode reward | 2        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9391   |
| steps                   | 204216   |
| td_erros                | 0.1677   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 26900    |
| lives                   | 26900    |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 7.56     |
| mean 100 episode reward | 2.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9189   |
| steps                   | 204872   |
| td_erros                | 0.1506   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 27000    |
| lives                   | 27000    |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 7.26     |
| mean 100 episode reward | 1.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9537   |
| steps                   | 205498   |
| td_erros                | 0.1414   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 27100    |
| lives                   | 27100    |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 7.89     |
| mean 100 episode reward | 2.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9663   |
| steps                   | 206187   |
| td_erros                | 0.1308   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 27200    |
| lives                   | 27200    |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 7.22     |
| mean 100 episode reward | 2.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9606   |
| steps                   | 206809   |
| td_erros                | 0.1025   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 27300    |
| lives                   | 27300    |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 7.3      |
| mean 100 episode reward | 2.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9556   |
| steps                   | 207439   |
| td_erros                | 0.0957   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 27400    |
| lives                   | 27400    |
| mean 100 episode ei     | 3.83     |
| mean 100 episode length | 6.93     |
| mean 100 episode reward | 2.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9991   |
| steps                   | 208032   |
| td_erros                | 0.1346   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 27500    |
| lives                   | 27500    |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 7.41     |
| mean 100 episode reward | 2.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9668   |
| steps                   | 208673   |
| td_erros                | 0.1612   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 27600    |
| lives                   | 27600    |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 7.92     |
| mean 100 episode reward | 2.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9125   |
| steps                   | 209365   |
| td_erros                | 0.1169   |
--------------------------------------
Saving model due to mean reward increase: 2.4852 -> 2.6038
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 27700    |
| lives                   | 27700    |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 8.28     |
| mean 100 episode reward | 2.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8749   |
| steps                   | 210093   |
| td_erros                | 0.1156   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 27800    |
| lives                   | 27800    |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 7.77     |
| mean 100 episode reward | 2.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8436   |
| steps                   | 210770   |
| td_erros                | 0.1067   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 27900    |
| lives                   | 27900    |
| mean 100 episode ei     | 4.48     |
| mean 100 episode length | 7.44     |
| mean 100 episode reward | 2.57     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8527   |
| steps                   | 211414   |
| td_erros                | 0.1127   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 28000    |
| lives                   | 28000    |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 7.42     |
| mean 100 episode reward | 2.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8771   |
| steps                   | 212056   |
| td_erros                | 0.1122   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 28100    |
| lives                   | 28100    |
| mean 100 episode ei     | 4.73     |
| mean 100 episode length | 8.07     |
| mean 100 episode reward | 1.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.932    |
| steps                   | 212763   |
| td_erros                | 0.1166   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 28200    |
| lives                   | 28200    |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 7.52     |
| mean 100 episode reward | 2.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0019   |
| steps                   | 213415   |
| td_erros                | 0.0871   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 28300    |
| lives                   | 28300    |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 7.86     |
| mean 100 episode reward | 2.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0155   |
| steps                   | 214101   |
| td_erros                | 0.0983   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 28400    |
| lives                   | 28400    |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 6.92     |
| mean 100 episode reward | 2.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0507   |
| steps                   | 214693   |
| td_erros                | 0.1081   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 28500    |
| lives                   | 28500    |
| mean 100 episode ei     | 3.74     |
| mean 100 episode length | 7.06     |
| mean 100 episode reward | 3.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0709   |
| steps                   | 215299   |
| td_erros                | 0.148    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 28600    |
| lives                   | 28600    |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 7.74     |
| mean 100 episode reward | 2.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0633   |
| steps                   | 215973   |
| td_erros                | 0.1477   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 28700    |
| lives                   | 28700    |
| mean 100 episode ei     | 3.79     |
| mean 100 episode length | 7.8      |
| mean 100 episode reward | 2.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0574   |
| steps                   | 216653   |
| td_erros                | 0.1562   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 28800    |
| lives                   | 28800    |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 7.8      |
| mean 100 episode reward | 2.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9614   |
| steps                   | 217333   |
| td_erros                | 0.1332   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 28900    |
| lives                   | 28900    |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 7.37     |
| mean 100 episode reward | 2.96     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9162   |
| steps                   | 217970   |
| td_erros                | 0.1301   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 29000    |
| lives                   | 29000    |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 7.19     |
| mean 100 episode reward | 2.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9217   |
| steps                   | 218589   |
| td_erros                | 0.1454   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 29100    |
| lives                   | 29100    |
| mean 100 episode ei     | 4.52     |
| mean 100 episode length | 7.66     |
| mean 100 episode reward | 2.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8597   |
| steps                   | 219255   |
| td_erros                | 0.1255   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 29200    |
| lives                   | 29200    |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 7.21     |
| mean 100 episode reward | 2.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8488   |
| steps                   | 219876   |
| td_erros                | 0.0854   |
--------------------------------------
Saving model due to mean reward increase: 2.6038 -> 2.6923
Saving model due to running mean reward increase: 2.2624 -> 2.6923
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 29300    |
| lives                   | 29300    |
| mean 100 episode ei     | 3.79     |
| mean 100 episode length | 6.88     |
| mean 100 episode reward | 2.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9129   |
| steps                   | 220464   |
| td_erros                | 0.1339   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 29400    |
| lives                   | 29400    |
| mean 100 episode ei     | 3.74     |
| mean 100 episode length | 7.45     |
| mean 100 episode reward | 2.57     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9002   |
| steps                   | 221109   |
| td_erros                | 0.1314   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 29500    |
| lives                   | 29500    |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 7.91     |
| mean 100 episode reward | 2.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9073   |
| steps                   | 221800   |
| td_erros                | 0.1314   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 29600    |
| lives                   | 29600    |
| mean 100 episode ei     | 3.16     |
| mean 100 episode length | 6.75     |
| mean 100 episode reward | 2.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8998   |
| steps                   | 222375   |
| td_erros                | 0.1188   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 29700    |
| lives                   | 29700    |
| mean 100 episode ei     | 3.79     |
| mean 100 episode length | 7.42     |
| mean 100 episode reward | 2.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8311   |
| steps                   | 223017   |
| td_erros                | 0.0947   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 29800    |
| lives                   | 29800    |
| mean 100 episode ei     | 3.6      |
| mean 100 episode length | 7.07     |
| mean 100 episode reward | 2.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.706    |
| steps                   | 223624   |
| td_erros                | 0.055    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 29900    |
| lives                   | 29900    |
| mean 100 episode ei     | 3.38     |
| mean 100 episode length | 6.79     |
| mean 100 episode reward | 2.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6331   |
| steps                   | 224203   |
| td_erros                | 0.0698   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 30000    |
| lives                   | 30000    |
| mean 100 episode ei     | 3.65     |
| mean 100 episode length | 6.76     |
| mean 100 episode reward | 1.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.514    |
| steps                   | 224779   |
| td_erros                | 0.038    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 30100    |
| lives                   | 30100    |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 7.03     |
| mean 100 episode reward | 2.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.44     |
| steps                   | 225382   |
| td_erros                | 0.0088   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 30200    |
| lives                   | 30200    |
| mean 100 episode ei     | 3.33     |
| mean 100 episode length | 6.58     |
| mean 100 episode reward | 1.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3723   |
| steps                   | 225940   |
| td_erros                | 0.0063   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 30300    |
| lives                   | 30300    |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 7.26     |
| mean 100 episode reward | 2.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3774   |
| steps                   | 226566   |
| td_erros                | 0.0288   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 30400    |
| lives                   | 30400    |
| mean 100 episode ei     | 3.54     |
| mean 100 episode length | 6.91     |
| mean 100 episode reward | 2.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3844   |
| steps                   | 227157   |
| td_erros                | 0.0549   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 30500    |
| lives                   | 30500    |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 7.47     |
| mean 100 episode reward | 2.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4665   |
| steps                   | 227804   |
| td_erros                | 0.0728   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 30600    |
| lives                   | 30600    |
| mean 100 episode ei     | 3.53     |
| mean 100 episode length | 6.83     |
| mean 100 episode reward | 2.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5181   |
| steps                   | 228387   |
| td_erros                | 0.0893   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 30700    |
| lives                   | 30700    |
| mean 100 episode ei     | 3.58     |
| mean 100 episode length | 6.78     |
| mean 100 episode reward | 2.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6257   |
| steps                   | 228965   |
| td_erros                | 0.1272   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 30800    |
| lives                   | 30800    |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 7.1      |
| mean 100 episode reward | 2.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7157   |
| steps                   | 229575   |
| td_erros                | 0.1495   |
--------------------------------------
Saving model due to mean reward increase: 2.6923 -> 2.8932
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 30900    |
| lives                   | 30900    |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 6.73     |
| mean 100 episode reward | 3.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7704   |
| steps                   | 230148   |
| td_erros                | 0.1893   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 31000    |
| lives                   | 31000    |
| mean 100 episode ei     | 3.69     |
| mean 100 episode length | 6.73     |
| mean 100 episode reward | 2.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7765   |
| steps                   | 230721   |
| td_erros                | 0.1852   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 31100    |
| lives                   | 31100    |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 7.17     |
| mean 100 episode reward | 2.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7888   |
| steps                   | 231338   |
| td_erros                | 0.19     |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 31200    |
| lives                   | 31200    |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 7.16     |
| mean 100 episode reward | 2.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8105   |
| steps                   | 231954   |
| td_erros                | 0.1873   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 31300    |
| lives                   | 31300    |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 7.31     |
| mean 100 episode reward | 2.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8511   |
| steps                   | 232585   |
| td_erros                | 0.1326   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 31400    |
| lives                   | 31400    |
| mean 100 episode ei     | 3.47     |
| mean 100 episode length | 6.74     |
| mean 100 episode reward | 1.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.808    |
| steps                   | 233159   |
| td_erros                | 0.1263   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 31500    |
| lives                   | 31500    |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 7.16     |
| mean 100 episode reward | 2.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7738   |
| steps                   | 233775   |
| td_erros                | 0.0827   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 31600    |
| lives                   | 31600    |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 7.3      |
| mean 100 episode reward | 2.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7478   |
| steps                   | 234405   |
| td_erros                | 0.0463   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 31700    |
| lives                   | 31700    |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 7.36     |
| mean 100 episode reward | 2.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.767    |
| steps                   | 235041   |
| td_erros                | 0.075    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 31800    |
| lives                   | 31800    |
| mean 100 episode ei     | 4.42     |
| mean 100 episode length | 7.63     |
| mean 100 episode reward | 3.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7101   |
| steps                   | 235704   |
| td_erros                | 0.0623   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 31900    |
| lives                   | 31900    |
| mean 100 episode ei     | 4.41     |
| mean 100 episode length | 7.83     |
| mean 100 episode reward | 2.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6899   |
| steps                   | 236387   |
| td_erros                | 0.0437   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 32000    |
| lives                   | 32000    |
| mean 100 episode ei     | 3.79     |
| mean 100 episode length | 7.12     |
| mean 100 episode reward | 2.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6646   |
| steps                   | 236999   |
| td_erros                | 0.0486   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 32100    |
| lives                   | 32100    |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 6.99     |
| mean 100 episode reward | 3.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7097   |
| steps                   | 237598   |
| td_erros                | 0.0651   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 32200    |
| lives                   | 32200    |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 7.65     |
| mean 100 episode reward | 2.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6939   |
| steps                   | 238263   |
| td_erros                | 0.0953   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 32300    |
| lives                   | 32300    |
| mean 100 episode ei     | 4.41     |
| mean 100 episode length | 7.33     |
| mean 100 episode reward | 2.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7301   |
| steps                   | 238896   |
| td_erros                | 0.1076   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 32400    |
| lives                   | 32400    |
| mean 100 episode ei     | 3.61     |
| mean 100 episode length | 6.51     |
| mean 100 episode reward | 2.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7583   |
| steps                   | 239447   |
| td_erros                | 0.1251   |
--------------------------------------
Saving model due to running mean reward increase: 2.4924 -> 2.5682
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 32500    |
| lives                   | 32500    |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 6.78     |
| mean 100 episode reward | 2.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8245   |
| steps                   | 240025   |
| td_erros                | 0.1488   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 32600    |
| lives                   | 32600    |
| mean 100 episode ei     | 3.74     |
| mean 100 episode length | 7.14     |
| mean 100 episode reward | 2        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8763   |
| steps                   | 240639   |
| td_erros                | 0.1608   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 32700    |
| lives                   | 32700    |
| mean 100 episode ei     | 3.6      |
| mean 100 episode length | 6.96     |
| mean 100 episode reward | 1.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9339   |
| steps                   | 241235   |
| td_erros                | 0.1924   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 32800    |
| lives                   | 32800    |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 7.45     |
| mean 100 episode reward | 2.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8677   |
| steps                   | 241880   |
| td_erros                | 0.1496   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 32900    |
| lives                   | 32900    |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 7.8      |
| mean 100 episode reward | 3.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7891   |
| steps                   | 242560   |
| td_erros                | 0.1106   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 33000    |
| lives                   | 33000    |
| mean 100 episode ei     | 3.65     |
| mean 100 episode length | 7.24     |
| mean 100 episode reward | 2.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7661   |
| steps                   | 243184   |
| td_erros                | 0.0826   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 33100    |
| lives                   | 33100    |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 7.19     |
| mean 100 episode reward | 2.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7057   |
| steps                   | 243803   |
| td_erros                | 0.0706   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 33200    |
| lives                   | 33200    |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 7.05     |
| mean 100 episode reward | 2.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6301   |
| steps                   | 244408   |
| td_erros                | 0.0441   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 33300    |
| lives                   | 33300    |
| mean 100 episode ei     | 3.83     |
| mean 100 episode length | 6.31     |
| mean 100 episode reward | 2.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6293   |
| steps                   | 244939   |
| td_erros                | 0.0519   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 33400    |
| lives                   | 33400    |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 6.81     |
| mean 100 episode reward | 2.57     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5554   |
| steps                   | 245520   |
| td_erros                | 0.0586   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 33500    |
| lives                   | 33500    |
| mean 100 episode ei     | 3.53     |
| mean 100 episode length | 6.67     |
| mean 100 episode reward | 2.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5291   |
| steps                   | 246087   |
| td_erros                | 0.029    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 33600    |
| lives                   | 33600    |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 7.1      |
| mean 100 episode reward | 2.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4976   |
| steps                   | 246697   |
| td_erros                | 0.0222   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 33700    |
| lives                   | 33700    |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 7.99     |
| mean 100 episode reward | 3.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4403   |
| steps                   | 247396   |
| td_erros                | -0.0151  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 33800    |
| lives                   | 33800    |
| mean 100 episode ei     | 3.47     |
| mean 100 episode length | 6.84     |
| mean 100 episode reward | 3        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3929   |
| steps                   | 247980   |
| td_erros                | -0.0168  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 33900    |
| lives                   | 33900    |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 7.55     |
| mean 100 episode reward | 3.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4176   |
| steps                   | 248635   |
| td_erros                | -0.0147  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 34000    |
| lives                   | 34000    |
| mean 100 episode ei     | 4.33     |
| mean 100 episode length | 7.21     |
| mean 100 episode reward | 3.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4862   |
| steps                   | 249256   |
| td_erros                | -0.0107  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 34100    |
| lives                   | 34100    |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 7.37     |
| mean 100 episode reward | 2.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5182   |
| steps                   | 249893   |
| td_erros                | 0.0008   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 34200    |
| lives                   | 34200    |
| mean 100 episode ei     | 4.83     |
| mean 100 episode length | 7.78     |
| mean 100 episode reward | 3.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6111   |
| steps                   | 250571   |
| td_erros                | 0.0004   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 34300    |
| lives                   | 34300    |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 7.47     |
| mean 100 episode reward | 2.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6327   |
| steps                   | 251218   |
| td_erros                | -0.0024  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 34400    |
| lives                   | 34400    |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 6.88     |
| mean 100 episode reward | 2.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6156   |
| steps                   | 251806   |
| td_erros                | -0.0254  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 34500    |
| lives                   | 34500    |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 7.1      |
| mean 100 episode reward | 2.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6259   |
| steps                   | 252416   |
| td_erros                | -0.0384  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 34600    |
| lives                   | 34600    |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 7.5      |
| mean 100 episode reward | 2.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5791   |
| steps                   | 253066   |
| td_erros                | -0.0483  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 34700    |
| lives                   | 34700    |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 7.11     |
| mean 100 episode reward | 3.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5577   |
| steps                   | 253677   |
| td_erros                | -0.0563  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 34800    |
| lives                   | 34800    |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 6.55     |
| mean 100 episode reward | 3.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5602   |
| steps                   | 254232   |
| td_erros                | -0.043   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 34900    |
| lives                   | 34900    |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 6.93     |
| mean 100 episode reward | 3.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5267   |
| steps                   | 254825   |
| td_erros                | -0.0515  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 35000    |
| lives                   | 35000    |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 7.09     |
| mean 100 episode reward | 2.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5404   |
| steps                   | 255434   |
| td_erros                | -0.0403  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 35100    |
| lives                   | 35100    |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 7.29     |
| mean 100 episode reward | 2.69     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5728   |
| steps                   | 256063   |
| td_erros                | -0.0156  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 35200    |
| lives                   | 35200    |
| mean 100 episode ei     | 4.36     |
| mean 100 episode length | 7.74     |
| mean 100 episode reward | 2.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5531   |
| steps                   | 256737   |
| td_erros                | -0.0073  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 35300    |
| lives                   | 35300    |
| mean 100 episode ei     | 4.81     |
| mean 100 episode length | 8.19     |
| mean 100 episode reward | 3.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5606   |
| steps                   | 257456   |
| td_erros                | -0.0187  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 35400    |
| lives                   | 35400    |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 7.28     |
| mean 100 episode reward | 2.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5806   |
| steps                   | 258084   |
| td_erros                | -0.0083  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 35500    |
| lives                   | 35500    |
| mean 100 episode ei     | 3.74     |
| mean 100 episode length | 6.95     |
| mean 100 episode reward | 2.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5508   |
| steps                   | 258679   |
| td_erros                | -0.0257  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 35600    |
| lives                   | 35600    |
| mean 100 episode ei     | 3.43     |
| mean 100 episode length | 6.67     |
| mean 100 episode reward | 3.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5143   |
| steps                   | 259246   |
| td_erros                | -0.0286  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 35700    |
| lives                   | 35700    |
| mean 100 episode ei     | 3.57     |
| mean 100 episode length | 7.03     |
| mean 100 episode reward | 3.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4687   |
| steps                   | 259849   |
| td_erros                | -0.0367  |
--------------------------------------
Saving model due to mean reward increase: 2.8932 -> 3.5682
Saving model due to running mean reward increase: 3.4772 -> 3.5682
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 35800    |
| lives                   | 35800    |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 7.25     |
| mean 100 episode reward | 3.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4067   |
| steps                   | 260474   |
| td_erros                | -0.0532  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 35900    |
| lives                   | 35900    |
| mean 100 episode ei     | 3.8      |
| mean 100 episode length | 7.64     |
| mean 100 episode reward | 3.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3582   |
| steps                   | 261138   |
| td_erros                | -0.0963  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 36000    |
| lives                   | 36000    |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 7.85     |
| mean 100 episode reward | 2.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2858   |
| steps                   | 261823   |
| td_erros                | -0.109   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 36100    |
| lives                   | 36100    |
| mean 100 episode ei     | 3.83     |
| mean 100 episode length | 6.88     |
| mean 100 episode reward | 2.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2359   |
| steps                   | 262411   |
| td_erros                | -0.1128  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 36200    |
| lives                   | 36200    |
| mean 100 episode ei     | 4.43     |
| mean 100 episode length | 7.2      |
| mean 100 episode reward | 3.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2295   |
| steps                   | 263031   |
| td_erros                | -0.1032  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 36300    |
| lives                   | 36300    |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 6.83     |
| mean 100 episode reward | 3.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2309   |
| steps                   | 263614   |
| td_erros                | -0.1192  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 36400    |
| lives                   | 36400    |
| mean 100 episode ei     | 4.48     |
| mean 100 episode length | 7.74     |
| mean 100 episode reward | 2.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2788   |
| steps                   | 264288   |
| td_erros                | -0.0924  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 36500    |
| lives                   | 36500    |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 6.37     |
| mean 100 episode reward | 2.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3234   |
| steps                   | 264825   |
| td_erros                | -0.0833  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 36600    |
| lives                   | 36600    |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 6.97     |
| mean 100 episode reward | 2.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3845   |
| steps                   | 265422   |
| td_erros                | -0.0588  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 36700    |
| lives                   | 36700    |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 6.99     |
| mean 100 episode reward | 2.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4208   |
| steps                   | 266021   |
| td_erros                | -0.0292  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 36800    |
| lives                   | 36800    |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 6.75     |
| mean 100 episode reward | 2.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4466   |
| steps                   | 266596   |
| td_erros                | -0.0137  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 36900    |
| lives                   | 36900    |
| mean 100 episode ei     | 4.35     |
| mean 100 episode length | 7.74     |
| mean 100 episode reward | 3        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4636   |
| steps                   | 267270   |
| td_erros                | -0.0435  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 37000    |
| lives                   | 37000    |
| mean 100 episode ei     | 3.63     |
| mean 100 episode length | 6.76     |
| mean 100 episode reward | 2.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5309   |
| steps                   | 267846   |
| td_erros                | -0.0209  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 37100    |
| lives                   | 37100    |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 7.22     |
| mean 100 episode reward | 3.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5708   |
| steps                   | 268468   |
| td_erros                | -0.0242  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 37200    |
| lives                   | 37200    |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 6.95     |
| mean 100 episode reward | 3.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6153   |
| steps                   | 269063   |
| td_erros                | -0.0184  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 37300    |
| lives                   | 37300    |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 7.43     |
| mean 100 episode reward | 3.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5726   |
| steps                   | 269706   |
| td_erros                | -0.0236  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 37400    |
| lives                   | 37400    |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 7.33     |
| mean 100 episode reward | 2.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.515    |
| steps                   | 270339   |
| td_erros                | -0.041   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 37500    |
| lives                   | 37500    |
| mean 100 episode ei     | 3.72     |
| mean 100 episode length | 7.08     |
| mean 100 episode reward | 3.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4421   |
| steps                   | 270947   |
| td_erros                | -0.0568  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 37600    |
| lives                   | 37600    |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 6.99     |
| mean 100 episode reward | 3.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4112   |
| steps                   | 271546   |
| td_erros                | -0.0504  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 37700    |
| lives                   | 37700    |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 7.7      |
| mean 100 episode reward | 3.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.364    |
| steps                   | 272216   |
| td_erros                | -0.0636  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 37800    |
| lives                   | 37800    |
| mean 100 episode ei     | 4.45     |
| mean 100 episode length | 7.32     |
| mean 100 episode reward | 2.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.33     |
| steps                   | 272848   |
| td_erros                | -0.075   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 37900    |
| lives                   | 37900    |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 6.64     |
| mean 100 episode reward | 2.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.359    |
| steps                   | 273412   |
| td_erros                | -0.0803  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 38000    |
| lives                   | 38000    |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 6.46     |
| mean 100 episode reward | 2.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4205   |
| steps                   | 273958   |
| td_erros                | -0.0786  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 38100    |
| lives                   | 38100    |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 6.98     |
| mean 100 episode reward | 3.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4036   |
| steps                   | 274556   |
| td_erros                | -0.1031  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 38200    |
| lives                   | 38200    |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 6.99     |
| mean 100 episode reward | 2.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3849   |
| steps                   | 275155   |
| td_erros                | -0.1086  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 38300    |
| lives                   | 38300    |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 6.77     |
| mean 100 episode reward | 3.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3792   |
| steps                   | 275732   |
| td_erros                | -0.1212  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 38400    |
| lives                   | 38400    |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 7.37     |
| mean 100 episode reward | 3.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4314   |
| steps                   | 276369   |
| td_erros                | -0.0979  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 38500    |
| lives                   | 38500    |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 7.43     |
| mean 100 episode reward | 3.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4947   |
| steps                   | 277012   |
| td_erros                | -0.0999  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 38600    |
| lives                   | 38600    |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 7.6      |
| mean 100 episode reward | 3.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5135   |
| steps                   | 277672   |
| td_erros                | -0.0793  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 38700    |
| lives                   | 38700    |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 7.15     |
| mean 100 episode reward | 3.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4936   |
| steps                   | 278287   |
| td_erros                | -0.0644  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 38800    |
| lives                   | 38800    |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 7.69     |
| mean 100 episode reward | 3.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4431   |
| steps                   | 278956   |
| td_erros                | -0.0753  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 38900    |
| lives                   | 38900    |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 7.21     |
| mean 100 episode reward | 3.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4532   |
| steps                   | 279577   |
| td_erros                | -0.0421  |
--------------------------------------
Saving model due to mean reward increase: 3.5682 -> 3.672
Saving model due to running mean reward increase: 3.5814 -> 3.672
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 39000    |
| lives                   | 39000    |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 7.44     |
| mean 100 episode reward | 3.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4851   |
| steps                   | 280221   |
| td_erros                | -0.0451  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 39100    |
| lives                   | 39100    |
| mean 100 episode ei     | 4.39     |
| mean 100 episode length | 7.09     |
| mean 100 episode reward | 4.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4814   |
| steps                   | 280830   |
| td_erros                | -0.053   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 39200    |
| lives                   | 39200    |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 6.39     |
| mean 100 episode reward | 3.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4863   |
| steps                   | 281369   |
| td_erros                | -0.0487  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 39300    |
| lives                   | 39300    |
| mean 100 episode ei     | 3.48     |
| mean 100 episode length | 5.95     |
| mean 100 episode reward | 3.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4946   |
| steps                   | 281864   |
| td_erros                | -0.0385  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 39400    |
| lives                   | 39400    |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 6.65     |
| mean 100 episode reward | 3.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4862   |
| steps                   | 282429   |
| td_erros                | -0.0298  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 39500    |
| lives                   | 39500    |
| mean 100 episode ei     | 3.63     |
| mean 100 episode length | 6.68     |
| mean 100 episode reward | 3.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4768   |
| steps                   | 282997   |
| td_erros                | -0.0384  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 39600    |
| lives                   | 39600    |
| mean 100 episode ei     | 3.47     |
| mean 100 episode length | 6.92     |
| mean 100 episode reward | 3.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4175   |
| steps                   | 283589   |
| td_erros                | -0.0449  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 39700    |
| lives                   | 39700    |
| mean 100 episode ei     | 3.67     |
| mean 100 episode length | 6.59     |
| mean 100 episode reward | 2.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3754   |
| steps                   | 284148   |
| td_erros                | -0.0412  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 39800    |
| lives                   | 39800    |
| mean 100 episode ei     | 4.39     |
| mean 100 episode length | 7.35     |
| mean 100 episode reward | 3.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.331    |
| steps                   | 284783   |
| td_erros                | -0.0684  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 39900    |
| lives                   | 39900    |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 6.55     |
| mean 100 episode reward | 3.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3349   |
| steps                   | 285338   |
| td_erros                | -0.0618  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 40000    |
| lives                   | 40000    |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 7.04     |
| mean 100 episode reward | 2.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3488   |
| steps                   | 285942   |
| td_erros                | -0.0278  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 40100    |
| lives                   | 40100    |
| mean 100 episode ei     | 4.42     |
| mean 100 episode length | 7.3      |
| mean 100 episode reward | 3.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3273   |
| steps                   | 286572   |
| td_erros                | -0.0184  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 40200    |
| lives                   | 40200    |
| mean 100 episode ei     | 4.41     |
| mean 100 episode length | 7.26     |
| mean 100 episode reward | 2.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3285   |
| steps                   | 287198   |
| td_erros                | -0.0424  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 40300    |
| lives                   | 40300    |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 6.61     |
| mean 100 episode reward | 2.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.328    |
| steps                   | 287759   |
| td_erros                | -0.0295  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 40400    |
| lives                   | 40400    |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 6.97     |
| mean 100 episode reward | 2.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3486   |
| steps                   | 288356   |
| td_erros                | -0.0344  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 40500    |
| lives                   | 40500    |
| mean 100 episode ei     | 3.58     |
| mean 100 episode length | 6.23     |
| mean 100 episode reward | 2.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3489   |
| steps                   | 288879   |
| td_erros                | -0.0458  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 40600    |
| lives                   | 40600    |
| mean 100 episode ei     | 3.54     |
| mean 100 episode length | 7.17     |
| mean 100 episode reward | 3.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.37     |
| steps                   | 289496   |
| td_erros                | -0.0436  |
--------------------------------------
Saving model due to running mean reward increase: 2.9468 -> 3.3933
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 40700    |
| lives                   | 40700    |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 7.5      |
| mean 100 episode reward | 3.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4039   |
| steps                   | 290146   |
| td_erros                | -0.0292  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 40800    |
| lives                   | 40800    |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 7.14     |
| mean 100 episode reward | 2.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3723   |
| steps                   | 290760   |
| td_erros                | -0.0479  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 40900    |
| lives                   | 40900    |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 7.37     |
| mean 100 episode reward | 3.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4113   |
| steps                   | 291397   |
| td_erros                | -0.0599  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 41000    |
| lives                   | 41000    |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 7.12     |
| mean 100 episode reward | 3.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3814   |
| steps                   | 292009   |
| td_erros                | -0.0415  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 41100    |
| lives                   | 41100    |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 6.89     |
| mean 100 episode reward | 3.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3925   |
| steps                   | 292598   |
| td_erros                | -0.0333  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 41200    |
| lives                   | 41200    |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 6.92     |
| mean 100 episode reward | 3.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3876   |
| steps                   | 293190   |
| td_erros                | -0.05    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 41300    |
| lives                   | 41300    |
| mean 100 episode ei     | 3.62     |
| mean 100 episode length | 6.7      |
| mean 100 episode reward | 2.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3733   |
| steps                   | 293760   |
| td_erros                | -0.0494  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 41400    |
| lives                   | 41400    |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 6.99     |
| mean 100 episode reward | 2.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3011   |
| steps                   | 294359   |
| td_erros                | -0.097   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 41500    |
| lives                   | 41500    |
| mean 100 episode ei     | 3.79     |
| mean 100 episode length | 6.78     |
| mean 100 episode reward | 2.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3108   |
| steps                   | 294937   |
| td_erros                | -0.0901  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 41600    |
| lives                   | 41600    |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 7.24     |
| mean 100 episode reward | 3.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2996   |
| steps                   | 295561   |
| td_erros                | -0.089   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 41700    |
| lives                   | 41700    |
| mean 100 episode ei     | 3.79     |
| mean 100 episode length | 6.84     |
| mean 100 episode reward | 2.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3096   |
| steps                   | 296145   |
| td_erros                | -0.106   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 41800    |
| lives                   | 41800    |
| mean 100 episode ei     | 3.4      |
| mean 100 episode length | 6.71     |
| mean 100 episode reward | 2.96     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3636   |
| steps                   | 296716   |
| td_erros                | -0.0971  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 41900    |
| lives                   | 41900    |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 6.96     |
| mean 100 episode reward | 4.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.35     |
| steps                   | 297312   |
| td_erros                | -0.0695  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 42000    |
| lives                   | 42000    |
| mean 100 episode ei     | 3.56     |
| mean 100 episode length | 7.15     |
| mean 100 episode reward | 3.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3196   |
| steps                   | 297927   |
| td_erros                | -0.0844  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 42100    |
| lives                   | 42100    |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 7.42     |
| mean 100 episode reward | 3.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2339   |
| steps                   | 298569   |
| td_erros                | -0.0988  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 42200    |
| lives                   | 42200    |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 7.29     |
| mean 100 episode reward | 3.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.212    |
| steps                   | 299198   |
| td_erros                | -0.1096  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 42300    |
| lives                   | 42300    |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 7.5      |
| mean 100 episode reward | 3.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2145   |
| steps                   | 299848   |
| td_erros                | -0.0972  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 42400    |
| lives                   | 42400    |
| mean 100 episode ei     | 3.7      |
| mean 100 episode length | 6.79     |
| mean 100 episode reward | 3.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2362   |
| steps                   | 300427   |
| td_erros                | -0.0771  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 42500    |
| lives                   | 42500    |
| mean 100 episode ei     | 3.42     |
| mean 100 episode length | 6.3      |
| mean 100 episode reward | 3.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2706   |
| steps                   | 300957   |
| td_erros                | -0.0533  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 42600    |
| lives                   | 42600    |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 6.49     |
| mean 100 episode reward | 3.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2513   |
| steps                   | 301506   |
| td_erros                | -0.0697  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 42700    |
| lives                   | 42700    |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 7.27     |
| mean 100 episode reward | 3.69     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2548   |
| steps                   | 302133   |
| td_erros                | -0.0483  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 42800    |
| lives                   | 42800    |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 7.1      |
| mean 100 episode reward | 3.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1939   |
| steps                   | 302743   |
| td_erros                | -0.0785  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 42900    |
| lives                   | 42900    |
| mean 100 episode ei     | 4.49     |
| mean 100 episode length | 7.25     |
| mean 100 episode reward | 3.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1829   |
| steps                   | 303368   |
| td_erros                | -0.084   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 43000    |
| lives                   | 43000    |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 6.98     |
| mean 100 episode reward | 3.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3053   |
| steps                   | 303966   |
| td_erros                | 0.0176   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 43100    |
| lives                   | 43100    |
| mean 100 episode ei     | 2.91     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 2.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2717   |
| steps                   | 304407   |
| td_erros                | -0.0368  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 43200    |
| lives                   | 43200    |
| mean 100 episode ei     | 2.74     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 2.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2349   |
| steps                   | 304851   |
| td_erros                | -0.0229  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 43300    |
| lives                   | 43300    |
| mean 100 episode ei     | 3.1      |
| mean 100 episode length | 6.06     |
| mean 100 episode reward | 3.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1574   |
| steps                   | 305357   |
| td_erros                | -0.0442  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 43400    |
| lives                   | 43400    |
| mean 100 episode ei     | 2.76     |
| mean 100 episode length | 5.74     |
| mean 100 episode reward | 2.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.173    |
| steps                   | 305831   |
| td_erros                | -0.0119  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 43500    |
| lives                   | 43500    |
| mean 100 episode ei     | 3.02     |
| mean 100 episode length | 6.19     |
| mean 100 episode reward | 2.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1665   |
| steps                   | 306350   |
| td_erros                | -0.0059  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 43600    |
| lives                   | 43600    |
| mean 100 episode ei     | 3.8      |
| mean 100 episode length | 7.01     |
| mean 100 episode reward | 3        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2021   |
| steps                   | 306951   |
| td_erros                | 0.0315   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 43700    |
| lives                   | 43700    |
| mean 100 episode ei     | 3.4      |
| mean 100 episode length | 6.23     |
| mean 100 episode reward | 3        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2119   |
| steps                   | 307474   |
| td_erros                | 0.0441   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 43800    |
| lives                   | 43800    |
| mean 100 episode ei     | 3.64     |
| mean 100 episode length | 6.71     |
| mean 100 episode reward | 3.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2405   |
| steps                   | 308045   |
| td_erros                | 0.0665   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 43900    |
| lives                   | 43900    |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 7.24     |
| mean 100 episode reward | 3.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2495   |
| steps                   | 308669   |
| td_erros                | 0.0564   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 44000    |
| lives                   | 44000    |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 7.24     |
| mean 100 episode reward | 3.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1525   |
| steps                   | 309293   |
| td_erros                | -0.029   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 44100    |
| lives                   | 44100    |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 7.02     |
| mean 100 episode reward | 2.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2236   |
| steps                   | 309895   |
| td_erros                | -0.0224  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 44200    |
| lives                   | 44200    |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 6.86     |
| mean 100 episode reward | 2.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.296    |
| steps                   | 310481   |
| td_erros                | 0.04     |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 44300    |
| lives                   | 44300    |
| mean 100 episode ei     | 3.42     |
| mean 100 episode length | 6.3      |
| mean 100 episode reward | 2.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2802   |
| steps                   | 311011   |
| td_erros                | 0.0069   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 44400    |
| lives                   | 44400    |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 6.51     |
| mean 100 episode reward | 3.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2845   |
| steps                   | 311562   |
| td_erros                | 0.018    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 44500    |
| lives                   | 44500    |
| mean 100 episode ei     | 4.33     |
| mean 100 episode length | 6.92     |
| mean 100 episode reward | 3.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3312   |
| steps                   | 312154   |
| td_erros                | 0.0163   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 44600    |
| lives                   | 44600    |
| mean 100 episode ei     | 3.83     |
| mean 100 episode length | 6.44     |
| mean 100 episode reward | 3.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3882   |
| steps                   | 312698   |
| td_erros                | 0.0156   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 44700    |
| lives                   | 44700    |
| mean 100 episode ei     | 3.13     |
| mean 100 episode length | 6.38     |
| mean 100 episode reward | 3.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3912   |
| steps                   | 313236   |
| td_erros                | -0.0022  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 44800    |
| lives                   | 44800    |
| mean 100 episode ei     | 3.19     |
| mean 100 episode length | 6.11     |
| mean 100 episode reward | 3.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3599   |
| steps                   | 313747   |
| td_erros                | -0.0164  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 44900    |
| lives                   | 44900    |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 6.89     |
| mean 100 episode reward | 3.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3045   |
| steps                   | 314336   |
| td_erros                | -0.0187  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 45000    |
| lives                   | 45000    |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 6.91     |
| mean 100 episode reward | 3.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2816   |
| steps                   | 314927   |
| td_erros                | -0.0382  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 45100    |
| lives                   | 45100    |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 6.86     |
| mean 100 episode reward | 3.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2258   |
| steps                   | 315513   |
| td_erros                | -0.0637  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 45200    |
| lives                   | 45200    |
| mean 100 episode ei     | 3.59     |
| mean 100 episode length | 6.46     |
| mean 100 episode reward | 2.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1459   |
| steps                   | 316059   |
| td_erros                | -0.0931  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 45300    |
| lives                   | 45300    |
| mean 100 episode ei     | 3.58     |
| mean 100 episode length | 6.55     |
| mean 100 episode reward | 3.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0898   |
| steps                   | 316614   |
| td_erros                | -0.1073  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 45400    |
| lives                   | 45400    |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 6.94     |
| mean 100 episode reward | 2.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0342   |
| steps                   | 317208   |
| td_erros                | -0.1268  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 45500    |
| lives                   | 45500    |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 6.59     |
| mean 100 episode reward | 3        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9529   |
| steps                   | 317767   |
| td_erros                | -0.1646  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 45600    |
| lives                   | 45600    |
| mean 100 episode ei     | 3.49     |
| mean 100 episode length | 6.67     |
| mean 100 episode reward | 2.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9464   |
| steps                   | 318334   |
| td_erros                | -0.1719  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 45700    |
| lives                   | 45700    |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 6.74     |
| mean 100 episode reward | 3.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9682   |
| steps                   | 318908   |
| td_erros                | -0.212   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 45800    |
| lives                   | 45800    |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 6.81     |
| mean 100 episode reward | 3.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0137   |
| steps                   | 319489   |
| td_erros                | -0.1915  |
--------------------------------------
Saving model due to mean reward increase: 3.672 -> 3.6834
Saving model due to running mean reward increase: 3.3553 -> 3.6834
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 45900    |
| lives                   | 45900    |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 6.57     |
| mean 100 episode reward | 3.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0262   |
| steps                   | 320046   |
| td_erros                | -0.1816  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 46000    |
| lives                   | 46000    |
| mean 100 episode ei     | 4.35     |
| mean 100 episode length | 6.98     |
| mean 100 episode reward | 3.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0814   |
| steps                   | 320644   |
| td_erros                | -0.1689  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 46100    |
| lives                   | 46100    |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 6.53     |
| mean 100 episode reward | 4.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1463   |
| steps                   | 321197   |
| td_erros                | -0.1411  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 46200    |
| lives                   | 46200    |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 6.87     |
| mean 100 episode reward | 3.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2106   |
| steps                   | 321784   |
| td_erros                | -0.1405  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 46300    |
| lives                   | 46300    |
| mean 100 episode ei     | 3.74     |
| mean 100 episode length | 6.93     |
| mean 100 episode reward | 3.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1792   |
| steps                   | 322377   |
| td_erros                | -0.161   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 46400    |
| lives                   | 46400    |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 6.55     |
| mean 100 episode reward | 3.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2556   |
| steps                   | 322932   |
| td_erros                | -0.1448  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 46500    |
| lives                   | 46500    |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 6.51     |
| mean 100 episode reward | 3.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.31     |
| steps                   | 323483   |
| td_erros                | -0.1167  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 46600    |
| lives                   | 46600    |
| mean 100 episode ei     | 3.72     |
| mean 100 episode length | 6.12     |
| mean 100 episode reward | 2.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2991   |
| steps                   | 323995   |
| td_erros                | -0.1153  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 46700    |
| lives                   | 46700    |
| mean 100 episode ei     | 2.56     |
| mean 100 episode length | 4.98     |
| mean 100 episode reward | 2.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.321    |
| steps                   | 324393   |
| td_erros                | -0.0767  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 46800    |
| lives                   | 46800    |
| mean 100 episode ei     | 3.5      |
| mean 100 episode length | 6.31     |
| mean 100 episode reward | 2.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2569   |
| steps                   | 324924   |
| td_erros                | -0.0537  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 46900    |
| lives                   | 46900    |
| mean 100 episode ei     | 3.74     |
| mean 100 episode length | 6.96     |
| mean 100 episode reward | 3.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1707   |
| steps                   | 325520   |
| td_erros                | -0.0823  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 47000    |
| lives                   | 47000    |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 7.14     |
| mean 100 episode reward | 3.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.08     |
| steps                   | 326134   |
| td_erros                | -0.1047  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 47100    |
| lives                   | 47100    |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 6.92     |
| mean 100 episode reward | 4.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0207   |
| steps                   | 326726   |
| td_erros                | -0.1297  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 47200    |
| lives                   | 47200    |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 6.75     |
| mean 100 episode reward | 3.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0342   |
| steps                   | 327301   |
| td_erros                | -0.11    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 47300    |
| lives                   | 47300    |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 6.91     |
| mean 100 episode reward | 3.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9701   |
| steps                   | 327892   |
| td_erros                | -0.1159  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 47400    |
| lives                   | 47400    |
| mean 100 episode ei     | 3.68     |
| mean 100 episode length | 7.28     |
| mean 100 episode reward | 3.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9403   |
| steps                   | 328520   |
| td_erros                | -0.1385  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 47500    |
| lives                   | 47500    |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 7.28     |
| mean 100 episode reward | 3.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9258   |
| steps                   | 329148   |
| td_erros                | -0.1433  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 47600    |
| lives                   | 47600    |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 6.89     |
| mean 100 episode reward | 3.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9483   |
| steps                   | 329737   |
| td_erros                | -0.1401  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 47700    |
| lives                   | 47700    |
| mean 100 episode ei     | 3.55     |
| mean 100 episode length | 5.8      |
| mean 100 episode reward | 2.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0824   |
| steps                   | 330217   |
| td_erros                | -0.0171  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 47800    |
| lives                   | 47800    |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 6.1      |
| mean 100 episode reward | 2.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0521   |
| steps                   | 330727   |
| td_erros                | -0.1306  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 47900    |
| lives                   | 47900    |
| mean 100 episode ei     | 3.18     |
| mean 100 episode length | 6.2      |
| mean 100 episode reward | 2.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9864   |
| steps                   | 331247   |
| td_erros                | -0.1723  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 48000    |
| lives                   | 48000    |
| mean 100 episode ei     | 3.1      |
| mean 100 episode length | 5.84     |
| mean 100 episode reward | 2.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9768   |
| steps                   | 331731   |
| td_erros                | -0.1968  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 48100    |
| lives                   | 48100    |
| mean 100 episode ei     | 3.4      |
| mean 100 episode length | 6.26     |
| mean 100 episode reward | 3.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9314   |
| steps                   | 332257   |
| td_erros                | -0.2061  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 48200    |
| lives                   | 48200    |
| mean 100 episode ei     | 3.55     |
| mean 100 episode length | 6.57     |
| mean 100 episode reward | 3.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9111   |
| steps                   | 332814   |
| td_erros                | -0.2156  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 48300    |
| lives                   | 48300    |
| mean 100 episode ei     | 3.69     |
| mean 100 episode length | 6.77     |
| mean 100 episode reward | 3.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8995   |
| steps                   | 333391   |
| td_erros                | -0.2262  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 48400    |
| lives                   | 48400    |
| mean 100 episode ei     | 3.8      |
| mean 100 episode length | 7.07     |
| mean 100 episode reward | 3.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.899    |
| steps                   | 333998   |
| td_erros                | -0.2281  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 48500    |
| lives                   | 48500    |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 7.23     |
| mean 100 episode reward | 3.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9197   |
| steps                   | 334621   |
| td_erros                | -0.21    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 48600    |
| lives                   | 48600    |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 6.98     |
| mean 100 episode reward | 3.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8949   |
| steps                   | 335219   |
| td_erros                | -0.1993  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 48700    |
| lives                   | 48700    |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 7.04     |
| mean 100 episode reward | 3.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9228   |
| steps                   | 335823   |
| td_erros                | -0.1877  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 48800    |
| lives                   | 48800    |
| mean 100 episode ei     | 4.43     |
| mean 100 episode length | 7.27     |
| mean 100 episode reward | 3.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9519   |
| steps                   | 336450   |
| td_erros                | -0.1809  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 48900    |
| lives                   | 48900    |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 6.42     |
| mean 100 episode reward | 2.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9952   |
| steps                   | 336992   |
| td_erros                | -0.1798  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 49000    |
| lives                   | 49000    |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 6.49     |
| mean 100 episode reward | 3.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0035   |
| steps                   | 337541   |
| td_erros                | -0.2029  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 49100    |
| lives                   | 49100    |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 6.72     |
| mean 100 episode reward | 4.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0486   |
| steps                   | 338113   |
| td_erros                | -0.2011  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 49200    |
| lives                   | 49200    |
| mean 100 episode ei     | 3.47     |
| mean 100 episode length | 6.04     |
| mean 100 episode reward | 3.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0473   |
| steps                   | 338617   |
| td_erros                | -0.1658  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 49300    |
| lives                   | 49300    |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 6.34     |
| mean 100 episode reward | 3.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0701   |
| steps                   | 339151   |
| td_erros                | -0.1503  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 49400    |
| lives                   | 49400    |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 6.88     |
| mean 100 episode reward | 4.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0899   |
| steps                   | 339739   |
| td_erros                | -0.1486  |
--------------------------------------
Saving model due to mean reward increase: 3.6834 -> 4.005
Saving model due to running mean reward increase: 3.9752 -> 4.005
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 49500    |
| lives                   | 49500    |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 7.17     |
| mean 100 episode reward | 3.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1001   |
| steps                   | 340356   |
| td_erros                | -0.1333  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 49600    |
| lives                   | 49600    |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 7.48     |
| mean 100 episode reward | 3.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0889   |
| steps                   | 341004   |
| td_erros                | -0.1335  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 49700    |
| lives                   | 49700    |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 6.96     |
| mean 100 episode reward | 4.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1143   |
| steps                   | 341600   |
| td_erros                | -0.1104  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 49800    |
| lives                   | 49800    |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 7.1      |
| mean 100 episode reward | 4.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0863   |
| steps                   | 342210   |
| td_erros                | -0.1116  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 49900    |
| lives                   | 49900    |
| mean 100 episode ei     | 4.24     |
| mean 100 episode length | 7.03     |
| mean 100 episode reward | 4.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0753   |
| steps                   | 342813   |
| td_erros                | -0.1226  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 50000    |
| lives                   | 50000    |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 7.1      |
| mean 100 episode reward | 3.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0298   |
| steps                   | 343423   |
| td_erros                | -0.1571  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 50100    |
| lives                   | 50100    |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 6.95     |
| mean 100 episode reward | 4.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0139   |
| steps                   | 344018   |
| td_erros                | -0.173   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 50200    |
| lives                   | 50200    |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 7.13     |
| mean 100 episode reward | 4.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0168   |
| steps                   | 344631   |
| td_erros                | -0.171   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 50300    |
| lives                   | 50300    |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 6.63     |
| mean 100 episode reward | 4.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0223   |
| steps                   | 345194   |
| td_erros                | -0.1864  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 50400    |
| lives                   | 50400    |
| mean 100 episode ei     | 3.41     |
| mean 100 episode length | 5.87     |
| mean 100 episode reward | 2.99     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0428   |
| steps                   | 345681   |
| td_erros                | -0.1825  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 50500    |
| lives                   | 50500    |
| mean 100 episode ei     | 3.61     |
| mean 100 episode length | 6.52     |
| mean 100 episode reward | 3.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0076   |
| steps                   | 346233   |
| td_erros                | -0.1894  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 50600    |
| lives                   | 50600    |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 6.57     |
| mean 100 episode reward | 3.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0027   |
| steps                   | 346790   |
| td_erros                | -0.1813  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 50700    |
| lives                   | 50700    |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 6.87     |
| mean 100 episode reward | 4.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9392   |
| steps                   | 347377   |
| td_erros                | -0.1995  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 50800    |
| lives                   | 50800    |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 6.82     |
| mean 100 episode reward | 4.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8821   |
| steps                   | 347959   |
| td_erros                | -0.1906  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 50900    |
| lives                   | 50900    |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 7.31     |
| mean 100 episode reward | 3.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8571   |
| steps                   | 348590   |
| td_erros                | -0.196   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 51000    |
| lives                   | 51000    |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 7.18     |
| mean 100 episode reward | 4.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8529   |
| steps                   | 349208   |
| td_erros                | -0.1994  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 51100    |
| lives                   | 51100    |
| mean 100 episode ei     | 4.49     |
| mean 100 episode length | 6.92     |
| mean 100 episode reward | 3.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9112   |
| steps                   | 349800   |
| td_erros                | -0.1929  |
--------------------------------------
Saving model due to mean reward increase: 4.005 -> 4.0106
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 51200    |
| lives                   | 51200    |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 6.75     |
| mean 100 episode reward | 3.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9759   |
| steps                   | 350375   |
| td_erros                | -0.1757  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 51300    |
| lives                   | 51300    |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 6.62     |
| mean 100 episode reward | 4.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0234   |
| steps                   | 350937   |
| td_erros                | -0.1733  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 51400    |
| lives                   | 51400    |
| mean 100 episode ei     | 4.51     |
| mean 100 episode length | 6.31     |
| mean 100 episode reward | 3.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.071    |
| steps                   | 351468   |
| td_erros                | -0.1901  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 51500    |
| lives                   | 51500    |
| mean 100 episode ei     | 4.52     |
| mean 100 episode length | 6.32     |
| mean 100 episode reward | 3.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0847   |
| steps                   | 352000   |
| td_erros                | -0.2062  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 51600    |
| lives                   | 51600    |
| mean 100 episode ei     | 4.23     |
| mean 100 episode length | 6.23     |
| mean 100 episode reward | 3.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1284   |
| steps                   | 352523   |
| td_erros                | -0.2334  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 51700    |
| lives                   | 51700    |
| mean 100 episode ei     | 3.65     |
| mean 100 episode length | 5.92     |
| mean 100 episode reward | 3.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1234   |
| steps                   | 353015   |
| td_erros                | -0.2305  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 51800    |
| lives                   | 51800    |
| mean 100 episode ei     | 3.61     |
| mean 100 episode length | 5.93     |
| mean 100 episode reward | 3.57     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0914   |
| steps                   | 353508   |
| td_erros                | -0.2328  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 51900    |
| lives                   | 51900    |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 6.46     |
| mean 100 episode reward | 3.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1054   |
| steps                   | 354054   |
| td_erros                | -0.2195  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 52000    |
| lives                   | 52000    |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 6.88     |
| mean 100 episode reward | 4.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0825   |
| steps                   | 354642   |
| td_erros                | -0.2217  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 52100    |
| lives                   | 52100    |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 6.74     |
| mean 100 episode reward | 4        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0476   |
| steps                   | 355216   |
| td_erros                | -0.2179  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 52200    |
| lives                   | 52200    |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 6.93     |
| mean 100 episode reward | 4.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0277   |
| steps                   | 355809   |
| td_erros                | -0.2187  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 52300    |
| lives                   | 52300    |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 6.94     |
| mean 100 episode reward | 3.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0202   |
| steps                   | 356403   |
| td_erros                | -0.1892  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 52400    |
| lives                   | 52400    |
| mean 100 episode ei     | 3.54     |
| mean 100 episode length | 5.93     |
| mean 100 episode reward | 3.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9643   |
| steps                   | 356896   |
| td_erros                | -0.1815  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 52500    |
| lives                   | 52500    |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 6.65     |
| mean 100 episode reward | 3.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9218   |
| steps                   | 357461   |
| td_erros                | -0.1762  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 52600    |
| lives                   | 52600    |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 6.92     |
| mean 100 episode reward | 4.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9633   |
| steps                   | 358053   |
| td_erros                | -0.1662  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 52700    |
| lives                   | 52700    |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 6.53     |
| mean 100 episode reward | 3.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0171   |
| steps                   | 358606   |
| td_erros                | -0.1441  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 52800    |
| lives                   | 52800    |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 6.62     |
| mean 100 episode reward | 3.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0585   |
| steps                   | 359168   |
| td_erros                | -0.1521  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 52900    |
| lives                   | 52900    |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 6.29     |
| mean 100 episode reward | 3.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0923   |
| steps                   | 359697   |
| td_erros                | -0.1569  |
--------------------------------------
Saving model due to running mean reward increase: 3.5996 -> 3.6745
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 53000    |
| lives                   | 53000    |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 6.24     |
| mean 100 episode reward | 3.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0566   |
| steps                   | 360221   |
| td_erros                | -0.1774  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 53100    |
| lives                   | 53100    |
| mean 100 episode ei     | 3.64     |
| mean 100 episode length | 6.73     |
| mean 100 episode reward | 3.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0679   |
| steps                   | 360794   |
| td_erros                | -0.2034  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 53200    |
| lives                   | 53200    |
| mean 100 episode ei     | 3.63     |
| mean 100 episode length | 6.95     |
| mean 100 episode reward | 3.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9889   |
| steps                   | 361389   |
| td_erros                | -0.2113  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 53300    |
| lives                   | 53300    |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 7        |
| mean 100 episode reward | 4.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9618   |
| steps                   | 361989   |
| td_erros                | -0.2276  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 53400    |
| lives                   | 53400    |
| mean 100 episode ei     | 3.83     |
| mean 100 episode length | 6.76     |
| mean 100 episode reward | 4.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9878   |
| steps                   | 362565   |
| td_erros                | -0.2113  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 53500    |
| lives                   | 53500    |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 6.7      |
| mean 100 episode reward | 3.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9716   |
| steps                   | 363135   |
| td_erros                | -0.1942  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 53600    |
| lives                   | 53600    |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 6.75     |
| mean 100 episode reward | 4.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8968   |
| steps                   | 363710   |
| td_erros                | -0.2089  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 53700    |
| lives                   | 53700    |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 6.1      |
| mean 100 episode reward | 4.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8616   |
| steps                   | 364220   |
| td_erros                | -0.2246  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 53800    |
| lives                   | 53800    |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 6.7      |
| mean 100 episode reward | 4.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8153   |
| steps                   | 364790   |
| td_erros                | -0.2346  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 53900    |
| lives                   | 53900    |
| mean 100 episode ei     | 3.41     |
| mean 100 episode length | 6.35     |
| mean 100 episode reward | 5.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7743   |
| steps                   | 365325   |
| td_erros                | -0.2191  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 54000    |
| lives                   | 54000    |
| mean 100 episode ei     | 3.4      |
| mean 100 episode length | 5.94     |
| mean 100 episode reward | 4.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7418   |
| steps                   | 365819   |
| td_erros                | -0.225   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 54100    |
| lives                   | 54100    |
| mean 100 episode ei     | 3.59     |
| mean 100 episode length | 5.95     |
| mean 100 episode reward | 4.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7522   |
| steps                   | 366314   |
| td_erros                | -0.2232  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 54200    |
| lives                   | 54200    |
| mean 100 episode ei     | 3.72     |
| mean 100 episode length | 6.48     |
| mean 100 episode reward | 4.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7322   |
| steps                   | 366862   |
| td_erros                | -0.2263  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 54300    |
| lives                   | 54300    |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 6.84     |
| mean 100 episode reward | 5.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6833   |
| steps                   | 367446   |
| td_erros                | -0.2389  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 54400    |
| lives                   | 54400    |
| mean 100 episode ei     | 3.58     |
| mean 100 episode length | 6.01     |
| mean 100 episode reward | 4.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6672   |
| steps                   | 367947   |
| td_erros                | -0.2564  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 54500    |
| lives                   | 54500    |
| mean 100 episode ei     | 3.25     |
| mean 100 episode length | 5.84     |
| mean 100 episode reward | 3.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6701   |
| steps                   | 368431   |
| td_erros                | -0.2229  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 54600    |
| lives                   | 54600    |
| mean 100 episode ei     | 3.71     |
| mean 100 episode length | 6.4      |
| mean 100 episode reward | 3.96     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6539   |
| steps                   | 368971   |
| td_erros                | -0.2123  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 54700    |
| lives                   | 54700    |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 7.06     |
| mean 100 episode reward | 4.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6386   |
| steps                   | 369577   |
| td_erros                | -0.2282  |
--------------------------------------
Saving model due to mean reward increase: 4.0106 -> 4.5037
Saving model due to running mean reward increase: 4.2133 -> 4.5037
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 54800    |
| lives                   | 54800    |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 6.6      |
| mean 100 episode reward | 4.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6411   |
| steps                   | 370137   |
| td_erros                | -0.2292  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 54900    |
| lives                   | 54900    |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 6.52     |
| mean 100 episode reward | 4.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6623   |
| steps                   | 370689   |
| td_erros                | -0.2379  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 55000    |
| lives                   | 55000    |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 6.88     |
| mean 100 episode reward | 4.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.699    |
| steps                   | 371277   |
| td_erros                | -0.2378  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 55100    |
| lives                   | 55100    |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 6.31     |
| mean 100 episode reward | 4.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7043   |
| steps                   | 371808   |
| td_erros                | -0.2446  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 55200    |
| lives                   | 55200    |
| mean 100 episode ei     | 3.83     |
| mean 100 episode length | 6.19     |
| mean 100 episode reward | 4.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7097   |
| steps                   | 372327   |
| td_erros                | -0.248   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 55300    |
| lives                   | 55300    |
| mean 100 episode ei     | 3.58     |
| mean 100 episode length | 5.94     |
| mean 100 episode reward | 4.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7251   |
| steps                   | 372821   |
| td_erros                | -0.244   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 55400    |
| lives                   | 55400    |
| mean 100 episode ei     | 3.7      |
| mean 100 episode length | 6.3      |
| mean 100 episode reward | 4.69     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.71     |
| steps                   | 373351   |
| td_erros                | -0.2752  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 55500    |
| lives                   | 55500    |
| mean 100 episode ei     | 3.79     |
| mean 100 episode length | 6.59     |
| mean 100 episode reward | 4.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6981   |
| steps                   | 373910   |
| td_erros                | -0.2851  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 55600    |
| lives                   | 55600    |
| mean 100 episode ei     | 3.63     |
| mean 100 episode length | 6.58     |
| mean 100 episode reward | 4.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7102   |
| steps                   | 374468   |
| td_erros                | -0.2745  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 55700    |
| lives                   | 55700    |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 7.44     |
| mean 100 episode reward | 4.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6602   |
| steps                   | 375112   |
| td_erros                | -0.2921  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 55800    |
| lives                   | 55800    |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 7.4      |
| mean 100 episode reward | 4.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6788   |
| steps                   | 375752   |
| td_erros                | -0.2855  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 55900    |
| lives                   | 55900    |
| mean 100 episode ei     | 3.4      |
| mean 100 episode length | 6.66     |
| mean 100 episode reward | 3.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6758   |
| steps                   | 376318   |
| td_erros                | -0.2957  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 56000    |
| lives                   | 56000    |
| mean 100 episode ei     | 3.42     |
| mean 100 episode length | 6.23     |
| mean 100 episode reward | 3.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7016   |
| steps                   | 376841   |
| td_erros                | -0.2691  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 56100    |
| lives                   | 56100    |
| mean 100 episode ei     | 2.94     |
| mean 100 episode length | 5.46     |
| mean 100 episode reward | 3.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7294   |
| steps                   | 377287   |
| td_erros                | -0.2206  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 56200    |
| lives                   | 56200    |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 6.72     |
| mean 100 episode reward | 4.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7406   |
| steps                   | 377859   |
| td_erros                | -0.2143  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 56300    |
| lives                   | 56300    |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 7.17     |
| mean 100 episode reward | 4.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7732   |
| steps                   | 378476   |
| td_erros                | -0.194   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 56400    |
| lives                   | 56400    |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 6.3      |
| mean 100 episode reward | 3.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7837   |
| steps                   | 379006   |
| td_erros                | -0.2004  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 56500    |
| lives                   | 56500    |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 6.44     |
| mean 100 episode reward | 2.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8055   |
| steps                   | 379550   |
| td_erros                | -0.1926  |
--------------------------------------
Saving model due to running mean reward increase: 2.689 -> 4.0555
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 56600    |
| lives                   | 56600    |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 6.21     |
| mean 100 episode reward | 4        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8235   |
| steps                   | 380071   |
| td_erros                | -0.1934  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 56700    |
| lives                   | 56700    |
| mean 100 episode ei     | 3.32     |
| mean 100 episode length | 5.69     |
| mean 100 episode reward | 3.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8602   |
| steps                   | 380540   |
| td_erros                | -0.1706  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 56800    |
| lives                   | 56800    |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.9      |
| mean 100 episode reward | 4.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8711   |
| steps                   | 381030   |
| td_erros                | -0.1753  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 56900    |
| lives                   | 56900    |
| mean 100 episode ei     | 3.45     |
| mean 100 episode length | 5.55     |
| mean 100 episode reward | 3.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8472   |
| steps                   | 381485   |
| td_erros                | -0.1663  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 57000    |
| lives                   | 57000    |
| mean 100 episode ei     | 3.62     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 4.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8303   |
| steps                   | 381946   |
| td_erros                | -0.1846  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 57100    |
| lives                   | 57100    |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 6.1      |
| mean 100 episode reward | 4.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8153   |
| steps                   | 382456   |
| td_erros                | -0.2072  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 57200    |
| lives                   | 57200    |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 7.05     |
| mean 100 episode reward | 3.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7902   |
| steps                   | 383061   |
| td_erros                | -0.2194  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 57300    |
| lives                   | 57300    |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 7.44     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7604   |
| steps                   | 383705   |
| td_erros                | -0.2165  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 57400    |
| lives                   | 57400    |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 6.73     |
| mean 100 episode reward | 4.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7924   |
| steps                   | 384278   |
| td_erros                | -0.2343  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 57500    |
| lives                   | 57500    |
| mean 100 episode ei     | 3.27     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 4.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8421   |
| steps                   | 384737   |
| td_erros                | -0.198   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 57600    |
| lives                   | 57600    |
| mean 100 episode ei     | 3.27     |
| mean 100 episode length | 5.92     |
| mean 100 episode reward | 3.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8141   |
| steps                   | 385229   |
| td_erros                | -0.217   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 57700    |
| lives                   | 57700    |
| mean 100 episode ei     | 3.35     |
| mean 100 episode length | 5.84     |
| mean 100 episode reward | 3.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7911   |
| steps                   | 385713   |
| td_erros                | -0.2075  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 57800    |
| lives                   | 57800    |
| mean 100 episode ei     | 3.25     |
| mean 100 episode length | 5.91     |
| mean 100 episode reward | 3.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7785   |
| steps                   | 386204   |
| td_erros                | -0.2312  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 57900    |
| lives                   | 57900    |
| mean 100 episode ei     | 3.56     |
| mean 100 episode length | 6.31     |
| mean 100 episode reward | 4.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7415   |
| steps                   | 386735   |
| td_erros                | -0.2352  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 58000    |
| lives                   | 58000    |
| mean 100 episode ei     | 3.43     |
| mean 100 episode length | 6.18     |
| mean 100 episode reward | 4.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6859   |
| steps                   | 387253   |
| td_erros                | -0.2484  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 58100    |
| lives                   | 58100    |
| mean 100 episode ei     | 3.46     |
| mean 100 episode length | 6.18     |
| mean 100 episode reward | 4.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6502   |
| steps                   | 387771   |
| td_erros                | -0.2485  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 58200    |
| lives                   | 58200    |
| mean 100 episode ei     | 3.69     |
| mean 100 episode length | 6.47     |
| mean 100 episode reward | 4.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6599   |
| steps                   | 388318   |
| td_erros                | -0.2291  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 58300    |
| lives                   | 58300    |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.98     |
| mean 100 episode reward | 4.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6308   |
| steps                   | 388816   |
| td_erros                | -0.2533  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 58400    |
| lives                   | 58400    |
| mean 100 episode ei     | 3.69     |
| mean 100 episode length | 6.01     |
| mean 100 episode reward | 3.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.644    |
| steps                   | 389317   |
| td_erros                | -0.2188  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 58500    |
| lives                   | 58500    |
| mean 100 episode ei     | 3.35     |
| mean 100 episode length | 6.31     |
| mean 100 episode reward | 4.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5978   |
| steps                   | 389848   |
| td_erros                | -0.2274  |
--------------------------------------
Saving model due to running mean reward increase: 3.7002 -> 4.1317
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 58600    |
| lives                   | 58600    |
| mean 100 episode ei     | 3.52     |
| mean 100 episode length | 6.27     |
| mean 100 episode reward | 3.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5965   |
| steps                   | 390375   |
| td_erros                | -0.2255  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 58700    |
| lives                   | 58700    |
| mean 100 episode ei     | 3.38     |
| mean 100 episode length | 6.22     |
| mean 100 episode reward | 3.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5871   |
| steps                   | 390897   |
| td_erros                | -0.2224  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 58800    |
| lives                   | 58800    |
| mean 100 episode ei     | 3.4      |
| mean 100 episode length | 5.89     |
| mean 100 episode reward | 3.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5636   |
| steps                   | 391386   |
| td_erros                | -0.2416  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 58900    |
| lives                   | 58900    |
| mean 100 episode ei     | 3.35     |
| mean 100 episode length | 6.04     |
| mean 100 episode reward | 3.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5497   |
| steps                   | 391890   |
| td_erros                | -0.2186  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 59000    |
| lives                   | 59000    |
| mean 100 episode ei     | 3.74     |
| mean 100 episode length | 6.35     |
| mean 100 episode reward | 3.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.532    |
| steps                   | 392425   |
| td_erros                | -0.2384  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 59100    |
| lives                   | 59100    |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 6.33     |
| mean 100 episode reward | 4.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5213   |
| steps                   | 392958   |
| td_erros                | -0.264   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 59200    |
| lives                   | 59200    |
| mean 100 episode ei     | 3.34     |
| mean 100 episode length | 5.47     |
| mean 100 episode reward | 3.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5415   |
| steps                   | 393405   |
| td_erros                | -0.2473  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 59300    |
| lives                   | 59300    |
| mean 100 episode ei     | 3.07     |
| mean 100 episode length | 4.72     |
| mean 100 episode reward | 3.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5641   |
| steps                   | 393777   |
| td_erros                | -0.2623  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 59400    |
| lives                   | 59400    |
| mean 100 episode ei     | 2.39     |
| mean 100 episode length | 4.14     |
| mean 100 episode reward | 2.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5627   |
| steps                   | 394091   |
| td_erros                | -0.2224  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 59500    |
| lives                   | 59500    |
| mean 100 episode ei     | 3.63     |
| mean 100 episode length | 5.97     |
| mean 100 episode reward | 4.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5415   |
| steps                   | 394588   |
| td_erros                | -0.2556  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 59600    |
| lives                   | 59600    |
| mean 100 episode ei     | 3.31     |
| mean 100 episode length | 6.04     |
| mean 100 episode reward | 4.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4992   |
| steps                   | 395092   |
| td_erros                | -0.2811  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 59700    |
| lives                   | 59700    |
| mean 100 episode ei     | 3.23     |
| mean 100 episode length | 6.1      |
| mean 100 episode reward | 4.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5041   |
| steps                   | 395602   |
| td_erros                | -0.2898  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 59800    |
| lives                   | 59800    |
| mean 100 episode ei     | 3.8      |
| mean 100 episode length | 6.4      |
| mean 100 episode reward | 4.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.502    |
| steps                   | 396142   |
| td_erros                | -0.2902  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 59900    |
| lives                   | 59900    |
| mean 100 episode ei     | 3.45     |
| mean 100 episode length | 6.08     |
| mean 100 episode reward | 4.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4869   |
| steps                   | 396650   |
| td_erros                | -0.2877  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 60000    |
| lives                   | 60000    |
| mean 100 episode ei     | 3.75     |
| mean 100 episode length | 6.37     |
| mean 100 episode reward | 4.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4913   |
| steps                   | 397187   |
| td_erros                | -0.2993  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 60100    |
| lives                   | 60100    |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 6.31     |
| mean 100 episode reward | 5.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4985   |
| steps                   | 397718   |
| td_erros                | -0.2732  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 60200    |
| lives                   | 60200    |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 6.15     |
| mean 100 episode reward | 4.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.484    |
| steps                   | 398233   |
| td_erros                | -0.3013  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 60300    |
| lives                   | 60300    |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 6.08     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4798   |
| steps                   | 398741   |
| td_erros                | -0.286   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 60400    |
| lives                   | 60400    |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 6.37     |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4691   |
| steps                   | 399278   |
| td_erros                | -0.3342  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 60500    |
| lives                   | 60500    |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 6.36     |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4899   |
| steps                   | 399814   |
| td_erros                | -0.3156  |
--------------------------------------
Saving model due to mean reward increase: 4.5037 -> 4.8242
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 60600    |
| lives                   | 60600    |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 5.91     |
| mean 100 episode reward | 4.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.482    |
| steps                   | 400305   |
| td_erros                | -0.3202  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 60700    |
| lives                   | 60700    |
| mean 100 episode ei     | 3.55     |
| mean 100 episode length | 5.48     |
| mean 100 episode reward | 4.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5141   |
| steps                   | 400753   |
| td_erros                | -0.2968  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 60800    |
| lives                   | 60800    |
| mean 100 episode ei     | 3.68     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 4.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5046   |
| steps                   | 401215   |
| td_erros                | -0.2662  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 60900    |
| lives                   | 60900    |
| mean 100 episode ei     | 3.41     |
| mean 100 episode length | 5.34     |
| mean 100 episode reward | 3.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4863   |
| steps                   | 401649   |
| td_erros                | -0.3039  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 61000    |
| lives                   | 61000    |
| mean 100 episode ei     | 3.65     |
| mean 100 episode length | 5.66     |
| mean 100 episode reward | 4.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5144   |
| steps                   | 402115   |
| td_erros                | -0.2778  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 61100    |
| lives                   | 61100    |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 5.87     |
| mean 100 episode reward | 4.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5111   |
| steps                   | 402602   |
| td_erros                | -0.2957  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 61200    |
| lives                   | 61200    |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 6.08     |
| mean 100 episode reward | 4.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5267   |
| steps                   | 403110   |
| td_erros                | -0.2965  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 61300    |
| lives                   | 61300    |
| mean 100 episode ei     | 3.63     |
| mean 100 episode length | 5.91     |
| mean 100 episode reward | 4.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5565   |
| steps                   | 403601   |
| td_erros                | -0.2755  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 61400    |
| lives                   | 61400    |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 6.06     |
| mean 100 episode reward | 4.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5568   |
| steps                   | 404107   |
| td_erros                | -0.2933  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 61500    |
| lives                   | 61500    |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 6.25     |
| mean 100 episode reward | 4.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5695   |
| steps                   | 404632   |
| td_erros                | -0.2918  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 61600    |
| lives                   | 61600    |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 5.85     |
| mean 100 episode reward | 4.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5726   |
| steps                   | 405117   |
| td_erros                | -0.2912  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 61700    |
| lives                   | 61700    |
| mean 100 episode ei     | 3.83     |
| mean 100 episode length | 5.81     |
| mean 100 episode reward | 4.69     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.588    |
| steps                   | 405598   |
| td_erros                | -0.3008  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 61800    |
| lives                   | 61800    |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 6.3      |
| mean 100 episode reward | 4.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5855   |
| steps                   | 406128   |
| td_erros                | -0.3025  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 61900    |
| lives                   | 61900    |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 6.21     |
| mean 100 episode reward | 4.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6004   |
| steps                   | 406649   |
| td_erros                | -0.2943  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 62000    |
| lives                   | 62000    |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.7      |
| mean 100 episode reward | 4.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6203   |
| steps                   | 407119   |
| td_erros                | -0.2996  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 62100    |
| lives                   | 62100    |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.72     |
| mean 100 episode reward | 4.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6675   |
| steps                   | 407591   |
| td_erros                | -0.3232  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 62200    |
| lives                   | 62200    |
| mean 100 episode ei     | 3.79     |
| mean 100 episode length | 5.99     |
| mean 100 episode reward | 3.57     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6671   |
| steps                   | 408090   |
| td_erros                | -0.3153  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 62300    |
| lives                   | 62300    |
| mean 100 episode ei     | 3.36     |
| mean 100 episode length | 5.93     |
| mean 100 episode reward | 3.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.665    |
| steps                   | 408583   |
| td_erros                | -0.3095  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 62400    |
| lives                   | 62400    |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 6.8      |
| mean 100 episode reward | 4.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6696   |
| steps                   | 409163   |
| td_erros                | -0.316   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 62500    |
| lives                   | 62500    |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 6.49     |
| mean 100 episode reward | 4.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.68     |
| steps                   | 409712   |
| td_erros                | -0.3073  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 62600    |
| lives                   | 62600    |
| mean 100 episode ei     | 3.71     |
| mean 100 episode length | 6.04     |
| mean 100 episode reward | 4.69     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7018   |
| steps                   | 410216   |
| td_erros                | -0.2922  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 62700    |
| lives                   | 62700    |
| mean 100 episode ei     | 3.64     |
| mean 100 episode length | 6.28     |
| mean 100 episode reward | 4.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.705    |
| steps                   | 410744   |
| td_erros                | -0.2564  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 62800    |
| lives                   | 62800    |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 6.49     |
| mean 100 episode reward | 4.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6907   |
| steps                   | 411293   |
| td_erros                | -0.2736  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 62900    |
| lives                   | 62900    |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 6.67     |
| mean 100 episode reward | 4.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6573   |
| steps                   | 411860   |
| td_erros                | -0.2824  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 63000    |
| lives                   | 63000    |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 6.51     |
| mean 100 episode reward | 5.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.627    |
| steps                   | 412411   |
| td_erros                | -0.2969  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 63100    |
| lives                   | 63100    |
| mean 100 episode ei     | 3.56     |
| mean 100 episode length | 6.21     |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.563    |
| steps                   | 412932   |
| td_erros                | -0.2999  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 63200    |
| lives                   | 63200    |
| mean 100 episode ei     | 3.4      |
| mean 100 episode length | 5.81     |
| mean 100 episode reward | 4.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5456   |
| steps                   | 413413   |
| td_erros                | -0.3148  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 63300    |
| lives                   | 63300    |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 6.08     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4972   |
| steps                   | 413921   |
| td_erros                | -0.3414  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 63400    |
| lives                   | 63400    |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.98     |
| mean 100 episode reward | 4.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4736   |
| steps                   | 414419   |
| td_erros                | -0.3407  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 63500    |
| lives                   | 63500    |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 5.76     |
| mean 100 episode reward | 4.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4902   |
| steps                   | 414895   |
| td_erros                | -0.3441  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 63600    |
| lives                   | 63600    |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 5.84     |
| mean 100 episode reward | 4.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5027   |
| steps                   | 415379   |
| td_erros                | -0.3592  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 63700    |
| lives                   | 63700    |
| mean 100 episode ei     | 3.55     |
| mean 100 episode length | 5.84     |
| mean 100 episode reward | 4.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5      |
| steps                   | 415863   |
| td_erros                | -0.3703  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 63800    |
| lives                   | 63800    |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.91     |
| mean 100 episode reward | 4.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4944   |
| steps                   | 416354   |
| td_erros                | -0.3718  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 63900    |
| lives                   | 63900    |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 6.12     |
| mean 100 episode reward | 4.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4827   |
| steps                   | 416866   |
| td_erros                | -0.3881  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 64000    |
| lives                   | 64000    |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 5.47     |
| mean 100 episode reward | 3.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5252   |
| steps                   | 417313   |
| td_erros                | -0.3762  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 64100    |
| lives                   | 64100    |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 5.86     |
| mean 100 episode reward | 5        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5482   |
| steps                   | 417799   |
| td_erros                | -0.3629  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 64200    |
| lives                   | 64200    |
| mean 100 episode ei     | 3.64     |
| mean 100 episode length | 5.72     |
| mean 100 episode reward | 4.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5523   |
| steps                   | 418271   |
| td_erros                | -0.3765  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 64300    |
| lives                   | 64300    |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 5.38     |
| mean 100 episode reward | 4.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.576    |
| steps                   | 418709   |
| td_erros                | -0.3672  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 64400    |
| lives                   | 64400    |
| mean 100 episode ei     | 3.6      |
| mean 100 episode length | 5.32     |
| mean 100 episode reward | 4.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6244   |
| steps                   | 419141   |
| td_erros                | -0.3448  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 64500    |
| lives                   | 64500    |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.89     |
| mean 100 episode reward | 4.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6329   |
| steps                   | 419630   |
| td_erros                | -0.3587  |
--------------------------------------
Saving model due to mean reward increase: 4.8242 -> 4.842
Saving model due to running mean reward increase: 4.5881 -> 4.842
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 64600    |
| lives                   | 64600    |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 5.86     |
| mean 100 episode reward | 5.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6502   |
| steps                   | 420116   |
| td_erros                | -0.3562  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 64700    |
| lives                   | 64700    |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 6.13     |
| mean 100 episode reward | 5.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6048   |
| steps                   | 420629   |
| td_erros                | -0.3614  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 64800    |
| lives                   | 64800    |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 6.35     |
| mean 100 episode reward | 5.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6506   |
| steps                   | 421164   |
| td_erros                | -0.357   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 64900    |
| lives                   | 64900    |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 6.3      |
| mean 100 episode reward | 5        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6707   |
| steps                   | 421694   |
| td_erros                | -0.3557  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 65000    |
| lives                   | 65000    |
| mean 100 episode ei     | 3.55     |
| mean 100 episode length | 5.98     |
| mean 100 episode reward | 4.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6283   |
| steps                   | 422192   |
| td_erros                | -0.3461  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 65100    |
| lives                   | 65100    |
| mean 100 episode ei     | 3.55     |
| mean 100 episode length | 6.28     |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5684   |
| steps                   | 422720   |
| td_erros                | -0.3585  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 65200    |
| lives                   | 65200    |
| mean 100 episode ei     | 3.72     |
| mean 100 episode length | 6.32     |
| mean 100 episode reward | 5.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5272   |
| steps                   | 423252   |
| td_erros                | -0.3574  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 65300    |
| lives                   | 65300    |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 6.67     |
| mean 100 episode reward | 5.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4775   |
| steps                   | 423819   |
| td_erros                | -0.3717  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 65400    |
| lives                   | 65400    |
| mean 100 episode ei     | 3.59     |
| mean 100 episode length | 6.53     |
| mean 100 episode reward | 4.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4413   |
| steps                   | 424372   |
| td_erros                | -0.3517  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 65500    |
| lives                   | 65500    |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 6.79     |
| mean 100 episode reward | 4.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4084   |
| steps                   | 424951   |
| td_erros                | -0.3659  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 65600    |
| lives                   | 65600    |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 6.78     |
| mean 100 episode reward | 4.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3728   |
| steps                   | 425529   |
| td_erros                | -0.3769  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 65700    |
| lives                   | 65700    |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 6.32     |
| mean 100 episode reward | 4.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3845   |
| steps                   | 426061   |
| td_erros                | -0.3474  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 65800    |
| lives                   | 65800    |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 6.97     |
| mean 100 episode reward | 4.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4056   |
| steps                   | 426658   |
| td_erros                | -0.3205  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 65900    |
| lives                   | 65900    |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 6.25     |
| mean 100 episode reward | 4.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4175   |
| steps                   | 427183   |
| td_erros                | -0.3079  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 66000    |
| lives                   | 66000    |
| mean 100 episode ei     | 3.62     |
| mean 100 episode length | 5.74     |
| mean 100 episode reward | 3.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4627   |
| steps                   | 427657   |
| td_erros                | -0.3234  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 66100    |
| lives                   | 66100    |
| mean 100 episode ei     | 3.57     |
| mean 100 episode length | 6.12     |
| mean 100 episode reward | 4.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4758   |
| steps                   | 428169   |
| td_erros                | -0.3041  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 66200    |
| lives                   | 66200    |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 7.42     |
| mean 100 episode reward | 5.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4817   |
| steps                   | 428811   |
| td_erros                | -0.3176  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 66300    |
| lives                   | 66300    |
| mean 100 episode ei     | 4.46     |
| mean 100 episode length | 7.31     |
| mean 100 episode reward | 5.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5339   |
| steps                   | 429442   |
| td_erros                | -0.3061  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 66400    |
| lives                   | 66400    |
| mean 100 episode ei     | 3.7      |
| mean 100 episode length | 6.58     |
| mean 100 episode reward | 5.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5577   |
| steps                   | 430000   |
| td_erros                | -0.295   |
--------------------------------------
Saving model due to mean reward increase: 4.842 -> 5.0977
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 66500    |
| lives                   | 66500    |
| mean 100 episode ei     | 3.2      |
| mean 100 episode length | 5.67     |
| mean 100 episode reward | 4.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6526   |
| steps                   | 430467   |
| td_erros                | -0.2455  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 66600    |
| lives                   | 66600    |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 7.13     |
| mean 100 episode reward | 5.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6189   |
| steps                   | 431080   |
| td_erros                | -0.2536  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 66700    |
| lives                   | 66700    |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 7.43     |
| mean 100 episode reward | 5.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6136   |
| steps                   | 431723   |
| td_erros                | -0.2978  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 66800    |
| lives                   | 66800    |
| mean 100 episode ei     | 4.4      |
| mean 100 episode length | 7.18     |
| mean 100 episode reward | 4.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6374   |
| steps                   | 432341   |
| td_erros                | -0.2906  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 66900    |
| lives                   | 66900    |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 6.72     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6147   |
| steps                   | 432913   |
| td_erros                | -0.3157  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 67000    |
| lives                   | 67000    |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 6.85     |
| mean 100 episode reward | 4.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6037   |
| steps                   | 433498   |
| td_erros                | -0.3361  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 67100    |
| lives                   | 67100    |
| mean 100 episode ei     | 4.49     |
| mean 100 episode length | 7.25     |
| mean 100 episode reward | 5.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5541   |
| steps                   | 434123   |
| td_erros                | -0.3475  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 67200    |
| lives                   | 67200    |
| mean 100 episode ei     | 4.36     |
| mean 100 episode length | 7.12     |
| mean 100 episode reward | 4.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5505   |
| steps                   | 434735   |
| td_erros                | -0.3489  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 67300    |
| lives                   | 67300    |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 7.28     |
| mean 100 episode reward | 4.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5495   |
| steps                   | 435363   |
| td_erros                | -0.3715  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 67400    |
| lives                   | 67400    |
| mean 100 episode ei     | 4.92     |
| mean 100 episode length | 7.28     |
| mean 100 episode reward | 4.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5666   |
| steps                   | 435991   |
| td_erros                | -0.3536  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 67500    |
| lives                   | 67500    |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 6.66     |
| mean 100 episode reward | 4.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5907   |
| steps                   | 436557   |
| td_erros                | -0.3431  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 67600    |
| lives                   | 67600    |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 6.31     |
| mean 100 episode reward | 5.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6073   |
| steps                   | 437088   |
| td_erros                | -0.3076  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 67700    |
| lives                   | 67700    |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 6.24     |
| mean 100 episode reward | 4.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6221   |
| steps                   | 437612   |
| td_erros                | -0.3023  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 67800    |
| lives                   | 67800    |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 6.52     |
| mean 100 episode reward | 4.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6544   |
| steps                   | 438164   |
| td_erros                | -0.2797  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 67900    |
| lives                   | 67900    |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 6.79     |
| mean 100 episode reward | 4.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.734    |
| steps                   | 438743   |
| td_erros                | -0.2734  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 68000    |
| lives                   | 68000    |
| mean 100 episode ei     | 4.33     |
| mean 100 episode length | 6.93     |
| mean 100 episode reward | 5.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7903   |
| steps                   | 439336   |
| td_erros                | -0.2497  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 68100    |
| lives                   | 68100    |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 6.7      |
| mean 100 episode reward | 4.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8276   |
| steps                   | 439906   |
| td_erros                | -0.2198  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 68200    |
| lives                   | 68200    |
| mean 100 episode ei     | 3.54     |
| mean 100 episode length | 5.96     |
| mean 100 episode reward | 4.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9098   |
| steps                   | 440402   |
| td_erros                | -0.1891  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 68300    |
| lives                   | 68300    |
| mean 100 episode ei     | 3.45     |
| mean 100 episode length | 6.41     |
| mean 100 episode reward | 4.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.915    |
| steps                   | 440943   |
| td_erros                | -0.1774  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 68400    |
| lives                   | 68400    |
| mean 100 episode ei     | 4.4      |
| mean 100 episode length | 7.02     |
| mean 100 episode reward | 5.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8622   |
| steps                   | 441545   |
| td_erros                | -0.2004  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 68500    |
| lives                   | 68500    |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 6.79     |
| mean 100 episode reward | 4.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8079   |
| steps                   | 442124   |
| td_erros                | -0.2006  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 68600    |
| lives                   | 68600    |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 6.78     |
| mean 100 episode reward | 5.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7745   |
| steps                   | 442702   |
| td_erros                | -0.2366  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 68700    |
| lives                   | 68700    |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 6.39     |
| mean 100 episode reward | 5.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.763    |
| steps                   | 443241   |
| td_erros                | -0.2203  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 68800    |
| lives                   | 68800    |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 6.02     |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7496   |
| steps                   | 443743   |
| td_erros                | -0.2412  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 68900    |
| lives                   | 68900    |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 5.94     |
| mean 100 episode reward | 5.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.721    |
| steps                   | 444237   |
| td_erros                | -0.2398  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 69000    |
| lives                   | 69000    |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 6.04     |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6974   |
| steps                   | 444741   |
| td_erros                | -0.2707  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 69100    |
| lives                   | 69100    |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 6.11     |
| mean 100 episode reward | 5.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6946   |
| steps                   | 445252   |
| td_erros                | -0.2831  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 69200    |
| lives                   | 69200    |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 6.38     |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.684    |
| steps                   | 445790   |
| td_erros                | -0.2942  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 69300    |
| lives                   | 69300    |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 6.34     |
| mean 100 episode reward | 4.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6715   |
| steps                   | 446324   |
| td_erros                | -0.3151  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 69400    |
| lives                   | 69400    |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 6.68     |
| mean 100 episode reward | 5        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.659    |
| steps                   | 446892   |
| td_erros                | -0.3231  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 69500    |
| lives                   | 69500    |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 6.43     |
| mean 100 episode reward | 5.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6481   |
| steps                   | 447435   |
| td_erros                | -0.3272  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 69600    |
| lives                   | 69600    |
| mean 100 episode ei     | 4.81     |
| mean 100 episode length | 6.88     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6653   |
| steps                   | 448023   |
| td_erros                | -0.3331  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 69700    |
| lives                   | 69700    |
| mean 100 episode ei     | 3.11     |
| mean 100 episode length | 5.27     |
| mean 100 episode reward | 3.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6634   |
| steps                   | 448450   |
| td_erros                | -0.3443  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 69800    |
| lives                   | 69800    |
| mean 100 episode ei     | 3.32     |
| mean 100 episode length | 5.66     |
| mean 100 episode reward | 4.57     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6288   |
| steps                   | 448916   |
| td_erros                | -0.3079  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 69900    |
| lives                   | 69900    |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 6.14     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6189   |
| steps                   | 449430   |
| td_erros                | -0.318   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 70000    |
| lives                   | 70000    |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 5.95     |
| mean 100 episode reward | 5.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6443   |
| steps                   | 449925   |
| td_erros                | -0.3173  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 70100    |
| lives                   | 70100    |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 5.99     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6293   |
| steps                   | 450424   |
| td_erros                | -0.3121  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 70200    |
| lives                   | 70200    |
| mean 100 episode ei     | 4.32     |
| mean 100 episode length | 6.37     |
| mean 100 episode reward | 4.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6081   |
| steps                   | 450961   |
| td_erros                | -0.3187  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 70300    |
| lives                   | 70300    |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 4.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.606    |
| steps                   | 451422   |
| td_erros                | -0.3241  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 70400    |
| lives                   | 70400    |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.78     |
| mean 100 episode reward | 4.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.596    |
| steps                   | 451900   |
| td_erros                | -0.3257  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 70500    |
| lives                   | 70500    |
| mean 100 episode ei     | 4.35     |
| mean 100 episode length | 5.5      |
| mean 100 episode reward | 3.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6426   |
| steps                   | 452350   |
| td_erros                | -0.35    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 70600    |
| lives                   | 70600    |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 4.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6375   |
| steps                   | 452794   |
| td_erros                | -0.3208  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 70700    |
| lives                   | 70700    |
| mean 100 episode ei     | 3.79     |
| mean 100 episode length | 5.71     |
| mean 100 episode reward | 5.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6721   |
| steps                   | 453265   |
| td_erros                | -0.3386  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 70800    |
| lives                   | 70800    |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 5.38     |
| mean 100 episode reward | 4.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6568   |
| steps                   | 453703   |
| td_erros                | -0.3519  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 70900    |
| lives                   | 70900    |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 5.11     |
| mean 100 episode reward | 5.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6457   |
| steps                   | 454114   |
| td_erros                | -0.356   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 71000    |
| lives                   | 71000    |
| mean 100 episode ei     | 3.57     |
| mean 100 episode length | 5.34     |
| mean 100 episode reward | 4.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.643    |
| steps                   | 454548   |
| td_erros                | -0.3546  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 71100    |
| lives                   | 71100    |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.9      |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.603    |
| steps                   | 455038   |
| td_erros                | -0.3431  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 71200    |
| lives                   | 71200    |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 4.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6406   |
| steps                   | 455498   |
| td_erros                | -0.3244  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 71300    |
| lives                   | 71300    |
| mean 100 episode ei     | 3.16     |
| mean 100 episode length | 5.49     |
| mean 100 episode reward | 3.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6486   |
| steps                   | 455947   |
| td_erros                | -0.2839  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 71400    |
| lives                   | 71400    |
| mean 100 episode ei     | 3.66     |
| mean 100 episode length | 6.13     |
| mean 100 episode reward | 5.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6052   |
| steps                   | 456460   |
| td_erros                | -0.2976  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 71500    |
| lives                   | 71500    |
| mean 100 episode ei     | 3.71     |
| mean 100 episode length | 5.86     |
| mean 100 episode reward | 4.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6133   |
| steps                   | 456946   |
| td_erros                | -0.2934  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 71600    |
| lives                   | 71600    |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 5.91     |
| mean 100 episode reward | 5.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.611    |
| steps                   | 457437   |
| td_erros                | -0.2764  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 71700    |
| lives                   | 71700    |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 6.37     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5557   |
| steps                   | 457974   |
| td_erros                | -0.3101  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 71800    |
| lives                   | 71800    |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 6.04     |
| mean 100 episode reward | 4.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5855   |
| steps                   | 458478   |
| td_erros                | -0.3249  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 71900    |
| lives                   | 71900    |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 5.86     |
| mean 100 episode reward | 5.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.569    |
| steps                   | 458964   |
| td_erros                | -0.3204  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 72000    |
| lives                   | 72000    |
| mean 100 episode ei     | 3.69     |
| mean 100 episode length | 5.73     |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5414   |
| steps                   | 459437   |
| td_erros                | -0.3194  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 72100    |
| lives                   | 72100    |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 5.85     |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.542    |
| steps                   | 459922   |
| td_erros                | -0.3127  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 72200    |
| lives                   | 72200    |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.87     |
| mean 100 episode reward | 5.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5378   |
| steps                   | 460409   |
| td_erros                | -0.3102  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 72300    |
| lives                   | 72300    |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 5.77     |
| mean 100 episode reward | 5.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5605   |
| steps                   | 460886   |
| td_erros                | -0.3056  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 72400    |
| lives                   | 72400    |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 5.85     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5696   |
| steps                   | 461371   |
| td_erros                | -0.346   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 72500    |
| lives                   | 72500    |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 5.9      |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5979   |
| steps                   | 461861   |
| td_erros                | -0.3426  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 72600    |
| lives                   | 72600    |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 5.88     |
| mean 100 episode reward | 4.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5908   |
| steps                   | 462349   |
| td_erros                | -0.3317  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 72700    |
| lives                   | 72700    |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.9      |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6023   |
| steps                   | 462839   |
| td_erros                | -0.3263  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 72800    |
| lives                   | 72800    |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 6.21     |
| mean 100 episode reward | 5.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5881   |
| steps                   | 463360   |
| td_erros                | -0.3256  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 72900    |
| lives                   | 72900    |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 6.17     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6068   |
| steps                   | 463877   |
| td_erros                | -0.3307  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 73000    |
| lives                   | 73000    |
| mean 100 episode ei     | 3.55     |
| mean 100 episode length | 5.73     |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5888   |
| steps                   | 464350   |
| td_erros                | -0.3238  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 73100    |
| lives                   | 73100    |
| mean 100 episode ei     | 3.1      |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 4.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5966   |
| steps                   | 464794   |
| td_erros                | -0.3279  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 73200    |
| lives                   | 73200    |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 5.81     |
| mean 100 episode reward | 4.99     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5767   |
| steps                   | 465275   |
| td_erros                | -0.3462  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 73300    |
| lives                   | 73300    |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.83     |
| mean 100 episode reward | 5        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.578    |
| steps                   | 465758   |
| td_erros                | -0.375   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 73400    |
| lives                   | 73400    |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.7      |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5553   |
| steps                   | 466228   |
| td_erros                | -0.3685  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 73500    |
| lives                   | 73500    |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 5.83     |
| mean 100 episode reward | 5.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5555   |
| steps                   | 466711   |
| td_erros                | -0.3648  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 73600    |
| lives                   | 73600    |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 6.02     |
| mean 100 episode reward | 5.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5676   |
| steps                   | 467213   |
| td_erros                | -0.3918  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 73700    |
| lives                   | 73700    |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 6.31     |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5731   |
| steps                   | 467744   |
| td_erros                | -0.3821  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 73800    |
| lives                   | 73800    |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 6.44     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5383   |
| steps                   | 468288   |
| td_erros                | -0.3831  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 73900    |
| lives                   | 73900    |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 6.4      |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.571    |
| steps                   | 468828   |
| td_erros                | -0.382   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 74000    |
| lives                   | 74000    |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 6.57     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5717   |
| steps                   | 469385   |
| td_erros                | -0.3861  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 74100    |
| lives                   | 74100    |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 6.59     |
| mean 100 episode reward | 5.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5583   |
| steps                   | 469944   |
| td_erros                | -0.3818  |
--------------------------------------
Saving model due to mean reward increase: 5.0977 -> 5.6247
Saving model due to running mean reward increase: 5.4969 -> 5.6247
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 74200    |
| lives                   | 74200    |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 6.64     |
| mean 100 episode reward | 5.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5689   |
| steps                   | 470508   |
| td_erros                | -0.403   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 74300    |
| lives                   | 74300    |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 6.32     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5388   |
| steps                   | 471040   |
| td_erros                | -0.3832  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 74400    |
| lives                   | 74400    |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 5.9      |
| mean 100 episode reward | 5.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5288   |
| steps                   | 471530   |
| td_erros                | -0.3889  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 74500    |
| lives                   | 74500    |
| mean 100 episode ei     | 3.8      |
| mean 100 episode length | 5.8      |
| mean 100 episode reward | 5.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5464   |
| steps                   | 472010   |
| td_erros                | -0.3956  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 74600    |
| lives                   | 74600    |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 5.85     |
| mean 100 episode reward | 5.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5397   |
| steps                   | 472495   |
| td_erros                | -0.382   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 74700    |
| lives                   | 74700    |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 6.06     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5194   |
| steps                   | 473001   |
| td_erros                | -0.3951  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 74800    |
| lives                   | 74800    |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 6.02     |
| mean 100 episode reward | 5.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5397   |
| steps                   | 473503   |
| td_erros                | -0.4278  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 74900    |
| lives                   | 74900    |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.89     |
| mean 100 episode reward | 5.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5275   |
| steps                   | 473992   |
| td_erros                | -0.4571  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 75000    |
| lives                   | 75000    |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 6.01     |
| mean 100 episode reward | 4.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5212   |
| steps                   | 474493   |
| td_erros                | -0.4754  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 75100    |
| lives                   | 75100    |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 6.05     |
| mean 100 episode reward | 4.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5551   |
| steps                   | 474998   |
| td_erros                | -0.491   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 75200    |
| lives                   | 75200    |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5527   |
| steps                   | 475459   |
| td_erros                | -0.4814  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 75300    |
| lives                   | 75300    |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 5.69     |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5596   |
| steps                   | 475928   |
| td_erros                | -0.4805  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 75400    |
| lives                   | 75400    |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.89     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5821   |
| steps                   | 476417   |
| td_erros                | -0.4878  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 75500    |
| lives                   | 75500    |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 6.36     |
| mean 100 episode reward | 5.57     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.585    |
| steps                   | 476953   |
| td_erros                | -0.4856  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 75600    |
| lives                   | 75600    |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 6.12     |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5811   |
| steps                   | 477465   |
| td_erros                | -0.4591  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 75700    |
| lives                   | 75700    |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 6.02     |
| mean 100 episode reward | 5.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5749   |
| steps                   | 477967   |
| td_erros                | -0.4584  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 75800    |
| lives                   | 75800    |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 6.03     |
| mean 100 episode reward | 5.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5839   |
| steps                   | 478470   |
| td_erros                | -0.4588  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 75900    |
| lives                   | 75900    |
| mean 100 episode ei     | 3.38     |
| mean 100 episode length | 5.69     |
| mean 100 episode reward | 4.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5923   |
| steps                   | 478939   |
| td_erros                | -0.4496  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 76000    |
| lives                   | 76000    |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 6.34     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5796   |
| steps                   | 479473   |
| td_erros                | -0.4149  |
--------------------------------------
Saving model due to running mean reward increase: 5.407 -> 5.4898
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 76100    |
| lives                   | 76100    |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 6.89     |
| mean 100 episode reward | 5.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5321   |
| steps                   | 480062   |
| td_erros                | -0.4031  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 76200    |
| lives                   | 76200    |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 6.58     |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.487    |
| steps                   | 480620   |
| td_erros                | -0.389   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 76300    |
| lives                   | 76300    |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 6.17     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4493   |
| steps                   | 481137   |
| td_erros                | -0.3788  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 76400    |
| lives                   | 76400    |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 6.09     |
| mean 100 episode reward | 5.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.438    |
| steps                   | 481646   |
| td_erros                | -0.3898  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 76500    |
| lives                   | 76500    |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.56     |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4729   |
| steps                   | 482102   |
| td_erros                | -0.409   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 76600    |
| lives                   | 76600    |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 5.53     |
| mean 100 episode reward | 5.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4973   |
| steps                   | 482555   |
| td_erros                | -0.4281  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 76700    |
| lives                   | 76700    |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4905   |
| steps                   | 483015   |
| td_erros                | -0.4198  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 76800    |
| lives                   | 76800    |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.73     |
| mean 100 episode reward | 5.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5038   |
| steps                   | 483488   |
| td_erros                | -0.4166  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 76900    |
| lives                   | 76900    |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 4.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5382   |
| steps                   | 483950   |
| td_erros                | -0.437   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 77000    |
| lives                   | 77000    |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.74     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5847   |
| steps                   | 484424   |
| td_erros                | -0.452   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 77100    |
| lives                   | 77100    |
| mean 100 episode ei     | 3.83     |
| mean 100 episode length | 5.75     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6454   |
| steps                   | 484899   |
| td_erros                | -0.4429  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 77200    |
| lives                   | 77200    |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 6        |
| mean 100 episode reward | 5.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6757   |
| steps                   | 485399   |
| td_erros                | -0.4165  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 77300    |
| lives                   | 77300    |
| mean 100 episode ei     | 4.36     |
| mean 100 episode length | 6.4      |
| mean 100 episode reward | 5.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7065   |
| steps                   | 485939   |
| td_erros                | -0.4485  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 77400    |
| lives                   | 77400    |
| mean 100 episode ei     | 4.32     |
| mean 100 episode length | 6.47     |
| mean 100 episode reward | 6.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7104   |
| steps                   | 486486   |
| td_erros                | -0.4245  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 77500    |
| lives                   | 77500    |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 6.34     |
| mean 100 episode reward | 5.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7282   |
| steps                   | 487020   |
| td_erros                | -0.4503  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 77600    |
| lives                   | 77600    |
| mean 100 episode ei     | 3.16     |
| mean 100 episode length | 5.88     |
| mean 100 episode reward | 5.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6818   |
| steps                   | 487508   |
| td_erros                | -0.3997  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 77700    |
| lives                   | 77700    |
| mean 100 episode ei     | 3.64     |
| mean 100 episode length | 5.74     |
| mean 100 episode reward | 5.69     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6594   |
| steps                   | 487982   |
| td_erros                | -0.3825  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 77800    |
| lives                   | 77800    |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.66     |
| mean 100 episode reward | 6.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6503   |
| steps                   | 488448   |
| td_erros                | -0.36    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 77900    |
| lives                   | 77900    |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6426   |
| steps                   | 488907   |
| td_erros                | -0.3524  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 78000    |
| lives                   | 78000    |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.91     |
| mean 100 episode reward | 5.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.663    |
| steps                   | 489398   |
| td_erros                | -0.3501  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 78100    |
| lives                   | 78100    |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 5.72     |
| mean 100 episode reward | 5.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.636    |
| steps                   | 489870   |
| td_erros                | -0.3644  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 78200    |
| lives                   | 78200    |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 6.19     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6358   |
| steps                   | 490389   |
| td_erros                | -0.3462  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 78300    |
| lives                   | 78300    |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.68     |
| mean 100 episode reward | 4.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6137   |
| steps                   | 490857   |
| td_erros                | -0.3522  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 78400    |
| lives                   | 78400    |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.32     |
| mean 100 episode reward | 4.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.628    |
| steps                   | 491289   |
| td_erros                | -0.3616  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 78500    |
| lives                   | 78500    |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 5.33     |
| mean 100 episode reward | 5.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6235   |
| steps                   | 491722   |
| td_erros                | -0.3741  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 78600    |
| lives                   | 78600    |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 5.32     |
| mean 100 episode reward | 4.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6547   |
| steps                   | 492154   |
| td_erros                | -0.3719  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 78700    |
| lives                   | 78700    |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.33     |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6798   |
| steps                   | 492587   |
| td_erros                | -0.3762  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 78800    |
| lives                   | 78800    |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 5.27     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6935   |
| steps                   | 493014   |
| td_erros                | -0.3971  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 78900    |
| lives                   | 78900    |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.71     |
| mean 100 episode reward | 4.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7035   |
| steps                   | 493485   |
| td_erros                | -0.4103  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 79000    |
| lives                   | 79000    |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 5.94     |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6896   |
| steps                   | 493979   |
| td_erros                | -0.4199  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 79100    |
| lives                   | 79100    |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.9      |
| mean 100 episode reward | 5.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6806   |
| steps                   | 494469   |
| td_erros                | -0.4221  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 79200    |
| lives                   | 79200    |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 5.68     |
| mean 100 episode reward | 5.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7104   |
| steps                   | 494937   |
| td_erros                | -0.4307  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 79300    |
| lives                   | 79300    |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.7      |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.712    |
| steps                   | 495407   |
| td_erros                | -0.4146  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 79400    |
| lives                   | 79400    |
| mean 100 episode ei     | 3.35     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6829   |
| steps                   | 495851   |
| td_erros                | -0.4166  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 79500    |
| lives                   | 79500    |
| mean 100 episode ei     | 3.38     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6962   |
| steps                   | 496313   |
| td_erros                | -0.3902  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 79600    |
| lives                   | 79600    |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 5.53     |
| mean 100 episode reward | 4.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6712   |
| steps                   | 496766   |
| td_erros                | -0.3777  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 79700    |
| lives                   | 79700    |
| mean 100 episode ei     | 3.83     |
| mean 100 episode length | 5.51     |
| mean 100 episode reward | 5.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6463   |
| steps                   | 497217   |
| td_erros                | -0.3949  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 79800    |
| lives                   | 79800    |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6197   |
| steps                   | 497659   |
| td_erros                | -0.37    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 79900    |
| lives                   | 79900    |
| mean 100 episode ei     | 3.64     |
| mean 100 episode length | 5.46     |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6117   |
| steps                   | 498105   |
| td_erros                | -0.358   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 80000    |
| lives                   | 80000    |
| mean 100 episode ei     | 3.64     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6173   |
| steps                   | 498548   |
| td_erros                | -0.3662  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 80100    |
| lives                   | 80100    |
| mean 100 episode ei     | 3.69     |
| mean 100 episode length | 5.75     |
| mean 100 episode reward | 5.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6133   |
| steps                   | 499023   |
| td_erros                | -0.3268  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 80200    |
| lives                   | 80200    |
| mean 100 episode ei     | 3.68     |
| mean 100 episode length | 5.52     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5952   |
| steps                   | 499475   |
| td_erros                | -0.3349  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 80300    |
| lives                   | 80300    |
| mean 100 episode ei     | 3.41     |
| mean 100 episode length | 5.31     |
| mean 100 episode reward | 5.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5754   |
| steps                   | 499906   |
| td_erros                | -0.2941  |
--------------------------------------
Saving model due to running mean reward increase: 5.129 -> 5.2713
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 80400    |
| lives                   | 80400    |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.56     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5545   |
| steps                   | 500362   |
| td_erros                | -0.2944  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 80500    |
| lives                   | 80500    |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 5.76     |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5254   |
| steps                   | 500838   |
| td_erros                | -0.3192  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 80600    |
| lives                   | 80600    |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 5.72     |
| mean 100 episode reward | 5        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4953   |
| steps                   | 501310   |
| td_erros                | -0.364   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 80700    |
| lives                   | 80700    |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.52     |
| mean 100 episode reward | 4.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4801   |
| steps                   | 501762   |
| td_erros                | -0.4046  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 80800    |
| lives                   | 80800    |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4988   |
| steps                   | 502205   |
| td_erros                | -0.4116  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 80900    |
| lives                   | 80900    |
| mean 100 episode ei     | 3.62     |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 5.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4945   |
| steps                   | 502663   |
| td_erros                | -0.3811  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 81000    |
| lives                   | 81000    |
| mean 100 episode ei     | 3.6      |
| mean 100 episode length | 5.89     |
| mean 100 episode reward | 5.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4758   |
| steps                   | 503152   |
| td_erros                | -0.3568  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 81100    |
| lives                   | 81100    |
| mean 100 episode ei     | 3.54     |
| mean 100 episode length | 5.81     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.47     |
| steps                   | 503633   |
| td_erros                | -0.3477  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 81200    |
| lives                   | 81200    |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 5.66     |
| mean 100 episode reward | 5.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4548   |
| steps                   | 504099   |
| td_erros                | -0.3637  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 81300    |
| lives                   | 81300    |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 5.82     |
| mean 100 episode reward | 5.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5041   |
| steps                   | 504581   |
| td_erros                | -0.4289  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 81400    |
| lives                   | 81400    |
| mean 100 episode ei     | 3.67     |
| mean 100 episode length | 5.66     |
| mean 100 episode reward | 5.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5268   |
| steps                   | 505047   |
| td_erros                | -0.4046  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 81500    |
| lives                   | 81500    |
| mean 100 episode ei     | 3.54     |
| mean 100 episode length | 5.97     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5007   |
| steps                   | 505544   |
| td_erros                | -0.3495  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 81600    |
| lives                   | 81600    |
| mean 100 episode ei     | 2.89     |
| mean 100 episode length | 5.37     |
| mean 100 episode reward | 5.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4633   |
| steps                   | 505981   |
| td_erros                | -0.31    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 81700    |
| lives                   | 81700    |
| mean 100 episode ei     | 3.18     |
| mean 100 episode length | 5.5      |
| mean 100 episode reward | 5.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4652   |
| steps                   | 506431   |
| td_erros                | -0.2802  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 81800    |
| lives                   | 81800    |
| mean 100 episode ei     | 3.72     |
| mean 100 episode length | 5.49     |
| mean 100 episode reward | 5.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.435    |
| steps                   | 506880   |
| td_erros                | -0.3042  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 81900    |
| lives                   | 81900    |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 4.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3975   |
| steps                   | 507321   |
| td_erros                | -0.3062  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 82000    |
| lives                   | 82000    |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 5.33     |
| mean 100 episode reward | 4.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3705   |
| steps                   | 507754   |
| td_erros                | -0.3523  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 82100    |
| lives                   | 82100    |
| mean 100 episode ei     | 4.46     |
| mean 100 episode length | 5.37     |
| mean 100 episode reward | 4.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3604   |
| steps                   | 508191   |
| td_erros                | -0.3952  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 82200    |
| lives                   | 82200    |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3917   |
| steps                   | 508632   |
| td_erros                | -0.3995  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 82300    |
| lives                   | 82300    |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 5.5      |
| mean 100 episode reward | 5.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.451    |
| steps                   | 509082   |
| td_erros                | -0.3457  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 82400    |
| lives                   | 82400    |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4845   |
| steps                   | 509542   |
| td_erros                | -0.3168  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 82500    |
| lives                   | 82500    |
| mean 100 episode ei     | 3.57     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5226   |
| steps                   | 509983   |
| td_erros                | -0.3002  |
--------------------------------------
Saving model due to running mean reward increase: 5.3045 -> 5.3162
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 82600    |
| lives                   | 82600    |
| mean 100 episode ei     | 3.57     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 5.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.585    |
| steps                   | 510427   |
| td_erros                | -0.2963  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 82700    |
| lives                   | 82700    |
| mean 100 episode ei     | 3.52     |
| mean 100 episode length | 5.48     |
| mean 100 episode reward | 5.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6652   |
| steps                   | 510875   |
| td_erros                | -0.3054  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 82800    |
| lives                   | 82800    |
| mean 100 episode ei     | 3.47     |
| mean 100 episode length | 5.15     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7078   |
| steps                   | 511290   |
| td_erros                | -0.3265  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 82900    |
| lives                   | 82900    |
| mean 100 episode ei     | 3.39     |
| mean 100 episode length | 4.85     |
| mean 100 episode reward | 4.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.803    |
| steps                   | 511675   |
| td_erros                | -0.3122  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 83000    |
| lives                   | 83000    |
| mean 100 episode ei     | 3.47     |
| mean 100 episode length | 5        |
| mean 100 episode reward | 4.96     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8578   |
| steps                   | 512075   |
| td_erros                | -0.2461  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 83100    |
| lives                   | 83100    |
| mean 100 episode ei     | 3.56     |
| mean 100 episode length | 5.3      |
| mean 100 episode reward | 5.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8844   |
| steps                   | 512505   |
| td_erros                | -0.2412  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 83200    |
| lives                   | 83200    |
| mean 100 episode ei     | 3.66     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8962   |
| steps                   | 512968   |
| td_erros                | -0.2495  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 83300    |
| lives                   | 83300    |
| mean 100 episode ei     | 3.6      |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8553   |
| steps                   | 513428   |
| td_erros                | -0.2447  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 83400    |
| lives                   | 83400    |
| mean 100 episode ei     | 3.5      |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7818   |
| steps                   | 513891   |
| td_erros                | -0.2519  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 83500    |
| lives                   | 83500    |
| mean 100 episode ei     | 3.79     |
| mean 100 episode length | 5.7      |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6876   |
| steps                   | 514361   |
| td_erros                | -0.2232  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 83600    |
| lives                   | 83600    |
| mean 100 episode ei     | 4.72     |
| mean 100 episode length | 6.02     |
| mean 100 episode reward | 4.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.613    |
| steps                   | 514863   |
| td_erros                | -0.2672  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 83700    |
| lives                   | 83700    |
| mean 100 episode ei     | 4.71     |
| mean 100 episode length | 5.96     |
| mean 100 episode reward | 4.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5178   |
| steps                   | 515359   |
| td_erros                | -0.319   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 83800    |
| lives                   | 83800    |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 5.98     |
| mean 100 episode reward | 4.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4929   |
| steps                   | 515857   |
| td_erros                | -0.3458  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 83900    |
| lives                   | 83900    |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 5.56     |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5019   |
| steps                   | 516313   |
| td_erros                | -0.3578  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 84000    |
| lives                   | 84000    |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5176   |
| steps                   | 516735   |
| td_erros                | -0.3918  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 84100    |
| lives                   | 84100    |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5387   |
| steps                   | 517155   |
| td_erros                | -0.3988  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 84200    |
| lives                   | 84200    |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 5.17     |
| mean 100 episode reward | 4.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.548    |
| steps                   | 517572   |
| td_erros                | -0.3832  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 84300    |
| lives                   | 84300    |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 5.02     |
| mean 100 episode reward | 4.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6013   |
| steps                   | 517974   |
| td_erros                | -0.3605  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 84400    |
| lives                   | 84400    |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 5.31     |
| mean 100 episode reward | 4.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6696   |
| steps                   | 518405   |
| td_erros                | -0.3056  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 84500    |
| lives                   | 84500    |
| mean 100 episode ei     | 3.41     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7202   |
| steps                   | 518826   |
| td_erros                | -0.2921  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 84600    |
| lives                   | 84600    |
| mean 100 episode ei     | 3.42     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7723   |
| steps                   | 519247   |
| td_erros                | -0.274   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 84700    |
| lives                   | 84700    |
| mean 100 episode ei     | 3.43     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8209   |
| steps                   | 519669   |
| td_erros                | -0.2945  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 84800    |
| lives                   | 84800    |
| mean 100 episode ei     | 3.62     |
| mean 100 episode length | 5.32     |
| mean 100 episode reward | 4.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.825    |
| steps                   | 520101   |
| td_erros                | -0.2812  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 84900    |
| lives                   | 84900    |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.67     |
| mean 100 episode reward | 4.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8339   |
| steps                   | 520568   |
| td_erros                | -0.2829  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 85000    |
| lives                   | 85000    |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.98     |
| mean 100 episode reward | 4.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8105   |
| steps                   | 521066   |
| td_erros                | -0.2658  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 85100    |
| lives                   | 85100    |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 6.14     |
| mean 100 episode reward | 4.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7578   |
| steps                   | 521580   |
| td_erros                | -0.2458  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 85200    |
| lives                   | 85200    |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 6.06     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7008   |
| steps                   | 522086   |
| td_erros                | -0.2417  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 85300    |
| lives                   | 85300    |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.73     |
| mean 100 episode reward | 4.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6602   |
| steps                   | 522559   |
| td_erros                | -0.2358  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 85400    |
| lives                   | 85400    |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 5.98     |
| mean 100 episode reward | 4.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6597   |
| steps                   | 523057   |
| td_erros                | -0.268   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 85500    |
| lives                   | 85500    |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 5.93     |
| mean 100 episode reward | 5.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6905   |
| steps                   | 523550   |
| td_erros                | -0.2847  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 85600    |
| lives                   | 85600    |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6996   |
| steps                   | 524015   |
| td_erros                | -0.3233  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 85700    |
| lives                   | 85700    |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 4.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7423   |
| steps                   | 524457   |
| td_erros                | -0.3281  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 85800    |
| lives                   | 85800    |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.47     |
| mean 100 episode reward | 4.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7647   |
| steps                   | 524904   |
| td_erros                | -0.3402  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 85900    |
| lives                   | 85900    |
| mean 100 episode ei     | 3.57     |
| mean 100 episode length | 5.38     |
| mean 100 episode reward | 4.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7799   |
| steps                   | 525342   |
| td_erros                | -0.3334  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 86000    |
| lives                   | 86000    |
| mean 100 episode ei     | 3.43     |
| mean 100 episode length | 4.9      |
| mean 100 episode reward | 4.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7815   |
| steps                   | 525732   |
| td_erros                | -0.3189  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 86100    |
| lives                   | 86100    |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 5.36     |
| mean 100 episode reward | 5.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7973   |
| steps                   | 526168   |
| td_erros                | -0.337   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 86200    |
| lives                   | 86200    |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 5.91     |
| mean 100 episode reward | 5.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7771   |
| steps                   | 526659   |
| td_erros                | -0.3362  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 86300    |
| lives                   | 86300    |
| mean 100 episode ei     | 4.23     |
| mean 100 episode length | 6.02     |
| mean 100 episode reward | 5.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8072   |
| steps                   | 527161   |
| td_erros                | -0.3496  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 86400    |
| lives                   | 86400    |
| mean 100 episode ei     | 4.43     |
| mean 100 episode length | 6.02     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8107   |
| steps                   | 527663   |
| td_erros                | -0.3207  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 86500    |
| lives                   | 86500    |
| mean 100 episode ei     | 4.43     |
| mean 100 episode length | 6.17     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8321   |
| steps                   | 528180   |
| td_erros                | -0.3371  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 86600    |
| lives                   | 86600    |
| mean 100 episode ei     | 4.32     |
| mean 100 episode length | 6.23     |
| mean 100 episode reward | 5.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.852    |
| steps                   | 528703   |
| td_erros                | -0.3171  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 86700    |
| lives                   | 86700    |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 6.13     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8761   |
| steps                   | 529216   |
| td_erros                | -0.2989  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 86800    |
| lives                   | 86800    |
| mean 100 episode ei     | 3.58     |
| mean 100 episode length | 5.49     |
| mean 100 episode reward | 4.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.873    |
| steps                   | 529665   |
| td_erros                | -0.3062  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 86900    |
| lives                   | 86900    |
| mean 100 episode ei     | 3.12     |
| mean 100 episode length | 4.84     |
| mean 100 episode reward | 3.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9181   |
| steps                   | 530049   |
| td_erros                | -0.2317  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 87000    |
| lives                   | 87000    |
| mean 100 episode ei     | 3.4      |
| mean 100 episode length | 5.04     |
| mean 100 episode reward | 3.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8904   |
| steps                   | 530453   |
| td_erros                | -0.229   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 87100    |
| lives                   | 87100    |
| mean 100 episode ei     | 3.66     |
| mean 100 episode length | 5.37     |
| mean 100 episode reward | 3.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.872    |
| steps                   | 530890   |
| td_erros                | -0.2409  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 87200    |
| lives                   | 87200    |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 4.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.876    |
| steps                   | 531352   |
| td_erros                | -0.2589  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 87300    |
| lives                   | 87300    |
| mean 100 episode ei     | 4.72     |
| mean 100 episode length | 6.25     |
| mean 100 episode reward | 5.69     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8596   |
| steps                   | 531877   |
| td_erros                | -0.3199  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 87400    |
| lives                   | 87400    |
| mean 100 episode ei     | 4.41     |
| mean 100 episode length | 6.12     |
| mean 100 episode reward | 5.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8234   |
| steps                   | 532389   |
| td_erros                | -0.3561  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 87500    |
| lives                   | 87500    |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.96     |
| mean 100 episode reward | 5.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8213   |
| steps                   | 532885   |
| td_erros                | -0.3938  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 87600    |
| lives                   | 87600    |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.28     |
| mean 100 episode reward | 4.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8448   |
| steps                   | 533313   |
| td_erros                | -0.398   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 87700    |
| lives                   | 87700    |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.17     |
| mean 100 episode reward | 4.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8308   |
| steps                   | 533730   |
| td_erros                | -0.3882  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 87800    |
| lives                   | 87800    |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.46     |
| mean 100 episode reward | 4.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7899   |
| steps                   | 534176   |
| td_erros                | -0.3775  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 87900    |
| lives                   | 87900    |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.754    |
| steps                   | 534618   |
| td_erros                | -0.3976  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 88000    |
| lives                   | 88000    |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7767   |
| steps                   | 535058   |
| td_erros                | -0.4396  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 88100    |
| lives                   | 88100    |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8286   |
| steps                   | 535499   |
| td_erros                | -0.4457  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 88200    |
| lives                   | 88200    |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9131   |
| steps                   | 535942   |
| td_erros                | -0.3858  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 88300    |
| lives                   | 88300    |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 4.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.95     |
| steps                   | 536404   |
| td_erros                | -0.3383  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 88400    |
| lives                   | 88400    |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.71     |
| mean 100 episode reward | 4.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9692   |
| steps                   | 536875   |
| td_erros                | -0.3237  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 88500    |
| lives                   | 88500    |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.95     |
| mean 100 episode reward | 4.57     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9246   |
| steps                   | 537370   |
| td_erros                | -0.3016  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 88600    |
| lives                   | 88600    |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.77     |
| mean 100 episode reward | 4.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8856   |
| steps                   | 537847   |
| td_erros                | -0.3552  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 88700    |
| lives                   | 88700    |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.81     |
| mean 100 episode reward | 4.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8365   |
| steps                   | 538328   |
| td_erros                | -0.4294  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 88800    |
| lives                   | 88800    |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 5.81     |
| mean 100 episode reward | 4.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.768    |
| steps                   | 538809   |
| td_erros                | -0.4723  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 88900    |
| lives                   | 88900    |
| mean 100 episode ei     | 4.21     |
| mean 100 episode length | 5.82     |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.746    |
| steps                   | 539291   |
| td_erros                | -0.5486  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 89000    |
| lives                   | 89000    |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 5.54     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7243   |
| steps                   | 539745   |
| td_erros                | -0.5819  |
--------------------------------------
Saving model due to running mean reward increase: 5.0509 -> 5.2248
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 89100    |
| lives                   | 89100    |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 5.52     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7043   |
| steps                   | 540197   |
| td_erros                | -0.6059  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 89200    |
| lives                   | 89200    |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7094   |
| steps                   | 540638   |
| td_erros                | -0.6674  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 89300    |
| lives                   | 89300    |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6979   |
| steps                   | 541078   |
| td_erros                | -0.7132  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 89400    |
| lives                   | 89400    |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6786   |
| steps                   | 541520   |
| td_erros                | -0.7495  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 89500    |
| lives                   | 89500    |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6883   |
| steps                   | 541978   |
| td_erros                | -0.7577  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 89600    |
| lives                   | 89600    |
| mean 100 episode ei     | 4.36     |
| mean 100 episode length | 5.76     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6503   |
| steps                   | 542454   |
| td_erros                | -0.7637  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 89700    |
| lives                   | 89700    |
| mean 100 episode ei     | 4.21     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6681   |
| steps                   | 542895   |
| td_erros                | -0.7999  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 89800    |
| lives                   | 89800    |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.45     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6591   |
| steps                   | 543340   |
| td_erros                | -0.8041  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 89900    |
| lives                   | 89900    |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 5        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6891   |
| steps                   | 543784   |
| td_erros                | -0.7745  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 90000    |
| lives                   | 90000    |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 5.67     |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6956   |
| steps                   | 544251   |
| td_erros                | -0.7619  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 90100    |
| lives                   | 90100    |
| mean 100 episode ei     | 4.21     |
| mean 100 episode length | 5.93     |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7238   |
| steps                   | 544744   |
| td_erros                | -0.7232  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 90200    |
| lives                   | 90200    |
| mean 100 episode ei     | 4.47     |
| mean 100 episode length | 6.14     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7343   |
| steps                   | 545258   |
| td_erros                | -0.6804  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 90300    |
| lives                   | 90300    |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 6.24     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7509   |
| steps                   | 545782   |
| td_erros                | -0.6256  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 90400    |
| lives                   | 90400    |
| mean 100 episode ei     | 4.95     |
| mean 100 episode length | 6.43     |
| mean 100 episode reward | 5.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.774    |
| steps                   | 546325   |
| td_erros                | -0.5924  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 90500    |
| lives                   | 90500    |
| mean 100 episode ei     | 4.32     |
| mean 100 episode length | 5.66     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8047   |
| steps                   | 546791   |
| td_erros                | -0.5723  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 90600    |
| lives                   | 90600    |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8543   |
| steps                   | 547214   |
| td_erros                | -0.4955  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 90700    |
| lives                   | 90700    |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8934   |
| steps                   | 547635   |
| td_erros                | -0.4972  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 90800    |
| lives                   | 90800    |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 5.28     |
| mean 100 episode reward | 4.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9261   |
| steps                   | 548063   |
| td_erros                | -0.4669  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 90900    |
| lives                   | 90900    |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 5.54     |
| mean 100 episode reward | 4.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9437   |
| steps                   | 548517   |
| td_erros                | -0.4638  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 91000    |
| lives                   | 91000    |
| mean 100 episode ei     | 4.8      |
| mean 100 episode length | 6.01     |
| mean 100 episode reward | 5.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9456   |
| steps                   | 549018   |
| td_erros                | -0.493   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 91100    |
| lives                   | 91100    |
| mean 100 episode ei     | 4.7      |
| mean 100 episode length | 5.97     |
| mean 100 episode reward | 5.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0044   |
| steps                   | 549515   |
| td_erros                | -0.483   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 91200    |
| lives                   | 91200    |
| mean 100 episode ei     | 4.86     |
| mean 100 episode length | 5.84     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0269   |
| steps                   | 549999   |
| td_erros                | -0.4841  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 91300    |
| lives                   | 91300    |
| mean 100 episode ei     | 4.81     |
| mean 100 episode length | 5.82     |
| mean 100 episode reward | 5.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0564   |
| steps                   | 550481   |
| td_erros                | -0.5293  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 91400    |
| lives                   | 91400    |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 5.8      |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0639   |
| steps                   | 550961   |
| td_erros                | -0.5571  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 91500    |
| lives                   | 91500    |
| mean 100 episode ei     | 4.83     |
| mean 100 episode length | 5.96     |
| mean 100 episode reward | 5.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0538   |
| steps                   | 551457   |
| td_erros                | -0.5823  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 91600    |
| lives                   | 91600    |
| mean 100 episode ei     | 4.71     |
| mean 100 episode length | 5.99     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0519   |
| steps                   | 551956   |
| td_erros                | -0.6111  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 91700    |
| lives                   | 91700    |
| mean 100 episode ei     | 4.82     |
| mean 100 episode length | 6.03     |
| mean 100 episode reward | 5.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0565   |
| steps                   | 552459   |
| td_erros                | -0.6679  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 91800    |
| lives                   | 91800    |
| mean 100 episode ei     | 4.85     |
| mean 100 episode length | 5.99     |
| mean 100 episode reward | 5.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0418   |
| steps                   | 552958   |
| td_erros                | -0.6707  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 91900    |
| lives                   | 91900    |
| mean 100 episode ei     | 4.9      |
| mean 100 episode length | 6.01     |
| mean 100 episode reward | 5.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.04     |
| steps                   | 553459   |
| td_erros                | -0.6986  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 92000    |
| lives                   | 92000    |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 5.75     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.045    |
| steps                   | 553934   |
| td_erros                | -0.7561  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 92100    |
| lives                   | 92100    |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 5.83     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0301   |
| steps                   | 554417   |
| td_erros                | -0.7174  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 92200    |
| lives                   | 92200    |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 5.75     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0273   |
| steps                   | 554892   |
| td_erros                | -0.706   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 92300    |
| lives                   | 92300    |
| mean 100 episode ei     | 4.81     |
| mean 100 episode length | 5.88     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9785   |
| steps                   | 555380   |
| td_erros                | -0.717   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 92400    |
| lives                   | 92400    |
| mean 100 episode ei     | 4.96     |
| mean 100 episode length | 6.01     |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9974   |
| steps                   | 555881   |
| td_erros                | -0.733   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 92500    |
| lives                   | 92500    |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 5.72     |
| mean 100 episode reward | 4.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9882   |
| steps                   | 556353   |
| td_erros                | -0.701   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 92600    |
| lives                   | 92600    |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 4.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0134   |
| steps                   | 556818   |
| td_erros                | -0.6743  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 92700    |
| lives                   | 92700    |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 4.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0014   |
| steps                   | 557277   |
| td_erros                | -0.6273  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 92800    |
| lives                   | 92800    |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 5.76     |
| mean 100 episode reward | 4.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9726   |
| steps                   | 557753   |
| td_erros                | -0.6084  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 92900    |
| lives                   | 92900    |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 4.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9545   |
| steps                   | 558216   |
| td_erros                | -0.5742  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 93000    |
| lives                   | 93000    |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.81     |
| mean 100 episode reward | 5.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9435   |
| steps                   | 558697   |
| td_erros                | -0.5792  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 93100    |
| lives                   | 93100    |
| mean 100 episode ei     | 4.88     |
| mean 100 episode length | 5.84     |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9463   |
| steps                   | 559181   |
| td_erros                | -0.5698  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 93200    |
| lives                   | 93200    |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 5.69     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9985   |
| steps                   | 559650   |
| td_erros                | -0.6114  |
--------------------------------------
Saving model due to running mean reward increase: 5.1591 -> 5.283
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 93300    |
| lives                   | 93300    |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0029   |
| steps                   | 560111   |
| td_erros                | -0.6465  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 93400    |
| lives                   | 93400    |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 5.67     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0145   |
| steps                   | 560578   |
| td_erros                | -0.6437  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 93500    |
| lives                   | 93500    |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0215   |
| steps                   | 561038   |
| td_erros                | -0.6532  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 93600    |
| lives                   | 93600    |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0147   |
| steps                   | 561499   |
| td_erros                | -0.722   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 93700    |
| lives                   | 93700    |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0425   |
| steps                   | 561959   |
| td_erros                | -0.7915  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 93800    |
| lives                   | 93800    |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0403   |
| steps                   | 562419   |
| td_erros                | -0.7847  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 93900    |
| lives                   | 93900    |
| mean 100 episode ei     | 4.61     |
| mean 100 episode length | 5.89     |
| mean 100 episode reward | 5.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0441   |
| steps                   | 562908   |
| td_erros                | -0.8448  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 94000    |
| lives                   | 94000    |
| mean 100 episode ei     | 4.21     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0602   |
| steps                   | 563369   |
| td_erros                | -0.9093  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 94100    |
| lives                   | 94100    |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0655   |
| steps                   | 563790   |
| td_erros                | -0.8225  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 94200    |
| lives                   | 94200    |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.28     |
| mean 100 episode reward | 4.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0622   |
| steps                   | 564218   |
| td_erros                | -0.7898  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 94300    |
| lives                   | 94300    |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 4.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0249   |
| steps                   | 564643   |
| td_erros                | -0.768   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 94400    |
| lives                   | 94400    |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0286   |
| steps                   | 565065   |
| td_erros                | -0.7298  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 94500    |
| lives                   | 94500    |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 5.91     |
| mean 100 episode reward | 4.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9939   |
| steps                   | 565556   |
| td_erros                | -0.7011  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 94600    |
| lives                   | 94600    |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 6.35     |
| mean 100 episode reward | 4.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9733   |
| steps                   | 566091   |
| td_erros                | -0.7095  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 94700    |
| lives                   | 94700    |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 6.41     |
| mean 100 episode reward | 4.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8984   |
| steps                   | 566632   |
| td_erros                | -0.6883  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 94800    |
| lives                   | 94800    |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 6.18     |
| mean 100 episode reward | 4.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.875    |
| steps                   | 567150   |
| td_erros                | -0.6688  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 94900    |
| lives                   | 94900    |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 5.95     |
| mean 100 episode reward | 4.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8139   |
| steps                   | 567645   |
| td_erros                | -0.6835  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 95000    |
| lives                   | 95000    |
| mean 100 episode ei     | 4.73     |
| mean 100 episode length | 6.07     |
| mean 100 episode reward | 4.69     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7411   |
| steps                   | 568152   |
| td_erros                | -0.6669  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 95100    |
| lives                   | 95100    |
| mean 100 episode ei     | 4.86     |
| mean 100 episode length | 5.99     |
| mean 100 episode reward | 4.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7016   |
| steps                   | 568651   |
| td_erros                | -0.748   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 95200    |
| lives                   | 95200    |
| mean 100 episode ei     | 4.73     |
| mean 100 episode length | 5.85     |
| mean 100 episode reward | 4.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7351   |
| steps                   | 569136   |
| td_erros                | -0.7883  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 95300    |
| lives                   | 95300    |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.68     |
| mean 100 episode reward | 5.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6993   |
| steps                   | 569604   |
| td_erros                | -0.8112  |
--------------------------------------
Saving model due to running mean reward increase: 5.1019 -> 5.209
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 95400    |
| lives                   | 95400    |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7099   |
| steps                   | 570064   |
| td_erros                | -0.8579  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 95500    |
| lives                   | 95500    |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 5.56     |
| mean 100 episode reward | 5.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7051   |
| steps                   | 570520   |
| td_erros                | -0.9105  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 95600    |
| lives                   | 95600    |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7296   |
| steps                   | 570981   |
| td_erros                | -0.8914  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 95700    |
| lives                   | 95700    |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7148   |
| steps                   | 571441   |
| td_erros                | -0.9344  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 95800    |
| lives                   | 95800    |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7807   |
| steps                   | 571902   |
| td_erros                | -0.9589  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 95900    |
| lives                   | 95900    |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 4.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7959   |
| steps                   | 572326   |
| td_erros                | -0.9328  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 96000    |
| lives                   | 96000    |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8494   |
| steps                   | 572751   |
| td_erros                | -0.8784  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 96100    |
| lives                   | 96100    |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.28     |
| mean 100 episode reward | 4.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8809   |
| steps                   | 573179   |
| td_erros                | -0.8695  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 96200    |
| lives                   | 96200    |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 4.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9297   |
| steps                   | 573639   |
| td_erros                | -0.8448  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 96300    |
| lives                   | 96300    |
| mean 100 episode ei     | 4.24     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 4.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9694   |
| steps                   | 574099   |
| td_erros                | -0.8131  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 96400    |
| lives                   | 96400    |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 5.89     |
| mean 100 episode reward | 4.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9637   |
| steps                   | 574588   |
| td_erros                | -0.7585  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 96500    |
| lives                   | 96500    |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 6.13     |
| mean 100 episode reward | 4.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9322   |
| steps                   | 575101   |
| td_erros                | -0.7078  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 96600    |
| lives                   | 96600    |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 6.39     |
| mean 100 episode reward | 4.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8912   |
| steps                   | 575640   |
| td_erros                | -0.6756  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 96700    |
| lives                   | 96700    |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 6.41     |
| mean 100 episode reward | 4.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8526   |
| steps                   | 576181   |
| td_erros                | -0.6425  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 96800    |
| lives                   | 96800    |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 6.34     |
| mean 100 episode reward | 4.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7724   |
| steps                   | 576715   |
| td_erros                | -0.6388  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 96900    |
| lives                   | 96900    |
| mean 100 episode ei     | 4.61     |
| mean 100 episode length | 6.23     |
| mean 100 episode reward | 4.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.701    |
| steps                   | 577238   |
| td_erros                | -0.6187  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 97000    |
| lives                   | 97000    |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.94     |
| mean 100 episode reward | 4.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.704    |
| steps                   | 577732   |
| td_erros                | -0.6511  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 97100    |
| lives                   | 97100    |
| mean 100 episode ei     | 4.84     |
| mean 100 episode length | 5.91     |
| mean 100 episode reward | 5.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6839   |
| steps                   | 578223   |
| td_erros                | -0.7308  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 97200    |
| lives                   | 97200    |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.693    |
| steps                   | 578682   |
| td_erros                | -0.7801  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 97300    |
| lives                   | 97300    |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6829   |
| steps                   | 579144   |
| td_erros                | -0.8233  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 97400    |
| lives                   | 97400    |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7122   |
| steps                   | 579606   |
| td_erros                | -0.9171  |
--------------------------------------
Saving model due to running mean reward increase: 5.206 -> 5.2421
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 97500    |
| lives                   | 97500    |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7134   |
| steps                   | 580066   |
| td_erros                | -0.9492  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 97600    |
| lives                   | 97600    |
| mean 100 episode ei     | 4.69     |
| mean 100 episode length | 5.75     |
| mean 100 episode reward | 5.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7609   |
| steps                   | 580541   |
| td_erros                | -0.9585  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 97700    |
| lives                   | 97700    |
| mean 100 episode ei     | 4.51     |
| mean 100 episode length | 5.79     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8078   |
| steps                   | 581020   |
| td_erros                | -0.9641  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 97800    |
| lives                   | 97800    |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.12     |
| mean 100 episode reward | 4.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.821    |
| steps                   | 581432   |
| td_erros                | -0.9569  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 97900    |
| lives                   | 97900    |
| mean 100 episode ei     | 4.47     |
| mean 100 episode length | 5.8      |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.863    |
| steps                   | 581912   |
| td_erros                | -0.9364  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 98000    |
| lives                   | 98000    |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 6.09     |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8969   |
| steps                   | 582421   |
| td_erros                | -1.0033  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 98100    |
| lives                   | 98100    |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 5.68     |
| mean 100 episode reward | 4.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8752   |
| steps                   | 582889   |
| td_erros                | -0.9609  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 98200    |
| lives                   | 98200    |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 5.27     |
| mean 100 episode reward | 4.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9076   |
| steps                   | 583316   |
| td_erros                | -0.9163  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 98300    |
| lives                   | 98300    |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 5.91     |
| mean 100 episode reward | 4.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9039   |
| steps                   | 583807   |
| td_erros                | -0.8345  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 98400    |
| lives                   | 98400    |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 6.24     |
| mean 100 episode reward | 3.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8199   |
| steps                   | 584331   |
| td_erros                | -0.7973  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 98500    |
| lives                   | 98500    |
| mean 100 episode ei     | 3.83     |
| mean 100 episode length | 5.96     |
| mean 100 episode reward | 3.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7833   |
| steps                   | 584827   |
| td_erros                | -0.7772  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 98600    |
| lives                   | 98600    |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 6        |
| mean 100 episode reward | 4.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7012   |
| steps                   | 585327   |
| td_erros                | -0.7532  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 98700    |
| lives                   | 98700    |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 6        |
| mean 100 episode reward | 4.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6662   |
| steps                   | 585827   |
| td_erros                | -0.7472  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 98800    |
| lives                   | 98800    |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 6.02     |
| mean 100 episode reward | 4.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6187   |
| steps                   | 586329   |
| td_erros                | -0.7534  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 98900    |
| lives                   | 98900    |
| mean 100 episode ei     | 4.23     |
| mean 100 episode length | 6.01     |
| mean 100 episode reward | 4.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5632   |
| steps                   | 586830   |
| td_erros                | -0.7503  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 99000    |
| lives                   | 99000    |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.97     |
| mean 100 episode reward | 4.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5205   |
| steps                   | 587327   |
| td_erros                | -0.7492  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 99100    |
| lives                   | 99100    |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 6        |
| mean 100 episode reward | 4.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4888   |
| steps                   | 587827   |
| td_erros                | -0.7505  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 99200    |
| lives                   | 99200    |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 6.18     |
| mean 100 episode reward | 4.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4074   |
| steps                   | 588345   |
| td_erros                | -0.8103  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 99300    |
| lives                   | 99300    |
| mean 100 episode ei     | 4.4      |
| mean 100 episode length | 6.2      |
| mean 100 episode reward | 4.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3168   |
| steps                   | 588865   |
| td_erros                | -0.8546  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 99400    |
| lives                   | 99400    |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 6.05     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2745   |
| steps                   | 589370   |
| td_erros                | -0.8286  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 99500    |
| lives                   | 99500    |
| mean 100 episode ei     | 4.62     |
| mean 100 episode length | 6.01     |
| mean 100 episode reward | 5.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2825   |
| steps                   | 589871   |
| td_erros                | -0.8686  |
--------------------------------------
Saving model due to running mean reward increase: 5.3341 -> 5.5666
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 99600    |
| lives                   | 99600    |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.93     |
| mean 100 episode reward | 5.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3058   |
| steps                   | 590364   |
| td_erros                | -0.9005  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 99700    |
| lives                   | 99700    |
| mean 100 episode ei     | 4.81     |
| mean 100 episode length | 5.94     |
| mean 100 episode reward | 5.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3744   |
| steps                   | 590858   |
| td_erros                | -0.932   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 99800    |
| lives                   | 99800    |
| mean 100 episode ei     | 4.89     |
| mean 100 episode length | 5.86     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4897   |
| steps                   | 591344   |
| td_erros                | -0.9707  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 99900    |
| lives                   | 99900    |
| mean 100 episode ei     | 4.94     |
| mean 100 episode length | 5.82     |
| mean 100 episode reward | 5.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5609   |
| steps                   | 591826   |
| td_erros                | -1.0196  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 100000   |
| lives                   | 100000   |
| mean 100 episode ei     | 4.95     |
| mean 100 episode length | 5.83     |
| mean 100 episode reward | 5.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5837   |
| steps                   | 592309   |
| td_erros                | -1.0535  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 100100   |
| lives                   | 100100   |
| mean 100 episode ei     | 4.81     |
| mean 100 episode length | 5.8      |
| mean 100 episode reward | 5        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.638    |
| steps                   | 592789   |
| td_erros                | -1.0819  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 100200   |
| lives                   | 100200   |
| mean 100 episode ei     | 4.92     |
| mean 100 episode length | 5.82     |
| mean 100 episode reward | 5.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6641   |
| steps                   | 593271   |
| td_erros                | -1.0869  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 100300   |
| lives                   | 100300   |
| mean 100 episode ei     | 4.98     |
| mean 100 episode length | 5.82     |
| mean 100 episode reward | 5.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.706    |
| steps                   | 593753   |
| td_erros                | -1.0982  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 100400   |
| lives                   | 100400   |
| mean 100 episode ei     | 4.76     |
| mean 100 episode length | 5.8      |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7152   |
| steps                   | 594233   |
| td_erros                | -1.0916  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 100500   |
| lives                   | 100500   |
| mean 100 episode ei     | 4.69     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7254   |
| steps                   | 594695   |
| td_erros                | -1.1107  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 100600   |
| lives                   | 100600   |
| mean 100 episode ei     | 4.62     |
| mean 100 episode length | 5.64     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7551   |
| steps                   | 595159   |
| td_erros                | -1.1427  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 100700   |
| lives                   | 100700   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7745   |
| steps                   | 595620   |
| td_erros                | -1.153   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 100800   |
| lives                   | 100800   |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 5.57     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.799    |
| steps                   | 596077   |
| td_erros                | -1.1544  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 100900   |
| lives                   | 100900   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8208   |
| steps                   | 596539   |
| td_erros                | -1.1556  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 101000   |
| lives                   | 101000   |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8133   |
| steps                   | 596999   |
| td_erros                | -1.1532  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 101100   |
| lives                   | 101100   |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 5.66     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8267   |
| steps                   | 597465   |
| td_erros                | -1.1752  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 101200   |
| lives                   | 101200   |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 5.8      |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8214   |
| steps                   | 597945   |
| td_erros                | -1.1469  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 101300   |
| lives                   | 101300   |
| mean 100 episode ei     | 4.51     |
| mean 100 episode length | 5.77     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8197   |
| steps                   | 598422   |
| td_erros                | -1.1788  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 101400   |
| lives                   | 101400   |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 5.78     |
| mean 100 episode reward | 5.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.806    |
| steps                   | 598900   |
| td_erros                | -1.1924  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 101500   |
| lives                   | 101500   |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 6        |
| mean 100 episode reward | 5.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.786    |
| steps                   | 599400   |
| td_erros                | -1.1984  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 101600   |
| lives                   | 101600   |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 5.99     |
| mean 100 episode reward | 5.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.751    |
| steps                   | 599899   |
| td_erros                | -1.2107  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 101700   |
| lives                   | 101700   |
| mean 100 episode ei     | 4.76     |
| mean 100 episode length | 6.23     |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7216   |
| steps                   | 600422   |
| td_erros                | -1.1768  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 101800   |
| lives                   | 101800   |
| mean 100 episode ei     | 4.61     |
| mean 100 episode length | 6.27     |
| mean 100 episode reward | 5.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.668    |
| steps                   | 600949   |
| td_erros                | -1.1548  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 101900   |
| lives                   | 101900   |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 6.19     |
| mean 100 episode reward | 5        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6161   |
| steps                   | 601468   |
| td_erros                | -1.1444  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 102000   |
| lives                   | 102000   |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 6.18     |
| mean 100 episode reward | 4.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6061   |
| steps                   | 601986   |
| td_erros                | -1.196   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 102100   |
| lives                   | 102100   |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 6.05     |
| mean 100 episode reward | 4.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5599   |
| steps                   | 602491   |
| td_erros                | -1.1734  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 102200   |
| lives                   | 102200   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.81     |
| mean 100 episode reward | 4.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5938   |
| steps                   | 602972   |
| td_erros                | -1.1428  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 102300   |
| lives                   | 102300   |
| mean 100 episode ei     | 3.57     |
| mean 100 episode length | 5.57     |
| mean 100 episode reward | 4.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6265   |
| steps                   | 603429   |
| td_erros                | -1.0759  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 102400   |
| lives                   | 102400   |
| mean 100 episode ei     | 3.46     |
| mean 100 episode length | 5.52     |
| mean 100 episode reward | 4.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6379   |
| steps                   | 603881   |
| td_erros                | -0.9102  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 102500   |
| lives                   | 102500   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 4.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7136   |
| steps                   | 604342   |
| td_erros                | -0.8679  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 102600   |
| lives                   | 102600   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 4.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7073   |
| steps                   | 604803   |
| td_erros                | -0.8856  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 102700   |
| lives                   | 102700   |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 5.71     |
| mean 100 episode reward | 4.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7088   |
| steps                   | 605274   |
| td_erros                | -0.8504  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 102800   |
| lives                   | 102800   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.84     |
| mean 100 episode reward | 4.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6957   |
| steps                   | 605758   |
| td_erros                | -0.8133  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 102900   |
| lives                   | 102900   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 6.03     |
| mean 100 episode reward | 4.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6565   |
| steps                   | 606261   |
| td_erros                | -0.7985  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 103000   |
| lives                   | 103000   |
| mean 100 episode ei     | 4.62     |
| mean 100 episode length | 6.06     |
| mean 100 episode reward | 4.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5815   |
| steps                   | 606767   |
| td_erros                | -0.7887  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 103100   |
| lives                   | 103100   |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 6.22     |
| mean 100 episode reward | 4.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5408   |
| steps                   | 607289   |
| td_erros                | -0.7921  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 103200   |
| lives                   | 103200   |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 6.23     |
| mean 100 episode reward | 4.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4903   |
| steps                   | 607812   |
| td_erros                | -0.7729  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 103300   |
| lives                   | 103300   |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 6.22     |
| mean 100 episode reward | 4.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4406   |
| steps                   | 608334   |
| td_erros                | -0.8459  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 103400   |
| lives                   | 103400   |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 6.25     |
| mean 100 episode reward | 4.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4044   |
| steps                   | 608859   |
| td_erros                | -0.9591  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 103500   |
| lives                   | 103500   |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 6.23     |
| mean 100 episode reward | 4.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3919   |
| steps                   | 609382   |
| td_erros                | -1.0554  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 103600   |
| lives                   | 103600   |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 6.04     |
| mean 100 episode reward | 4.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3563   |
| steps                   | 609886   |
| td_erros                | -1.0679  |
--------------------------------------
Saving model due to running mean reward increase: 4.4279 -> 4.6715
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 103700   |
| lives                   | 103700   |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 6.01     |
| mean 100 episode reward | 4.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3679   |
| steps                   | 610387   |
| td_erros                | -1.0729  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 103800   |
| lives                   | 103800   |
| mean 100 episode ei     | 4.52     |
| mean 100 episode length | 6        |
| mean 100 episode reward | 4.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3921   |
| steps                   | 610887   |
| td_erros                | -1.0842  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 103900   |
| lives                   | 103900   |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 6.14     |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4062   |
| steps                   | 611401   |
| td_erros                | -1.0961  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 104000   |
| lives                   | 104000   |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 6.18     |
| mean 100 episode reward | 4.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4714   |
| steps                   | 611919   |
| td_erros                | -1.0871  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 104100   |
| lives                   | 104100   |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 6.21     |
| mean 100 episode reward | 4.96     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4761   |
| steps                   | 612440   |
| td_erros                | -1.1072  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 104200   |
| lives                   | 104200   |
| mean 100 episode ei     | 4.71     |
| mean 100 episode length | 6.3      |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5162   |
| steps                   | 612970   |
| td_erros                | -1.126   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 104300   |
| lives                   | 104300   |
| mean 100 episode ei     | 4.75     |
| mean 100 episode length | 6.12     |
| mean 100 episode reward | 5.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5589   |
| steps                   | 613482   |
| td_erros                | -1.1334  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 104400   |
| lives                   | 104400   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 6.01     |
| mean 100 episode reward | 5.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6169   |
| steps                   | 613983   |
| td_erros                | -1.208   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 104500   |
| lives                   | 104500   |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 5.99     |
| mean 100 episode reward | 5.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6521   |
| steps                   | 614482   |
| td_erros                | -1.2115  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 104600   |
| lives                   | 104600   |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 5.89     |
| mean 100 episode reward | 5.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6607   |
| steps                   | 614971   |
| td_erros                | -1.2607  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 104700   |
| lives                   | 104700   |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 5.76     |
| mean 100 episode reward | 5.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6503   |
| steps                   | 615447   |
| td_erros                | -1.247   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 104800   |
| lives                   | 104800   |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 5.9      |
| mean 100 episode reward | 5.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6702   |
| steps                   | 615937   |
| td_erros                | -1.2577  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 104900   |
| lives                   | 104900   |
| mean 100 episode ei     | 4.49     |
| mean 100 episode length | 5.94     |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6366   |
| steps                   | 616431   |
| td_erros                | -1.2645  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 105000   |
| lives                   | 105000   |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 5.9      |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6484   |
| steps                   | 616921   |
| td_erros                | -1.2499  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 105100   |
| lives                   | 105100   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.82     |
| mean 100 episode reward | 4.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6572   |
| steps                   | 617403   |
| td_erros                | -1.2164  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 105200   |
| lives                   | 105200   |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 5.96     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6505   |
| steps                   | 617899   |
| td_erros                | -1.1808  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 105300   |
| lives                   | 105300   |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 6        |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6835   |
| steps                   | 618399   |
| td_erros                | -1.2464  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 105400   |
| lives                   | 105400   |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 5.78     |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6746   |
| steps                   | 618877   |
| td_erros                | -1.1786  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 105500   |
| lives                   | 105500   |
| mean 100 episode ei     | 4.7      |
| mean 100 episode length | 6.02     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6468   |
| steps                   | 619379   |
| td_erros                | -1.141   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 105600   |
| lives                   | 105600   |
| mean 100 episode ei     | 4.69     |
| mean 100 episode length | 5.87     |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6381   |
| steps                   | 619866   |
| td_erros                | -1.1627  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 105700   |
| lives                   | 105700   |
| mean 100 episode ei     | 4.61     |
| mean 100 episode length | 5.8      |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6052   |
| steps                   | 620346   |
| td_erros                | -1.1841  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 105800   |
| lives                   | 105800   |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.87     |
| mean 100 episode reward | 5.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6325   |
| steps                   | 620833   |
| td_erros                | -1.1931  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 105900   |
| lives                   | 105900   |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 5.8      |
| mean 100 episode reward | 5.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6466   |
| steps                   | 621313   |
| td_erros                | -1.2431  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 106000   |
| lives                   | 106000   |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 6        |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6815   |
| steps                   | 621813   |
| td_erros                | -1.1973  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 106100   |
| lives                   | 106100   |
| mean 100 episode ei     | 4.48     |
| mean 100 episode length | 5.68     |
| mean 100 episode reward | 5.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6627   |
| steps                   | 622281   |
| td_erros                | -1.2465  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 106200   |
| lives                   | 106200   |
| mean 100 episode ei     | 4.62     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6814   |
| steps                   | 622743   |
| td_erros                | -1.257   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 106300   |
| lives                   | 106300   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.48     |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6927   |
| steps                   | 623191   |
| td_erros                | -1.3014  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 106400   |
| lives                   | 106400   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.38     |
| mean 100 episode reward | 4.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7226   |
| steps                   | 623629   |
| td_erros                | -1.2848  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 106500   |
| lives                   | 106500   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.34     |
| mean 100 episode reward | 4.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7366   |
| steps                   | 624063   |
| td_erros                | -1.269   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 106600   |
| lives                   | 106600   |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 5.36     |
| mean 100 episode reward | 4.99     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7715   |
| steps                   | 624499   |
| td_erros                | -1.2239  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 106700   |
| lives                   | 106700   |
| mean 100 episode ei     | 4.51     |
| mean 100 episode length | 5.56     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7866   |
| steps                   | 624955   |
| td_erros                | -1.164   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 106800   |
| lives                   | 106800   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.29     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8018   |
| steps                   | 625384   |
| td_erros                | -1.1779  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 106900   |
| lives                   | 106900   |
| mean 100 episode ei     | 4.61     |
| mean 100 episode length | 5.64     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7929   |
| steps                   | 625848   |
| td_erros                | -1.0654  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 107000   |
| lives                   | 107000   |
| mean 100 episode ei     | 4.7      |
| mean 100 episode length | 5.84     |
| mean 100 episode reward | 5.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7609   |
| steps                   | 626332   |
| td_erros                | -1.0627  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 107100   |
| lives                   | 107100   |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 5.9      |
| mean 100 episode reward | 5.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7433   |
| steps                   | 626822   |
| td_erros                | -1.1659  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 107200   |
| lives                   | 107200   |
| mean 100 episode ei     | 4.71     |
| mean 100 episode length | 6.02     |
| mean 100 episode reward | 4.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7519   |
| steps                   | 627324   |
| td_erros                | -1.1339  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 107300   |
| lives                   | 107300   |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 6.04     |
| mean 100 episode reward | 4.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7415   |
| steps                   | 627828   |
| td_erros                | -1.1431  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 107400   |
| lives                   | 107400   |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 5.97     |
| mean 100 episode reward | 4.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7415   |
| steps                   | 628325   |
| td_erros                | -1.1416  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 107500   |
| lives                   | 107500   |
| mean 100 episode ei     | 4.61     |
| mean 100 episode length | 6.01     |
| mean 100 episode reward | 4.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7404   |
| steps                   | 628826   |
| td_erros                | -1.1598  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 107600   |
| lives                   | 107600   |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 6        |
| mean 100 episode reward | 4.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7266   |
| steps                   | 629326   |
| td_erros                | -1.258   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 107700   |
| lives                   | 107700   |
| mean 100 episode ei     | 4.61     |
| mean 100 episode length | 6        |
| mean 100 episode reward | 4.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6973   |
| steps                   | 629826   |
| td_erros                | -1.3693  |
--------------------------------------
Saving model due to running mean reward increase: 4.7724 -> 4.7902
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 107800   |
| lives                   | 107800   |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.92     |
| mean 100 episode reward | 4.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6969   |
| steps                   | 630318   |
| td_erros                | -1.3781  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 107900   |
| lives                   | 107900   |
| mean 100 episode ei     | 4.43     |
| mean 100 episode length | 5.7      |
| mean 100 episode reward | 4.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6771   |
| steps                   | 630788   |
| td_erros                | -1.4277  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 108000   |
| lives                   | 108000   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.53     |
| mean 100 episode reward | 4.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6908   |
| steps                   | 631241   |
| td_erros                | -1.3613  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 108100   |
| lives                   | 108100   |
| mean 100 episode ei     | 4.69     |
| mean 100 episode length | 6.03     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.681    |
| steps                   | 631744   |
| td_erros                | -1.28    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 108200   |
| lives                   | 108200   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.89     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6856   |
| steps                   | 632233   |
| td_erros                | -1.2734  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 108300   |
| lives                   | 108300   |
| mean 100 episode ei     | 4.52     |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6961   |
| steps                   | 632691   |
| td_erros                | -1.2964  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 108400   |
| lives                   | 108400   |
| mean 100 episode ei     | 4.62     |
| mean 100 episode length | 5.8      |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6996   |
| steps                   | 633171   |
| td_erros                | -1.2997  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 108500   |
| lives                   | 108500   |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.78     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6932   |
| steps                   | 633649   |
| td_erros                | -1.2886  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 108600   |
| lives                   | 108600   |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 5.82     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7209   |
| steps                   | 634131   |
| td_erros                | -1.3396  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 108700   |
| lives                   | 108700   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 6        |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7168   |
| steps                   | 634631   |
| td_erros                | -1.3371  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 108800   |
| lives                   | 108800   |
| mean 100 episode ei     | 4.69     |
| mean 100 episode length | 6.03     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7337   |
| steps                   | 635134   |
| td_erros                | -1.3134  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 108900   |
| lives                   | 108900   |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 6.01     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.741    |
| steps                   | 635635   |
| td_erros                | -1.3196  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 109000   |
| lives                   | 109000   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.8      |
| mean 100 episode reward | 5.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7286   |
| steps                   | 636115   |
| td_erros                | -1.34    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 109100   |
| lives                   | 109100   |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 5.81     |
| mean 100 episode reward | 5.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6962   |
| steps                   | 636596   |
| td_erros                | -1.4326  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 109200   |
| lives                   | 109200   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.82     |
| mean 100 episode reward | 5.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6997   |
| steps                   | 637078   |
| td_erros                | -1.4582  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 109300   |
| lives                   | 109300   |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 5.81     |
| mean 100 episode reward | 5.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6822   |
| steps                   | 637559   |
| td_erros                | -1.449   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 109400   |
| lives                   | 109400   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.85     |
| mean 100 episode reward | 5.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6448   |
| steps                   | 638044   |
| td_erros                | -1.477   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 109500   |
| lives                   | 109500   |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 5.83     |
| mean 100 episode reward | 5.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.652    |
| steps                   | 638527   |
| td_erros                | -1.4951  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 109600   |
| lives                   | 109600   |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 5.88     |
| mean 100 episode reward | 5.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.643    |
| steps                   | 639015   |
| td_erros                | -1.4616  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 109700   |
| lives                   | 109700   |
| mean 100 episode ei     | 4.4      |
| mean 100 episode length | 5.93     |
| mean 100 episode reward | 5.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6284   |
| steps                   | 639508   |
| td_erros                | -1.4722  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 109800   |
| lives                   | 109800   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.8      |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6404   |
| steps                   | 639988   |
| td_erros                | -1.4302  |
--------------------------------------
Saving model due to running mean reward increase: 5.1531 -> 5.3446
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 109900   |
| lives                   | 109900   |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6374   |
| steps                   | 640450   |
| td_erros                | -1.4651  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 110000   |
| lives                   | 110000   |
| mean 100 episode ei     | 4.52     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6419   |
| steps                   | 640912   |
| td_erros                | -1.5013  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 110100   |
| lives                   | 110100   |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6584   |
| steps                   | 641375   |
| td_erros                | -1.4573  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 110200   |
| lives                   | 110200   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6596   |
| steps                   | 641837   |
| td_erros                | -1.462   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 110300   |
| lives                   | 110300   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6641   |
| steps                   | 642302   |
| td_erros                | -1.4962  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 110400   |
| lives                   | 110400   |
| mean 100 episode ei     | 4.39     |
| mean 100 episode length | 5.53     |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6812   |
| steps                   | 642755   |
| td_erros                | -1.4765  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 110500   |
| lives                   | 110500   |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6616   |
| steps                   | 643214   |
| td_erros                | -1.4986  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 110600   |
| lives                   | 110600   |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 5.85     |
| mean 100 episode reward | 5.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6651   |
| steps                   | 643699   |
| td_erros                | -1.4506  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 110700   |
| lives                   | 110700   |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 5.81     |
| mean 100 episode reward | 5.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6546   |
| steps                   | 644180   |
| td_erros                | -1.4897  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 110800   |
| lives                   | 110800   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.85     |
| mean 100 episode reward | 5.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.662    |
| steps                   | 644665   |
| td_erros                | -1.4271  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 110900   |
| lives                   | 110900   |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 5.87     |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6814   |
| steps                   | 645152   |
| td_erros                | -1.4456  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 111000   |
| lives                   | 111000   |
| mean 100 episode ei     | 4.62     |
| mean 100 episode length | 5.81     |
| mean 100 episode reward | 5.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6539   |
| steps                   | 645633   |
| td_erros                | -1.5083  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 111100   |
| lives                   | 111100   |
| mean 100 episode ei     | 4.39     |
| mean 100 episode length | 5.72     |
| mean 100 episode reward | 4.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.643    |
| steps                   | 646105   |
| td_erros                | -1.4226  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 111200   |
| lives                   | 111200   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.73     |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6118   |
| steps                   | 646578   |
| td_erros                | -1.4396  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 111300   |
| lives                   | 111300   |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 5.48     |
| mean 100 episode reward | 5.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6289   |
| steps                   | 647026   |
| td_erros                | -1.4304  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 111400   |
| lives                   | 111400   |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6316   |
| steps                   | 647484   |
| td_erros                | -1.4297  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 111500   |
| lives                   | 111500   |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 5.56     |
| mean 100 episode reward | 5.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6484   |
| steps                   | 647940   |
| td_erros                | -1.4047  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 111600   |
| lives                   | 111600   |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6278   |
| steps                   | 648401   |
| td_erros                | -1.3958  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 111700   |
| lives                   | 111700   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5944   |
| steps                   | 648864   |
| td_erros                | -1.416   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 111800   |
| lives                   | 111800   |
| mean 100 episode ei     | 4.71     |
| mean 100 episode length | 5.68     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6355   |
| steps                   | 649332   |
| td_erros                | -1.3945  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 111900   |
| lives                   | 111900   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6417   |
| steps                   | 649794   |
| td_erros                | -1.4105  |
--------------------------------------
Saving model due to running mean reward increase: 5.2657 -> 5.2765
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 112000   |
| lives                   | 112000   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6766   |
| steps                   | 650259   |
| td_erros                | -1.4117  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 112100   |
| lives                   | 112100   |
| mean 100 episode ei     | 4.51     |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6697   |
| steps                   | 650717   |
| td_erros                | -1.4443  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 112200   |
| lives                   | 112200   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.64     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6562   |
| steps                   | 651181   |
| td_erros                | -1.4507  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 112300   |
| lives                   | 112300   |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7087   |
| steps                   | 651642   |
| td_erros                | -1.4456  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 112400   |
| lives                   | 112400   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.82     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6867   |
| steps                   | 652124   |
| td_erros                | -1.4439  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 112500   |
| lives                   | 112500   |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.81     |
| mean 100 episode reward | 5.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6567   |
| steps                   | 652605   |
| td_erros                | -1.4467  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 112600   |
| lives                   | 112600   |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 5.8      |
| mean 100 episode reward | 5.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6635   |
| steps                   | 653085   |
| td_erros                | -1.4673  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 112700   |
| lives                   | 112700   |
| mean 100 episode ei     | 4.36     |
| mean 100 episode length | 5.76     |
| mean 100 episode reward | 4.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.65     |
| steps                   | 653561   |
| td_erros                | -1.503   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 112800   |
| lives                   | 112800   |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 5.79     |
| mean 100 episode reward | 4.99     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6385   |
| steps                   | 654040   |
| td_erros                | -1.4715  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 112900   |
| lives                   | 112900   |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.81     |
| mean 100 episode reward | 5.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6465   |
| steps                   | 654521   |
| td_erros                | -1.4728  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 113000   |
| lives                   | 113000   |
| mean 100 episode ei     | 4.39     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6308   |
| steps                   | 654981   |
| td_erros                | -1.4263  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 113100   |
| lives                   | 113100   |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 5.57     |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6336   |
| steps                   | 655438   |
| td_erros                | -1.4476  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 113200   |
| lives                   | 113200   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6337   |
| steps                   | 655901   |
| td_erros                | -1.4476  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 113300   |
| lives                   | 113300   |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6443   |
| steps                   | 656366   |
| td_erros                | -1.4837  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 113400   |
| lives                   | 113400   |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6479   |
| steps                   | 656829   |
| td_erros                | -1.5047  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 113500   |
| lives                   | 113500   |
| mean 100 episode ei     | 4.74     |
| mean 100 episode length | 5.67     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6587   |
| steps                   | 657296   |
| td_erros                | -1.4561  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 113600   |
| lives                   | 113600   |
| mean 100 episode ei     | 4.48     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 5.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.677    |
| steps                   | 657761   |
| td_erros                | -1.509   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 113700   |
| lives                   | 113700   |
| mean 100 episode ei     | 4.35     |
| mean 100 episode length | 5.5      |
| mean 100 episode reward | 5.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6842   |
| steps                   | 658211   |
| td_erros                | -1.4518  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 113800   |
| lives                   | 113800   |
| mean 100 episode ei     | 3.57     |
| mean 100 episode length | 5.14     |
| mean 100 episode reward | 4.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7333   |
| steps                   | 658625   |
| td_erros                | -1.4595  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 113900   |
| lives                   | 113900   |
| mean 100 episode ei     | 3.58     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 4.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.765    |
| steps                   | 659044   |
| td_erros                | -1.2609  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 114000   |
| lives                   | 114000   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7648   |
| steps                   | 659484   |
| td_erros                | -1.189   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 114100   |
| lives                   | 114100   |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 5.56     |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7767   |
| steps                   | 659940   |
| td_erros                | -1.1837  |
--------------------------------------
Saving model due to running mean reward increase: 4.9319 -> 5.2712
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 114200   |
| lives                   | 114200   |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7553   |
| steps                   | 660399   |
| td_erros                | -1.2287  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 114300   |
| lives                   | 114300   |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 5.72     |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7483   |
| steps                   | 660871   |
| td_erros                | -1.1378  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 114400   |
| lives                   | 114400   |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 5.82     |
| mean 100 episode reward | 5.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7372   |
| steps                   | 661353   |
| td_erros                | -1.2123  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 114500   |
| lives                   | 114500   |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 5.84     |
| mean 100 episode reward | 5.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7493   |
| steps                   | 661837   |
| td_erros                | -1.2068  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 114600   |
| lives                   | 114600   |
| mean 100 episode ei     | 4.48     |
| mean 100 episode length | 5.92     |
| mean 100 episode reward | 4.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7282   |
| steps                   | 662329   |
| td_erros                | -1.1473  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 114700   |
| lives                   | 114700   |
| mean 100 episode ei     | 4.51     |
| mean 100 episode length | 5.96     |
| mean 100 episode reward | 4.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.729    |
| steps                   | 662825   |
| td_erros                | -1.1281  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 114800   |
| lives                   | 114800   |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 5.99     |
| mean 100 episode reward | 4.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.684    |
| steps                   | 663324   |
| td_erros                | -1.1271  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 114900   |
| lives                   | 114900   |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 6        |
| mean 100 episode reward | 4.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6612   |
| steps                   | 663824   |
| td_erros                | -1.2179  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 115000   |
| lives                   | 115000   |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 6.01     |
| mean 100 episode reward | 4.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6796   |
| steps                   | 664325   |
| td_erros                | -1.3765  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 115100   |
| lives                   | 115100   |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.85     |
| mean 100 episode reward | 5.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6605   |
| steps                   | 664810   |
| td_erros                | -1.4683  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 115200   |
| lives                   | 115200   |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 5.82     |
| mean 100 episode reward | 5.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6516   |
| steps                   | 665292   |
| td_erros                | -1.4934  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 115300   |
| lives                   | 115300   |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 5.76     |
| mean 100 episode reward | 5.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6415   |
| steps                   | 665768   |
| td_erros                | -1.4584  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 115400   |
| lives                   | 115400   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6324   |
| steps                   | 666231   |
| td_erros                | -1.472   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 115500   |
| lives                   | 115500   |
| mean 100 episode ei     | 4.61     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6565   |
| steps                   | 666691   |
| td_erros                | -1.4422  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 115600   |
| lives                   | 115600   |
| mean 100 episode ei     | 4.61     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6681   |
| steps                   | 667154   |
| td_erros                | -1.4379  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 115700   |
| lives                   | 115700   |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.64     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6754   |
| steps                   | 667618   |
| td_erros                | -1.4414  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 115800   |
| lives                   | 115800   |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6823   |
| steps                   | 668078   |
| td_erros                | -1.4824  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 115900   |
| lives                   | 115900   |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6769   |
| steps                   | 668540   |
| td_erros                | -1.4857  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 116000   |
| lives                   | 116000   |
| mean 100 episode ei     | 4.49     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6794   |
| steps                   | 669001   |
| td_erros                | -1.4553  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 116100   |
| lives                   | 116100   |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7085   |
| steps                   | 669462   |
| td_erros                | -1.4902  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 116200   |
| lives                   | 116200   |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7346   |
| steps                   | 669906   |
| td_erros                | -1.4811  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 116300   |
| lives                   | 116300   |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.732    |
| steps                   | 670346   |
| td_erros                | -1.4253  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 116400   |
| lives                   | 116400   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7614   |
| steps                   | 670811   |
| td_erros                | -1.4283  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 116500   |
| lives                   | 116500   |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7819   |
| steps                   | 671254   |
| td_erros                | -1.4243  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 116600   |
| lives                   | 116600   |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 5.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8093   |
| steps                   | 671712   |
| td_erros                | -1.4331  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 116700   |
| lives                   | 116700   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 5.53     |
| mean 100 episode reward | 4.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8386   |
| steps                   | 672165   |
| td_erros                | -1.3276  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 116800   |
| lives                   | 116800   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.57     |
| mean 100 episode reward | 4.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8641   |
| steps                   | 672622   |
| td_erros                | -1.266   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 116900   |
| lives                   | 116900   |
| mean 100 episode ei     | 4.43     |
| mean 100 episode length | 5.77     |
| mean 100 episode reward | 4.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8439   |
| steps                   | 673099   |
| td_erros                | -1.2204  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 117000   |
| lives                   | 117000   |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 5.81     |
| mean 100 episode reward | 5.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8149   |
| steps                   | 673580   |
| td_erros                | -1.1792  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 117100   |
| lives                   | 117100   |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 5.84     |
| mean 100 episode reward | 5.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7724   |
| steps                   | 674064   |
| td_erros                | -1.1915  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 117200   |
| lives                   | 117200   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.81     |
| mean 100 episode reward | 5.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7901   |
| steps                   | 674545   |
| td_erros                | -1.1687  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 117300   |
| lives                   | 117300   |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 5.79     |
| mean 100 episode reward | 5.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7793   |
| steps                   | 675024   |
| td_erros                | -1.1983  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 117400   |
| lives                   | 117400   |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.83     |
| mean 100 episode reward | 5.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.749    |
| steps                   | 675507   |
| td_erros                | -1.2032  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 117500   |
| lives                   | 117500   |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.81     |
| mean 100 episode reward | 5.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7319   |
| steps                   | 675988   |
| td_erros                | -1.2     |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 117600   |
| lives                   | 117600   |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 5.7      |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7161   |
| steps                   | 676458   |
| td_erros                | -1.2776  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 117700   |
| lives                   | 117700   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7183   |
| steps                   | 676920   |
| td_erros                | -1.2647  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 117800   |
| lives                   | 117800   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.7      |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6989   |
| steps                   | 677390   |
| td_erros                | -1.4297  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 117900   |
| lives                   | 117900   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6974   |
| steps                   | 677852   |
| td_erros                | -1.4364  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 118000   |
| lives                   | 118000   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7107   |
| steps                   | 678312   |
| td_erros                | -1.4641  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 118100   |
| lives                   | 118100   |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7078   |
| steps                   | 678775   |
| td_erros                | -1.5061  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 118200   |
| lives                   | 118200   |
| mean 100 episode ei     | 4.69     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7277   |
| steps                   | 679237   |
| td_erros                | -1.5134  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 118300   |
| lives                   | 118300   |
| mean 100 episode ei     | 4.71     |
| mean 100 episode length | 5.68     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7456   |
| steps                   | 679705   |
| td_erros                | -1.4915  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 118400   |
| lives                   | 118400   |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7499   |
| steps                   | 680164   |
| td_erros                | -1.4978  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 118500   |
| lives                   | 118500   |
| mean 100 episode ei     | 4.7      |
| mean 100 episode length | 5.67     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7655   |
| steps                   | 680631   |
| td_erros                | -1.4591  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 118600   |
| lives                   | 118600   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7562   |
| steps                   | 681091   |
| td_erros                | -1.4722  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 118700   |
| lives                   | 118700   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7736   |
| steps                   | 681553   |
| td_erros                | -1.4753  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 118800   |
| lives                   | 118800   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7711   |
| steps                   | 682013   |
| td_erros                | -1.4571  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 118900   |
| lives                   | 118900   |
| mean 100 episode ei     | 4.69     |
| mean 100 episode length | 5.64     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7622   |
| steps                   | 682477   |
| td_erros                | -1.4521  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 119000   |
| lives                   | 119000   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.9      |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7788   |
| steps                   | 682967   |
| td_erros                | -1.4866  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 119100   |
| lives                   | 119100   |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 6.03     |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7505   |
| steps                   | 683470   |
| td_erros                | -1.4692  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 119200   |
| lives                   | 119200   |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 5.87     |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7153   |
| steps                   | 683957   |
| td_erros                | -1.4994  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 119300   |
| lives                   | 119300   |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 5.77     |
| mean 100 episode reward | 5.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7216   |
| steps                   | 684434   |
| td_erros                | -1.4807  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 119400   |
| lives                   | 119400   |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 5.76     |
| mean 100 episode reward | 5.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6931   |
| steps                   | 684910   |
| td_erros                | -1.462   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 119500   |
| lives                   | 119500   |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 5.82     |
| mean 100 episode reward | 5.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6769   |
| steps                   | 685392   |
| td_erros                | -1.4804  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 119600   |
| lives                   | 119600   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.81     |
| mean 100 episode reward | 5.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6662   |
| steps                   | 685873   |
| td_erros                | -1.5209  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 119700   |
| lives                   | 119700   |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 5.82     |
| mean 100 episode reward | 5.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6725   |
| steps                   | 686355   |
| td_erros                | -1.4501  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 119800   |
| lives                   | 119800   |
| mean 100 episode ei     | 4.62     |
| mean 100 episode length | 5.7      |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6683   |
| steps                   | 686825   |
| td_erros                | -1.4026  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 119900   |
| lives                   | 119900   |
| mean 100 episode ei     | 4.7      |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6405   |
| steps                   | 687288   |
| td_erros                | -1.4571  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 120000   |
| lives                   | 120000   |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6386   |
| steps                   | 687750   |
| td_erros                | -1.5169  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 120100   |
| lives                   | 120100   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6809   |
| steps                   | 688212   |
| td_erros                | -1.515   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 120200   |
| lives                   | 120200   |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6768   |
| steps                   | 688677   |
| td_erros                | -1.4713  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 120300   |
| lives                   | 120300   |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6805   |
| steps                   | 689140   |
| td_erros                | -1.5021  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 120400   |
| lives                   | 120400   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7027   |
| steps                   | 689603   |
| td_erros                | -1.5336  |
--------------------------------------
Saving model due to running mean reward increase: 5.2236 -> 5.3305
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 120500   |
| lives                   | 120500   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.686    |
| steps                   | 690063   |
| td_erros                | -1.5606  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 120600   |
| lives                   | 120600   |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.687    |
| steps                   | 690524   |
| td_erros                | -1.573   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 120700   |
| lives                   | 120700   |
| mean 100 episode ei     | 4.47     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7172   |
| steps                   | 690987   |
| td_erros                | -1.5583  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 120800   |
| lives                   | 120800   |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 5.8      |
| mean 100 episode reward | 5.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6845   |
| steps                   | 691467   |
| td_erros                | -1.573   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 120900   |
| lives                   | 120900   |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.82     |
| mean 100 episode reward | 5.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7141   |
| steps                   | 691949   |
| td_erros                | -1.5702  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 121000   |
| lives                   | 121000   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.78     |
| mean 100 episode reward | 5.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6965   |
| steps                   | 692427   |
| td_erros                | -1.5634  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 121100   |
| lives                   | 121100   |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 5.81     |
| mean 100 episode reward | 5.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6878   |
| steps                   | 692908   |
| td_erros                | -1.5777  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 121200   |
| lives                   | 121200   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.82     |
| mean 100 episode reward | 5.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6474   |
| steps                   | 693390   |
| td_erros                | -1.5394  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 121300   |
| lives                   | 121300   |
| mean 100 episode ei     | 4.61     |
| mean 100 episode length | 5.83     |
| mean 100 episode reward | 5.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6488   |
| steps                   | 693873   |
| td_erros                | -1.5595  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 121400   |
| lives                   | 121400   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.8      |
| mean 100 episode reward | 5.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6406   |
| steps                   | 694353   |
| td_erros                | -1.5576  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 121500   |
| lives                   | 121500   |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 5.77     |
| mean 100 episode reward | 5.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6373   |
| steps                   | 694830   |
| td_erros                | -1.5158  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 121600   |
| lives                   | 121600   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6507   |
| steps                   | 695291   |
| td_erros                | -1.5171  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 121700   |
| lives                   | 121700   |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6308   |
| steps                   | 695750   |
| td_erros                | -1.5358  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 121800   |
| lives                   | 121800   |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.645    |
| steps                   | 696209   |
| td_erros                | -1.5561  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 121900   |
| lives                   | 121900   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6682   |
| steps                   | 696671   |
| td_erros                | -1.5511  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 122000   |
| lives                   | 122000   |
| mean 100 episode ei     | 4.62     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6661   |
| steps                   | 697136   |
| td_erros                | -1.5954  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 122100   |
| lives                   | 122100   |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6625   |
| steps                   | 697596   |
| td_erros                | -1.5684  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 122200   |
| lives                   | 122200   |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6832   |
| steps                   | 698054   |
| td_erros                | -1.5594  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 122300   |
| lives                   | 122300   |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6892   |
| steps                   | 698513   |
| td_erros                | -1.5736  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 122400   |
| lives                   | 122400   |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.688    |
| steps                   | 698972   |
| td_erros                | -1.5901  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 122500   |
| lives                   | 122500   |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 5.64     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7021   |
| steps                   | 699436   |
| td_erros                | -1.5942  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 122600   |
| lives                   | 122600   |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 5.64     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6983   |
| steps                   | 699900   |
| td_erros                | -1.5507  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 122700   |
| lives                   | 122700   |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6846   |
| steps                   | 700363   |
| td_erros                | -1.5677  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 122800   |
| lives                   | 122800   |
| mean 100 episode ei     | 4.51     |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6757   |
| steps                   | 700821   |
| td_erros                | -1.5932  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 122900   |
| lives                   | 122900   |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6801   |
| steps                   | 701281   |
| td_erros                | -1.5216  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 123000   |
| lives                   | 123000   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6532   |
| steps                   | 701742   |
| td_erros                | -1.5557  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 123100   |
| lives                   | 123100   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6707   |
| steps                   | 702202   |
| td_erros                | -1.532   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 123200   |
| lives                   | 123200   |
| mean 100 episode ei     | 4.45     |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 5.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6858   |
| steps                   | 702660   |
| td_erros                | -1.5666  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 123300   |
| lives                   | 123300   |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 5.57     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6777   |
| steps                   | 703117   |
| td_erros                | -1.518   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 123400   |
| lives                   | 123400   |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6641   |
| steps                   | 703578   |
| td_erros                | -1.6121  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 123500   |
| lives                   | 123500   |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.687    |
| steps                   | 704040   |
| td_erros                | -1.581   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 123600   |
| lives                   | 123600   |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.694    |
| steps                   | 704501   |
| td_erros                | -1.5977  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 123700   |
| lives                   | 123700   |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7122   |
| steps                   | 704945   |
| td_erros                | -1.5104  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 123800   |
| lives                   | 123800   |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 4.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7311   |
| steps                   | 705410   |
| td_erros                | -1.4505  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 123900   |
| lives                   | 123900   |
| mean 100 episode ei     | 4.39     |
| mean 100 episode length | 5.77     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7439   |
| steps                   | 705887   |
| td_erros                | -1.4502  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 124000   |
| lives                   | 124000   |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 5.38     |
| mean 100 episode reward | 4.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7649   |
| steps                   | 706325   |
| td_erros                | -1.3315  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 124100   |
| lives                   | 124100   |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 5.5      |
| mean 100 episode reward | 4.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7758   |
| steps                   | 706775   |
| td_erros                | -1.2401  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 124200   |
| lives                   | 124200   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.51     |
| mean 100 episode reward | 4.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7629   |
| steps                   | 707226   |
| td_erros                | -1.1708  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 124300   |
| lives                   | 124300   |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 5.78     |
| mean 100 episode reward | 5.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7657   |
| steps                   | 707704   |
| td_erros                | -1.1513  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 124400   |
| lives                   | 124400   |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 5.81     |
| mean 100 episode reward | 5.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7361   |
| steps                   | 708185   |
| td_erros                | -1.1465  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 124500   |
| lives                   | 124500   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.81     |
| mean 100 episode reward | 5.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7074   |
| steps                   | 708666   |
| td_erros                | -1.0815  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 124600   |
| lives                   | 124600   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.83     |
| mean 100 episode reward | 5.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6911   |
| steps                   | 709149   |
| td_erros                | -1.1058  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 124700   |
| lives                   | 124700   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.66     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7143   |
| steps                   | 709615   |
| td_erros                | -1.1399  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 124800   |
| lives                   | 124800   |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 5.64     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7149   |
| steps                   | 710079   |
| td_erros                | -1.1527  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 124900   |
| lives                   | 124900   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7257   |
| steps                   | 710540   |
| td_erros                | -1.2064  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 125000   |
| lives                   | 125000   |
| mean 100 episode ei     | 4.49     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7711   |
| steps                   | 711003   |
| td_erros                | -1.2265  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 125100   |
| lives                   | 125100   |
| mean 100 episode ei     | 4.62     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7722   |
| steps                   | 711468   |
| td_erros                | -1.3239  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 125200   |
| lives                   | 125200   |
| mean 100 episode ei     | 4.46     |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 5.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7635   |
| steps                   | 711926   |
| td_erros                | -1.4276  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 125300   |
| lives                   | 125300   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7578   |
| steps                   | 712387   |
| td_erros                | -1.5251  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 125400   |
| lives                   | 125400   |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7447   |
| steps                   | 712846   |
| td_erros                | -1.5442  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 125500   |
| lives                   | 125500   |
| mean 100 episode ei     | 4.62     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7286   |
| steps                   | 713307   |
| td_erros                | -1.5275  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 125600   |
| lives                   | 125600   |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7587   |
| steps                   | 713770   |
| td_erros                | -1.5377  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 125700   |
| lives                   | 125700   |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7461   |
| steps                   | 714229   |
| td_erros                | -1.5261  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 125800   |
| lives                   | 125800   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 5        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7633   |
| steps                   | 714654   |
| td_erros                | -1.5175  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 125900   |
| lives                   | 125900   |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.789    |
| steps                   | 715074   |
| td_erros                | -1.4036  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 126000   |
| lives                   | 126000   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8271   |
| steps                   | 715499   |
| td_erros                | -1.3331  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 126100   |
| lives                   | 126100   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8671   |
| steps                   | 715960   |
| td_erros                | -1.2601  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 126200   |
| lives                   | 126200   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8872   |
| steps                   | 716422   |
| td_erros                | -1.294   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 126300   |
| lives                   | 126300   |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8893   |
| steps                   | 716884   |
| td_erros                | -1.271   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 126400   |
| lives                   | 126400   |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8964   |
| steps                   | 717345   |
| td_erros                | -1.3041  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 126500   |
| lives                   | 126500   |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8909   |
| steps                   | 717805   |
| td_erros                | -1.311   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 126600   |
| lives                   | 126600   |
| mean 100 episode ei     | 4.51     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8888   |
| steps                   | 718267   |
| td_erros                | -1.2858  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 126700   |
| lives                   | 126700   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.67     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8775   |
| steps                   | 718734   |
| td_erros                | -1.2867  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 126800   |
| lives                   | 126800   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8759   |
| steps                   | 719194   |
| td_erros                | -1.3355  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 126900   |
| lives                   | 126900   |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8551   |
| steps                   | 719657   |
| td_erros                | -1.3255  |
--------------------------------------
Saving model due to running mean reward increase: 5.1968 -> 5.3101
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 127000   |
| lives                   | 127000   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8191   |
| steps                   | 720117   |
| td_erros                | -1.4264  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 127100   |
| lives                   | 127100   |
| mean 100 episode ei     | 4.42     |
| mean 100 episode length | 5.52     |
| mean 100 episode reward | 5.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.813    |
| steps                   | 720569   |
| td_erros                | -1.527   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 127200   |
| lives                   | 127200   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8008   |
| steps                   | 721034   |
| td_erros                | -1.5653  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 127300   |
| lives                   | 127300   |
| mean 100 episode ei     | 4.61     |
| mean 100 episode length | 5.66     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7899   |
| steps                   | 721500   |
| td_erros                | -1.5498  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 127400   |
| lives                   | 127400   |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7776   |
| steps                   | 721961   |
| td_erros                | -1.5657  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 127500   |
| lives                   | 127500   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7893   |
| steps                   | 722424   |
| td_erros                | -1.563   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 127600   |
| lives                   | 127600   |
| mean 100 episode ei     | 4.62     |
| mean 100 episode length | 5.64     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7752   |
| steps                   | 722888   |
| td_erros                | -1.5295  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 127700   |
| lives                   | 127700   |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.771    |
| steps                   | 723347   |
| td_erros                | -1.5417  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 127800   |
| lives                   | 127800   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.66     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.758    |
| steps                   | 723813   |
| td_erros                | -1.5578  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 127900   |
| lives                   | 127900   |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7423   |
| steps                   | 724274   |
| td_erros                | -1.5036  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 128000   |
| lives                   | 128000   |
| mean 100 episode ei     | 4.61     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7276   |
| steps                   | 724737   |
| td_erros                | -1.4951  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 128100   |
| lives                   | 128100   |
| mean 100 episode ei     | 4.62     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7145   |
| steps                   | 725198   |
| td_erros                | -1.5229  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 128200   |
| lives                   | 128200   |
| mean 100 episode ei     | 4.49     |
| mean 100 episode length | 5.5      |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7119   |
| steps                   | 725648   |
| td_erros                | -1.5342  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 128300   |
| lives                   | 128300   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.35     |
| mean 100 episode reward | 4.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7369   |
| steps                   | 726083   |
| td_erros                | -1.5217  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 128400   |
| lives                   | 128400   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 4.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.769    |
| steps                   | 726522   |
| td_erros                | -1.4004  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 128500   |
| lives                   | 128500   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 4.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8133   |
| steps                   | 726966   |
| td_erros                | -1.2992  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 128600   |
| lives                   | 128600   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 4.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8494   |
| steps                   | 727431   |
| td_erros                | -1.2191  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 128700   |
| lives                   | 128700   |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 5.73     |
| mean 100 episode reward | 4.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8365   |
| steps                   | 727904   |
| td_erros                | -1.1802  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 128800   |
| lives                   | 128800   |
| mean 100 episode ei     | 4.62     |
| mean 100 episode length | 5.8      |
| mean 100 episode reward | 5.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8221   |
| steps                   | 728384   |
| td_erros                | -1.1325  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 128900   |
| lives                   | 128900   |
| mean 100 episode ei     | 4.47     |
| mean 100 episode length | 5.74     |
| mean 100 episode reward | 4.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.793    |
| steps                   | 728858   |
| td_erros                | -1.1433  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 129000   |
| lives                   | 129000   |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 4.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.769    |
| steps                   | 729316   |
| td_erros                | -1.063   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 129100   |
| lives                   | 129100   |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 5.83     |
| mean 100 episode reward | 5.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.751    |
| steps                   | 729799   |
| td_erros                | -1.0471  |
--------------------------------------
Saving model due to running mean reward increase: 4.9441 -> 5.0248
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 129200   |
| lives                   | 129200   |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 5.82     |
| mean 100 episode reward | 5.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7712   |
| steps                   | 730281   |
| td_erros                | -1.0528  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 129300   |
| lives                   | 129300   |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 5.73     |
| mean 100 episode reward | 5.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7375   |
| steps                   | 730754   |
| td_erros                | -1.0437  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 129400   |
| lives                   | 129400   |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.85     |
| mean 100 episode reward | 5.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7474   |
| steps                   | 731239   |
| td_erros                | -1.1083  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 129500   |
| lives                   | 129500   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.67     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.743    |
| steps                   | 731706   |
| td_erros                | -1.1628  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 129600   |
| lives                   | 129600   |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.716    |
| steps                   | 732168   |
| td_erros                | -1.285   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 129700   |
| lives                   | 129700   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.29     |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7437   |
| steps                   | 732597   |
| td_erros                | -1.3193  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 129800   |
| lives                   | 129800   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 4.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7852   |
| steps                   | 733016   |
| td_erros                | -1.2988  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 129900   |
| lives                   | 129900   |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8363   |
| steps                   | 733457   |
| td_erros                | -1.2269  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 130000   |
| lives                   | 130000   |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 5.56     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8461   |
| steps                   | 733913   |
| td_erros                | -1.2294  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 130100   |
| lives                   | 130100   |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8514   |
| steps                   | 734371   |
| td_erros                | -1.2871  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 130200   |
| lives                   | 130200   |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8705   |
| steps                   | 734829   |
| td_erros                | -1.3276  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 130300   |
| lives                   | 130300   |
| mean 100 episode ei     | 4.71     |
| mean 100 episode length | 5.66     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8828   |
| steps                   | 735295   |
| td_erros                | -1.2677  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 130400   |
| lives                   | 130400   |
| mean 100 episode ei     | 4.21     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 4.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8787   |
| steps                   | 735734   |
| td_erros                | -1.312   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 130500   |
| lives                   | 130500   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8917   |
| steps                   | 736158   |
| td_erros                | -1.2454  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 130600   |
| lives                   | 130600   |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 5.46     |
| mean 100 episode reward | 5.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9157   |
| steps                   | 736604   |
| td_erros                | -1.206   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 130700   |
| lives                   | 130700   |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.924    |
| steps                   | 737065   |
| td_erros                | -1.1592  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 130800   |
| lives                   | 130800   |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.869    |
| steps                   | 737528   |
| td_erros                | -1.1748  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 130900   |
| lives                   | 130900   |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 5.57     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8547   |
| steps                   | 737985   |
| td_erros                | -1.2529  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 131000   |
| lives                   | 131000   |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8289   |
| steps                   | 738447   |
| td_erros                | -1.3103  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 131100   |
| lives                   | 131100   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8607   |
| steps                   | 738909   |
| td_erros                | -1.352   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 131200   |
| lives                   | 131200   |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8478   |
| steps                   | 739372   |
| td_erros                | -1.3572  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 131300   |
| lives                   | 131300   |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8657   |
| steps                   | 739834   |
| td_erros                | -1.3729  |
--------------------------------------
Saving model due to running mean reward increase: 5.2526 -> 5.2554
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 131400   |
| lives                   | 131400   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8685   |
| steps                   | 740294   |
| td_erros                | -1.3889  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 131500   |
| lives                   | 131500   |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8784   |
| steps                   | 740754   |
| td_erros                | -1.4266  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 131600   |
| lives                   | 131600   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8816   |
| steps                   | 741216   |
| td_erros                | -1.4533  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 131700   |
| lives                   | 131700   |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 5.53     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8682   |
| steps                   | 741669   |
| td_erros                | -1.4882  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 131800   |
| lives                   | 131800   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.28     |
| mean 100 episode reward | 4.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8473   |
| steps                   | 742097   |
| td_erros                | -1.4782  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 131900   |
| lives                   | 131900   |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 5.37     |
| mean 100 episode reward | 4.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8565   |
| steps                   | 742534   |
| td_erros                | -1.3654  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 132000   |
| lives                   | 132000   |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 5.64     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.885    |
| steps                   | 742998   |
| td_erros                | -1.326   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 132100   |
| lives                   | 132100   |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 5.75     |
| mean 100 episode reward | 4.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8688   |
| steps                   | 743473   |
| td_erros                | -1.3717  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 132200   |
| lives                   | 132200   |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 5.78     |
| mean 100 episode reward | 5.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8691   |
| steps                   | 743951   |
| td_erros                | -1.371   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 132300   |
| lives                   | 132300   |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 5.83     |
| mean 100 episode reward | 5.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8654   |
| steps                   | 744434   |
| td_erros                | -1.3953  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 132400   |
| lives                   | 132400   |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 5.83     |
| mean 100 episode reward | 5.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8633   |
| steps                   | 744917   |
| td_erros                | -1.3492  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 132500   |
| lives                   | 132500   |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 5.79     |
| mean 100 episode reward | 5.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8626   |
| steps                   | 745396   |
| td_erros                | -1.3647  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 132600   |
| lives                   | 132600   |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 5.75     |
| mean 100 episode reward | 4.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8476   |
| steps                   | 745871   |
| td_erros                | -1.3617  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 132700   |
| lives                   | 132700   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.76     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.826    |
| steps                   | 746347   |
| td_erros                | -1.3189  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 132800   |
| lives                   | 132800   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8312   |
| steps                   | 746810   |
| td_erros                | -1.3628  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 132900   |
| lives                   | 132900   |
| mean 100 episode ei     | 4.51     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8117   |
| steps                   | 747269   |
| td_erros                | -1.4182  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 133000   |
| lives                   | 133000   |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 5.5      |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7724   |
| steps                   | 747719   |
| td_erros                | -1.4626  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 133100   |
| lives                   | 133100   |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 5.53     |
| mean 100 episode reward | 5.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7827   |
| steps                   | 748172   |
| td_erros                | -1.4895  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 133200   |
| lives                   | 133200   |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.74     |
| steps                   | 748633   |
| td_erros                | -1.4907  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 133300   |
| lives                   | 133300   |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 5.66     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7539   |
| steps                   | 749099   |
| td_erros                | -1.4667  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 133400   |
| lives                   | 133400   |
| mean 100 episode ei     | 4.71     |
| mean 100 episode length | 5.66     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7343   |
| steps                   | 749565   |
| td_erros                | -1.4711  |
--------------------------------------
Saving model due to running mean reward increase: 5.3064 -> 5.3178
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 133500   |
| lives                   | 133500   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7271   |
| steps                   | 750025   |
| td_erros                | -1.4824  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 133600   |
| lives                   | 133600   |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.7      |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.737    |
| steps                   | 750495   |
| td_erros                | -1.5291  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 133700   |
| lives                   | 133700   |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 5.53     |
| mean 100 episode reward | 4.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7634   |
| steps                   | 750948   |
| td_erros                | -1.5091  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 133800   |
| lives                   | 133800   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 4.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7741   |
| steps                   | 751392   |
| td_erros                | -1.4461  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 133900   |
| lives                   | 133900   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 4.57     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7826   |
| steps                   | 751836   |
| td_erros                | -1.4037  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 134000   |
| lives                   | 134000   |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 4.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.812    |
| steps                   | 752298   |
| td_erros                | -1.317   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 134100   |
| lives                   | 134100   |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 5.64     |
| mean 100 episode reward | 4.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8268   |
| steps                   | 752762   |
| td_erros                | -1.1605  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 134200   |
| lives                   | 134200   |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 5.72     |
| mean 100 episode reward | 4.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8181   |
| steps                   | 753234   |
| td_erros                | -1.1028  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 134300   |
| lives                   | 134300   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.99     |
| mean 100 episode reward | 4.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8132   |
| steps                   | 753733   |
| td_erros                | -1.0987  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 134400   |
| lives                   | 134400   |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 5.99     |
| mean 100 episode reward | 4.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.782    |
| steps                   | 754232   |
| td_erros                | -1.064   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 134500   |
| lives                   | 134500   |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 6.02     |
| mean 100 episode reward | 4.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7458   |
| steps                   | 754734   |
| td_erros                | -1.0687  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 134600   |
| lives                   | 134600   |
| mean 100 episode ei     | 4.48     |
| mean 100 episode length | 6.03     |
| mean 100 episode reward | 4.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.718    |
| steps                   | 755237   |
| td_erros                | -1.0226  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 134700   |
| lives                   | 134700   |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 6.03     |
| mean 100 episode reward | 4.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6713   |
| steps                   | 755740   |
| td_erros                | -0.9969  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 134800   |
| lives                   | 134800   |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 6.01     |
| mean 100 episode reward | 4.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6875   |
| steps                   | 756241   |
| td_erros                | -1.0499  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 134900   |
| lives                   | 134900   |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 6.01     |
| mean 100 episode reward | 4.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6712   |
| steps                   | 756742   |
| td_erros                | -1.1049  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 135000   |
| lives                   | 135000   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 6.01     |
| mean 100 episode reward | 4.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6851   |
| steps                   | 757243   |
| td_erros                | -1.1742  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 135100   |
| lives                   | 135100   |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 5.98     |
| mean 100 episode reward | 4.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6984   |
| steps                   | 757741   |
| td_erros                | -1.2652  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 135200   |
| lives                   | 135200   |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 6.03     |
| mean 100 episode reward | 4.69     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.676    |
| steps                   | 758244   |
| td_erros                | -1.3962  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 135300   |
| lives                   | 135300   |
| mean 100 episode ei     | 4.61     |
| mean 100 episode length | 6.01     |
| mean 100 episode reward | 4.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6635   |
| steps                   | 758745   |
| td_erros                | -1.4498  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 135400   |
| lives                   | 135400   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.86     |
| mean 100 episode reward | 5.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6736   |
| steps                   | 759231   |
| td_erros                | -1.4942  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 135500   |
| lives                   | 135500   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 4.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6882   |
| steps                   | 759671   |
| td_erros                | -1.4292  |
--------------------------------------
Saving model due to running mean reward increase: 4.7093 -> 4.8366
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 135600   |
| lives                   | 135600   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.743    |
| steps                   | 760092   |
| td_erros                | -1.3504  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 135700   |
| lives                   | 135700   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 4.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7823   |
| steps                   | 760516   |
| td_erros                | -1.2945  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 135800   |
| lives                   | 135800   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.28     |
| mean 100 episode reward | 4.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8382   |
| steps                   | 760944   |
| td_erros                | -1.255   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 135900   |
| lives                   | 135900   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8648   |
| steps                   | 761364   |
| td_erros                | -1.1839  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 136000   |
| lives                   | 136000   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.28     |
| mean 100 episode reward | 4.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8787   |
| steps                   | 761792   |
| td_erros                | -1.0686  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 136100   |
| lives                   | 136100   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8745   |
| steps                   | 762215   |
| td_erros                | -1.0304  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 136200   |
| lives                   | 136200   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8781   |
| steps                   | 762638   |
| td_erros                | -0.9247  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 136300   |
| lives                   | 136300   |
| mean 100 episode ei     | 4.21     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 4.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8195   |
| steps                   | 763081   |
| td_erros                | -0.8625  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 136400   |
| lives                   | 136400   |
| mean 100 episode ei     | 3.72     |
| mean 100 episode length | 5.05     |
| mean 100 episode reward | 4.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7612   |
| steps                   | 763486   |
| td_erros                | -0.8475  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 136500   |
| lives                   | 136500   |
| mean 100 episode ei     | 4.62     |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7047   |
| steps                   | 763944   |
| td_erros                | -0.748   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 136600   |
| lives                   | 136600   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6638   |
| steps                   | 764406   |
| td_erros                | -0.7536  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 136700   |
| lives                   | 136700   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.661    |
| steps                   | 764868   |
| td_erros                | -0.8003  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 136800   |
| lives                   | 136800   |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6408   |
| steps                   | 765329   |
| td_erros                | -0.8529  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 136900   |
| lives                   | 136900   |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6632   |
| steps                   | 765787   |
| td_erros                | -0.908   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 137000   |
| lives                   | 137000   |
| mean 100 episode ei     | 4.47     |
| mean 100 episode length | 5.56     |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6646   |
| steps                   | 766243   |
| td_erros                | -0.9364  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 137100   |
| lives                   | 137100   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.64     |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7393   |
| steps                   | 766707   |
| td_erros                | -1.0374  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 137200   |
| lives                   | 137200   |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7684   |
| steps                   | 767169   |
| td_erros                | -1.1801  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 137300   |
| lives                   | 137300   |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 5.57     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7566   |
| steps                   | 767626   |
| td_erros                | -1.2218  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 137400   |
| lives                   | 137400   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7339   |
| steps                   | 768048   |
| td_erros                | -1.2644  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 137500   |
| lives                   | 137500   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7778   |
| steps                   | 768471   |
| td_erros                | -1.2615  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 137600   |
| lives                   | 137600   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8046   |
| steps                   | 768894   |
| td_erros                | -1.2404  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 137700   |
| lives                   | 137700   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.18     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8235   |
| steps                   | 769312   |
| td_erros                | -1.2072  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 137800   |
| lives                   | 137800   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 4.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8836   |
| steps                   | 769731   |
| td_erros                | -1.1344  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 137900   |
| lives                   | 137900   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9053   |
| steps                   | 770153   |
| td_erros                | -1.1101  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 138000   |
| lives                   | 138000   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9128   |
| steps                   | 770574   |
| td_erros                | -1.0177  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 138100   |
| lives                   | 138100   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8907   |
| steps                   | 770996   |
| td_erros                | -0.9358  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 138200   |
| lives                   | 138200   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.3      |
| mean 100 episode reward | 4.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.824    |
| steps                   | 771426   |
| td_erros                | -0.9113  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 138300   |
| lives                   | 138300   |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 5.51     |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7257   |
| steps                   | 771877   |
| td_erros                | -0.8764  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 138400   |
| lives                   | 138400   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.68     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6413   |
| steps                   | 772345   |
| td_erros                | -0.8839  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 138500   |
| lives                   | 138500   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5719   |
| steps                   | 772806   |
| td_erros                | -0.9104  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 138600   |
| lives                   | 138600   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5781   |
| steps                   | 773266   |
| td_erros                | -0.9393  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 138700   |
| lives                   | 138700   |
| mean 100 episode ei     | 4.7      |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5921   |
| steps                   | 773728   |
| td_erros                | -0.969   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 138800   |
| lives                   | 138800   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6532   |
| steps                   | 774190   |
| td_erros                | -0.9891  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 138900   |
| lives                   | 138900   |
| mean 100 episode ei     | 4.61     |
| mean 100 episode length | 5.57     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6945   |
| steps                   | 774647   |
| td_erros                | -1.0729  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 139000   |
| lives                   | 139000   |
| mean 100 episode ei     | 4.7      |
| mean 100 episode length | 5.74     |
| mean 100 episode reward | 5.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7456   |
| steps                   | 775121   |
| td_erros                | -1.152   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 139100   |
| lives                   | 139100   |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8031   |
| steps                   | 775586   |
| td_erros                | -1.2193  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 139200   |
| lives                   | 139200   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8053   |
| steps                   | 776051   |
| td_erros                | -1.2784  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 139300   |
| lives                   | 139300   |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8214   |
| steps                   | 776516   |
| td_erros                | -1.3644  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 139400   |
| lives                   | 139400   |
| mean 100 episode ei     | 4.33     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7938   |
| steps                   | 776956   |
| td_erros                | -1.4041  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 139500   |
| lives                   | 139500   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 4.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7631   |
| steps                   | 777380   |
| td_erros                | -1.3109  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 139600   |
| lives                   | 139600   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.784    |
| steps                   | 777801   |
| td_erros                | -1.2609  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 139700   |
| lives                   | 139700   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.18     |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8131   |
| steps                   | 778219   |
| td_erros                | -1.1593  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 139800   |
| lives                   | 139800   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.26     |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8454   |
| steps                   | 778645   |
| td_erros                | -1.1097  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 139900   |
| lives                   | 139900   |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8469   |
| steps                   | 779067   |
| td_erros                | -1.0512  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 140000   |
| lives                   | 140000   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8731   |
| steps                   | 779490   |
| td_erros                | -1.042   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 140100   |
| lives                   | 140100   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8917   |
| steps                   | 779913   |
| td_erros                | -0.9761  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 140200   |
| lives                   | 140200   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9166   |
| steps                   | 780335   |
| td_erros                | -0.9258  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 140300   |
| lives                   | 140300   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9061   |
| steps                   | 780757   |
| td_erros                | -0.8939  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 140400   |
| lives                   | 140400   |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 5.46     |
| mean 100 episode reward | 5.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8716   |
| steps                   | 781203   |
| td_erros                | -0.8482  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 140500   |
| lives                   | 140500   |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 5.66     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7724   |
| steps                   | 781669   |
| td_erros                | -0.8533  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 140600   |
| lives                   | 140600   |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6629   |
| steps                   | 782130   |
| td_erros                | -0.8824  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 140700   |
| lives                   | 140700   |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6003   |
| steps                   | 782595   |
| td_erros                | -0.8991  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 140800   |
| lives                   | 140800   |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5938   |
| steps                   | 783057   |
| td_erros                | -0.9504  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 140900   |
| lives                   | 140900   |
| mean 100 episode ei     | 4.47     |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5945   |
| steps                   | 783515   |
| td_erros                | -1.0049  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 141000   |
| lives                   | 141000   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6623   |
| steps                   | 783977   |
| td_erros                | -1.0389  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 141100   |
| lives                   | 141100   |
| mean 100 episode ei     | 4.7      |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7086   |
| steps                   | 784438   |
| td_erros                | -1.1214  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 141200   |
| lives                   | 141200   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.67     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7582   |
| steps                   | 784905   |
| td_erros                | -1.1415  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 141300   |
| lives                   | 141300   |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 5.35     |
| mean 100 episode reward | 4.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7816   |
| steps                   | 785340   |
| td_erros                | -1.2847  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 141400   |
| lives                   | 141400   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.28     |
| mean 100 episode reward | 4.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7994   |
| steps                   | 785768   |
| td_erros                | -1.2796  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 141500   |
| lives                   | 141500   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8036   |
| steps                   | 786192   |
| td_erros                | -1.2616  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 141600   |
| lives                   | 141600   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8161   |
| steps                   | 786614   |
| td_erros                | -1.1775  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 141700   |
| lives                   | 141700   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8223   |
| steps                   | 787036   |
| td_erros                | -1.1518  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 141800   |
| lives                   | 141800   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.85     |
| steps                   | 787460   |
| td_erros                | -1.0703  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 141900   |
| lives                   | 141900   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.28     |
| mean 100 episode reward | 4.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8706   |
| steps                   | 787888   |
| td_erros                | -1.0521  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 142000   |
| lives                   | 142000   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8582   |
| steps                   | 788311   |
| td_erros                | -1.0127  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 142100   |
| lives                   | 142100   |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 4.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8892   |
| steps                   | 788735   |
| td_erros                | -0.965   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 142200   |
| lives                   | 142200   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8518   |
| steps                   | 789157   |
| td_erros                | -0.9177  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 142300   |
| lives                   | 142300   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.27     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7899   |
| steps                   | 789584   |
| td_erros                | -0.8654  |
--------------------------------------
Saving model due to running mean reward increase: 4.8961 -> 5.2415
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 142400   |
| lives                   | 142400   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.66     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7128   |
| steps                   | 790050   |
| td_erros                | -0.8369  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 142500   |
| lives                   | 142500   |
| mean 100 episode ei     | 4.71     |
| mean 100 episode length | 5.66     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6419   |
| steps                   | 790516   |
| td_erros                | -0.8505  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 142600   |
| lives                   | 142600   |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 5.56     |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5841   |
| steps                   | 790972   |
| td_erros                | -0.8992  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 142700   |
| lives                   | 142700   |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.66     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6052   |
| steps                   | 791438   |
| td_erros                | -0.9322  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 142800   |
| lives                   | 142800   |
| mean 100 episode ei     | 4.45     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6209   |
| steps                   | 791897   |
| td_erros                | -0.9781  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 142900   |
| lives                   | 142900   |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6703   |
| steps                   | 792356   |
| td_erros                | -1.0521  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 143000   |
| lives                   | 143000   |
| mean 100 episode ei     | 4.41     |
| mean 100 episode length | 5.55     |
| mean 100 episode reward | 5.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7183   |
| steps                   | 792811   |
| td_erros                | -1.095   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 143100   |
| lives                   | 143100   |
| mean 100 episode ei     | 4.4      |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7614   |
| steps                   | 793254   |
| td_erros                | -1.1808  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 143200   |
| lives                   | 143200   |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7995   |
| steps                   | 793696   |
| td_erros                | -1.2107  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 143300   |
| lives                   | 143300   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7948   |
| steps                   | 794118   |
| td_erros                | -1.2592  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 143400   |
| lives                   | 143400   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 4.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8145   |
| steps                   | 794542   |
| td_erros                | -1.2607  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 143500   |
| lives                   | 143500   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8088   |
| steps                   | 794967   |
| td_erros                | -1.2002  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 143600   |
| lives                   | 143600   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8087   |
| steps                   | 795389   |
| td_erros                | -1.1803  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 143700   |
| lives                   | 143700   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 4.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8208   |
| steps                   | 795814   |
| td_erros                | -1.0977  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 143800   |
| lives                   | 143800   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8328   |
| steps                   | 796236   |
| td_erros                | -1.046   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 143900   |
| lives                   | 143900   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 5.27     |
| mean 100 episode reward | 4.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8525   |
| steps                   | 796663   |
| td_erros                | -1.0208  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 144000   |
| lives                   | 144000   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 4.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8143   |
| steps                   | 797087   |
| td_erros                | -0.9947  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 144100   |
| lives                   | 144100   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.27     |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7642   |
| steps                   | 797514   |
| td_erros                | -0.9117  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 144200   |
| lives                   | 144200   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.36     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6629   |
| steps                   | 797950   |
| td_erros                | -0.8656  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 144300   |
| lives                   | 144300   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6167   |
| steps                   | 798410   |
| td_erros                | -0.8508  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 144400   |
| lives                   | 144400   |
| mean 100 episode ei     | 4.69     |
| mean 100 episode length | 5.64     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5555   |
| steps                   | 798874   |
| td_erros                | -0.8765  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 144500   |
| lives                   | 144500   |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5632   |
| steps                   | 799334   |
| td_erros                | -0.9477  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 144600   |
| lives                   | 144600   |
| mean 100 episode ei     | 4.61     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6028   |
| steps                   | 799793   |
| td_erros                | -0.981   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 144700   |
| lives                   | 144700   |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 5.36     |
| mean 100 episode reward | 4.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6386   |
| steps                   | 800229   |
| td_erros                | -0.9987  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 144800   |
| lives                   | 144800   |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6598   |
| steps                   | 800670   |
| td_erros                | -1.006   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 144900   |
| lives                   | 144900   |
| mean 100 episode ei     | 4.24     |
| mean 100 episode length | 5.35     |
| mean 100 episode reward | 5.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6837   |
| steps                   | 801105   |
| td_erros                | -1.0277  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 145000   |
| lives                   | 145000   |
| mean 100 episode ei     | 4.24     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7078   |
| steps                   | 801546   |
| td_erros                | -1.0842  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 145100   |
| lives                   | 145100   |
| mean 100 episode ei     | 4.33     |
| mean 100 episode length | 5.47     |
| mean 100 episode reward | 5.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7514   |
| steps                   | 801993   |
| td_erros                | -1.1423  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 145200   |
| lives                   | 145200   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7786   |
| steps                   | 802415   |
| td_erros                | -1.1005  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 145300   |
| lives                   | 145300   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 4.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7895   |
| steps                   | 802839   |
| td_erros                | -1.1535  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 145400   |
| lives                   | 145400   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 5.27     |
| mean 100 episode reward | 4.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8003   |
| steps                   | 803266   |
| td_erros                | -1.0873  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 145500   |
| lives                   | 145500   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8117   |
| steps                   | 803688   |
| td_erros                | -1.0414  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 145600   |
| lives                   | 145600   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8034   |
| steps                   | 804109   |
| td_erros                | -1.0671  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 145700   |
| lives                   | 145700   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.02     |
| mean 100 episode reward | 4.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.781    |
| steps                   | 804511   |
| td_erros                | -0.9704  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 145800   |
| lives                   | 145800   |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7368   |
| steps                   | 804931   |
| td_erros                | -0.9372  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 145900   |
| lives                   | 145900   |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 5.51     |
| mean 100 episode reward | 5.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.703    |
| steps                   | 805382   |
| td_erros                | -0.8713  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 146000   |
| lives                   | 146000   |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7064   |
| steps                   | 805845   |
| td_erros                | -0.9475  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 146100   |
| lives                   | 146100   |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6983   |
| steps                   | 806310   |
| td_erros                | -0.9491  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 146200   |
| lives                   | 146200   |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7378   |
| steps                   | 806775   |
| td_erros                | -0.9533  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 146300   |
| lives                   | 146300   |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7539   |
| steps                   | 807237   |
| td_erros                | -1.0161  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 146400   |
| lives                   | 146400   |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 5.5      |
| mean 100 episode reward | 5.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7983   |
| steps                   | 807687   |
| td_erros                | -0.9836  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 146500   |
| lives                   | 146500   |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7791   |
| steps                   | 808149   |
| td_erros                | -1.0581  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 146600   |
| lives                   | 146600   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8275   |
| steps                   | 808573   |
| td_erros                | -1.092   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 146700   |
| lives                   | 146700   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8375   |
| steps                   | 808995   |
| td_erros                | -1.1315  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 146800   |
| lives                   | 146800   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8352   |
| steps                   | 809418   |
| td_erros                | -1.1261  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 146900   |
| lives                   | 146900   |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 4.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8424   |
| steps                   | 809837   |
| td_erros                | -1.1167  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 147000   |
| lives                   | 147000   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8184   |
| steps                   | 810261   |
| td_erros                | -1.0662  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 147100   |
| lives                   | 147100   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 4.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8177   |
| steps                   | 810686   |
| td_erros                | -1.0501  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 147200   |
| lives                   | 147200   |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8319   |
| steps                   | 811108   |
| td_erros                | -1.0052  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 147300   |
| lives                   | 147300   |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8434   |
| steps                   | 811529   |
| td_erros                | -0.9296  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 147400   |
| lives                   | 147400   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8118   |
| steps                   | 811949   |
| td_erros                | -0.878   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 147500   |
| lives                   | 147500   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7806   |
| steps                   | 812370   |
| td_erros                | -0.8542  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 147600   |
| lives                   | 147600   |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7243   |
| steps                   | 812809   |
| td_erros                | -0.8181  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 147700   |
| lives                   | 147700   |
| mean 100 episode ei     | 4.62     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6554   |
| steps                   | 813274   |
| td_erros                | -0.8385  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 147800   |
| lives                   | 147800   |
| mean 100 episode ei     | 4.49     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6358   |
| steps                   | 813733   |
| td_erros                | -0.85    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 147900   |
| lives                   | 147900   |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 5.55     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6091   |
| steps                   | 814188   |
| td_erros                | -0.9055  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 148000   |
| lives                   | 148000   |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6477   |
| steps                   | 814651   |
| td_erros                | -0.947   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 148100   |
| lives                   | 148100   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6844   |
| steps                   | 815112   |
| td_erros                | -1.0099  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 148200   |
| lives                   | 148200   |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7032   |
| steps                   | 815573   |
| td_erros                | -1.0496  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 148300   |
| lives                   | 148300   |
| mean 100 episode ei     | 4.61     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7701   |
| steps                   | 816032   |
| td_erros                | -1.1324  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 148400   |
| lives                   | 148400   |
| mean 100 episode ei     | 3.49     |
| mean 100 episode length | 5.08     |
| mean 100 episode reward | 5.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8046   |
| steps                   | 816440   |
| td_erros                | -1.1092  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 148500   |
| lives                   | 148500   |
| mean 100 episode ei     | 3.57     |
| mean 100 episode length | 5.06     |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.797    |
| steps                   | 816846   |
| td_erros                | -1.1018  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 148600   |
| lives                   | 148600   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.16     |
| mean 100 episode reward | 5.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.79     |
| steps                   | 817262   |
| td_erros                | -1.0778  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 148700   |
| lives                   | 148700   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.26     |
| mean 100 episode reward | 4.99     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7785   |
| steps                   | 817688   |
| td_erros                | -1.0817  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 148800   |
| lives                   | 148800   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.777    |
| steps                   | 818109   |
| td_erros                | -1.0956  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 148900   |
| lives                   | 148900   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 5.26     |
| mean 100 episode reward | 4.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7723   |
| steps                   | 818535   |
| td_erros                | -0.9709  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 149000   |
| lives                   | 149000   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7838   |
| steps                   | 818957   |
| td_erros                | -0.9637  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 149100   |
| lives                   | 149100   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7942   |
| steps                   | 819379   |
| td_erros                | -0.9488  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 149200   |
| lives                   | 149200   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7933   |
| steps                   | 819801   |
| td_erros                | -0.8687  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 149300   |
| lives                   | 149300   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8016   |
| steps                   | 820226   |
| td_erros                | -0.8669  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 149400   |
| lives                   | 149400   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.826    |
| steps                   | 820685   |
| td_erros                | -0.8038  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 149500   |
| lives                   | 149500   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7938   |
| steps                   | 821147   |
| td_erros                | -0.8321  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 149600   |
| lives                   | 149600   |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7753   |
| steps                   | 821610   |
| td_erros                | -0.864   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 149700   |
| lives                   | 149700   |
| mean 100 episode ei     | 4.51     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7353   |
| steps                   | 822069   |
| td_erros                | -0.9569  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 149800   |
| lives                   | 149800   |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 5.55     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7712   |
| steps                   | 822524   |
| td_erros                | -0.9542  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 149900   |
| lives                   | 149900   |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7866   |
| steps                   | 822987   |
| td_erros                | -1.0033  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 150000   |
| lives                   | 150000   |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.71     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8098   |
| steps                   | 823458   |
| td_erros                | -1.1129  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 150100   |
| lives                   | 150100   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8323   |
| steps                   | 823919   |
| td_erros                | -1.1623  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 150200   |
| lives                   | 150200   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.32     |
| mean 100 episode reward | 4.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8025   |
| steps                   | 824351   |
| td_erros                | -1.2416  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 150300   |
| lives                   | 150300   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 5.18     |
| mean 100 episode reward | 4.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8044   |
| steps                   | 824769   |
| td_erros                | -1.2467  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 150400   |
| lives                   | 150400   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8105   |
| steps                   | 825188   |
| td_erros                | -1.18    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 150500   |
| lives                   | 150500   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8182   |
| steps                   | 825609   |
| td_erros                | -1.1466  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 150600   |
| lives                   | 150600   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.3      |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8266   |
| steps                   | 826039   |
| td_erros                | -1.0736  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 150700   |
| lives                   | 150700   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.819    |
| steps                   | 826462   |
| td_erros                | -1.0355  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 150800   |
| lives                   | 150800   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.871    |
| steps                   | 826884   |
| td_erros                | -1.0187  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 150900   |
| lives                   | 150900   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8938   |
| steps                   | 827306   |
| td_erros                | -0.9493  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 151000   |
| lives                   | 151000   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9026   |
| steps                   | 827726   |
| td_erros                | -0.9519  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 151100   |
| lives                   | 151100   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.29     |
| mean 100 episode reward | 4.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8576   |
| steps                   | 828155   |
| td_erros                | -0.909   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 151200   |
| lives                   | 151200   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 5.27     |
| mean 100 episode reward | 4.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7759   |
| steps                   | 828582   |
| td_erros                | -0.8098  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 151300   |
| lives                   | 151300   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 4.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6854   |
| steps                   | 829023   |
| td_erros                | -0.7751  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 151400   |
| lives                   | 151400   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 4.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5754   |
| steps                   | 829485   |
| td_erros                | -0.7413  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 151500   |
| lives                   | 151500   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.66     |
| mean 100 episode reward | 4.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.534    |
| steps                   | 829951   |
| td_erros                | -0.8127  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 151600   |
| lives                   | 151600   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 4.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5256   |
| steps                   | 830412   |
| td_erros                | -0.8348  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 151700   |
| lives                   | 151700   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 4.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5108   |
| steps                   | 830877   |
| td_erros                | -0.8342  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 151800   |
| lives                   | 151800   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 4.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4823   |
| steps                   | 831339   |
| td_erros                | -0.8211  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 151900   |
| lives                   | 151900   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 4.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4989   |
| steps                   | 831801   |
| td_erros                | -0.8747  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 152000   |
| lives                   | 152000   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.7      |
| mean 100 episode reward | 4.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4695   |
| steps                   | 832271   |
| td_erros                | -0.9021  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 152100   |
| lives                   | 152100   |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 5.64     |
| mean 100 episode reward | 4.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4793   |
| steps                   | 832735   |
| td_erros                | -0.8793  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 152200   |
| lives                   | 152200   |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5015   |
| steps                   | 833200   |
| td_erros                | -0.9299  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 152300   |
| lives                   | 152300   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.37     |
| mean 100 episode reward | 4.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4983   |
| steps                   | 833637   |
| td_erros                | -0.9884  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 152400   |
| lives                   | 152400   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5195   |
| steps                   | 834057   |
| td_erros                | -0.9712  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 152500   |
| lives                   | 152500   |
| mean 100 episode ei     | 3.79     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 4.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5315   |
| steps                   | 834482   |
| td_erros                | -0.9575  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 152600   |
| lives                   | 152600   |
| mean 100 episode ei     | 3.15     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 4.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5454   |
| steps                   | 834907   |
| td_erros                | -0.9352  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 152700   |
| lives                   | 152700   |
| mean 100 episode ei     | 3.27     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 4.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5415   |
| steps                   | 835332   |
| td_erros                | -0.9173  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 152800   |
| lives                   | 152800   |
| mean 100 episode ei     | 3.19     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5276   |
| steps                   | 835752   |
| td_erros                | -0.7945  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 152900   |
| lives                   | 152900   |
| mean 100 episode ei     | 3.18     |
| mean 100 episode length | 5.17     |
| mean 100 episode reward | 4.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4992   |
| steps                   | 836169   |
| td_erros                | -0.755   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 153000   |
| lives                   | 153000   |
| mean 100 episode ei     | 3.23     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5131   |
| steps                   | 836589   |
| td_erros                | -0.65    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 153100   |
| lives                   | 153100   |
| mean 100 episode ei     | 3.14     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4827   |
| steps                   | 837011   |
| td_erros                | -0.5743  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 153200   |
| lives                   | 153200   |
| mean 100 episode ei     | 3.36     |
| mean 100 episode length | 5.33     |
| mean 100 episode reward | 4.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4684   |
| steps                   | 837444   |
| td_erros                | -0.5455  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 153300   |
| lives                   | 153300   |
| mean 100 episode ei     | 3.67     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 4.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3877   |
| steps                   | 837886   |
| td_erros                | -0.5201  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 153400   |
| lives                   | 153400   |
| mean 100 episode ei     | 3.46     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 4.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.312    |
| steps                   | 838329   |
| td_erros                | -0.479   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 153500   |
| lives                   | 153500   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 4.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2205   |
| steps                   | 838791   |
| td_erros                | -0.4605  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 153600   |
| lives                   | 153600   |
| mean 100 episode ei     | 4.33     |
| mean 100 episode length | 5.8      |
| mean 100 episode reward | 5.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1825   |
| steps                   | 839271   |
| td_erros                | -0.493   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 153700   |
| lives                   | 153700   |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 5.83     |
| mean 100 episode reward | 5.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1107   |
| steps                   | 839754   |
| td_erros                | -0.5469  |
--------------------------------------
Saving model due to running mean reward increase: 5.0346 -> 5.0919
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 153800   |
| lives                   | 153800   |
| mean 100 episode ei     | 4.33     |
| mean 100 episode length | 5.81     |
| mean 100 episode reward | 5.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1048   |
| steps                   | 840235   |
| td_erros                | -0.5921  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 153900   |
| lives                   | 153900   |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 5.85     |
| mean 100 episode reward | 5.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1514   |
| steps                   | 840720   |
| td_erros                | -0.6277  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 154000   |
| lives                   | 154000   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.77     |
| mean 100 episode reward | 4.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1947   |
| steps                   | 841197   |
| td_erros                | -0.6949  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 154100   |
| lives                   | 154100   |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 5.89     |
| mean 100 episode reward | 4.96     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2417   |
| steps                   | 841686   |
| td_erros                | -0.7742  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 154200   |
| lives                   | 154200   |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 5.78     |
| mean 100 episode reward | 4.99     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3083   |
| steps                   | 842164   |
| td_erros                | -0.8274  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 154300   |
| lives                   | 154300   |
| mean 100 episode ei     | 4.52     |
| mean 100 episode length | 5.66     |
| mean 100 episode reward | 5.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3725   |
| steps                   | 842630   |
| td_erros                | -0.8379  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 154400   |
| lives                   | 154400   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4173   |
| steps                   | 843090   |
| td_erros                | -0.8757  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 154500   |
| lives                   | 154500   |
| mean 100 episode ei     | 4.61     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4864   |
| steps                   | 843551   |
| td_erros                | -0.9494  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 154600   |
| lives                   | 154600   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5171   |
| steps                   | 844016   |
| td_erros                | -1.0141  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 154700   |
| lives                   | 154700   |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5382   |
| steps                   | 844475   |
| td_erros                | -1.0247  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 154800   |
| lives                   | 154800   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5864   |
| steps                   | 844937   |
| td_erros                | -0.9998  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 154900   |
| lives                   | 154900   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6105   |
| steps                   | 845398   |
| td_erros                | -1.0429  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 155000   |
| lives                   | 155000   |
| mean 100 episode ei     | 4.21     |
| mean 100 episode length | 5.35     |
| mean 100 episode reward | 4.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6323   |
| steps                   | 845833   |
| td_erros                | -1.0327  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 155100   |
| lives                   | 155100   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.685    |
| steps                   | 846255   |
| td_erros                | -0.9721  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 155200   |
| lives                   | 155200   |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 5.29     |
| mean 100 episode reward | 4.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7308   |
| steps                   | 846684   |
| td_erros                | -0.8977  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 155300   |
| lives                   | 155300   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7816   |
| steps                   | 847104   |
| td_erros                | -0.877   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 155400   |
| lives                   | 155400   |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7937   |
| steps                   | 847527   |
| td_erros                | -0.8694  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 155500   |
| lives                   | 155500   |
| mean 100 episode ei     | 3.49     |
| mean 100 episode length | 4.8      |
| mean 100 episode reward | 4.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8343   |
| steps                   | 847907   |
| td_erros                | -0.7408  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 155600   |
| lives                   | 155600   |
| mean 100 episode ei     | 3.55     |
| mean 100 episode length | 4.84     |
| mean 100 episode reward | 4.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8454   |
| steps                   | 848291   |
| td_erros                | -0.6718  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 155700   |
| lives                   | 155700   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 5.16     |
| mean 100 episode reward | 4.69     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8558   |
| steps                   | 848707   |
| td_erros                | -0.585   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 155800   |
| lives                   | 155800   |
| mean 100 episode ei     | 3.8      |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8699   |
| steps                   | 849129   |
| td_erros                | -0.5909  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 155900   |
| lives                   | 155900   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8637   |
| steps                   | 849551   |
| td_erros                | -0.5264  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 156000   |
| lives                   | 156000   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8371   |
| steps                   | 849970   |
| td_erros                | -0.4935  |
--------------------------------------
Saving model due to running mean reward increase: 4.8162 -> 4.8867
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 156100   |
| lives                   | 156100   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.3      |
| mean 100 episode reward | 4.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8178   |
| steps                   | 850400   |
| td_erros                | -0.4913  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 156200   |
| lives                   | 156200   |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 5.54     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7743   |
| steps                   | 850854   |
| td_erros                | -0.4656  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 156300   |
| lives                   | 156300   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7248   |
| steps                   | 851314   |
| td_erros                | -0.4995  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 156400   |
| lives                   | 156400   |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.685    |
| steps                   | 851772   |
| td_erros                | -0.6028  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 156500   |
| lives                   | 156500   |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 5.64     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7133   |
| steps                   | 852236   |
| td_erros                | -0.6584  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 156600   |
| lives                   | 156600   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.56     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7369   |
| steps                   | 852692   |
| td_erros                | -0.681   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 156700   |
| lives                   | 156700   |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7585   |
| steps                   | 853153   |
| td_erros                | -0.8264  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 156800   |
| lives                   | 156800   |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 5.64     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8023   |
| steps                   | 853617   |
| td_erros                | -0.9644  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 156900   |
| lives                   | 156900   |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8411   |
| steps                   | 854077   |
| td_erros                | -1.0224  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 157000   |
| lives                   | 157000   |
| mean 100 episode ei     | 4.4      |
| mean 100 episode length | 5.46     |
| mean 100 episode reward | 5.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8581   |
| steps                   | 854523   |
| td_erros                | -1.0688  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 157100   |
| lives                   | 157100   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8453   |
| steps                   | 854944   |
| td_erros                | -1.1108  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 157200   |
| lives                   | 157200   |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 4.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8159   |
| steps                   | 855363   |
| td_erros                | -1.0571  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 157300   |
| lives                   | 157300   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 4.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8503   |
| steps                   | 855782   |
| td_erros                | -1.0476  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 157400   |
| lives                   | 157400   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8549   |
| steps                   | 856202   |
| td_erros                | -1.0009  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 157500   |
| lives                   | 157500   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8605   |
| steps                   | 856625   |
| td_erros                | -0.9515  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 157600   |
| lives                   | 157600   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8631   |
| steps                   | 857046   |
| td_erros                | -0.9181  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 157700   |
| lives                   | 157700   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8744   |
| steps                   | 857470   |
| td_erros                | -0.884   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 157800   |
| lives                   | 157800   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.26     |
| mean 100 episode reward | 4.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8925   |
| steps                   | 857896   |
| td_erros                | -0.843   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 157900   |
| lives                   | 157900   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.28     |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8983   |
| steps                   | 858324   |
| td_erros                | -0.7931  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 158000   |
| lives                   | 158000   |
| mean 100 episode ei     | 4.42     |
| mean 100 episode length | 5.54     |
| mean 100 episode reward | 5.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8652   |
| steps                   | 858778   |
| td_erros                | -0.7465  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 158100   |
| lives                   | 158100   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.66     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7994   |
| steps                   | 859244   |
| td_erros                | -0.7733  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 158200   |
| lives                   | 158200   |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.734    |
| steps                   | 859702   |
| td_erros                | -0.8272  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 158300   |
| lives                   | 158300   |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7177   |
| steps                   | 860167   |
| td_erros                | -0.8324  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 158400   |
| lives                   | 158400   |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 5.32     |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6929   |
| steps                   | 860599   |
| td_erros                | -0.8643  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 158500   |
| lives                   | 158500   |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 5.38     |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7103   |
| steps                   | 861037   |
| td_erros                | -0.938   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 158600   |
| lives                   | 158600   |
| mean 100 episode ei     | 4.52     |
| mean 100 episode length | 5.54     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.738    |
| steps                   | 861491   |
| td_erros                | -1.0034  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 158700   |
| lives                   | 158700   |
| mean 100 episode ei     | 4.42     |
| mean 100 episode length | 5.49     |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7544   |
| steps                   | 861940   |
| td_erros                | -1.0828  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 158800   |
| lives                   | 158800   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.64     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8024   |
| steps                   | 862404   |
| td_erros                | -1.1132  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 158900   |
| lives                   | 158900   |
| mean 100 episode ei     | 4.69     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8063   |
| steps                   | 862866   |
| td_erros                | -1.1656  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 159000   |
| lives                   | 159000   |
| mean 100 episode ei     | 4.49     |
| mean 100 episode length | 5.52     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8272   |
| steps                   | 863318   |
| td_erros                | -1.1943  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 159100   |
| lives                   | 159100   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7842   |
| steps                   | 863739   |
| td_erros                | -1.2823  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 159200   |
| lives                   | 159200   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.776    |
| steps                   | 864160   |
| td_erros                | -1.2532  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 159300   |
| lives                   | 159300   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7745   |
| steps                   | 864585   |
| td_erros                | -1.1503  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 159400   |
| lives                   | 159400   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7987   |
| steps                   | 865005   |
| td_erros                | -1.1432  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 159500   |
| lives                   | 159500   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.28     |
| mean 100 episode reward | 4.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8083   |
| steps                   | 865433   |
| td_erros                | -1.0874  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 159600   |
| lives                   | 159600   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 4.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8496   |
| steps                   | 865858   |
| td_erros                | -1.0288  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 159700   |
| lives                   | 159700   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8535   |
| steps                   | 866278   |
| td_erros                | -1.0024  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 159800   |
| lives                   | 159800   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8359   |
| steps                   | 866701   |
| td_erros                | -0.9455  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 159900   |
| lives                   | 159900   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8139   |
| steps                   | 867124   |
| td_erros                | -0.9515  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 160000   |
| lives                   | 160000   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7996   |
| steps                   | 867545   |
| td_erros                | -0.864   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 160100   |
| lives                   | 160100   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 5.3      |
| mean 100 episode reward | 4.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.73     |
| steps                   | 867975   |
| td_erros                | -0.8367  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 160200   |
| lives                   | 160200   |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6706   |
| steps                   | 868434   |
| td_erros                | -0.7907  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 160300   |
| lives                   | 160300   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6      |
| steps                   | 868894   |
| td_erros                | -0.8239  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 160400   |
| lives                   | 160400   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5928   |
| steps                   | 869356   |
| td_erros                | -0.864   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 160500   |
| lives                   | 160500   |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5948   |
| steps                   | 869818   |
| td_erros                | -0.9375  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 160600   |
| lives                   | 160600   |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6352   |
| steps                   | 870279   |
| td_erros                | -0.9674  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 160700   |
| lives                   | 160700   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6777   |
| steps                   | 870739   |
| td_erros                | -0.9909  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 160800   |
| lives                   | 160800   |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7254   |
| steps                   | 871202   |
| td_erros                | -1.077   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 160900   |
| lives                   | 160900   |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7596   |
| steps                   | 871665   |
| td_erros                | -1.1763  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 161000   |
| lives                   | 161000   |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.811    |
| steps                   | 872128   |
| td_erros                | -1.2245  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 161100   |
| lives                   | 161100   |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 5.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8461   |
| steps                   | 872593   |
| td_erros                | -1.286   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 161200   |
| lives                   | 161200   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8605   |
| steps                   | 873016   |
| td_erros                | -1.3542  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 161300   |
| lives                   | 161300   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 4.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8121   |
| steps                   | 873440   |
| td_erros                | -1.3589  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 161400   |
| lives                   | 161400   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7925   |
| steps                   | 873863   |
| td_erros                | -1.2647  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 161500   |
| lives                   | 161500   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8034   |
| steps                   | 874287   |
| td_erros                | -1.1818  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 161600   |
| lives                   | 161600   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8138   |
| steps                   | 874707   |
| td_erros                | -1.141   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 161700   |
| lives                   | 161700   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8353   |
| steps                   | 875128   |
| td_erros                | -1.1218  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 161800   |
| lives                   | 161800   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8403   |
| steps                   | 875552   |
| td_erros                | -1.0807  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 161900   |
| lives                   | 161900   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 4.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8411   |
| steps                   | 875976   |
| td_erros                | -1.0005  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 162000   |
| lives                   | 162000   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.3      |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8421   |
| steps                   | 876406   |
| td_erros                | -0.9385  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 162100   |
| lives                   | 162100   |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8137   |
| steps                   | 876864   |
| td_erros                | -0.9891  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 162200   |
| lives                   | 162200   |
| mean 100 episode ei     | 4.49     |
| mean 100 episode length | 5.57     |
| mean 100 episode reward | 5.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7461   |
| steps                   | 877321   |
| td_erros                | -0.9322  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 162300   |
| lives                   | 162300   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.698    |
| steps                   | 877783   |
| td_erros                | -0.9238  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 162400   |
| lives                   | 162400   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6638   |
| steps                   | 878245   |
| td_erros                | -1.0041  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 162500   |
| lives                   | 162500   |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6604   |
| steps                   | 878708   |
| td_erros                | -1.0271  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 162600   |
| lives                   | 162600   |
| mean 100 episode ei     | 4.45     |
| mean 100 episode length | 5.45     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7131   |
| steps                   | 879153   |
| td_erros                | -1.1128  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 162700   |
| lives                   | 162700   |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 5.26     |
| mean 100 episode reward | 4.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7593   |
| steps                   | 879579   |
| td_erros                | -1.1292  |
--------------------------------------
Saving model due to running mean reward increase: 4.9506 -> 5.1885
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 162800   |
| lives                   | 162800   |
| mean 100 episode ei     | 4.35     |
| mean 100 episode length | 5.48     |
| mean 100 episode reward | 5.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7653   |
| steps                   | 880027   |
| td_erros                | -1.2125  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 162900   |
| lives                   | 162900   |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8008   |
| steps                   | 880489   |
| td_erros                | -1.2395  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 163000   |
| lives                   | 163000   |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 5.33     |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7929   |
| steps                   | 880922   |
| td_erros                | -1.3446  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 163100   |
| lives                   | 163100   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.36     |
| mean 100 episode reward | 4.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7926   |
| steps                   | 881358   |
| td_erros                | -1.3763  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 163200   |
| lives                   | 163200   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7632   |
| steps                   | 881780   |
| td_erros                | -1.3137  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 163300   |
| lives                   | 163300   |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7574   |
| steps                   | 882201   |
| td_erros                | -1.2684  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 163400   |
| lives                   | 163400   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.26     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7481   |
| steps                   | 882627   |
| td_erros                | -1.2014  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 163500   |
| lives                   | 163500   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7784   |
| steps                   | 883048   |
| td_erros                | -1.1414  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 163600   |
| lives                   | 163600   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.3      |
| mean 100 episode reward | 4.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.781    |
| steps                   | 883478   |
| td_erros                | -1.0959  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 163700   |
| lives                   | 163700   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 5.28     |
| mean 100 episode reward | 4.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7691   |
| steps                   | 883906   |
| td_erros                | -1.0923  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 163800   |
| lives                   | 163800   |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 4.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7476   |
| steps                   | 884330   |
| td_erros                | -0.9751  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 163900   |
| lives                   | 163900   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 5.26     |
| mean 100 episode reward | 4.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7319   |
| steps                   | 884756   |
| td_erros                | -0.9603  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 164000   |
| lives                   | 164000   |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 5.32     |
| mean 100 episode reward | 5.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6844   |
| steps                   | 885188   |
| td_erros                | -0.9124  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 164100   |
| lives                   | 164100   |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6421   |
| steps                   | 885649   |
| td_erros                | -0.9061  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 164200   |
| lives                   | 164200   |
| mean 100 episode ei     | 4.45     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.599    |
| steps                   | 886110   |
| td_erros                | -0.8899  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 164300   |
| lives                   | 164300   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.64     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5789   |
| steps                   | 886574   |
| td_erros                | -0.9209  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 164400   |
| lives                   | 164400   |
| mean 100 episode ei     | 4.69     |
| mean 100 episode length | 5.69     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5894   |
| steps                   | 887043   |
| td_erros                | -0.9773  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 164500   |
| lives                   | 164500   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6257   |
| steps                   | 887504   |
| td_erros                | -1.0293  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 164600   |
| lives                   | 164600   |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 5.64     |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.656    |
| steps                   | 887968   |
| td_erros                | -1.0919  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 164700   |
| lives                   | 164700   |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7085   |
| steps                   | 888430   |
| td_erros                | -1.2171  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 164800   |
| lives                   | 164800   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7452   |
| steps                   | 888893   |
| td_erros                | -1.2099  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 164900   |
| lives                   | 164900   |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7814   |
| steps                   | 889356   |
| td_erros                | -1.325   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 165000   |
| lives                   | 165000   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.3      |
| mean 100 episode reward | 4.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.789    |
| steps                   | 889786   |
| td_erros                | -1.364   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 165100   |
| lives                   | 165100   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7678   |
| steps                   | 890207   |
| td_erros                | -1.3176  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 165200   |
| lives                   | 165200   |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 5.16     |
| mean 100 episode reward | 4.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7572   |
| steps                   | 890623   |
| td_erros                | -1.2537  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 165300   |
| lives                   | 165300   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.767    |
| steps                   | 891044   |
| td_erros                | -1.1708  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 165400   |
| lives                   | 165400   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.53     |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7918   |
| steps                   | 891497   |
| td_erros                | -1.1099  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 165500   |
| lives                   | 165500   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7951   |
| steps                   | 891958   |
| td_erros                | -1.0697  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 165600   |
| lives                   | 165600   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 4.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8178   |
| steps                   | 892420   |
| td_erros                | -1.0251  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 165700   |
| lives                   | 165700   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.64     |
| mean 100 episode reward | 4.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8215   |
| steps                   | 892884   |
| td_erros                | -0.9613  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 165800   |
| lives                   | 165800   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7645   |
| steps                   | 893347   |
| td_erros                | -0.9197  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 165900   |
| lives                   | 165900   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 4.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7263   |
| steps                   | 893806   |
| td_erros                | -0.861   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 166000   |
| lives                   | 166000   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.56     |
| mean 100 episode reward | 4.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6442   |
| steps                   | 894262   |
| td_erros                | -0.819   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 166100   |
| lives                   | 166100   |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5873   |
| steps                   | 894722   |
| td_erros                | -0.7968  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 166200   |
| lives                   | 166200   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5345   |
| steps                   | 895182   |
| td_erros                | -0.8081  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 166300   |
| lives                   | 166300   |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5232   |
| steps                   | 895643   |
| td_erros                | -0.8998  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 166400   |
| lives                   | 166400   |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5036   |
| steps                   | 896106   |
| td_erros                | -0.8871  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 166500   |
| lives                   | 166500   |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5488   |
| steps                   | 896565   |
| td_erros                | -0.9871  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 166600   |
| lives                   | 166600   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6021   |
| steps                   | 897025   |
| td_erros                | -1.0734  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 166700   |
| lives                   | 166700   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6722   |
| steps                   | 897486   |
| td_erros                | -1.1344  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 166800   |
| lives                   | 166800   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.45     |
| mean 100 episode reward | 4.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7367   |
| steps                   | 897931   |
| td_erros                | -1.2271  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 166900   |
| lives                   | 166900   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.38     |
| mean 100 episode reward | 4.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7323   |
| steps                   | 898369   |
| td_erros                | -1.2869  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 167000   |
| lives                   | 167000   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 5.71     |
| mean 100 episode reward | 4.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7351   |
| steps                   | 898840   |
| td_erros                | -1.2757  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 167100   |
| lives                   | 167100   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 4.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.722    |
| steps                   | 899301   |
| td_erros                | -1.306   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 167200   |
| lives                   | 167200   |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 4.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.706    |
| steps                   | 899766   |
| td_erros                | -1.2231  |
--------------------------------------
Saving model due to running mean reward increase: 4.6645 -> 4.8413
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 167300   |
| lives                   | 167300   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7056   |
| steps                   | 900228   |
| td_erros                | -1.1719  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 167400   |
| lives                   | 167400   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 4.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7062   |
| steps                   | 900689   |
| td_erros                | -1.123   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 167500   |
| lives                   | 167500   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 4.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6885   |
| steps                   | 901147   |
| td_erros                | -1.0319  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 167600   |
| lives                   | 167600   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.33     |
| mean 100 episode reward | 4.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6421   |
| steps                   | 901580   |
| td_erros                | -0.9719  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 167700   |
| lives                   | 167700   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 5.27     |
| mean 100 episode reward | 4.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6055   |
| steps                   | 902007   |
| td_erros                | -0.911   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 167800   |
| lives                   | 167800   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 4.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5015   |
| steps                   | 902446   |
| td_erros                | -0.8982  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 167900   |
| lives                   | 167900   |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4371   |
| steps                   | 902909   |
| td_erros                | -0.8506  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 168000   |
| lives                   | 168000   |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4168   |
| steps                   | 903368   |
| td_erros                | -0.9109  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 168100   |
| lives                   | 168100   |
| mean 100 episode ei     | 4.52     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4593   |
| steps                   | 903828   |
| td_erros                | -0.9106  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 168200   |
| lives                   | 168200   |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5331   |
| steps                   | 904288   |
| td_erros                | -1.0243  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 168300   |
| lives                   | 168300   |
| mean 100 episode ei     | 4.62     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5756   |
| steps                   | 904750   |
| td_erros                | -1.0744  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 168400   |
| lives                   | 168400   |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 5.57     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6512   |
| steps                   | 905207   |
| td_erros                | -1.1431  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 168500   |
| lives                   | 168500   |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7034   |
| steps                   | 905668   |
| td_erros                | -1.1599  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 168600   |
| lives                   | 168600   |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 5.7      |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7288   |
| steps                   | 906138   |
| td_erros                | -1.2834  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 168700   |
| lives                   | 168700   |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7468   |
| steps                   | 906601   |
| td_erros                | -1.3625  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 168800   |
| lives                   | 168800   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.33     |
| mean 100 episode reward | 4.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.762    |
| steps                   | 907034   |
| td_erros                | -1.3713  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 168900   |
| lives                   | 168900   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7565   |
| steps                   | 907455   |
| td_erros                | -1.3986  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 169000   |
| lives                   | 169000   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7389   |
| steps                   | 907877   |
| td_erros                | -1.3698  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 169100   |
| lives                   | 169100   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7317   |
| steps                   | 908298   |
| td_erros                | -1.2673  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 169200   |
| lives                   | 169200   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.27     |
| mean 100 episode reward | 4.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7322   |
| steps                   | 908725   |
| td_erros                | -1.2259  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 169300   |
| lives                   | 169300   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.28     |
| mean 100 episode reward | 4.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7278   |
| steps                   | 909153   |
| td_erros                | -1.1332  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 169400   |
| lives                   | 169400   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7404   |
| steps                   | 909576   |
| td_erros                | -1.1258  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 169500   |
| lives                   | 169500   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.18     |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7458   |
| steps                   | 909994   |
| td_erros                | -1.0688  |
--------------------------------------
Saving model due to running mean reward increase: 4.854 -> 4.8669
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 169600   |
| lives                   | 169600   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.26     |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7278   |
| steps                   | 910420   |
| td_erros                | -1.0059  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 169700   |
| lives                   | 169700   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 5.29     |
| mean 100 episode reward | 4.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7618   |
| steps                   | 910849   |
| td_erros                | -0.9635  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 169800   |
| lives                   | 169800   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.27     |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7428   |
| steps                   | 911276   |
| td_erros                | -0.9287  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 169900   |
| lives                   | 169900   |
| mean 100 episode ei     | 4.21     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 4.99     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.703    |
| steps                   | 911715   |
| td_erros                | -0.8788  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 170000   |
| lives                   | 170000   |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6722   |
| steps                   | 912177   |
| td_erros                | -0.8677  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 170100   |
| lives                   | 170100   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.66     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6365   |
| steps                   | 912643   |
| td_erros                | -0.901   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 170200   |
| lives                   | 170200   |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6033   |
| steps                   | 913108   |
| td_erros                | -0.9451  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 170300   |
| lives                   | 170300   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.615    |
| steps                   | 913568   |
| td_erros                | -1.0046  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 170400   |
| lives                   | 170400   |
| mean 100 episode ei     | 4.52     |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6386   |
| steps                   | 914026   |
| td_erros                | -1.0981  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 170500   |
| lives                   | 170500   |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 5.64     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6855   |
| steps                   | 914490   |
| td_erros                | -1.1297  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 170600   |
| lives                   | 170600   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7239   |
| steps                   | 914955   |
| td_erros                | -1.2129  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 170700   |
| lives                   | 170700   |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 5.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7709   |
| steps                   | 915420   |
| td_erros                | -1.2463  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 170800   |
| lives                   | 170800   |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7548   |
| steps                   | 915864   |
| td_erros                | -1.3644  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 170900   |
| lives                   | 170900   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7752   |
| steps                   | 916287   |
| td_erros                | -1.3079  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 171000   |
| lives                   | 171000   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 4.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7579   |
| steps                   | 916706   |
| td_erros                | -1.3265  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 171100   |
| lives                   | 171100   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7413   |
| steps                   | 917131   |
| td_erros                | -1.2379  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 171200   |
| lives                   | 171200   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.33     |
| mean 100 episode reward | 4.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7591   |
| steps                   | 917564   |
| td_erros                | -1.1894  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 171300   |
| lives                   | 171300   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.28     |
| mean 100 episode reward | 4.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7718   |
| steps                   | 917992   |
| td_erros                | -1.1381  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 171400   |
| lives                   | 171400   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.31     |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7801   |
| steps                   | 918423   |
| td_erros                | -1.0477  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 171500   |
| lives                   | 171500   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 4.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7749   |
| steps                   | 918884   |
| td_erros                | -1.059   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 171600   |
| lives                   | 171600   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7921   |
| steps                   | 919305   |
| td_erros                | -0.9975  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 171700   |
| lives                   | 171700   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7805   |
| steps                   | 919729   |
| td_erros                | -0.9518  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 171800   |
| lives                   | 171800   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7482   |
| steps                   | 920153   |
| td_erros                | -0.9214  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 171900   |
| lives                   | 171900   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.32     |
| mean 100 episode reward | 4.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7046   |
| steps                   | 920585   |
| td_erros                | -0.8746  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 172000   |
| lives                   | 172000   |
| mean 100 episode ei     | 4.41     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6156   |
| steps                   | 921045   |
| td_erros                | -0.8899  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 172100   |
| lives                   | 172100   |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5711   |
| steps                   | 921508   |
| td_erros                | -0.9132  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 172200   |
| lives                   | 172200   |
| mean 100 episode ei     | 4.72     |
| mean 100 episode length | 5.7      |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5289   |
| steps                   | 921978   |
| td_erros                | -0.9483  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 172300   |
| lives                   | 172300   |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 5.57     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5654   |
| steps                   | 922435   |
| td_erros                | -1.0546  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 172400   |
| lives                   | 172400   |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6048   |
| steps                   | 922894   |
| td_erros                | -1.0772  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 172500   |
| lives                   | 172500   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6739   |
| steps                   | 923356   |
| td_erros                | -1.1615  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 172600   |
| lives                   | 172600   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7075   |
| steps                   | 923816   |
| td_erros                | -1.1943  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 172700   |
| lives                   | 172700   |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.758    |
| steps                   | 924278   |
| td_erros                | -1.275   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 172800   |
| lives                   | 172800   |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 5.54     |
| mean 100 episode reward | 5.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7502   |
| steps                   | 924732   |
| td_erros                | -1.3086  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 172900   |
| lives                   | 172900   |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 5.57     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8054   |
| steps                   | 925189   |
| td_erros                | -1.3142  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 173000   |
| lives                   | 173000   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.27     |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7778   |
| steps                   | 925616   |
| td_erros                | -1.3795  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 173100   |
| lives                   | 173100   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 4.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7602   |
| steps                   | 926035   |
| td_erros                | -1.3362  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 173200   |
| lives                   | 173200   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.27     |
| mean 100 episode reward | 4.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7585   |
| steps                   | 926462   |
| td_erros                | -1.2     |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 173300   |
| lives                   | 173300   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7232   |
| steps                   | 926883   |
| td_erros                | -1.1807  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 173400   |
| lives                   | 173400   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7091   |
| steps                   | 927305   |
| td_erros                | -1.1866  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 173500   |
| lives                   | 173500   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.26     |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7402   |
| steps                   | 927731   |
| td_erros                | -1.0834  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 173600   |
| lives                   | 173600   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.76     |
| steps                   | 928152   |
| td_erros                | -1.0623  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 173700   |
| lives                   | 173700   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 4.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7784   |
| steps                   | 928577   |
| td_erros                | -0.9922  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 173800   |
| lives                   | 173800   |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 4.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.77     |
| steps                   | 929002   |
| td_erros                | -0.9855  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 173900   |
| lives                   | 173900   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7153   |
| steps                   | 929427   |
| td_erros                | -0.9661  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 174000   |
| lives                   | 174000   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.26     |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6972   |
| steps                   | 929853   |
| td_erros                | -0.9189  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 174100   |
| lives                   | 174100   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 5.26     |
| mean 100 episode reward | 4.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6228   |
| steps                   | 930279   |
| td_erros                | -0.8594  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 174200   |
| lives                   | 174200   |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 5.55     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5746   |
| steps                   | 930734   |
| td_erros                | -0.8323  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 174300   |
| lives                   | 174300   |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5213   |
| steps                   | 931192   |
| td_erros                | -0.8923  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 174400   |
| lives                   | 174400   |
| mean 100 episode ei     | 4.43     |
| mean 100 episode length | 5.56     |
| mean 100 episode reward | 5.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5316   |
| steps                   | 931648   |
| td_erros                | -0.9348  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 174500   |
| lives                   | 174500   |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5358   |
| steps                   | 932107   |
| td_erros                | -0.9969  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 174600   |
| lives                   | 174600   |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5581   |
| steps                   | 932570   |
| td_erros                | -0.9936  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 174700   |
| lives                   | 174700   |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6136   |
| steps                   | 933028   |
| td_erros                | -1.1077  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 174800   |
| lives                   | 174800   |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6625   |
| steps                   | 933491   |
| td_erros                | -1.1824  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 174900   |
| lives                   | 174900   |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 5.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7002   |
| steps                   | 933949   |
| td_erros                | -1.2191  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 175000   |
| lives                   | 175000   |
| mean 100 episode ei     | 4.33     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7294   |
| steps                   | 934392   |
| td_erros                | -1.2731  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 175100   |
| lives                   | 175100   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.29     |
| mean 100 episode reward | 4.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7226   |
| steps                   | 934821   |
| td_erros                | -1.2682  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 175200   |
| lives                   | 175200   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7249   |
| steps                   | 935243   |
| td_erros                | -1.2505  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 175300   |
| lives                   | 175300   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 4.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7139   |
| steps                   | 935668   |
| td_erros                | -1.2706  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 175400   |
| lives                   | 175400   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.748    |
| steps                   | 936091   |
| td_erros                | -1.1947  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 175500   |
| lives                   | 175500   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7442   |
| steps                   | 936513   |
| td_erros                | -1.1482  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 175600   |
| lives                   | 175600   |
| mean 100 episode ei     | 3.79     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 4.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7655   |
| steps                   | 936932   |
| td_erros                | -1.0742  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 175700   |
| lives                   | 175700   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 5.26     |
| mean 100 episode reward | 4.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7597   |
| steps                   | 937358   |
| td_erros                | -1.0206  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 175800   |
| lives                   | 175800   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 4.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7862   |
| steps                   | 937783   |
| td_erros                | -1.003   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 175900   |
| lives                   | 175900   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.778    |
| steps                   | 938206   |
| td_erros                | -0.9577  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 176000   |
| lives                   | 176000   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7328   |
| steps                   | 938628   |
| td_erros                | -0.8801  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 176100   |
| lives                   | 176100   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6703   |
| steps                   | 939051   |
| td_erros                | -0.844   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 176200   |
| lives                   | 176200   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5882   |
| steps                   | 939471   |
| td_erros                | -0.8323  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 176300   |
| lives                   | 176300   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5251   |
| steps                   | 939893   |
| td_erros                | -0.8084  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 176400   |
| lives                   | 176400   |
| mean 100 episode ei     | 4.4      |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4562   |
| steps                   | 940337   |
| td_erros                | -0.8109  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 176500   |
| lives                   | 176500   |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4426   |
| steps                   | 940797   |
| td_erros                | -0.8857  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 176600   |
| lives                   | 176600   |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 5.54     |
| mean 100 episode reward | 5.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4632   |
| steps                   | 941251   |
| td_erros                | -0.92    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 176700   |
| lives                   | 176700   |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5166   |
| steps                   | 941714   |
| td_erros                | -0.988   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 176800   |
| lives                   | 176800   |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5543   |
| steps                   | 942173   |
| td_erros                | -1.0065  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 176900   |
| lives                   | 176900   |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 5.64     |
| mean 100 episode reward | 5.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6246   |
| steps                   | 942637   |
| td_erros                | -1.1085  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 177000   |
| lives                   | 177000   |
| mean 100 episode ei     | 4.7      |
| mean 100 episode length | 5.68     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6804   |
| steps                   | 943105   |
| td_erros                | -1.1737  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 177100   |
| lives                   | 177100   |
| mean 100 episode ei     | 4.47     |
| mean 100 episode length | 5.47     |
| mean 100 episode reward | 5.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7172   |
| steps                   | 943552   |
| td_erros                | -1.2716  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 177200   |
| lives                   | 177200   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 4.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7323   |
| steps                   | 943976   |
| td_erros                | -1.2858  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 177300   |
| lives                   | 177300   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7232   |
| steps                   | 944401   |
| td_erros                | -1.2485  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 177400   |
| lives                   | 177400   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 4.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.717    |
| steps                   | 944820   |
| td_erros                | -1.2438  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 177500   |
| lives                   | 177500   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7372   |
| steps                   | 945240   |
| td_erros                | -1.2133  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 177600   |
| lives                   | 177600   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7326   |
| steps                   | 945660   |
| td_erros                | -1.1883  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 177700   |
| lives                   | 177700   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7301   |
| steps                   | 946083   |
| td_erros                | -1.1175  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 177800   |
| lives                   | 177800   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.29     |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7445   |
| steps                   | 946512   |
| td_erros                | -1.0756  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 177900   |
| lives                   | 177900   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7681   |
| steps                   | 946935   |
| td_erros                | -1.0489  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 178000   |
| lives                   | 178000   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7381   |
| steps                   | 947356   |
| td_erros                | -1.0264  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 178100   |
| lives                   | 178100   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7231   |
| steps                   | 947779   |
| td_erros                | -0.9551  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 178200   |
| lives                   | 178200   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7077   |
| steps                   | 948198   |
| td_erros                | -0.9463  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 178300   |
| lives                   | 178300   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.652    |
| steps                   | 948618   |
| td_erros                | -0.8769  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 178400   |
| lives                   | 178400   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.27     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.601    |
| steps                   | 949045   |
| td_erros                | -0.878   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 178500   |
| lives                   | 178500   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5369   |
| steps                   | 949466   |
| td_erros                | -0.8742  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 178600   |
| lives                   | 178600   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.26     |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5131   |
| steps                   | 949892   |
| td_erros                | -0.8934  |
--------------------------------------
Saving model due to running mean reward increase: 4.8205 -> 4.9277
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 178700   |
| lives                   | 178700   |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 5.53     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5189   |
| steps                   | 950345   |
| td_erros                | -0.8649  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 178800   |
| lives                   | 178800   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5163   |
| steps                   | 950807   |
| td_erros                | -0.9427  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 178900   |
| lives                   | 178900   |
| mean 100 episode ei     | 4.52     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5432   |
| steps                   | 951268   |
| td_erros                | -0.9639  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 179000   |
| lives                   | 179000   |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 5.5      |
| mean 100 episode reward | 4.96     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5598   |
| steps                   | 951718   |
| td_erros                | -1.0148  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 179100   |
| lives                   | 179100   |
| mean 100 episode ei     | 4.51     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5933   |
| steps                   | 952177   |
| td_erros                | -1.0328  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 179200   |
| lives                   | 179200   |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6353   |
| steps                   | 952618   |
| td_erros                | -1.1027  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 179300   |
| lives                   | 179300   |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 5.17     |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6625   |
| steps                   | 953035   |
| td_erros                | -1.152   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 179400   |
| lives                   | 179400   |
| mean 100 episode ei     | 3.56     |
| mean 100 episode length | 5.08     |
| mean 100 episode reward | 5.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7209   |
| steps                   | 953443   |
| td_erros                | -1.0852  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 179500   |
| lives                   | 179500   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.29     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7494   |
| steps                   | 953872   |
| td_erros                | -1.1453  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 179600   |
| lives                   | 179600   |
| mean 100 episode ei     | 4.48     |
| mean 100 episode length | 5.56     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.792    |
| steps                   | 954328   |
| td_erros                | -1.131   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 179700   |
| lives                   | 179700   |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 5.38     |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7857   |
| steps                   | 954766   |
| td_erros                | -1.1732  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 179800   |
| lives                   | 179800   |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7981   |
| steps                   | 955187   |
| td_erros                | -1.2144  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 179900   |
| lives                   | 179900   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7834   |
| steps                   | 955607   |
| td_erros                | -1.1385  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 180000   |
| lives                   | 180000   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8025   |
| steps                   | 956030   |
| td_erros                | -1.0693  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 180100   |
| lives                   | 180100   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7653   |
| steps                   | 956452   |
| td_erros                | -1.0182  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 180200   |
| lives                   | 180200   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 4.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7427   |
| steps                   | 956876   |
| td_erros                | -1.0261  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 180300   |
| lives                   | 180300   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.759    |
| steps                   | 957296   |
| td_erros                | -0.9396  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 180400   |
| lives                   | 180400   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 5.29     |
| mean 100 episode reward | 4.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7381   |
| steps                   | 957725   |
| td_erros                | -0.8777  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 180500   |
| lives                   | 180500   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7349   |
| steps                   | 958144   |
| td_erros                | -0.9178  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 180600   |
| lives                   | 180600   |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7436   |
| steps                   | 958604   |
| td_erros                | -0.9186  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 180700   |
| lives                   | 180700   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7138   |
| steps                   | 959066   |
| td_erros                | -0.975   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 180800   |
| lives                   | 180800   |
| mean 100 episode ei     | 4.62     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7167   |
| steps                   | 959527   |
| td_erros                | -0.9973  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 180900   |
| lives                   | 180900   |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.728    |
| steps                   | 959992   |
| td_erros                | -1.0242  |
--------------------------------------
Saving model due to running mean reward increase: 5.2819 -> 5.2986
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 181000   |
| lives                   | 181000   |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7175   |
| steps                   | 960435   |
| td_erros                | -1.0412  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 181100   |
| lives                   | 181100   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.27     |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7153   |
| steps                   | 960862   |
| td_erros                | -1.1104  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 181200   |
| lives                   | 181200   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 4.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7335   |
| steps                   | 961286   |
| td_erros                | -1.0373  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 181300   |
| lives                   | 181300   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7108   |
| steps                   | 961709   |
| td_erros                | -1.0985  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 181400   |
| lives                   | 181400   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7322   |
| steps                   | 962132   |
| td_erros                | -1.0991  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 181500   |
| lives                   | 181500   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 5.18     |
| mean 100 episode reward | 4.96     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.741    |
| steps                   | 962550   |
| td_erros                | -1.0681  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 181600   |
| lives                   | 181600   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 4.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7361   |
| steps                   | 962969   |
| td_erros                | -1.0865  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 181700   |
| lives                   | 181700   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7303   |
| steps                   | 963391   |
| td_erros                | -1.0759  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 181800   |
| lives                   | 181800   |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7207   |
| steps                   | 963814   |
| td_erros                | -1.0419  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 181900   |
| lives                   | 181900   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7292   |
| steps                   | 964237   |
| td_erros                | -0.9584  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 182000   |
| lives                   | 182000   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.724    |
| steps                   | 964660   |
| td_erros                | -0.9311  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 182100   |
| lives                   | 182100   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.691    |
| steps                   | 965080   |
| td_erros                | -0.9031  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 182200   |
| lives                   | 182200   |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 5.38     |
| mean 100 episode reward | 5.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6503   |
| steps                   | 965518   |
| td_erros                | -0.8831  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 182300   |
| lives                   | 182300   |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 5.68     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6419   |
| steps                   | 965986   |
| td_erros                | -0.9053  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 182400   |
| lives                   | 182400   |
| mean 100 episode ei     | 4.52     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6225   |
| steps                   | 966446   |
| td_erros                | -0.9296  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 182500   |
| lives                   | 182500   |
| mean 100 episode ei     | 4.52     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6279   |
| steps                   | 966906   |
| td_erros                | -0.9959  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 182600   |
| lives                   | 182600   |
| mean 100 episode ei     | 4.49     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.644    |
| steps                   | 967366   |
| td_erros                | -1.0338  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 182700   |
| lives                   | 182700   |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6536   |
| steps                   | 967829   |
| td_erros                | -1.1044  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 182800   |
| lives                   | 182800   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7193   |
| steps                   | 968291   |
| td_erros                | -1.1509  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 182900   |
| lives                   | 182900   |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7469   |
| steps                   | 968731   |
| td_erros                | -1.2111  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 183000   |
| lives                   | 183000   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7439   |
| steps                   | 969151   |
| td_erros                | -1.2183  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 183100   |
| lives                   | 183100   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.26     |
| mean 100 episode reward | 4.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7502   |
| steps                   | 969577   |
| td_erros                | -1.1958  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 183200   |
| lives                   | 183200   |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 4.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7525   |
| steps                   | 969996   |
| td_erros                | -1.1829  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 183300   |
| lives                   | 183300   |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 5.18     |
| mean 100 episode reward | 4.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7354   |
| steps                   | 970414   |
| td_erros                | -1.2222  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 183400   |
| lives                   | 183400   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7254   |
| steps                   | 970836   |
| td_erros                | -1.163   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 183500   |
| lives                   | 183500   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7068   |
| steps                   | 971255   |
| td_erros                | -1.1176  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 183600   |
| lives                   | 183600   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7231   |
| steps                   | 971676   |
| td_erros                | -1.0746  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 183700   |
| lives                   | 183700   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7333   |
| steps                   | 972098   |
| td_erros                | -1.0384  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 183800   |
| lives                   | 183800   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.28     |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.73     |
| steps                   | 972526   |
| td_erros                | -0.9918  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 183900   |
| lives                   | 183900   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7252   |
| steps                   | 972949   |
| td_erros                | -0.9534  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 184000   |
| lives                   | 184000   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6852   |
| steps                   | 973369   |
| td_erros                | -0.9261  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 184100   |
| lives                   | 184100   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6493   |
| steps                   | 973792   |
| td_erros                | -0.8712  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 184200   |
| lives                   | 184200   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.643    |
| steps                   | 974213   |
| td_erros                | -0.8564  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 184300   |
| lives                   | 184300   |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 4.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6234   |
| steps                   | 974653   |
| td_erros                | -0.8134  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 184400   |
| lives                   | 184400   |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6008   |
| steps                   | 975111   |
| td_erros                | -0.8722  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 184500   |
| lives                   | 184500   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6022   |
| steps                   | 975573   |
| td_erros                | -0.9091  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 184600   |
| lives                   | 184600   |
| mean 100 episode ei     | 4.69     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6313   |
| steps                   | 976036   |
| td_erros                | -0.99    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 184700   |
| lives                   | 184700   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6646   |
| steps                   | 976498   |
| td_erros                | -1.0314  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 184800   |
| lives                   | 184800   |
| mean 100 episode ei     | 4.4      |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6754   |
| steps                   | 976942   |
| td_erros                | -1.0819  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 184900   |
| lives                   | 184900   |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 5.49     |
| mean 100 episode reward | 5.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6912   |
| steps                   | 977391   |
| td_erros                | -1.077   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 185000   |
| lives                   | 185000   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.31     |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7241   |
| steps                   | 977822   |
| td_erros                | -1.1794  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 185100   |
| lives                   | 185100   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7357   |
| steps                   | 978245   |
| td_erros                | -1.1709  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 185200   |
| lives                   | 185200   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.26     |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7396   |
| steps                   | 978671   |
| td_erros                | -1.1285  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 185300   |
| lives                   | 185300   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 4.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7588   |
| steps                   | 979095   |
| td_erros                | -1.1754  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 185400   |
| lives                   | 185400   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7632   |
| steps                   | 979515   |
| td_erros                | -1.2142  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 185500   |
| lives                   | 185500   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.26     |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7427   |
| steps                   | 979941   |
| td_erros                | -1.1716  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 185600   |
| lives                   | 185600   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 4.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7253   |
| steps                   | 980365   |
| td_erros                | -1.1238  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 185700   |
| lives                   | 185700   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7173   |
| steps                   | 980785   |
| td_erros                | -1.1028  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 185800   |
| lives                   | 185800   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.742    |
| steps                   | 981206   |
| td_erros                | -1.0408  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 185900   |
| lives                   | 185900   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 4.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7138   |
| steps                   | 981630   |
| td_erros                | -0.9923  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 186000   |
| lives                   | 186000   |
| mean 100 episode ei     | 4.4      |
| mean 100 episode length | 5.5      |
| mean 100 episode reward | 5.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6858   |
| steps                   | 982080   |
| td_erros                | -0.945   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 186100   |
| lives                   | 186100   |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6553   |
| steps                   | 982539   |
| td_erros                | -0.9795  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 186200   |
| lives                   | 186200   |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6399   |
| steps                   | 983001   |
| td_erros                | -0.9741  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 186300   |
| lives                   | 186300   |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6544   |
| steps                   | 983460   |
| td_erros                | -1.0021  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 186400   |
| lives                   | 186400   |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6522   |
| steps                   | 983923   |
| td_erros                | -1.0196  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 186500   |
| lives                   | 186500   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7074   |
| steps                   | 984381   |
| td_erros                | -1.1244  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 186600   |
| lives                   | 186600   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 5.64     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.736    |
| steps                   | 984845   |
| td_erros                | -1.1534  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 186700   |
| lives                   | 186700   |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 5.46     |
| mean 100 episode reward | 5.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.762    |
| steps                   | 985291   |
| td_erros                | -1.2361  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 186800   |
| lives                   | 186800   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.26     |
| mean 100 episode reward | 4.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7697   |
| steps                   | 985717   |
| td_erros                | -1.275   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 186900   |
| lives                   | 186900   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7657   |
| steps                   | 986140   |
| td_erros                | -1.2256  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 187000   |
| lives                   | 187000   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 4.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7739   |
| steps                   | 986565   |
| td_erros                | -1.2462  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 187100   |
| lives                   | 187100   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 5.26     |
| mean 100 episode reward | 4.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7682   |
| steps                   | 986991   |
| td_erros                | -1.2365  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 187200   |
| lives                   | 187200   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7415   |
| steps                   | 987412   |
| td_erros                | -1.1793  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 187300   |
| lives                   | 187300   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.29     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7277   |
| steps                   | 987841   |
| td_erros                | -1.1509  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 187400   |
| lives                   | 187400   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7314   |
| steps                   | 988263   |
| td_erros                | -1.0589  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 187500   |
| lives                   | 187500   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7442   |
| steps                   | 988686   |
| td_erros                | -1.0598  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 187600   |
| lives                   | 187600   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7542   |
| steps                   | 989106   |
| td_erros                | -1.0075  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 187700   |
| lives                   | 187700   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 5.26     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7328   |
| steps                   | 989532   |
| td_erros                | -0.9856  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 187800   |
| lives                   | 187800   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 4.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6973   |
| steps                   | 989951   |
| td_erros                | -0.9093  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 187900   |
| lives                   | 187900   |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 5.36     |
| mean 100 episode reward | 4.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6283   |
| steps                   | 990387   |
| td_erros                | -0.8501  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 188000   |
| lives                   | 188000   |
| mean 100 episode ei     | 4.49     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6174   |
| steps                   | 990848   |
| td_erros                | -0.8846  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 188100   |
| lives                   | 188100   |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 5.7      |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5939   |
| steps                   | 991318   |
| td_erros                | -0.9187  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 188200   |
| lives                   | 188200   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5928   |
| steps                   | 991778   |
| td_erros                | -0.9798  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 188300   |
| lives                   | 188300   |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6163   |
| steps                   | 992236   |
| td_erros                | -1.0367  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 188400   |
| lives                   | 188400   |
| mean 100 episode ei     | 4.46     |
| mean 100 episode length | 5.52     |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6559   |
| steps                   | 992688   |
| td_erros                | -1.1022  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 188500   |
| lives                   | 188500   |
| mean 100 episode ei     | 4.61     |
| mean 100 episode length | 5.54     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6859   |
| steps                   | 993142   |
| td_erros                | -1.1376  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 188600   |
| lives                   | 188600   |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7339   |
| steps                   | 993565   |
| td_erros                | -1.1734  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 188700   |
| lives                   | 188700   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 4.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.738    |
| steps                   | 993990   |
| td_erros                | -1.2648  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 188800   |
| lives                   | 188800   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7584   |
| steps                   | 994410   |
| td_erros                | -1.3222  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 188900   |
| lives                   | 188900   |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 5.18     |
| mean 100 episode reward | 4.69     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7461   |
| steps                   | 994828   |
| td_erros                | -1.2836  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 189000   |
| lives                   | 189000   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.746    |
| steps                   | 995251   |
| td_erros                | -1.3025  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 189100   |
| lives                   | 189100   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.724    |
| steps                   | 995672   |
| td_erros                | -1.2602  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 189200   |
| lives                   | 189200   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7146   |
| steps                   | 996095   |
| td_erros                | -1.2501  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 189300   |
| lives                   | 189300   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7243   |
| steps                   | 996516   |
| td_erros                | -1.1317  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 189400   |
| lives                   | 189400   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7193   |
| steps                   | 996938   |
| td_erros                | -1.1025  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 189500   |
| lives                   | 189500   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7075   |
| steps                   | 997360   |
| td_erros                | -1.0756  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 189600   |
| lives                   | 189600   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.3      |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6871   |
| steps                   | 997790   |
| td_erros                | -1.0165  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 189700   |
| lives                   | 189700   |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 5.66     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6724   |
| steps                   | 998256   |
| td_erros                | -0.9965  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 189800   |
| lives                   | 189800   |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6407   |
| steps                   | 998718   |
| td_erros                | -0.9838  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 189900   |
| lives                   | 189900   |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6259   |
| steps                   | 999179   |
| td_erros                | -0.977   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 190000   |
| lives                   | 190000   |
| mean 100 episode ei     | 4.49     |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 5.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6503   |
| steps                   | 999637   |
| td_erros                | -0.9879  |
--------------------------------------
Restored model with mean reward: 5.6247
