Logging to /Users/janrichtr/Desktop/RL-HPO/buffer_size-2000/cell-32/checkpoint_freq-10000/dueling-0/ei-True/env_id-nnMeta-v40/learning_starts-2000/lr-0.0001/new_env_id-Taxi-v3/nhidden-128/num_timesteps-2000000/prioritized-1/prioritized_replay_alpha-0.6/seed-0/target_network_update_freq-500/train_freq-1/
--------------------------------------
| % time spent exploring  | 99       |
| episodes                | 100      |
| lives                   | 100      |
| mean 100 episode ei     | 4.95     |
| mean 100 episode length | 10       |
| mean 100 episode reward | 0.551    |
| most_used_dataset       | 0        |
| number_of_used          | 20       |
| q_t                     | nan      |
| steps                   | 890      |
| td_erros                | nan      |
--------------------------------------
--------------------------------------
| % time spent exploring  | 99       |
| episodes                | 200      |
| lives                   | 200      |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 10.1     |
| mean 100 episode reward | -0.166   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | nan      |
| steps                   | 1801     |
| td_erros                | nan      |
--------------------------------------
--------------------------------------
| % time spent exploring  | 99       |
| episodes                | 300      |
| lives                   | 300      |
| mean 100 episode ei     | 4.82     |
| mean 100 episode length | 10.2     |
| mean 100 episode reward | 0.313    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | nan      |
| steps                   | 2720     |
| td_erros                | nan      |
--------------------------------------
--------------------------------------
| % time spent exploring  | 99       |
| episodes                | 400      |
| lives                   | 400      |
| mean 100 episode ei     | 4.24     |
| mean 100 episode length | 10.1     |
| mean 100 episode reward | -0.695   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | nan      |
| steps                   | 3634     |
| td_erros                | nan      |
--------------------------------------
--------------------------------------
| % time spent exploring  | 99       |
| episodes                | 500      |
| lives                   | 500      |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 10       |
| mean 100 episode reward | 0.158    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | nan      |
| steps                   | 4538     |
| td_erros                | nan      |
--------------------------------------
--------------------------------------
| % time spent exploring  | 99       |
| episodes                | 600      |
| lives                   | 600      |
| mean 100 episode ei     | 4.71     |
| mean 100 episode length | 9.93     |
| mean 100 episode reward | -0.0227  |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 0.0158   |
| steps                   | 5431     |
| td_erros                | -1.0532  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 99       |
| episodes                | 700      |
| lives                   | 700      |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 9.96     |
| mean 100 episode reward | -0.0391  |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 0.0931   |
| steps                   | 6327     |
| td_erros                | -1.2846  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 99       |
| episodes                | 800      |
| lives                   | 800      |
| mean 100 episode ei     | 4.52     |
| mean 100 episode length | 10       |
| mean 100 episode reward | 0.0826   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 0.2285   |
| steps                   | 7227     |
| td_erros                | -1.253   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 99       |
| episodes                | 900      |
| lives                   | 900      |
| mean 100 episode ei     | 5.08     |
| mean 100 episode length | 10.1     |
| mean 100 episode reward | 0.876    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 0.44     |
| steps                   | 8138     |
| td_erros                | -1.2154  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 99       |
| episodes                | 1000     |
| lives                   | 1000     |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 9.68     |
| mean 100 episode reward | 0.0305   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 0.7984   |
| steps                   | 9006     |
| td_erros                | -1.107   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 99       |
| episodes                | 1100     |
| lives                   | 1100     |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 10.1     |
| mean 100 episode reward | 0.306    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1963   |
| steps                   | 9916     |
| td_erros                | -1.1441  |
--------------------------------------
Saving model due to mean reward increase: None -> 0.4049
Saving model due to running mean reward increase: 0.0934 -> 0.4049
--------------------------------------
| % time spent exploring  | 99       |
| episodes                | 1200     |
| lives                   | 1200     |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 9.08     |
| mean 100 episode reward | -0.203   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6401   |
| steps                   | 10724    |
| td_erros                | -1.0905  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 99       |
| episodes                | 1300     |
| lives                   | 1300     |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 9.91     |
| mean 100 episode reward | 0.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1899   |
| steps                   | 11615    |
| td_erros                | -0.9089  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 99       |
| episodes                | 1400     |
| lives                   | 1400     |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 9.5      |
| mean 100 episode reward | -0.245   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8772   |
| steps                   | 12465    |
| td_erros                | -0.7229  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 99       |
| episodes                | 1500     |
| lives                   | 1500     |
| mean 100 episode ei     | 4.76     |
| mean 100 episode length | 9.61     |
| mean 100 episode reward | 0.169    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7595   |
| steps                   | 13326    |
| td_erros                | -0.3371  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 99       |
| episodes                | 1600     |
| lives                   | 1600     |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 9.09     |
| mean 100 episode reward | -0.224   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.1366   |
| steps                   | 14135    |
| td_erros                | 0.567    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 99       |
| episodes                | 1700     |
| lives                   | 1700     |
| mean 100 episode ei     | 4.87     |
| mean 100 episode length | 9.77     |
| mean 100 episode reward | 0.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 6.4814   |
| steps                   | 15012    |
| td_erros                | 1.1874   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 99       |
| episodes                | 1800     |
| lives                   | 1800     |
| mean 100 episode ei     | 5.44     |
| mean 100 episode length | 10.8     |
| mean 100 episode reward | -0.158   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 7.8215   |
| steps                   | 15987    |
| td_erros                | 1.7595   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 98       |
| episodes                | 1900     |
| lives                   | 1900     |
| mean 100 episode ei     | 4.7      |
| mean 100 episode length | 10       |
| mean 100 episode reward | -0.354   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 9.1925   |
| steps                   | 16891    |
| td_erros                | 2.3372   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 98       |
| episodes                | 2000     |
| lives                   | 2000     |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 9.32     |
| mean 100 episode reward | 0.615    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 10.3246  |
| steps                   | 17723    |
| td_erros                | 2.8029   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 98       |
| episodes                | 2100     |
| lives                   | 2100     |
| mean 100 episode ei     | 4.35     |
| mean 100 episode length | 9.65     |
| mean 100 episode reward | 0.293    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 11.3673  |
| steps                   | 18588    |
| td_erros                | 3.224    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 98       |
| episodes                | 2200     |
| lives                   | 2200     |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 9.63     |
| mean 100 episode reward | 0.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 12.4187  |
| steps                   | 19451    |
| td_erros                | 3.7376   |
--------------------------------------
Saving model due to running mean reward increase: 0.187 -> 0.3839
--------------------------------------
| % time spent exploring  | 98       |
| episodes                | 2300     |
| lives                   | 2300     |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 9.33     |
| mean 100 episode reward | -0.0795  |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 13.3468  |
| steps                   | 20284    |
| td_erros                | 4.2486   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 98       |
| episodes                | 2400     |
| lives                   | 2400     |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 9.41     |
| mean 100 episode reward | 0.432    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 14.253   |
| steps                   | 21125    |
| td_erros                | 4.8535   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 98       |
| episodes                | 2500     |
| lives                   | 2500     |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 9.63     |
| mean 100 episode reward | 0.321    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 15.0775  |
| steps                   | 21988    |
| td_erros                | 5.7573   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 98       |
| episodes                | 2600     |
| lives                   | 2600     |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 9.37     |
| mean 100 episode reward | -0.147   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 15.81    |
| steps                   | 22825    |
| td_erros                | 6.2128   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 98       |
| episodes                | 2700     |
| lives                   | 2700     |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 9.35     |
| mean 100 episode reward | 0.148    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 16.562   |
| steps                   | 23660    |
| td_erros                | 6.4759   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 98       |
| episodes                | 2800     |
| lives                   | 2800     |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 9.84     |
| mean 100 episode reward | -0.252   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 17.1773  |
| steps                   | 24544    |
| td_erros                | 6.9329   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 98       |
| episodes                | 2900     |
| lives                   | 2900     |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 9.85     |
| mean 100 episode reward | 0.247    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 17.6947  |
| steps                   | 25429    |
| td_erros                | 6.8629   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 98       |
| episodes                | 3000     |
| lives                   | 3000     |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 10       |
| mean 100 episode reward | -0.338   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 18.2039  |
| steps                   | 26330    |
| td_erros                | 7.1391   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 98       |
| episodes                | 3100     |
| lives                   | 3100     |
| mean 100 episode ei     | 4.39     |
| mean 100 episode length | 9.58     |
| mean 100 episode reward | 0.745    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 18.6981  |
| steps                   | 27188    |
| td_erros                | 7.3893   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 98       |
| episodes                | 3200     |
| lives                   | 3200     |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 10.2     |
| mean 100 episode reward | -0.308   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 19.1996  |
| steps                   | 28110    |
| td_erros                | 7.6458   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 98       |
| episodes                | 3300     |
| lives                   | 3300     |
| mean 100 episode ei     | 4.43     |
| mean 100 episode length | 9.66     |
| mean 100 episode reward | 0.208    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 19.6556  |
| steps                   | 28976    |
| td_erros                | 8.1795   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 98       |
| episodes                | 3400     |
| lives                   | 3400     |
| mean 100 episode ei     | 4.45     |
| mean 100 episode length | 9.73     |
| mean 100 episode reward | 0.098    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 20.1843  |
| steps                   | 29849    |
| td_erros                | 8.896    |
--------------------------------------
Saving model due to running mean reward increase: -0.1235 -> 0.3199
--------------------------------------
| % time spent exploring  | 98       |
| episodes                | 3500     |
| lives                   | 3500     |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 9.59     |
| mean 100 episode reward | 0.0698   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 20.7303  |
| steps                   | 30708    |
| td_erros                | 9.6656   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 98       |
| episodes                | 3600     |
| lives                   | 3600     |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 10.2     |
| mean 100 episode reward | -0.284   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 21.1521  |
| steps                   | 31626    |
| td_erros                | 10.1012  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 97       |
| episodes                | 3700     |
| lives                   | 3700     |
| mean 100 episode ei     | 4.42     |
| mean 100 episode length | 9.5      |
| mean 100 episode reward | 0.595    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 21.449   |
| steps                   | 32476    |
| td_erros                | 10.3401  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 97       |
| episodes                | 3800     |
| lives                   | 3800     |
| mean 100 episode ei     | 4.79     |
| mean 100 episode length | 10.2     |
| mean 100 episode reward | 0.277    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 21.7264  |
| steps                   | 33393    |
| td_erros                | 10.3195  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 97       |
| episodes                | 3900     |
| lives                   | 3900     |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 9.46     |
| mean 100 episode reward | -0.103   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 22.0536  |
| steps                   | 34239    |
| td_erros                | 10.4631  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 97       |
| episodes                | 4000     |
| lives                   | 4000     |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 10       |
| mean 100 episode reward | -0.515   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 22.2928  |
| steps                   | 35141    |
| td_erros                | 10.6426  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 97       |
| episodes                | 4100     |
| lives                   | 4100     |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 9.13     |
| mean 100 episode reward | 0.438    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 22.5807  |
| steps                   | 35954    |
| td_erros                | 10.8224  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 97       |
| episodes                | 4200     |
| lives                   | 4200     |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 9.55     |
| mean 100 episode reward | -0.225   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 22.9016  |
| steps                   | 36809    |
| td_erros                | 10.7978  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 97       |
| episodes                | 4300     |
| lives                   | 4300     |
| mean 100 episode ei     | 4.74     |
| mean 100 episode length | 9.42     |
| mean 100 episode reward | 0.0381   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 23.1887  |
| steps                   | 37651    |
| td_erros                | 11.1025  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 97       |
| episodes                | 4400     |
| lives                   | 4400     |
| mean 100 episode ei     | 4.46     |
| mean 100 episode length | 9.69     |
| mean 100 episode reward | 0.295    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 23.5044  |
| steps                   | 38520    |
| td_erros                | 11.3327  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 97       |
| episodes                | 4500     |
| lives                   | 4500     |
| mean 100 episode ei     | 4.52     |
| mean 100 episode length | 9.37     |
| mean 100 episode reward | 0.428    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 24.0609  |
| steps                   | 39357    |
| td_erros                | 11.5116  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 97       |
| episodes                | 4600     |
| lives                   | 4600     |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 9.13     |
| mean 100 episode reward | 0.0013   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 24.5447  |
| steps                   | 40170    |
| td_erros                | 12.4213  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 97       |
| episodes                | 4700     |
| lives                   | 4700     |
| mean 100 episode ei     | 4.45     |
| mean 100 episode length | 9.72     |
| mean 100 episode reward | -0.257   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 24.7887  |
| steps                   | 41042    |
| td_erros                | 12.3924  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 97       |
| episodes                | 4800     |
| lives                   | 4800     |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 9.48     |
| mean 100 episode reward | 0.238    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 25.0762  |
| steps                   | 41890    |
| td_erros                | 12.4042  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 97       |
| episodes                | 4900     |
| lives                   | 4900     |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 9.8      |
| mean 100 episode reward | 0.0848   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 25.4348  |
| steps                   | 42770    |
| td_erros                | 12.2919  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 97       |
| episodes                | 5000     |
| lives                   | 5000     |
| mean 100 episode ei     | 4.43     |
| mean 100 episode length | 10.3     |
| mean 100 episode reward | -0.0222  |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 25.7474  |
| steps                   | 43697    |
| td_erros                | 12.7682  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 97       |
| episodes                | 5100     |
| lives                   | 5100     |
| mean 100 episode ei     | 4.24     |
| mean 100 episode length | 9.36     |
| mean 100 episode reward | -0.0459  |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 26.1204  |
| steps                   | 44533    |
| td_erros                | 12.6966  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 97       |
| episodes                | 5200     |
| lives                   | 5200     |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 9.17     |
| mean 100 episode reward | 0.312    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 26.4429  |
| steps                   | 45350    |
| td_erros                | 13.0898  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 97       |
| episodes                | 5300     |
| lives                   | 5300     |
| mean 100 episode ei     | 4.92     |
| mean 100 episode length | 9.81     |
| mean 100 episode reward | 0.221    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 26.7689  |
| steps                   | 46231    |
| td_erros                | 13.3092  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 97       |
| episodes                | 5400     |
| lives                   | 5400     |
| mean 100 episode ei     | 4.35     |
| mean 100 episode length | 9.54     |
| mean 100 episode reward | 0.669    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 26.9596  |
| steps                   | 47085    |
| td_erros                | 13.581   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 97       |
| episodes                | 5500     |
| lives                   | 5500     |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 9.75     |
| mean 100 episode reward | 0.0527   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 27.1436  |
| steps                   | 47960    |
| td_erros                | 13.7044  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 96       |
| episodes                | 5600     |
| lives                   | 5600     |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 9.53     |
| mean 100 episode reward | -0.247   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 27.3833  |
| steps                   | 48813    |
| td_erros                | 14.4232  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 96       |
| episodes                | 5700     |
| lives                   | 5700     |
| mean 100 episode ei     | 4.48     |
| mean 100 episode length | 9.32     |
| mean 100 episode reward | 0.273    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 27.6284  |
| steps                   | 49645    |
| td_erros                | 14.6845  |
--------------------------------------
Saving model due to mean reward increase: 0.4049 -> 0.5545
Saving model due to running mean reward increase: -0.0572 -> 0.5545
--------------------------------------
| % time spent exploring  | 96       |
| episodes                | 5800     |
| lives                   | 5800     |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 9.71     |
| mean 100 episode reward | 0.454    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 27.7233  |
| steps                   | 50516    |
| td_erros                | 14.9203  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 96       |
| episodes                | 5900     |
| lives                   | 5900     |
| mean 100 episode ei     | 4.49     |
| mean 100 episode length | 10.6     |
| mean 100 episode reward | -0.423   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 27.947   |
| steps                   | 51477    |
| td_erros                | 14.6412  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 96       |
| episodes                | 6000     |
| lives                   | 6000     |
| mean 100 episode ei     | 4.48     |
| mean 100 episode length | 9.54     |
| mean 100 episode reward | -0.147   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 28.1503  |
| steps                   | 52331    |
| td_erros                | 14.9535  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 96       |
| episodes                | 6100     |
| lives                   | 6100     |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 9.17     |
| mean 100 episode reward | 0.601    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 28.2736  |
| steps                   | 53148    |
| td_erros                | 15.2947  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 96       |
| episodes                | 6200     |
| lives                   | 6200     |
| mean 100 episode ei     | 4.77     |
| mean 100 episode length | 10.3     |
| mean 100 episode reward | -0.303   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 28.3757  |
| steps                   | 54082    |
| td_erros                | 15.2873  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 96       |
| episodes                | 6300     |
| lives                   | 6300     |
| mean 100 episode ei     | 4.82     |
| mean 100 episode length | 10.1     |
| mean 100 episode reward | 0.362    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 28.459   |
| steps                   | 54987    |
| td_erros                | 15.5032  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 96       |
| episodes                | 6400     |
| lives                   | 6400     |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 9.51     |
| mean 100 episode reward | 0.122    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 28.5867  |
| steps                   | 55838    |
| td_erros                | 15.1041  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 96       |
| episodes                | 6500     |
| lives                   | 6500     |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 9.36     |
| mean 100 episode reward | 0.695    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 28.6969  |
| steps                   | 56674    |
| td_erros                | 15.4349  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 96       |
| episodes                | 6600     |
| lives                   | 6600     |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 9.43     |
| mean 100 episode reward | 0.579    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 28.7683  |
| steps                   | 57517    |
| td_erros                | 15.5042  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 96       |
| episodes                | 6700     |
| lives                   | 6700     |
| mean 100 episode ei     | 4.92     |
| mean 100 episode length | 10.1     |
| mean 100 episode reward | 0.323    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 28.8587  |
| steps                   | 58425    |
| td_erros                | 15.4864  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 96       |
| episodes                | 6800     |
| lives                   | 6800     |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 9.23     |
| mean 100 episode reward | -0.0725  |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 28.9744  |
| steps                   | 59248    |
| td_erros                | 15.589   |
--------------------------------------
Saving model due to mean reward increase: 0.5545 -> 0.6755
Saving model due to running mean reward increase: -0.121 -> 0.6755
--------------------------------------
| % time spent exploring  | 96       |
| episodes                | 6900     |
| lives                   | 6900     |
| mean 100 episode ei     | 4.24     |
| mean 100 episode length | 8.99     |
| mean 100 episode reward | 0.562    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 28.9908  |
| steps                   | 60047    |
| td_erros                | 16.1767  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 96       |
| episodes                | 7000     |
| lives                   | 7000     |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 9.55     |
| mean 100 episode reward | -0.0618  |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 28.9793  |
| steps                   | 60902    |
| td_erros                | 16.1766  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 96       |
| episodes                | 7100     |
| lives                   | 7100     |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 8.71     |
| mean 100 episode reward | 0.901    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 29.0292  |
| steps                   | 61673    |
| td_erros                | 16.0022  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 96       |
| episodes                | 7200     |
| lives                   | 7200     |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 9.93     |
| mean 100 episode reward | 0.0186   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 29.0689  |
| steps                   | 62566    |
| td_erros                | 15.9068  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 96       |
| episodes                | 7300     |
| lives                   | 7300     |
| mean 100 episode ei     | 4.35     |
| mean 100 episode length | 9.34     |
| mean 100 episode reward | 0.678    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 29.1708  |
| steps                   | 63400    |
| td_erros                | 15.7476  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 96       |
| episodes                | 7400     |
| lives                   | 7400     |
| mean 100 episode ei     | 4.81     |
| mean 100 episode length | 9.89     |
| mean 100 episode reward | 0.631    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 29.3022  |
| steps                   | 64289    |
| td_erros                | 16.0812  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 95       |
| episodes                | 7500     |
| lives                   | 7500     |
| mean 100 episode ei     | 4.96     |
| mean 100 episode length | 9.95     |
| mean 100 episode reward | 0.582    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 29.3674  |
| steps                   | 65184    |
| td_erros                | 15.9322  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 95       |
| episodes                | 7600     |
| lives                   | 7600     |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 9.51     |
| mean 100 episode reward | 0.557    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 29.4737  |
| steps                   | 66035    |
| td_erros                | 15.797   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 95       |
| episodes                | 7700     |
| lives                   | 7700     |
| mean 100 episode ei     | 3.63     |
| mean 100 episode length | 8.85     |
| mean 100 episode reward | -0.335   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 29.517   |
| steps                   | 66820    |
| td_erros                | 16.3954  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 95       |
| episodes                | 7800     |
| lives                   | 7800     |
| mean 100 episode ei     | 4.8      |
| mean 100 episode length | 9.75     |
| mean 100 episode reward | 0.473    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 29.5408  |
| steps                   | 67695    |
| td_erros                | 16.1563  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 95       |
| episodes                | 7900     |
| lives                   | 7900     |
| mean 100 episode ei     | 4.97     |
| mean 100 episode length | 10.1     |
| mean 100 episode reward | 0.0853   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 29.6974  |
| steps                   | 68601    |
| td_erros                | 15.7781  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 95       |
| episodes                | 8000     |
| lives                   | 8000     |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 9.08     |
| mean 100 episode reward | 0.0005   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 29.8245  |
| steps                   | 69409    |
| td_erros                | 16.165   |
--------------------------------------
Saving model due to running mean reward increase: 0.2527 -> 0.3988
--------------------------------------
| % time spent exploring  | 95       |
| episodes                | 8100     |
| lives                   | 8100     |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 9.58     |
| mean 100 episode reward | 0.806    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 29.8655  |
| steps                   | 70267    |
| td_erros                | 16.2618  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 95       |
| episodes                | 8200     |
| lives                   | 8200     |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 9.31     |
| mean 100 episode reward | 0.627    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 29.9915  |
| steps                   | 71098    |
| td_erros                | 16.1164  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 95       |
| episodes                | 8300     |
| lives                   | 8300     |
| mean 100 episode ei     | 4.76     |
| mean 100 episode length | 9.88     |
| mean 100 episode reward | 0.172    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 30.1094  |
| steps                   | 71986    |
| td_erros                | 16.148   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 95       |
| episodes                | 8400     |
| lives                   | 8400     |
| mean 100 episode ei     | 4.69     |
| mean 100 episode length | 9.9      |
| mean 100 episode reward | 0.203    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 30.1929  |
| steps                   | 72876    |
| td_erros                | 16.1863  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 95       |
| episodes                | 8500     |
| lives                   | 8500     |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 9.29     |
| mean 100 episode reward | 0.329    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 30.3004  |
| steps                   | 73705    |
| td_erros                | 16.3297  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 95       |
| episodes                | 8600     |
| lives                   | 8600     |
| mean 100 episode ei     | 5        |
| mean 100 episode length | 9.64     |
| mean 100 episode reward | 0.573    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 30.378   |
| steps                   | 74569    |
| td_erros                | 16.3182  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 95       |
| episodes                | 8700     |
| lives                   | 8700     |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 9.56     |
| mean 100 episode reward | 0.229    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 30.4066  |
| steps                   | 75425    |
| td_erros                | 16.8153  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 95       |
| episodes                | 8800     |
| lives                   | 8800     |
| mean 100 episode ei     | 4.81     |
| mean 100 episode length | 9.49     |
| mean 100 episode reward | 0.629    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 30.3485  |
| steps                   | 76274    |
| td_erros                | 16.9625  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 95       |
| episodes                | 8900     |
| lives                   | 8900     |
| mean 100 episode ei     | 4.69     |
| mean 100 episode length | 9.88     |
| mean 100 episode reward | -0.526   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 30.3686  |
| steps                   | 77162    |
| td_erros                | 16.7832  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 95       |
| episodes                | 9000     |
| lives                   | 9000     |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 9.88     |
| mean 100 episode reward | 0.313    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 30.4679  |
| steps                   | 78050    |
| td_erros                | 16.6299  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 95       |
| episodes                | 9100     |
| lives                   | 9100     |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 10.1     |
| mean 100 episode reward | 0.166    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 30.4738  |
| steps                   | 78964    |
| td_erros                | 16.9817  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 95       |
| episodes                | 9200     |
| lives                   | 9200     |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 9.71     |
| mean 100 episode reward | 0.104    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 30.5     |
| steps                   | 79835    |
| td_erros                | 16.7723  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 95       |
| episodes                | 9300     |
| lives                   | 9300     |
| mean 100 episode ei     | 4.4      |
| mean 100 episode length | 9.68     |
| mean 100 episode reward | 0.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 30.494   |
| steps                   | 80703    |
| td_erros                | 16.6594  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 94       |
| episodes                | 9400     |
| lives                   | 9400     |
| mean 100 episode ei     | 4.33     |
| mean 100 episode length | 9.94     |
| mean 100 episode reward | -0.455   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 30.3804  |
| steps                   | 81597    |
| td_erros                | 16.9024  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 94       |
| episodes                | 9500     |
| lives                   | 9500     |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 9.31     |
| mean 100 episode reward | 0.587    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 30.0978  |
| steps                   | 82428    |
| td_erros                | 16.3417  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 94       |
| episodes                | 9600     |
| lives                   | 9600     |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 9.38     |
| mean 100 episode reward | 0.0472   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 29.2706  |
| steps                   | 83266    |
| td_erros                | 15.5479  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 94       |
| episodes                | 9700     |
| lives                   | 9700     |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 9.28     |
| mean 100 episode reward | 0.557    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 27.7968  |
| steps                   | 84094    |
| td_erros                | 14.0375  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 94       |
| episodes                | 9800     |
| lives                   | 9800     |
| mean 100 episode ei     | 4.36     |
| mean 100 episode length | 9.53     |
| mean 100 episode reward | 0.573    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 26.1547  |
| steps                   | 84947    |
| td_erros                | 12.3697  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 94       |
| episodes                | 9900     |
| lives                   | 9900     |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 9.69     |
| mean 100 episode reward | 0.825    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 24.361   |
| steps                   | 85816    |
| td_erros                | 10.8481  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 94       |
| episodes                | 10000    |
| lives                   | 10000    |
| mean 100 episode ei     | 4.4      |
| mean 100 episode length | 9.66     |
| mean 100 episode reward | -0.131   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 22.8953  |
| steps                   | 86682    |
| td_erros                | 10.0092  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 94       |
| episodes                | 10100    |
| lives                   | 10100    |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 9.85     |
| mean 100 episode reward | 0.111    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 21.6752  |
| steps                   | 87567    |
| td_erros                | 9.0599   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 94       |
| episodes                | 10200    |
| lives                   | 10200    |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 9.98     |
| mean 100 episode reward | 0.181    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 20.9622  |
| steps                   | 88465    |
| td_erros                | 8.4502   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 94       |
| episodes                | 10300    |
| lives                   | 10300    |
| mean 100 episode ei     | 4.45     |
| mean 100 episode length | 9.33     |
| mean 100 episode reward | 0.324    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 20.9161  |
| steps                   | 89298    |
| td_erros                | 8.4781   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 94       |
| episodes                | 10400    |
| lives                   | 10400    |
| mean 100 episode ei     | 4.33     |
| mean 100 episode length | 9.39     |
| mean 100 episode reward | -0.259   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 20.8556  |
| steps                   | 90137    |
| td_erros                | 8.7254   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 94       |
| episodes                | 10500    |
| lives                   | 10500    |
| mean 100 episode ei     | 4.73     |
| mean 100 episode length | 9.5      |
| mean 100 episode reward | 0.214    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 20.4879  |
| steps                   | 90987    |
| td_erros                | 8.5941   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 94       |
| episodes                | 10600    |
| lives                   | 10600    |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 9.84     |
| mean 100 episode reward | 0.213    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 19.7725  |
| steps                   | 91871    |
| td_erros                | 8.3592   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 94       |
| episodes                | 10700    |
| lives                   | 10700    |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 9.51     |
| mean 100 episode reward | 0.447    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 19.0442  |
| steps                   | 92722    |
| td_erros                | 8.3765   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 94       |
| episodes                | 10800    |
| lives                   | 10800    |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 9.31     |
| mean 100 episode reward | -0.172   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 18.9122  |
| steps                   | 93553    |
| td_erros                | 8.654    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 94       |
| episodes                | 10900    |
| lives                   | 10900    |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 9.27     |
| mean 100 episode reward | 0.424    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 18.6905  |
| steps                   | 94380    |
| td_erros                | 8.5289   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 94       |
| episodes                | 11000    |
| lives                   | 11000    |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 9.11     |
| mean 100 episode reward | 0.306    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 18.1828  |
| steps                   | 95191    |
| td_erros                | 8.0881   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 94       |
| episodes                | 11100    |
| lives                   | 11100    |
| mean 100 episode ei     | 4.48     |
| mean 100 episode length | 9.5      |
| mean 100 episode reward | 0.753    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 17.6809  |
| steps                   | 96041    |
| td_erros                | 7.5573   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 94       |
| episodes                | 11200    |
| lives                   | 11200    |
| mean 100 episode ei     | 4.87     |
| mean 100 episode length | 10.2     |
| mean 100 episode reward | 0.247    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 16.9586  |
| steps                   | 96957    |
| td_erros                | 7.0648   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 93       |
| episodes                | 11300    |
| lives                   | 11300    |
| mean 100 episode ei     | 4.85     |
| mean 100 episode length | 9.64     |
| mean 100 episode reward | 0.483    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 16.1711  |
| steps                   | 97821    |
| td_erros                | 6.5502   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 93       |
| episodes                | 11400    |
| lives                   | 11400    |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 9.27     |
| mean 100 episode reward | 0.597    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 15.5066  |
| steps                   | 98648    |
| td_erros                | 6.022    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 93       |
| episodes                | 11500    |
| lives                   | 11500    |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 9.63     |
| mean 100 episode reward | -0.145   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 14.6993  |
| steps                   | 99511    |
| td_erros                | 5.5628   |
--------------------------------------
Saving model due to running mean reward increase: -0.1119 -> 0.3505
--------------------------------------
| % time spent exploring  | 93       |
| episodes                | 11600    |
| lives                   | 11600    |
| mean 100 episode ei     | 4.9      |
| mean 100 episode length | 9.88     |
| mean 100 episode reward | 0.761    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 13.9256  |
| steps                   | 100399   |
| td_erros                | 5.0523   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 93       |
| episodes                | 11700    |
| lives                   | 11700    |
| mean 100 episode ei     | 4.21     |
| mean 100 episode length | 9.45     |
| mean 100 episode reward | 0.536    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 13.169   |
| steps                   | 101244   |
| td_erros                | 4.6765   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 93       |
| episodes                | 11800    |
| lives                   | 11800    |
| mean 100 episode ei     | 4.4      |
| mean 100 episode length | 9.5      |
| mean 100 episode reward | 0.565    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 12.4984  |
| steps                   | 102094   |
| td_erros                | 4.3624   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 93       |
| episodes                | 11900    |
| lives                   | 11900    |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 9.87     |
| mean 100 episode reward | 0.224    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 11.6768  |
| steps                   | 102981   |
| td_erros                | 3.9226   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 93       |
| episodes                | 12000    |
| lives                   | 12000    |
| mean 100 episode ei     | 4.9      |
| mean 100 episode length | 10.7     |
| mean 100 episode reward | 0.0248   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 10.8482  |
| steps                   | 103948   |
| td_erros                | 3.4217   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 93       |
| episodes                | 12100    |
| lives                   | 12100    |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 9.19     |
| mean 100 episode reward | 0.0279   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 10.2113  |
| steps                   | 104767   |
| td_erros                | 3.1318   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 93       |
| episodes                | 12200    |
| lives                   | 12200    |
| mean 100 episode ei     | 4.51     |
| mean 100 episode length | 9.09     |
| mean 100 episode reward | 1.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 9.7205   |
| steps                   | 105576   |
| td_erros                | 2.9143   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 93       |
| episodes                | 12300    |
| lives                   | 12300    |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 9.5      |
| mean 100 episode reward | 0.157    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 9.2307   |
| steps                   | 106426   |
| td_erros                | 2.6655   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 93       |
| episodes                | 12400    |
| lives                   | 12400    |
| mean 100 episode ei     | 4.9      |
| mean 100 episode length | 9.73     |
| mean 100 episode reward | 0.637    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 8.7606   |
| steps                   | 107299   |
| td_erros                | 2.3408   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 93       |
| episodes                | 12500    |
| lives                   | 12500    |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 9.34     |
| mean 100 episode reward | 0.234    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 8.2803   |
| steps                   | 108133   |
| td_erros                | 2.1296   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 93       |
| episodes                | 12600    |
| lives                   | 12600    |
| mean 100 episode ei     | 5.11     |
| mean 100 episode length | 10       |
| mean 100 episode reward | 0.531    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 7.8592   |
| steps                   | 109033   |
| td_erros                | 1.9008   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 93       |
| episodes                | 12700    |
| lives                   | 12700    |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 9.19     |
| mean 100 episode reward | 0.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 7.5498   |
| steps                   | 109852   |
| td_erros                | 1.7114   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 93       |
| episodes                | 12800    |
| lives                   | 12800    |
| mean 100 episode ei     | 4.82     |
| mean 100 episode length | 9.86     |
| mean 100 episode reward | 0.308    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 7.1291   |
| steps                   | 110738   |
| td_erros                | 1.4769   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 93       |
| episodes                | 12900    |
| lives                   | 12900    |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 9.15     |
| mean 100 episode reward | 0.624    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 6.8299   |
| steps                   | 111553   |
| td_erros                | 1.2757   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 93       |
| episodes                | 13000    |
| lives                   | 13000    |
| mean 100 episode ei     | 4.45     |
| mean 100 episode length | 8.83     |
| mean 100 episode reward | 0.524    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 6.4821   |
| steps                   | 112336   |
| td_erros                | 1.1836   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 92       |
| episodes                | 13100    |
| lives                   | 13100    |
| mean 100 episode ei     | 4.96     |
| mean 100 episode length | 10       |
| mean 100 episode reward | 0.478    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 6.1919   |
| steps                   | 113237   |
| td_erros                | 1.0097   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 92       |
| episodes                | 13200    |
| lives                   | 13200    |
| mean 100 episode ei     | 4.99     |
| mean 100 episode length | 9.84     |
| mean 100 episode reward | 0.927    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.9678   |
| steps                   | 114121   |
| td_erros                | 0.9533   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 92       |
| episodes                | 13300    |
| lives                   | 13300    |
| mean 100 episode ei     | 4.79     |
| mean 100 episode length | 9.65     |
| mean 100 episode reward | 0.191    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.7447   |
| steps                   | 114986   |
| td_erros                | 0.8547   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 92       |
| episodes                | 13400    |
| lives                   | 13400    |
| mean 100 episode ei     | 4.62     |
| mean 100 episode length | 9.54     |
| mean 100 episode reward | 0.482    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.7291   |
| steps                   | 115840   |
| td_erros                | 0.8378   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 92       |
| episodes                | 13500    |
| lives                   | 13500    |
| mean 100 episode ei     | 5        |
| mean 100 episode length | 9.89     |
| mean 100 episode reward | 0.745    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.7665   |
| steps                   | 116729   |
| td_erros                | 0.8451   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 92       |
| episodes                | 13600    |
| lives                   | 13600    |
| mean 100 episode ei     | 4.95     |
| mean 100 episode length | 10.1     |
| mean 100 episode reward | 0.827    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.7825   |
| steps                   | 117634   |
| td_erros                | 0.7962   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 92       |
| episodes                | 13700    |
| lives                   | 13700    |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 9.52     |
| mean 100 episode reward | 0.132    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.6414   |
| steps                   | 118486   |
| td_erros                | 0.7376   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 92       |
| episodes                | 13800    |
| lives                   | 13800    |
| mean 100 episode ei     | 4.43     |
| mean 100 episode length | 9.73     |
| mean 100 episode reward | 0.526    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.5552   |
| steps                   | 119359   |
| td_erros                | 0.7405   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 92       |
| episodes                | 13900    |
| lives                   | 13900    |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 9.96     |
| mean 100 episode reward | 0.579    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.3962   |
| steps                   | 120255   |
| td_erros                | 0.672    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 92       |
| episodes                | 14000    |
| lives                   | 14000    |
| mean 100 episode ei     | 4.97     |
| mean 100 episode length | 10.1     |
| mean 100 episode reward | 0.609    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.3318   |
| steps                   | 121160   |
| td_erros                | 0.6672   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 92       |
| episodes                | 14100    |
| lives                   | 14100    |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 8.79     |
| mean 100 episode reward | 0.454    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.3276   |
| steps                   | 121939   |
| td_erros                | 0.7032   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 92       |
| episodes                | 14200    |
| lives                   | 14200    |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 9.3      |
| mean 100 episode reward | 0.665    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.1075   |
| steps                   | 122769   |
| td_erros                | 0.6475   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 92       |
| episodes                | 14300    |
| lives                   | 14300    |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 9.62     |
| mean 100 episode reward | 0.445    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.8204   |
| steps                   | 123631   |
| td_erros                | 0.4908   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 92       |
| episodes                | 14400    |
| lives                   | 14400    |
| mean 100 episode ei     | 5.38     |
| mean 100 episode length | 10.1     |
| mean 100 episode reward | 1.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.5554   |
| steps                   | 124540   |
| td_erros                | 0.4318   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 92       |
| episodes                | 14500    |
| lives                   | 14500    |
| mean 100 episode ei     | 4.45     |
| mean 100 episode length | 9.62     |
| mean 100 episode reward | 0.834    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.4764   |
| steps                   | 125402   |
| td_erros                | 0.443    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 92       |
| episodes                | 14600    |
| lives                   | 14600    |
| mean 100 episode ei     | 4.52     |
| mean 100 episode length | 9.07     |
| mean 100 episode reward | 0.657    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.4986   |
| steps                   | 126209   |
| td_erros                | 0.4913   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 92       |
| episodes                | 14700    |
| lives                   | 14700    |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 9.25     |
| mean 100 episode reward | 0.575    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.5687   |
| steps                   | 127034   |
| td_erros                | 0.5354   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 92       |
| episodes                | 14800    |
| lives                   | 14800    |
| mean 100 episode ei     | 4.81     |
| mean 100 episode length | 9.63     |
| mean 100 episode reward | 0.321    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.6683   |
| steps                   | 127897   |
| td_erros                | 0.5756   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 92       |
| episodes                | 14900    |
| lives                   | 14900    |
| mean 100 episode ei     | 5.16     |
| mean 100 episode length | 9.98     |
| mean 100 episode reward | 0.729    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.8785   |
| steps                   | 128795   |
| td_erros                | 0.6483   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 91       |
| episodes                | 15000    |
| lives                   | 15000    |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 9.08     |
| mean 100 episode reward | 0.548    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.0441   |
| steps                   | 129603   |
| td_erros                | 0.6895   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 91       |
| episodes                | 15100    |
| lives                   | 15100    |
| mean 100 episode ei     | 4.36     |
| mean 100 episode length | 9.2      |
| mean 100 episode reward | 0.932    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.1059   |
| steps                   | 130423   |
| td_erros                | 0.7412   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 91       |
| episodes                | 15200    |
| lives                   | 15200    |
| mean 100 episode ei     | 4.72     |
| mean 100 episode length | 9.57     |
| mean 100 episode reward | 0.693    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.1655   |
| steps                   | 131280   |
| td_erros                | 0.7774   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 91       |
| episodes                | 15300    |
| lives                   | 15300    |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 9.41     |
| mean 100 episode reward | 0.958    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.2616   |
| steps                   | 132121   |
| td_erros                | 0.8068   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 91       |
| episodes                | 15400    |
| lives                   | 15400    |
| mean 100 episode ei     | 4.7      |
| mean 100 episode length | 9.8      |
| mean 100 episode reward | 0.299    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.2764   |
| steps                   | 133001   |
| td_erros                | 0.7733   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 91       |
| episodes                | 15500    |
| lives                   | 15500    |
| mean 100 episode ei     | 4.72     |
| mean 100 episode length | 9.55     |
| mean 100 episode reward | 1.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.274    |
| steps                   | 133856   |
| td_erros                | 0.7767   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 91       |
| episodes                | 15600    |
| lives                   | 15600    |
| mean 100 episode ei     | 4.21     |
| mean 100 episode length | 9.08     |
| mean 100 episode reward | 0.693    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.1333   |
| steps                   | 134664   |
| td_erros                | 0.7079   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 91       |
| episodes                | 15700    |
| lives                   | 15700    |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 9.06     |
| mean 100 episode reward | 1.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.0035   |
| steps                   | 135470   |
| td_erros                | 0.6454   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 91       |
| episodes                | 15800    |
| lives                   | 15800    |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 8.4      |
| mean 100 episode reward | 0.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.8581   |
| steps                   | 136210   |
| td_erros                | 0.5772   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 91       |
| episodes                | 15900    |
| lives                   | 15900    |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 9.32     |
| mean 100 episode reward | 0.459    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.7881   |
| steps                   | 137042   |
| td_erros                | 0.5561   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 91       |
| episodes                | 16000    |
| lives                   | 16000    |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 9.38     |
| mean 100 episode reward | 0.549    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.7171   |
| steps                   | 137880   |
| td_erros                | 0.5469   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 91       |
| episodes                | 16100    |
| lives                   | 16100    |
| mean 100 episode ei     | 4.47     |
| mean 100 episode length | 9.22     |
| mean 100 episode reward | 0.706    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.6409   |
| steps                   | 138702   |
| td_erros                | 0.5486   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 91       |
| episodes                | 16200    |
| lives                   | 16200    |
| mean 100 episode ei     | 5.02     |
| mean 100 episode length | 10.1     |
| mean 100 episode reward | 0.358    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.6316   |
| steps                   | 139615   |
| td_erros                | 0.5225   |
--------------------------------------
Saving model due to mean reward increase: 0.6755 -> 0.8992
Saving model due to running mean reward increase: 0.5475 -> 0.8992
--------------------------------------
| % time spent exploring  | 91       |
| episodes                | 16300    |
| lives                   | 16300    |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 8.9      |
| mean 100 episode reward | 0.906    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.6153   |
| steps                   | 140405   |
| td_erros                | 0.5165   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 91       |
| episodes                | 16400    |
| lives                   | 16400    |
| mean 100 episode ei     | 4.75     |
| mean 100 episode length | 10.1     |
| mean 100 episode reward | 0.936    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.5683   |
| steps                   | 141314   |
| td_erros                | 0.5117   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 91       |
| episodes                | 16500    |
| lives                   | 16500    |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 8.98     |
| mean 100 episode reward | 0.739    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.6963   |
| steps                   | 142112   |
| td_erros                | 0.5639   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 91       |
| episodes                | 16600    |
| lives                   | 16600    |
| mean 100 episode ei     | 5.16     |
| mean 100 episode length | 9.8      |
| mean 100 episode reward | 1.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.7776   |
| steps                   | 142992   |
| td_erros                | 0.6407   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 91       |
| episodes                | 16700    |
| lives                   | 16700    |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 9.13     |
| mean 100 episode reward | 1.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.9797   |
| steps                   | 143805   |
| td_erros                | 0.7177   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 91       |
| episodes                | 16800    |
| lives                   | 16800    |
| mean 100 episode ei     | 4.36     |
| mean 100 episode length | 9.09     |
| mean 100 episode reward | 1.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.1293   |
| steps                   | 144614   |
| td_erros                | 0.7597   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 90       |
| episodes                | 16900    |
| lives                   | 16900    |
| mean 100 episode ei     | 4.43     |
| mean 100 episode length | 9.62     |
| mean 100 episode reward | 0.984    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.0271   |
| steps                   | 145476   |
| td_erros                | 0.6761   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 90       |
| episodes                | 17000    |
| lives                   | 17000    |
| mean 100 episode ei     | 4.51     |
| mean 100 episode length | 9.4      |
| mean 100 episode reward | 0.315    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.9007   |
| steps                   | 146316   |
| td_erros                | 0.599    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 90       |
| episodes                | 17100    |
| lives                   | 17100    |
| mean 100 episode ei     | 5.06     |
| mean 100 episode length | 10.1     |
| mean 100 episode reward | 0.872    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.7286   |
| steps                   | 147222   |
| td_erros                | 0.5497   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 90       |
| episodes                | 17200    |
| lives                   | 17200    |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 9.71     |
| mean 100 episode reward | 0.324    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.7028   |
| steps                   | 148093   |
| td_erros                | 0.5211   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 90       |
| episodes                | 17300    |
| lives                   | 17300    |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 9.3      |
| mean 100 episode reward | 0.618    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.728    |
| steps                   | 148923   |
| td_erros                | 0.5577   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 90       |
| episodes                | 17400    |
| lives                   | 17400    |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 9.01     |
| mean 100 episode reward | 0.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.8306   |
| steps                   | 149724   |
| td_erros                | 0.6341   |
--------------------------------------
Saving model due to mean reward increase: 0.8992 -> 0.9277
Saving model due to running mean reward increase: 0.2885 -> 0.9277
--------------------------------------
| % time spent exploring  | 90       |
| episodes                | 17500    |
| lives                   | 17500    |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 9.34     |
| mean 100 episode reward | 0.444    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.7475   |
| steps                   | 150558   |
| td_erros                | 0.6184   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 90       |
| episodes                | 17600    |
| lives                   | 17600    |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 9.17     |
| mean 100 episode reward | 0.558    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.6804   |
| steps                   | 151375   |
| td_erros                | 0.5458   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 90       |
| episodes                | 17700    |
| lives                   | 17700    |
| mean 100 episode ei     | 4.32     |
| mean 100 episode length | 9.09     |
| mean 100 episode reward | 0.0013   |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.6066   |
| steps                   | 152184   |
| td_erros                | 0.5105   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 90       |
| episodes                | 17800    |
| lives                   | 17800    |
| mean 100 episode ei     | 4.41     |
| mean 100 episode length | 9.39     |
| mean 100 episode reward | 1.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.5412   |
| steps                   | 153023   |
| td_erros                | 0.5677   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 90       |
| episodes                | 17900    |
| lives                   | 17900    |
| mean 100 episode ei     | 4.89     |
| mean 100 episode length | 9.61     |
| mean 100 episode reward | 1.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.5512   |
| steps                   | 153884   |
| td_erros                | 0.5678   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 90       |
| episodes                | 18000    |
| lives                   | 18000    |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 9.48     |
| mean 100 episode reward | 0.745    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.7184   |
| steps                   | 154732   |
| td_erros                | 0.6171   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 90       |
| episodes                | 18100    |
| lives                   | 18100    |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 8.91     |
| mean 100 episode reward | 0.363    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.7961   |
| steps                   | 155523   |
| td_erros                | 0.669    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 90       |
| episodes                | 18200    |
| lives                   | 18200    |
| mean 100 episode ei     | 4.21     |
| mean 100 episode length | 8.84     |
| mean 100 episode reward | 0.499    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.9423   |
| steps                   | 156307   |
| td_erros                | 0.7977   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 90       |
| episodes                | 18300    |
| lives                   | 18300    |
| mean 100 episode ei     | 4.23     |
| mean 100 episode length | 9.02     |
| mean 100 episode reward | 0.697    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.1066   |
| steps                   | 157109   |
| td_erros                | 0.8419   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 90       |
| episodes                | 18400    |
| lives                   | 18400    |
| mean 100 episode ei     | 4.45     |
| mean 100 episode length | 9.5      |
| mean 100 episode reward | 0.817    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.1827   |
| steps                   | 157959   |
| td_erros                | 0.8773   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 90       |
| episodes                | 18500    |
| lives                   | 18500    |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 9.77     |
| mean 100 episode reward | 0.278    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.0508   |
| steps                   | 158836   |
| td_erros                | 0.7893   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 90       |
| episodes                | 18600    |
| lives                   | 18600    |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 9.33     |
| mean 100 episode reward | 1        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.9421   |
| steps                   | 159669   |
| td_erros                | 0.738    |
--------------------------------------
Saving model due to running mean reward increase: 0.6265 -> 0.7429
--------------------------------------
| % time spent exploring  | 90       |
| episodes                | 18700    |
| lives                   | 18700    |
| mean 100 episode ei     | 4.79     |
| mean 100 episode length | 9.66     |
| mean 100 episode reward | 0.99     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.9556   |
| steps                   | 160535   |
| td_erros                | 0.6923   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 90       |
| episodes                | 18800    |
| lives                   | 18800    |
| mean 100 episode ei     | 4.86     |
| mean 100 episode length | 9.91     |
| mean 100 episode reward | 1.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.8145   |
| steps                   | 161426   |
| td_erros                | 0.6113   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 89       |
| episodes                | 18900    |
| lives                   | 18900    |
| mean 100 episode ei     | 4.4      |
| mean 100 episode length | 9.1      |
| mean 100 episode reward | 0.776    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.769    |
| steps                   | 162236   |
| td_erros                | 0.6217   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 89       |
| episodes                | 19000    |
| lives                   | 19000    |
| mean 100 episode ei     | 4.72     |
| mean 100 episode length | 9.53     |
| mean 100 episode reward | 1.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.7521   |
| steps                   | 163089   |
| td_erros                | 0.5903   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 89       |
| episodes                | 19100    |
| lives                   | 19100    |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 9.2      |
| mean 100 episode reward | 0.807    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.7238   |
| steps                   | 163909   |
| td_erros                | 0.5909   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 89       |
| episodes                | 19200    |
| lives                   | 19200    |
| mean 100 episode ei     | 4.51     |
| mean 100 episode length | 9.11     |
| mean 100 episode reward | 0.621    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.7275   |
| steps                   | 164720   |
| td_erros                | 0.6251   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 89       |
| episodes                | 19300    |
| lives                   | 19300    |
| mean 100 episode ei     | 4.61     |
| mean 100 episode length | 9.43     |
| mean 100 episode reward | 0.505    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.652    |
| steps                   | 165563   |
| td_erros                | 0.5696   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 89       |
| episodes                | 19400    |
| lives                   | 19400    |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 8.54     |
| mean 100 episode reward | 0.496    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.6035   |
| steps                   | 166317   |
| td_erros                | 0.5956   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 89       |
| episodes                | 19500    |
| lives                   | 19500    |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 9.59     |
| mean 100 episode reward | 0.879    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.5307   |
| steps                   | 167176   |
| td_erros                | 0.5884   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 89       |
| episodes                | 19600    |
| lives                   | 19600    |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 9.24     |
| mean 100 episode reward | 0.887    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.6624   |
| steps                   | 168000   |
| td_erros                | 0.6389   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 89       |
| episodes                | 19700    |
| lives                   | 19700    |
| mean 100 episode ei     | 4.9      |
| mean 100 episode length | 9.51     |
| mean 100 episode reward | 0.803    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.7649   |
| steps                   | 168851   |
| td_erros                | 0.6601   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 89       |
| episodes                | 19800    |
| lives                   | 19800    |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 8.79     |
| mean 100 episode reward | 0.562    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.8393   |
| steps                   | 169630   |
| td_erros                | 0.6817   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 89       |
| episodes                | 19900    |
| lives                   | 19900    |
| mean 100 episode ei     | 5.23     |
| mean 100 episode length | 9.86     |
| mean 100 episode reward | 1.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.9101   |
| steps                   | 170516   |
| td_erros                | 0.722    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 89       |
| episodes                | 20000    |
| lives                   | 20000    |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 9.29     |
| mean 100 episode reward | 0.509    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.9129   |
| steps                   | 171345   |
| td_erros                | 0.6742   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 89       |
| episodes                | 20100    |
| lives                   | 20100    |
| mean 100 episode ei     | 4.39     |
| mean 100 episode length | 9.8      |
| mean 100 episode reward | 0.855    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.7934   |
| steps                   | 172225   |
| td_erros                | 0.59     |
--------------------------------------
--------------------------------------
| % time spent exploring  | 89       |
| episodes                | 20200    |
| lives                   | 20200    |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 8.9      |
| mean 100 episode reward | 1.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.8146   |
| steps                   | 173015   |
| td_erros                | 0.5807   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 89       |
| episodes                | 20300    |
| lives                   | 20300    |
| mean 100 episode ei     | 5.12     |
| mean 100 episode length | 10.2     |
| mean 100 episode reward | 0.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.7748   |
| steps                   | 173931   |
| td_erros                | 0.578    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 89       |
| episodes                | 20400    |
| lives                   | 20400    |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 9.34     |
| mean 100 episode reward | 0.717    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.7498   |
| steps                   | 174765   |
| td_erros                | 0.5746   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 89       |
| episodes                | 20500    |
| lives                   | 20500    |
| mean 100 episode ei     | 4.74     |
| mean 100 episode length | 9.71     |
| mean 100 episode reward | 0.876    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.6612   |
| steps                   | 175636   |
| td_erros                | 0.5101   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 89       |
| episodes                | 20600    |
| lives                   | 20600    |
| mean 100 episode ei     | 4.72     |
| mean 100 episode length | 9.32     |
| mean 100 episode reward | 1.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.629    |
| steps                   | 176468   |
| td_erros                | 0.5206   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 89       |
| episodes                | 20700    |
| lives                   | 20700    |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 9        |
| mean 100 episode reward | 1.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.5645   |
| steps                   | 177268   |
| td_erros                | 0.5168   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 88       |
| episodes                | 20800    |
| lives                   | 20800    |
| mean 100 episode ei     | 4.99     |
| mean 100 episode length | 9.52     |
| mean 100 episode reward | 0.719    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.5501   |
| steps                   | 178120   |
| td_erros                | 0.4781   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 88       |
| episodes                | 20900    |
| lives                   | 20900    |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 8.67     |
| mean 100 episode reward | 1.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.7664   |
| steps                   | 178887   |
| td_erros                | 0.6244   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 88       |
| episodes                | 21000    |
| lives                   | 21000    |
| mean 100 episode ei     | 4.84     |
| mean 100 episode length | 9.58     |
| mean 100 episode reward | 0.469    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.8077   |
| steps                   | 179745   |
| td_erros                | 0.5814   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 88       |
| episodes                | 21100    |
| lives                   | 21100    |
| mean 100 episode ei     | 4.43     |
| mean 100 episode length | 8.66     |
| mean 100 episode reward | 0.877    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.961    |
| steps                   | 180511   |
| td_erros                | 0.6298   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 88       |
| episodes                | 21200    |
| lives                   | 21200    |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 9.02     |
| mean 100 episode reward | 0.337    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.0104   |
| steps                   | 181313   |
| td_erros                | 0.6678   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 88       |
| episodes                | 21300    |
| lives                   | 21300    |
| mean 100 episode ei     | 4.84     |
| mean 100 episode length | 9.88     |
| mean 100 episode reward | 0.907    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.1442   |
| steps                   | 182201   |
| td_erros                | 0.7479   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 88       |
| episodes                | 21400    |
| lives                   | 21400    |
| mean 100 episode ei     | 4.96     |
| mean 100 episode length | 9.39     |
| mean 100 episode reward | 0.794    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.1815   |
| steps                   | 183040   |
| td_erros                | 0.7648   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 88       |
| episodes                | 21500    |
| lives                   | 21500    |
| mean 100 episode ei     | 4.75     |
| mean 100 episode length | 9.26     |
| mean 100 episode reward | 0.972    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.1285   |
| steps                   | 183866   |
| td_erros                | 0.7577   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 88       |
| episodes                | 21600    |
| lives                   | 21600    |
| mean 100 episode ei     | 4.4      |
| mean 100 episode length | 8.91     |
| mean 100 episode reward | 1.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.0973   |
| steps                   | 184657   |
| td_erros                | 0.7726   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 88       |
| episodes                | 21700    |
| lives                   | 21700    |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 8.67     |
| mean 100 episode reward | 0.826    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.1123   |
| steps                   | 185424   |
| td_erros                | 0.7734   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 88       |
| episodes                | 21800    |
| lives                   | 21800    |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 9.62     |
| mean 100 episode reward | 1.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 5.0066   |
| steps                   | 186286   |
| td_erros                | 0.7494   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 88       |
| episodes                | 21900    |
| lives                   | 21900    |
| mean 100 episode ei     | 5.16     |
| mean 100 episode length | 9.79     |
| mean 100 episode reward | 1.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.9589   |
| steps                   | 187165   |
| td_erros                | 0.6923   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 88       |
| episodes                | 22000    |
| lives                   | 22000    |
| mean 100 episode ei     | 4.48     |
| mean 100 episode length | 8.77     |
| mean 100 episode reward | 1.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.9741   |
| steps                   | 187942   |
| td_erros                | 0.7145   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 88       |
| episodes                | 22100    |
| lives                   | 22100    |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 8.51     |
| mean 100 episode reward | 0.432    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.8031   |
| steps                   | 188693   |
| td_erros                | 0.6174   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 88       |
| episodes                | 22200    |
| lives                   | 22200    |
| mean 100 episode ei     | 4.79     |
| mean 100 episode length | 8.88     |
| mean 100 episode reward | 0.811    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.8265   |
| steps                   | 189481   |
| td_erros                | 0.6095   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 88       |
| episodes                | 22300    |
| lives                   | 22300    |
| mean 100 episode ei     | 4.82     |
| mean 100 episode length | 8.93     |
| mean 100 episode reward | 0.855    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.7713   |
| steps                   | 190274   |
| td_erros                | 0.5756   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 88       |
| episodes                | 22400    |
| lives                   | 22400    |
| mean 100 episode ei     | 4.91     |
| mean 100 episode length | 9.7      |
| mean 100 episode reward | 1.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.7552   |
| steps                   | 191144   |
| td_erros                | 0.5492   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 88       |
| episodes                | 22500    |
| lives                   | 22500    |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 8.9      |
| mean 100 episode reward | 0.719    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.6694   |
| steps                   | 191934   |
| td_erros                | 0.5065   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 88       |
| episodes                | 22600    |
| lives                   | 22600    |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 9.27     |
| mean 100 episode reward | 0.741    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.5823   |
| steps                   | 192761   |
| td_erros                | 0.5182   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 88       |
| episodes                | 22700    |
| lives                   | 22700    |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 9.09     |
| mean 100 episode reward | 0.974    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.5949   |
| steps                   | 193570   |
| td_erros                | 0.563    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 87       |
| episodes                | 22800    |
| lives                   | 22800    |
| mean 100 episode ei     | 4.41     |
| mean 100 episode length | 9.11     |
| mean 100 episode reward | 1.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.6055   |
| steps                   | 194381   |
| td_erros                | 0.5505   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 87       |
| episodes                | 22900    |
| lives                   | 22900    |
| mean 100 episode ei     | 4.46     |
| mean 100 episode length | 8.92     |
| mean 100 episode reward | 0.957    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.6532   |
| steps                   | 195173   |
| td_erros                | 0.5887   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 87       |
| episodes                | 23000    |
| lives                   | 23000    |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 8.95     |
| mean 100 episode reward | 0.778    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.6217   |
| steps                   | 195968   |
| td_erros                | 0.5856   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 87       |
| episodes                | 23100    |
| lives                   | 23100    |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 8.45     |
| mean 100 episode reward | 0.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.4432   |
| steps                   | 196713   |
| td_erros                | 0.5448   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 87       |
| episodes                | 23200    |
| lives                   | 23200    |
| mean 100 episode ei     | 5.14     |
| mean 100 episode length | 9.59     |
| mean 100 episode reward | 1.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3031   |
| steps                   | 197572   |
| td_erros                | 0.4571   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 87       |
| episodes                | 23300    |
| lives                   | 23300    |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 9.35     |
| mean 100 episode reward | 1.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.197    |
| steps                   | 198407   |
| td_erros                | 0.3934   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 87       |
| episodes                | 23400    |
| lives                   | 23400    |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 8.92     |
| mean 100 episode reward | 0.551    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1498   |
| steps                   | 199199   |
| td_erros                | 0.3885   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 87       |
| episodes                | 23500    |
| lives                   | 23500    |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 8.79     |
| mean 100 episode reward | 1.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1495   |
| steps                   | 199978   |
| td_erros                | 0.4085   |
--------------------------------------
Saving model due to mean reward increase: 0.9277 -> 1.4385
Saving model due to running mean reward increase: 0.5014 -> 1.4385
--------------------------------------
| % time spent exploring  | 87       |
| episodes                | 23600    |
| lives                   | 23600    |
| mean 100 episode ei     | 4.84     |
| mean 100 episode length | 9.18     |
| mean 100 episode reward | 1.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2776   |
| steps                   | 200796   |
| td_erros                | 0.4479   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 87       |
| episodes                | 23700    |
| lives                   | 23700    |
| mean 100 episode ei     | 4.42     |
| mean 100 episode length | 8.9      |
| mean 100 episode reward | 0.646    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2668   |
| steps                   | 201586   |
| td_erros                | 0.423    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 87       |
| episodes                | 23800    |
| lives                   | 23800    |
| mean 100 episode ei     | 4.52     |
| mean 100 episode length | 9.48     |
| mean 100 episode reward | 0.257    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2609   |
| steps                   | 202434   |
| td_erros                | 0.4481   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 87       |
| episodes                | 23900    |
| lives                   | 23900    |
| mean 100 episode ei     | 4.69     |
| mean 100 episode length | 9.43     |
| mean 100 episode reward | 0.882    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3421   |
| steps                   | 203277   |
| td_erros                | 0.4877   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 87       |
| episodes                | 24000    |
| lives                   | 24000    |
| mean 100 episode ei     | 4.71     |
| mean 100 episode length | 9.19     |
| mean 100 episode reward | 1.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.372    |
| steps                   | 204096   |
| td_erros                | 0.5109   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 87       |
| episodes                | 24100    |
| lives                   | 24100    |
| mean 100 episode ei     | 4.4      |
| mean 100 episode length | 8.99     |
| mean 100 episode reward | 0.626    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3509   |
| steps                   | 204895   |
| td_erros                | 0.4689   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 87       |
| episodes                | 24200    |
| lives                   | 24200    |
| mean 100 episode ei     | 4.72     |
| mean 100 episode length | 9.05     |
| mean 100 episode reward | 0.208    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3617   |
| steps                   | 205700   |
| td_erros                | 0.505    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 87       |
| episodes                | 24300    |
| lives                   | 24300    |
| mean 100 episode ei     | 4.82     |
| mean 100 episode length | 9.18     |
| mean 100 episode reward | 1.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3296   |
| steps                   | 206518   |
| td_erros                | 0.4686   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 87       |
| episodes                | 24400    |
| lives                   | 24400    |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 9.02     |
| mean 100 episode reward | 0.662    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3555   |
| steps                   | 207320   |
| td_erros                | 0.4536   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 87       |
| episodes                | 24500    |
| lives                   | 24500    |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 8.59     |
| mean 100 episode reward | 0.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.5137   |
| steps                   | 208079   |
| td_erros                | 0.5293   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 87       |
| episodes                | 24600    |
| lives                   | 24600    |
| mean 100 episode ei     | 4.84     |
| mean 100 episode length | 9.05     |
| mean 100 episode reward | 1.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.5434   |
| steps                   | 208884   |
| td_erros                | 0.5564   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 87       |
| episodes                | 24700    |
| lives                   | 24700    |
| mean 100 episode ei     | 4.91     |
| mean 100 episode length | 9.27     |
| mean 100 episode reward | 1.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.6225   |
| steps                   | 209711   |
| td_erros                | 0.5425   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 86       |
| episodes                | 24800    |
| lives                   | 24800    |
| mean 100 episode ei     | 4.41     |
| mean 100 episode length | 8.85     |
| mean 100 episode reward | 1.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.7045   |
| steps                   | 210496   |
| td_erros                | 0.5953   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 86       |
| episodes                | 24900    |
| lives                   | 24900    |
| mean 100 episode ei     | 4.71     |
| mean 100 episode length | 9.16     |
| mean 100 episode reward | 0.614    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.7503   |
| steps                   | 211312   |
| td_erros                | 0.6389   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 86       |
| episodes                | 25000    |
| lives                   | 25000    |
| mean 100 episode ei     | 4.71     |
| mean 100 episode length | 8.89     |
| mean 100 episode reward | 1.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.6637   |
| steps                   | 212101   |
| td_erros                | 0.5862   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 86       |
| episodes                | 25100    |
| lives                   | 25100    |
| mean 100 episode ei     | 5.01     |
| mean 100 episode length | 9.54     |
| mean 100 episode reward | 0.586    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.5886   |
| steps                   | 212955   |
| td_erros                | 0.5501   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 86       |
| episodes                | 25200    |
| lives                   | 25200    |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 8.8      |
| mean 100 episode reward | 1.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.563    |
| steps                   | 213735   |
| td_erros                | 0.5375   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 86       |
| episodes                | 25300    |
| lives                   | 25300    |
| mean 100 episode ei     | 4.4      |
| mean 100 episode length | 8.57     |
| mean 100 episode reward | 0.946    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.528    |
| steps                   | 214492   |
| td_erros                | 0.5443   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 86       |
| episodes                | 25400    |
| lives                   | 25400    |
| mean 100 episode ei     | 4.49     |
| mean 100 episode length | 8.92     |
| mean 100 episode reward | 1.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.5166   |
| steps                   | 215284   |
| td_erros                | 0.542    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 86       |
| episodes                | 25500    |
| lives                   | 25500    |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 9.55     |
| mean 100 episode reward | 0.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.496    |
| steps                   | 216139   |
| td_erros                | 0.5121   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 86       |
| episodes                | 25600    |
| lives                   | 25600    |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 9.01     |
| mean 100 episode reward | 1.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.5487   |
| steps                   | 216940   |
| td_erros                | 0.5603   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 86       |
| episodes                | 25700    |
| lives                   | 25700    |
| mean 100 episode ei     | 4.35     |
| mean 100 episode length | 8.62     |
| mean 100 episode reward | 0.951    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.5603   |
| steps                   | 217702   |
| td_erros                | 0.5775   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 86       |
| episodes                | 25800    |
| lives                   | 25800    |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 8.37     |
| mean 100 episode reward | 1.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.5667   |
| steps                   | 218439   |
| td_erros                | 0.575    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 86       |
| episodes                | 25900    |
| lives                   | 25900    |
| mean 100 episode ei     | 4.32     |
| mean 100 episode length | 8.6      |
| mean 100 episode reward | 1.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.4569   |
| steps                   | 219199   |
| td_erros                | 0.5903   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 86       |
| episodes                | 26000    |
| lives                   | 26000    |
| mean 100 episode ei     | 4.21     |
| mean 100 episode length | 9.07     |
| mean 100 episode reward | 0.534    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.4634   |
| steps                   | 220006   |
| td_erros                | 0.5756   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 86       |
| episodes                | 26100    |
| lives                   | 26100    |
| mean 100 episode ei     | 4.71     |
| mean 100 episode length | 9.09     |
| mean 100 episode reward | 0.976    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.5495   |
| steps                   | 220815   |
| td_erros                | 0.6182   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 86       |
| episodes                | 26200    |
| lives                   | 26200    |
| mean 100 episode ei     | 4.85     |
| mean 100 episode length | 9.65     |
| mean 100 episode reward | 0.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.516    |
| steps                   | 221680   |
| td_erros                | 0.5699   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 86       |
| episodes                | 26300    |
| lives                   | 26300    |
| mean 100 episode ei     | 4.51     |
| mean 100 episode length | 8.79     |
| mean 100 episode reward | 1.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.4316   |
| steps                   | 222459   |
| td_erros                | 0.5073   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 86       |
| episodes                | 26400    |
| lives                   | 26400    |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 8.51     |
| mean 100 episode reward | 1.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3401   |
| steps                   | 223210   |
| td_erros                | 0.524    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 86       |
| episodes                | 26500    |
| lives                   | 26500    |
| mean 100 episode ei     | 4.46     |
| mean 100 episode length | 9.17     |
| mean 100 episode reward | 0.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3002   |
| steps                   | 224027   |
| td_erros                | 0.4798   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 86       |
| episodes                | 26600    |
| lives                   | 26600    |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 9.14     |
| mean 100 episode reward | 1.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1983   |
| steps                   | 224841   |
| td_erros                | 0.4395   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 86       |
| episodes                | 26700    |
| lives                   | 26700    |
| mean 100 episode ei     | 5.03     |
| mean 100 episode length | 9.5      |
| mean 100 episode reward | 1.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2302   |
| steps                   | 225691   |
| td_erros                | 0.4223   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 85       |
| episodes                | 26800    |
| lives                   | 26800    |
| mean 100 episode ei     | 4.85     |
| mean 100 episode length | 9.12     |
| mean 100 episode reward | 1.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2674   |
| steps                   | 226503   |
| td_erros                | 0.4671   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 85       |
| episodes                | 26900    |
| lives                   | 26900    |
| mean 100 episode ei     | 4.32     |
| mean 100 episode length | 9.15     |
| mean 100 episode reward | 1.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3634   |
| steps                   | 227318   |
| td_erros                | 0.5092   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 85       |
| episodes                | 27000    |
| lives                   | 27000    |
| mean 100 episode ei     | 5.15     |
| mean 100 episode length | 9.72     |
| mean 100 episode reward | 0.545    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3752   |
| steps                   | 228190   |
| td_erros                | 0.4859   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 85       |
| episodes                | 27100    |
| lives                   | 27100    |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 8.77     |
| mean 100 episode reward | 1.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.4153   |
| steps                   | 228967   |
| td_erros                | 0.4757   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 85       |
| episodes                | 27200    |
| lives                   | 27200    |
| mean 100 episode ei     | 4.51     |
| mean 100 episode length | 8.76     |
| mean 100 episode reward | 1.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.5261   |
| steps                   | 229743   |
| td_erros                | 0.5207   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 85       |
| episodes                | 27300    |
| lives                   | 27300    |
| mean 100 episode ei     | 4.61     |
| mean 100 episode length | 9.1      |
| mean 100 episode reward | 1.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.6357   |
| steps                   | 230553   |
| td_erros                | 0.5525   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 85       |
| episodes                | 27400    |
| lives                   | 27400    |
| mean 100 episode ei     | 4.41     |
| mean 100 episode length | 8.7      |
| mean 100 episode reward | 1.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.7807   |
| steps                   | 231323   |
| td_erros                | 0.5952   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 85       |
| episodes                | 27500    |
| lives                   | 27500    |
| mean 100 episode ei     | 4.45     |
| mean 100 episode length | 8.52     |
| mean 100 episode reward | 1.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.8383   |
| steps                   | 232075   |
| td_erros                | 0.6238   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 85       |
| episodes                | 27600    |
| lives                   | 27600    |
| mean 100 episode ei     | 4.86     |
| mean 100 episode length | 8.99     |
| mean 100 episode reward | 1.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.8687   |
| steps                   | 232874   |
| td_erros                | 0.6077   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 85       |
| episodes                | 27700    |
| lives                   | 27700    |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 9.04     |
| mean 100 episode reward | 0.604    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.8178   |
| steps                   | 233678   |
| td_erros                | 0.6292   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 85       |
| episodes                | 27800    |
| lives                   | 27800    |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 8.24     |
| mean 100 episode reward | 1.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.6496   |
| steps                   | 234402   |
| td_erros                | 0.5816   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 85       |
| episodes                | 27900    |
| lives                   | 27900    |
| mean 100 episode ei     | 4.51     |
| mean 100 episode length | 8.65     |
| mean 100 episode reward | 0.795    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.5609   |
| steps                   | 235167   |
| td_erros                | 0.5659   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 85       |
| episodes                | 28000    |
| lives                   | 28000    |
| mean 100 episode ei     | 4.46     |
| mean 100 episode length | 8.7      |
| mean 100 episode reward | 0.752    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.458    |
| steps                   | 235937   |
| td_erros                | 0.5076   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 85       |
| episodes                | 28100    |
| lives                   | 28100    |
| mean 100 episode ei     | 4.33     |
| mean 100 episode length | 9.13     |
| mean 100 episode reward | 0.502    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3297   |
| steps                   | 236750   |
| td_erros                | 0.4385   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 85       |
| episodes                | 28200    |
| lives                   | 28200    |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 8.92     |
| mean 100 episode reward | 0.928    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1874   |
| steps                   | 237542   |
| td_erros                | 0.3806   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 85       |
| episodes                | 28300    |
| lives                   | 28300    |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 9.01     |
| mean 100 episode reward | 0.988    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9333   |
| steps                   | 238343   |
| td_erros                | 0.3134   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 85       |
| episodes                | 28400    |
| lives                   | 28400    |
| mean 100 episode ei     | 4.46     |
| mean 100 episode length | 8.44     |
| mean 100 episode reward | 1.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8596   |
| steps                   | 239087   |
| td_erros                | 0.3186   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 85       |
| episodes                | 28500    |
| lives                   | 28500    |
| mean 100 episode ei     | 4.62     |
| mean 100 episode length | 9.02     |
| mean 100 episode reward | 1.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8912   |
| steps                   | 239889   |
| td_erros                | 0.3581   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 85       |
| episodes                | 28600    |
| lives                   | 28600    |
| mean 100 episode ei     | 4.33     |
| mean 100 episode length | 8.84     |
| mean 100 episode reward | 1.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.991    |
| steps                   | 240673   |
| td_erros                | 0.3759   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 85       |
| episodes                | 28700    |
| lives                   | 28700    |
| mean 100 episode ei     | 4.48     |
| mean 100 episode length | 9.05     |
| mean 100 episode reward | 1.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1381   |
| steps                   | 241478   |
| td_erros                | 0.47     |
--------------------------------------
--------------------------------------
| % time spent exploring  | 85       |
| episodes                | 28800    |
| lives                   | 28800    |
| mean 100 episode ei     | 4.23     |
| mean 100 episode length | 8.23     |
| mean 100 episode reward | 1.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1764   |
| steps                   | 242201   |
| td_erros                | 0.4647   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 28900    |
| lives                   | 28900    |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 8.82     |
| mean 100 episode reward | 1.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1353   |
| steps                   | 242983   |
| td_erros                | 0.4927   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 29000    |
| lives                   | 29000    |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 9.12     |
| mean 100 episode reward | 0.147    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9952   |
| steps                   | 243795   |
| td_erros                | 0.4002   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 29100    |
| lives                   | 29100    |
| mean 100 episode ei     | 4.24     |
| mean 100 episode length | 8.37     |
| mean 100 episode reward | 0.756    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0067   |
| steps                   | 244532   |
| td_erros                | 0.4015   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 29200    |
| lives                   | 29200    |
| mean 100 episode ei     | 4.85     |
| mean 100 episode length | 8.86     |
| mean 100 episode reward | 1.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0569   |
| steps                   | 245318   |
| td_erros                | 0.4569   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 29300    |
| lives                   | 29300    |
| mean 100 episode ei     | 5.03     |
| mean 100 episode length | 8.9      |
| mean 100 episode reward | 1.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1035   |
| steps                   | 246108   |
| td_erros                | 0.4666   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 29400    |
| lives                   | 29400    |
| mean 100 episode ei     | 4.46     |
| mean 100 episode length | 8.65     |
| mean 100 episode reward | 1.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1464   |
| steps                   | 246873   |
| td_erros                | 0.4598   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 29500    |
| lives                   | 29500    |
| mean 100 episode ei     | 4.69     |
| mean 100 episode length | 9.18     |
| mean 100 episode reward | 1.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1351   |
| steps                   | 247691   |
| td_erros                | 0.4472   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 29600    |
| lives                   | 29600    |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 8.14     |
| mean 100 episode reward | 1.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1638   |
| steps                   | 248405   |
| td_erros                | 0.462    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 29700    |
| lives                   | 29700    |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 7.9      |
| mean 100 episode reward | 1.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2288   |
| steps                   | 249095   |
| td_erros                | 0.5019   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 29800    |
| lives                   | 29800    |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 9.27     |
| mean 100 episode reward | 1.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1164   |
| steps                   | 249922   |
| td_erros                | 0.4757   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 29900    |
| lives                   | 29900    |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 9.21     |
| mean 100 episode reward | 0.911    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9935   |
| steps                   | 250743   |
| td_erros                | 0.4449   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 30000    |
| lives                   | 30000    |
| mean 100 episode ei     | 4.73     |
| mean 100 episode length | 9.49     |
| mean 100 episode reward | 0.538    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8724   |
| steps                   | 251592   |
| td_erros                | 0.3956   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 30100    |
| lives                   | 30100    |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 8.62     |
| mean 100 episode reward | 1.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8342   |
| steps                   | 252354   |
| td_erros                | 0.3813   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 30200    |
| lives                   | 30200    |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 8.58     |
| mean 100 episode reward | 1.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0037   |
| steps                   | 253112   |
| td_erros                | 0.4458   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 30300    |
| lives                   | 30300    |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 8.9      |
| mean 100 episode reward | 1.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0431   |
| steps                   | 253902   |
| td_erros                | 0.4315   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 30400    |
| lives                   | 30400    |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 8.16     |
| mean 100 episode reward | 0.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0845   |
| steps                   | 254618   |
| td_erros                | 0.4334   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 30500    |
| lives                   | 30500    |
| mean 100 episode ei     | 5.25     |
| mean 100 episode length | 9.57     |
| mean 100 episode reward | 1.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1738   |
| steps                   | 255475   |
| td_erros                | 0.4539   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 30600    |
| lives                   | 30600    |
| mean 100 episode ei     | 4.81     |
| mean 100 episode length | 8.68     |
| mean 100 episode reward | 1.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2623   |
| steps                   | 256243   |
| td_erros                | 0.4491   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 30700    |
| lives                   | 30700    |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 8.93     |
| mean 100 episode reward | 0.885    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2474   |
| steps                   | 257036   |
| td_erros                | 0.4424   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 30800    |
| lives                   | 30800    |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 8.35     |
| mean 100 episode reward | 1.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2202   |
| steps                   | 257771   |
| td_erros                | 0.4489   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 84       |
| episodes                | 30900    |
| lives                   | 30900    |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 8.33     |
| mean 100 episode reward | 0.769    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2563   |
| steps                   | 258504   |
| td_erros                | 0.4628   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 83       |
| episodes                | 31000    |
| lives                   | 31000    |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 8.62     |
| mean 100 episode reward | 0.811    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.241    |
| steps                   | 259266   |
| td_erros                | 0.4879   |
--------------------------------------
Saving model due to mean reward increase: 1.4385 -> 1.5038
Saving model due to running mean reward increase: 0.5447 -> 1.5038
--------------------------------------
| % time spent exploring  | 83       |
| episodes                | 31100    |
| lives                   | 31100    |
| mean 100 episode ei     | 4.76     |
| mean 100 episode length | 9.38     |
| mean 100 episode reward | 1.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2371   |
| steps                   | 260104   |
| td_erros                | 0.4782   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 83       |
| episodes                | 31200    |
| lives                   | 31200    |
| mean 100 episode ei     | 4.23     |
| mean 100 episode length | 8.42     |
| mean 100 episode reward | 1.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2721   |
| steps                   | 260846   |
| td_erros                | 0.5187   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 83       |
| episodes                | 31300    |
| lives                   | 31300    |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 8.35     |
| mean 100 episode reward | 1.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2661   |
| steps                   | 261581   |
| td_erros                | 0.5131   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 83       |
| episodes                | 31400    |
| lives                   | 31400    |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 8.53     |
| mean 100 episode reward | 1.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2806   |
| steps                   | 262334   |
| td_erros                | 0.4941   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 83       |
| episodes                | 31500    |
| lives                   | 31500    |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 9.21     |
| mean 100 episode reward | 0.958    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1792   |
| steps                   | 263155   |
| td_erros                | 0.4354   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 83       |
| episodes                | 31600    |
| lives                   | 31600    |
| mean 100 episode ei     | 4.9      |
| mean 100 episode length | 9.16     |
| mean 100 episode reward | 1.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.123    |
| steps                   | 263971   |
| td_erros                | 0.4062   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 83       |
| episodes                | 31700    |
| lives                   | 31700    |
| mean 100 episode ei     | 4.32     |
| mean 100 episode length | 8.34     |
| mean 100 episode reward | 1.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1425   |
| steps                   | 264705   |
| td_erros                | 0.4281   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 83       |
| episodes                | 31800    |
| lives                   | 31800    |
| mean 100 episode ei     | 5.05     |
| mean 100 episode length | 9.13     |
| mean 100 episode reward | 1.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1834   |
| steps                   | 265518   |
| td_erros                | 0.4472   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 83       |
| episodes                | 31900    |
| lives                   | 31900    |
| mean 100 episode ei     | 4.51     |
| mean 100 episode length | 8.66     |
| mean 100 episode reward | 1.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3024   |
| steps                   | 266284   |
| td_erros                | 0.5284   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 83       |
| episodes                | 32000    |
| lives                   | 32000    |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 9.16     |
| mean 100 episode reward | 1.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3771   |
| steps                   | 267100   |
| td_erros                | 0.5145   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 83       |
| episodes                | 32100    |
| lives                   | 32100    |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 9.23     |
| mean 100 episode reward | 0.835    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3431   |
| steps                   | 267923   |
| td_erros                | 0.4762   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 83       |
| episodes                | 32200    |
| lives                   | 32200    |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 8.53     |
| mean 100 episode reward | 1.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.4242   |
| steps                   | 268676   |
| td_erros                | 0.5182   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 83       |
| episodes                | 32300    |
| lives                   | 32300    |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 8.73     |
| mean 100 episode reward | 1.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2549   |
| steps                   | 269449   |
| td_erros                | 0.4107   |
--------------------------------------
Saving model due to mean reward increase: 1.5038 -> 1.5191
Saving model due to running mean reward increase: 1.2476 -> 1.5191
--------------------------------------
| % time spent exploring  | 83       |
| episodes                | 32400    |
| lives                   | 32400    |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 8.96     |
| mean 100 episode reward | 1.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1339   |
| steps                   | 270245   |
| td_erros                | 0.3675   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 83       |
| episodes                | 32500    |
| lives                   | 32500    |
| mean 100 episode ei     | 4.46     |
| mean 100 episode length | 8.36     |
| mean 100 episode reward | 1.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1945   |
| steps                   | 270981   |
| td_erros                | 0.3832   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 83       |
| episodes                | 32600    |
| lives                   | 32600    |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 9.41     |
| mean 100 episode reward | 0.979    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0719   |
| steps                   | 271822   |
| td_erros                | 0.3601   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 83       |
| episodes                | 32700    |
| lives                   | 32700    |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 8.85     |
| mean 100 episode reward | 1.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0235   |
| steps                   | 272607   |
| td_erros                | 0.3876   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 83       |
| episodes                | 32800    |
| lives                   | 32800    |
| mean 100 episode ei     | 4.49     |
| mean 100 episode length | 8.6      |
| mean 100 episode reward | 1.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9803   |
| steps                   | 273367   |
| td_erros                | 0.3724   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 83       |
| episodes                | 32900    |
| lives                   | 32900    |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 9.1      |
| mean 100 episode reward | 0.508    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9391   |
| steps                   | 274177   |
| td_erros                | 0.3659   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 33000    |
| lives                   | 33000    |
| mean 100 episode ei     | 4.73     |
| mean 100 episode length | 9.12     |
| mean 100 episode reward | 0.795    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0923   |
| steps                   | 274989   |
| td_erros                | 0.4097   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 33100    |
| lives                   | 33100    |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 8.67     |
| mean 100 episode reward | 1.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1877   |
| steps                   | 275756   |
| td_erros                | 0.4299   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 33200    |
| lives                   | 33200    |
| mean 100 episode ei     | 4.71     |
| mean 100 episode length | 9.28     |
| mean 100 episode reward | 1.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1139   |
| steps                   | 276584   |
| td_erros                | 0.4055   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 33300    |
| lives                   | 33300    |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 8.77     |
| mean 100 episode reward | 2.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1691   |
| steps                   | 277361   |
| td_erros                | 0.418    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 33400    |
| lives                   | 33400    |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 8.82     |
| mean 100 episode reward | 1.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2146   |
| steps                   | 278143   |
| td_erros                | 0.4193   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 33500    |
| lives                   | 33500    |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 9.04     |
| mean 100 episode reward | 1.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2656   |
| steps                   | 278947   |
| td_erros                | 0.4534   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 33600    |
| lives                   | 33600    |
| mean 100 episode ei     | 4.49     |
| mean 100 episode length | 8.62     |
| mean 100 episode reward | 1.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2388   |
| steps                   | 279709   |
| td_erros                | 0.45     |
--------------------------------------
Saving model due to running mean reward increase: 0.9918 -> 1.198
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 33700    |
| lives                   | 33700    |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 8.66     |
| mean 100 episode reward | 1.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3275   |
| steps                   | 280475   |
| td_erros                | 0.4615   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 33800    |
| lives                   | 33800    |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 8.17     |
| mean 100 episode reward | 1.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3446   |
| steps                   | 281192   |
| td_erros                | 0.4731   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 33900    |
| lives                   | 33900    |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 9.09     |
| mean 100 episode reward | 0.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2977   |
| steps                   | 282001   |
| td_erros                | 0.4456   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 34000    |
| lives                   | 34000    |
| mean 100 episode ei     | 4.61     |
| mean 100 episode length | 8.98     |
| mean 100 episode reward | 1.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3638   |
| steps                   | 282799   |
| td_erros                | 0.4673   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 34100    |
| lives                   | 34100    |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 8.92     |
| mean 100 episode reward | 1.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3185   |
| steps                   | 283591   |
| td_erros                | 0.452    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 34200    |
| lives                   | 34200    |
| mean 100 episode ei     | 4.36     |
| mean 100 episode length | 8.74     |
| mean 100 episode reward | 0.334    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3431   |
| steps                   | 284365   |
| td_erros                | 0.4786   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 34300    |
| lives                   | 34300    |
| mean 100 episode ei     | 4.77     |
| mean 100 episode length | 9.24     |
| mean 100 episode reward | 0.752    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.255    |
| steps                   | 285189   |
| td_erros                | 0.4146   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 34400    |
| lives                   | 34400    |
| mean 100 episode ei     | 4.35     |
| mean 100 episode length | 8.61     |
| mean 100 episode reward | 0.985    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2342   |
| steps                   | 285950   |
| td_erros                | 0.425    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 34500    |
| lives                   | 34500    |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 8.19     |
| mean 100 episode reward | 1.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2477   |
| steps                   | 286669   |
| td_erros                | 0.4435   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 34600    |
| lives                   | 34600    |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 9.31     |
| mean 100 episode reward | 0.928    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3076   |
| steps                   | 287500   |
| td_erros                | 0.4872   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 34700    |
| lives                   | 34700    |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 8.8      |
| mean 100 episode reward | 1.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3546   |
| steps                   | 288280   |
| td_erros                | 0.4785   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 34800    |
| lives                   | 34800    |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 8.8      |
| mean 100 episode reward | 0.972    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2247   |
| steps                   | 289060   |
| td_erros                | 0.4112   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 34900    |
| lives                   | 34900    |
| mean 100 episode ei     | 4.71     |
| mean 100 episode length | 9.2      |
| mean 100 episode reward | 1.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1506   |
| steps                   | 289880   |
| td_erros                | 0.3585   |
--------------------------------------
Saving model due to running mean reward increase: 1.0701 -> 1.4525
--------------------------------------
| % time spent exploring  | 82       |
| episodes                | 35000    |
| lives                   | 35000    |
| mean 100 episode ei     | 4.35     |
| mean 100 episode length | 8.73     |
| mean 100 episode reward | 1.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0614   |
| steps                   | 290653   |
| td_erros                | 0.3501   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 35100    |
| lives                   | 35100    |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 8.35     |
| mean 100 episode reward | 1.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1039   |
| steps                   | 291388   |
| td_erros                | 0.3792   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 35200    |
| lives                   | 35200    |
| mean 100 episode ei     | 4.32     |
| mean 100 episode length | 8.19     |
| mean 100 episode reward | 1.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1206   |
| steps                   | 292107   |
| td_erros                | 0.398    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 35300    |
| lives                   | 35300    |
| mean 100 episode ei     | 4.78     |
| mean 100 episode length | 9.2      |
| mean 100 episode reward | 1.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0755   |
| steps                   | 292927   |
| td_erros                | 0.4005   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 35400    |
| lives                   | 35400    |
| mean 100 episode ei     | 4.7      |
| mean 100 episode length | 9        |
| mean 100 episode reward | 2        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0388   |
| steps                   | 293727   |
| td_erros                | 0.4087   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 35500    |
| lives                   | 35500    |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 8.44     |
| mean 100 episode reward | 1.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0262   |
| steps                   | 294471   |
| td_erros                | 0.453    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 35600    |
| lives                   | 35600    |
| mean 100 episode ei     | 4.35     |
| mean 100 episode length | 8.63     |
| mean 100 episode reward | 1.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0361   |
| steps                   | 295234   |
| td_erros                | 0.4744   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 35700    |
| lives                   | 35700    |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 8.61     |
| mean 100 episode reward | 1.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9989   |
| steps                   | 295995   |
| td_erros                | 0.4562   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 35800    |
| lives                   | 35800    |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 8.11     |
| mean 100 episode reward | 1.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0957   |
| steps                   | 296706   |
| td_erros                | 0.4619   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 35900    |
| lives                   | 35900    |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 7.91     |
| mean 100 episode reward | 1.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1466   |
| steps                   | 297397   |
| td_erros                | 0.4733   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 36000    |
| lives                   | 36000    |
| mean 100 episode ei     | 4.51     |
| mean 100 episode length | 8.8      |
| mean 100 episode reward | 1.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.055    |
| steps                   | 298177   |
| td_erros                | 0.4525   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 36100    |
| lives                   | 36100    |
| mean 100 episode ei     | 4.61     |
| mean 100 episode length | 8.77     |
| mean 100 episode reward | 1.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1098   |
| steps                   | 298954   |
| td_erros                | 0.467    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 36200    |
| lives                   | 36200    |
| mean 100 episode ei     | 4.42     |
| mean 100 episode length | 8.91     |
| mean 100 episode reward | 1.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0199   |
| steps                   | 299745   |
| td_erros                | 0.4199   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 36300    |
| lives                   | 36300    |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 8.4      |
| mean 100 episode reward | 1.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0663   |
| steps                   | 300485   |
| td_erros                | 0.4536   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 36400    |
| lives                   | 36400    |
| mean 100 episode ei     | 4.97     |
| mean 100 episode length | 9.51     |
| mean 100 episode reward | 0.978    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1517   |
| steps                   | 301336   |
| td_erros                | 0.4788   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 36500    |
| lives                   | 36500    |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 8.66     |
| mean 100 episode reward | 1.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2242   |
| steps                   | 302102   |
| td_erros                | 0.493    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 36600    |
| lives                   | 36600    |
| mean 100 episode ei     | 4.42     |
| mean 100 episode length | 9.04     |
| mean 100 episode reward | 1.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1245   |
| steps                   | 302906   |
| td_erros                | 0.4513   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 36700    |
| lives                   | 36700    |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 8.83     |
| mean 100 episode reward | 1.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1744   |
| steps                   | 303689   |
| td_erros                | 0.4742   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 36800    |
| lives                   | 36800    |
| mean 100 episode ei     | 4.7      |
| mean 100 episode length | 9.05     |
| mean 100 episode reward | 1.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2038   |
| steps                   | 304494   |
| td_erros                | 0.5075   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 36900    |
| lives                   | 36900    |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 8.07     |
| mean 100 episode reward | 1.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3197   |
| steps                   | 305201   |
| td_erros                | 0.5284   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 37000    |
| lives                   | 37000    |
| mean 100 episode ei     | 4.71     |
| mean 100 episode length | 9.06     |
| mean 100 episode reward | 1.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3678   |
| steps                   | 306007   |
| td_erros                | 0.5436   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 81       |
| episodes                | 37100    |
| lives                   | 37100    |
| mean 100 episode ei     | 4.48     |
| mean 100 episode length | 8.89     |
| mean 100 episode reward | 1.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3456   |
| steps                   | 306796   |
| td_erros                | 0.561    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 80       |
| episodes                | 37200    |
| lives                   | 37200    |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 8.36     |
| mean 100 episode reward | 2.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3637   |
| steps                   | 307532   |
| td_erros                | 0.558    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 80       |
| episodes                | 37300    |
| lives                   | 37300    |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 8.53     |
| mean 100 episode reward | 1.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.3149   |
| steps                   | 308285   |
| td_erros                | 0.5125   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 80       |
| episodes                | 37400    |
| lives                   | 37400    |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 8.99     |
| mean 100 episode reward | 1.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1578   |
| steps                   | 309084   |
| td_erros                | 0.465    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 80       |
| episodes                | 37500    |
| lives                   | 37500    |
| mean 100 episode ei     | 4.41     |
| mean 100 episode length | 8.56     |
| mean 100 episode reward | 2.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.061    |
| steps                   | 309840   |
| td_erros                | 0.4359   |
--------------------------------------
Saving model due to mean reward increase: 1.5191 -> 1.7849
Saving model due to running mean reward increase: 1.4312 -> 1.7849
--------------------------------------
| % time spent exploring  | 80       |
| episodes                | 37600    |
| lives                   | 37600    |
| mean 100 episode ei     | 4.61     |
| mean 100 episode length | 9.26     |
| mean 100 episode reward | 1.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0087   |
| steps                   | 310666   |
| td_erros                | 0.433    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 80       |
| episodes                | 37700    |
| lives                   | 37700    |
| mean 100 episode ei     | 4.96     |
| mean 100 episode length | 8.76     |
| mean 100 episode reward | 1.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0175   |
| steps                   | 311442   |
| td_erros                | 0.4549   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 80       |
| episodes                | 37800    |
| lives                   | 37800    |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 8.65     |
| mean 100 episode reward | 1.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0644   |
| steps                   | 312207   |
| td_erros                | 0.4685   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 80       |
| episodes                | 37900    |
| lives                   | 37900    |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 8        |
| mean 100 episode reward | 1.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0661   |
| steps                   | 312907   |
| td_erros                | 0.448    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 80       |
| episodes                | 38000    |
| lives                   | 38000    |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 8.63     |
| mean 100 episode reward | 1.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.038    |
| steps                   | 313670   |
| td_erros                | 0.472    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 80       |
| episodes                | 38100    |
| lives                   | 38100    |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 7.92     |
| mean 100 episode reward | 1.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0716   |
| steps                   | 314362   |
| td_erros                | 0.4824   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 80       |
| episodes                | 38200    |
| lives                   | 38200    |
| mean 100 episode ei     | 4.32     |
| mean 100 episode length | 8.73     |
| mean 100 episode reward | 1.57     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1021   |
| steps                   | 315135   |
| td_erros                | 0.4622   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 80       |
| episodes                | 38300    |
| lives                   | 38300    |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 9.11     |
| mean 100 episode reward | 1.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0967   |
| steps                   | 315946   |
| td_erros                | 0.4321   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 80       |
| episodes                | 38400    |
| lives                   | 38400    |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 8.35     |
| mean 100 episode reward | 1.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0384   |
| steps                   | 316681   |
| td_erros                | 0.4194   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 80       |
| episodes                | 38500    |
| lives                   | 38500    |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 9.02     |
| mean 100 episode reward | 1.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9573   |
| steps                   | 317483   |
| td_erros                | 0.3964   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 80       |
| episodes                | 38600    |
| lives                   | 38600    |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 8.47     |
| mean 100 episode reward | 1.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9424   |
| steps                   | 318230   |
| td_erros                | 0.3824   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 80       |
| episodes                | 38700    |
| lives                   | 38700    |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 9.15     |
| mean 100 episode reward | 1.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8767   |
| steps                   | 319045   |
| td_erros                | 0.358    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 80       |
| episodes                | 38800    |
| lives                   | 38800    |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 8.35     |
| mean 100 episode reward | 1.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8857   |
| steps                   | 319780   |
| td_erros                | 0.3722   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 80       |
| episodes                | 38900    |
| lives                   | 38900    |
| mean 100 episode ei     | 4.49     |
| mean 100 episode length | 8.83     |
| mean 100 episode reward | 1.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8009   |
| steps                   | 320563   |
| td_erros                | 0.336    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 80       |
| episodes                | 39000    |
| lives                   | 39000    |
| mean 100 episode ei     | 5        |
| mean 100 episode length | 9.05     |
| mean 100 episode reward | 1.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8329   |
| steps                   | 321368   |
| td_erros                | 0.3569   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 80       |
| episodes                | 39100    |
| lives                   | 39100    |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 8.59     |
| mean 100 episode reward | 1.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9135   |
| steps                   | 322127   |
| td_erros                | 0.3802   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 80       |
| episodes                | 39200    |
| lives                   | 39200    |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 9.07     |
| mean 100 episode reward | 1.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9774   |
| steps                   | 322934   |
| td_erros                | 0.401    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 79       |
| episodes                | 39300    |
| lives                   | 39300    |
| mean 100 episode ei     | 4.39     |
| mean 100 episode length | 8.06     |
| mean 100 episode reward | 2.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1824   |
| steps                   | 323640   |
| td_erros                | 0.4478   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 79       |
| episodes                | 39400    |
| lives                   | 39400    |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 8.65     |
| mean 100 episode reward | 1.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2176   |
| steps                   | 324405   |
| td_erros                | 0.4599   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 79       |
| episodes                | 39500    |
| lives                   | 39500    |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 8.49     |
| mean 100 episode reward | 1.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.229    |
| steps                   | 325154   |
| td_erros                | 0.437    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 79       |
| episodes                | 39600    |
| lives                   | 39600    |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 8.72     |
| mean 100 episode reward | 1.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.2143   |
| steps                   | 325926   |
| td_erros                | 0.4404   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 79       |
| episodes                | 39700    |
| lives                   | 39700    |
| mean 100 episode ei     | 4.42     |
| mean 100 episode length | 9.19     |
| mean 100 episode reward | 1.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.202    |
| steps                   | 326745   |
| td_erros                | 0.4274   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 79       |
| episodes                | 39800    |
| lives                   | 39800    |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 8.2      |
| mean 100 episode reward | 1.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0416   |
| steps                   | 327465   |
| td_erros                | 0.3811   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 79       |
| episodes                | 39900    |
| lives                   | 39900    |
| mean 100 episode ei     | 4.94     |
| mean 100 episode length | 9.16     |
| mean 100 episode reward | 0.712    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9836   |
| steps                   | 328281   |
| td_erros                | 0.3818   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 79       |
| episodes                | 40000    |
| lives                   | 40000    |
| mean 100 episode ei     | 4.97     |
| mean 100 episode length | 8.61     |
| mean 100 episode reward | 1.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.006    |
| steps                   | 329042   |
| td_erros                | 0.3885   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 79       |
| episodes                | 40100    |
| lives                   | 40100    |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 8.15     |
| mean 100 episode reward | 1.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0434   |
| steps                   | 329757   |
| td_erros                | 0.4039   |
--------------------------------------
Saving model due to running mean reward increase: 1.6732 -> 1.7311
--------------------------------------
| % time spent exploring  | 79       |
| episodes                | 40200    |
| lives                   | 40200    |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 8.43     |
| mean 100 episode reward | 1.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1311   |
| steps                   | 330500   |
| td_erros                | 0.4426   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 79       |
| episodes                | 40300    |
| lives                   | 40300    |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 8.82     |
| mean 100 episode reward | 1.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0805   |
| steps                   | 331282   |
| td_erros                | 0.4262   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 79       |
| episodes                | 40400    |
| lives                   | 40400    |
| mean 100 episode ei     | 4.42     |
| mean 100 episode length | 8.47     |
| mean 100 episode reward | 0.824    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0095   |
| steps                   | 332029   |
| td_erros                | 0.4019   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 79       |
| episodes                | 40500    |
| lives                   | 40500    |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 8.71     |
| mean 100 episode reward | 1.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0258   |
| steps                   | 332800   |
| td_erros                | 0.4086   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 79       |
| episodes                | 40600    |
| lives                   | 40600    |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 8.41     |
| mean 100 episode reward | 1.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0016   |
| steps                   | 333541   |
| td_erros                | 0.4      |
--------------------------------------
--------------------------------------
| % time spent exploring  | 79       |
| episodes                | 40700    |
| lives                   | 40700    |
| mean 100 episode ei     | 4.39     |
| mean 100 episode length | 8.75     |
| mean 100 episode reward | 1.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9493   |
| steps                   | 334316   |
| td_erros                | 0.3974   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 79       |
| episodes                | 40800    |
| lives                   | 40800    |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 8.29     |
| mean 100 episode reward | 1.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8122   |
| steps                   | 335045   |
| td_erros                | 0.3812   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 79       |
| episodes                | 40900    |
| lives                   | 40900    |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 8.87     |
| mean 100 episode reward | 1.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8524   |
| steps                   | 335832   |
| td_erros                | 0.3892   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 79       |
| episodes                | 41000    |
| lives                   | 41000    |
| mean 100 episode ei     | 4.36     |
| mean 100 episode length | 8.71     |
| mean 100 episode reward | 1.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7575   |
| steps                   | 336603   |
| td_erros                | 0.356    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 79       |
| episodes                | 41100    |
| lives                   | 41100    |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 7.99     |
| mean 100 episode reward | 1.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7796   |
| steps                   | 337302   |
| td_erros                | 0.3863   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 79       |
| episodes                | 41200    |
| lives                   | 41200    |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 8.62     |
| mean 100 episode reward | 1.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8114   |
| steps                   | 338064   |
| td_erros                | 0.3713   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 79       |
| episodes                | 41300    |
| lives                   | 41300    |
| mean 100 episode ei     | 4.43     |
| mean 100 episode length | 8.64     |
| mean 100 episode reward | 1.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.808    |
| steps                   | 338828   |
| td_erros                | 0.3477   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 41400    |
| lives                   | 41400    |
| mean 100 episode ei     | 4.47     |
| mean 100 episode length | 8.38     |
| mean 100 episode reward | 1.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7908   |
| steps                   | 339566   |
| td_erros                | 0.3373   |
--------------------------------------
Saving model due to mean reward increase: 1.7849 -> 1.9125
Saving model due to running mean reward increase: 1.6069 -> 1.9125
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 41500    |
| lives                   | 41500    |
| mean 100 episode ei     | 4.39     |
| mean 100 episode length | 8.39     |
| mean 100 episode reward | 1.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7366   |
| steps                   | 340305   |
| td_erros                | 0.3127   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 41600    |
| lives                   | 41600    |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 7.79     |
| mean 100 episode reward | 1.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7317   |
| steps                   | 340984   |
| td_erros                | 0.3228   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 41700    |
| lives                   | 41700    |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 8.19     |
| mean 100 episode reward | 1.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.771    |
| steps                   | 341703   |
| td_erros                | 0.3829   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 41800    |
| lives                   | 41800    |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 9.23     |
| mean 100 episode reward | 1.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7841   |
| steps                   | 342526   |
| td_erros                | 0.403    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 41900    |
| lives                   | 41900    |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 8.34     |
| mean 100 episode reward | 1.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8479   |
| steps                   | 343260   |
| td_erros                | 0.4158   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 42000    |
| lives                   | 42000    |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 8.31     |
| mean 100 episode reward | 1.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8867   |
| steps                   | 343991   |
| td_erros                | 0.459    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 42100    |
| lives                   | 42100    |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 8.57     |
| mean 100 episode reward | 1.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8932   |
| steps                   | 344748   |
| td_erros                | 0.4545   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 42200    |
| lives                   | 42200    |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 8.66     |
| mean 100 episode reward | 1.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9027   |
| steps                   | 345514   |
| td_erros                | 0.4438   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 42300    |
| lives                   | 42300    |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 7.67     |
| mean 100 episode reward | 1.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9014   |
| steps                   | 346181   |
| td_erros                | 0.3889   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 42400    |
| lives                   | 42400    |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 8.54     |
| mean 100 episode reward | 1.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9174   |
| steps                   | 346935   |
| td_erros                | 0.351    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 42500    |
| lives                   | 42500    |
| mean 100 episode ei     | 3.8      |
| mean 100 episode length | 7.68     |
| mean 100 episode reward | 1.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9339   |
| steps                   | 347603   |
| td_erros                | 0.3808   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 42600    |
| lives                   | 42600    |
| mean 100 episode ei     | 4.32     |
| mean 100 episode length | 8.45     |
| mean 100 episode reward | 1.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8783   |
| steps                   | 348348   |
| td_erros                | 0.3807   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 42700    |
| lives                   | 42700    |
| mean 100 episode ei     | 4.42     |
| mean 100 episode length | 8.53     |
| mean 100 episode reward | 0.986    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8397   |
| steps                   | 349101   |
| td_erros                | 0.3285   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 42800    |
| lives                   | 42800    |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 8.46     |
| mean 100 episode reward | 1.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.85     |
| steps                   | 349847   |
| td_erros                | 0.3232   |
--------------------------------------
Saving model due to running mean reward increase: 1.1982 -> 1.266
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 42900    |
| lives                   | 42900    |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 8.69     |
| mean 100 episode reward | 0.871    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8798   |
| steps                   | 350616   |
| td_erros                | 0.3453   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 43000    |
| lives                   | 43000    |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 8.83     |
| mean 100 episode reward | 1.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9419   |
| steps                   | 351399   |
| td_erros                | 0.3993   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 43100    |
| lives                   | 43100    |
| mean 100 episode ei     | 4.45     |
| mean 100 episode length | 8.56     |
| mean 100 episode reward | 1.99     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9504   |
| steps                   | 352155   |
| td_erros                | 0.3874   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 43200    |
| lives                   | 43200    |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 8.64     |
| mean 100 episode reward | 2.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8692   |
| steps                   | 352919   |
| td_erros                | 0.3522   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 43300    |
| lives                   | 43300    |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 8.08     |
| mean 100 episode reward | 1.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9159   |
| steps                   | 353627   |
| td_erros                | 0.3181   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 43400    |
| lives                   | 43400    |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 8.29     |
| mean 100 episode reward | 1.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9534   |
| steps                   | 354356   |
| td_erros                | 0.3468   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 78       |
| episodes                | 43500    |
| lives                   | 43500    |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 8.31     |
| mean 100 episode reward | 1.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9256   |
| steps                   | 355087   |
| td_erros                | 0.3647   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 77       |
| episodes                | 43600    |
| lives                   | 43600    |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 8.16     |
| mean 100 episode reward | 1.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9697   |
| steps                   | 355803   |
| td_erros                | 0.355    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 77       |
| episodes                | 43700    |
| lives                   | 43700    |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 8.89     |
| mean 100 episode reward | 1.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9179   |
| steps                   | 356592   |
| td_erros                | 0.3513   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 77       |
| episodes                | 43800    |
| lives                   | 43800    |
| mean 100 episode ei     | 4.46     |
| mean 100 episode length | 8.72     |
| mean 100 episode reward | 1.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9257   |
| steps                   | 357364   |
| td_erros                | 0.3102   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 77       |
| episodes                | 43900    |
| lives                   | 43900    |
| mean 100 episode ei     | 4.47     |
| mean 100 episode length | 8.35     |
| mean 100 episode reward | 1.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8284   |
| steps                   | 358099   |
| td_erros                | 0.2982   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 77       |
| episodes                | 44000    |
| lives                   | 44000    |
| mean 100 episode ei     | 4.51     |
| mean 100 episode length | 8.68     |
| mean 100 episode reward | 0.978    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7694   |
| steps                   | 358867   |
| td_erros                | 0.2548   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 77       |
| episodes                | 44100    |
| lives                   | 44100    |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 7.91     |
| mean 100 episode reward | 1.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7718   |
| steps                   | 359558   |
| td_erros                | 0.2726   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 77       |
| episodes                | 44200    |
| lives                   | 44200    |
| mean 100 episode ei     | 4.43     |
| mean 100 episode length | 8.46     |
| mean 100 episode reward | 1.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8709   |
| steps                   | 360304   |
| td_erros                | 0.3488   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 77       |
| episodes                | 44300    |
| lives                   | 44300    |
| mean 100 episode ei     | 4.46     |
| mean 100 episode length | 8.05     |
| mean 100 episode reward | 2.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9075   |
| steps                   | 361009   |
| td_erros                | 0.346    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 77       |
| episodes                | 44400    |
| lives                   | 44400    |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 7.58     |
| mean 100 episode reward | 1.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9074   |
| steps                   | 361667   |
| td_erros                | 0.3555   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 77       |
| episodes                | 44500    |
| lives                   | 44500    |
| mean 100 episode ei     | 4.24     |
| mean 100 episode length | 7.71     |
| mean 100 episode reward | 1.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9213   |
| steps                   | 362338   |
| td_erros                | 0.4213   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 77       |
| episodes                | 44600    |
| lives                   | 44600    |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 8.49     |
| mean 100 episode reward | 0.795    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9332   |
| steps                   | 363087   |
| td_erros                | 0.4283   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 77       |
| episodes                | 44700    |
| lives                   | 44700    |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 9.04     |
| mean 100 episode reward | 1.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8947   |
| steps                   | 363891   |
| td_erros                | 0.4195   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 77       |
| episodes                | 44800    |
| lives                   | 44800    |
| mean 100 episode ei     | 4.46     |
| mean 100 episode length | 8.97     |
| mean 100 episode reward | 1.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8687   |
| steps                   | 364688   |
| td_erros                | 0.369    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 77       |
| episodes                | 44900    |
| lives                   | 44900    |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 7.49     |
| mean 100 episode reward | 1.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8798   |
| steps                   | 365337   |
| td_erros                | 0.383    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 77       |
| episodes                | 45000    |
| lives                   | 45000    |
| mean 100 episode ei     | 3.7      |
| mean 100 episode length | 7.53     |
| mean 100 episode reward | 1.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9028   |
| steps                   | 365990   |
| td_erros                | 0.413    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 77       |
| episodes                | 45100    |
| lives                   | 45100    |
| mean 100 episode ei     | 4.77     |
| mean 100 episode length | 9.11     |
| mean 100 episode reward | 0.559    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8656   |
| steps                   | 366801   |
| td_erros                | 0.3909   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 77       |
| episodes                | 45200    |
| lives                   | 45200    |
| mean 100 episode ei     | 4.75     |
| mean 100 episode length | 9.57     |
| mean 100 episode reward | 1.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8375   |
| steps                   | 367658   |
| td_erros                | 0.3384   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 77       |
| episodes                | 45300    |
| lives                   | 45300    |
| mean 100 episode ei     | 4.23     |
| mean 100 episode length | 8.54     |
| mean 100 episode reward | 1.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.854    |
| steps                   | 368412   |
| td_erros                | 0.3521   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 77       |
| episodes                | 45400    |
| lives                   | 45400    |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 8.38     |
| mean 100 episode reward | 1.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8213   |
| steps                   | 369150   |
| td_erros                | 0.3644   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 77       |
| episodes                | 45500    |
| lives                   | 45500    |
| mean 100 episode ei     | 4.84     |
| mean 100 episode length | 9.48     |
| mean 100 episode reward | 1.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8728   |
| steps                   | 369998   |
| td_erros                | 0.3848   |
--------------------------------------
Saving model due to running mean reward increase: 1.122 -> 1.1642
--------------------------------------
| % time spent exploring  | 77       |
| episodes                | 45600    |
| lives                   | 45600    |
| mean 100 episode ei     | 5.04     |
| mean 100 episode length | 9.24     |
| mean 100 episode reward | 1.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8776   |
| steps                   | 370822   |
| td_erros                | 0.37     |
--------------------------------------
--------------------------------------
| % time spent exploring  | 77       |
| episodes                | 45700    |
| lives                   | 45700    |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 8.1      |
| mean 100 episode reward | 2.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8792   |
| steps                   | 371532   |
| td_erros                | 0.3225   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 45800    |
| lives                   | 45800    |
| mean 100 episode ei     | 4.33     |
| mean 100 episode length | 8.15     |
| mean 100 episode reward | 1.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0376   |
| steps                   | 372247   |
| td_erros                | 0.3842   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 45900    |
| lives                   | 45900    |
| mean 100 episode ei     | 4.59     |
| mean 100 episode length | 8.85     |
| mean 100 episode reward | 1.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0375   |
| steps                   | 373032   |
| td_erros                | 0.3748   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 46000    |
| lives                   | 46000    |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 8.51     |
| mean 100 episode reward | 1.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0345   |
| steps                   | 373783   |
| td_erros                | 0.3514   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 46100    |
| lives                   | 46100    |
| mean 100 episode ei     | 4.74     |
| mean 100 episode length | 8.72     |
| mean 100 episode reward | 1.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0109   |
| steps                   | 374555   |
| td_erros                | 0.3502   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 46200    |
| lives                   | 46200    |
| mean 100 episode ei     | 4.24     |
| mean 100 episode length | 8.42     |
| mean 100 episode reward | 1.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9188   |
| steps                   | 375297   |
| td_erros                | 0.3127   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 46300    |
| lives                   | 46300    |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 8.04     |
| mean 100 episode reward | 1.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9095   |
| steps                   | 376001   |
| td_erros                | 0.3564   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 46400    |
| lives                   | 46400    |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 8.51     |
| mean 100 episode reward | 1.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8552   |
| steps                   | 376752   |
| td_erros                | 0.3363   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 46500    |
| lives                   | 46500    |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 8.57     |
| mean 100 episode reward | 1.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8111   |
| steps                   | 377509   |
| td_erros                | 0.3582   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 46600    |
| lives                   | 46600    |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 8.79     |
| mean 100 episode reward | 1.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7318   |
| steps                   | 378288   |
| td_erros                | 0.3568   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 46700    |
| lives                   | 46700    |
| mean 100 episode ei     | 4.72     |
| mean 100 episode length | 9.16     |
| mean 100 episode reward | 1.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7292   |
| steps                   | 379104   |
| td_erros                | 0.3688   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 46800    |
| lives                   | 46800    |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 8.48     |
| mean 100 episode reward | 1.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7468   |
| steps                   | 379852   |
| td_erros                | 0.395    |
--------------------------------------
Saving model due to running mean reward increase: 1.1906 -> 1.4162
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 46900    |
| lives                   | 46900    |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 8.08     |
| mean 100 episode reward | 1.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8251   |
| steps                   | 380560   |
| td_erros                | 0.4192   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 47000    |
| lives                   | 47000    |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 8.39     |
| mean 100 episode reward | 2.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9019   |
| steps                   | 381299   |
| td_erros                | 0.446    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 47100    |
| lives                   | 47100    |
| mean 100 episode ei     | 5.1      |
| mean 100 episode length | 9.7      |
| mean 100 episode reward | 1.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9988   |
| steps                   | 382169   |
| td_erros                | 0.4541   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 47200    |
| lives                   | 47200    |
| mean 100 episode ei     | 4.76     |
| mean 100 episode length | 8.93     |
| mean 100 episode reward | 1.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9791   |
| steps                   | 382962   |
| td_erros                | 0.4209   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 47300    |
| lives                   | 47300    |
| mean 100 episode ei     | 4.47     |
| mean 100 episode length | 8.7      |
| mean 100 episode reward | 1.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0729   |
| steps                   | 383732   |
| td_erros                | 0.39     |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 47400    |
| lives                   | 47400    |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 8.42     |
| mean 100 episode reward | 1.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.1044   |
| steps                   | 384474   |
| td_erros                | 0.4065   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 47500    |
| lives                   | 47500    |
| mean 100 episode ei     | 4.43     |
| mean 100 episode length | 9.14     |
| mean 100 episode reward | 1.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0111   |
| steps                   | 385288   |
| td_erros                | 0.3596   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 47600    |
| lives                   | 47600    |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 8.4      |
| mean 100 episode reward | 1.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9731   |
| steps                   | 386028   |
| td_erros                | 0.3417   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 47700    |
| lives                   | 47700    |
| mean 100 episode ei     | 4.62     |
| mean 100 episode length | 8.58     |
| mean 100 episode reward | 1.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9242   |
| steps                   | 386786   |
| td_erros                | 0.3206   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 76       |
| episodes                | 47800    |
| lives                   | 47800    |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 7.58     |
| mean 100 episode reward | 1.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.938    |
| steps                   | 387444   |
| td_erros                | 0.3568   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 47900    |
| lives                   | 47900    |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 8.44     |
| mean 100 episode reward | 1.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.865    |
| steps                   | 388188   |
| td_erros                | 0.3644   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 48000    |
| lives                   | 48000    |
| mean 100 episode ei     | 4.49     |
| mean 100 episode length | 8.28     |
| mean 100 episode reward | 2.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8572   |
| steps                   | 388916   |
| td_erros                | 0.3702   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 48100    |
| lives                   | 48100    |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 7.84     |
| mean 100 episode reward | 1.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8811   |
| steps                   | 389600   |
| td_erros                | 0.4326   |
--------------------------------------
Saving model due to mean reward increase: 1.9125 -> 1.9431
Saving model due to running mean reward increase: 1.7579 -> 1.9431
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 48200    |
| lives                   | 48200    |
| mean 100 episode ei     | 4.93     |
| mean 100 episode length | 9.26     |
| mean 100 episode reward | 1.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8625   |
| steps                   | 390426   |
| td_erros                | 0.4245   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 48300    |
| lives                   | 48300    |
| mean 100 episode ei     | 4.8      |
| mean 100 episode length | 8.63     |
| mean 100 episode reward | 1.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8852   |
| steps                   | 391189   |
| td_erros                | 0.3953   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 48400    |
| lives                   | 48400    |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 7.9      |
| mean 100 episode reward | 1.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8902   |
| steps                   | 391879   |
| td_erros                | 0.3924   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 48500    |
| lives                   | 48500    |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 8.71     |
| mean 100 episode reward | 1.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8812   |
| steps                   | 392650   |
| td_erros                | 0.3686   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 48600    |
| lives                   | 48600    |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 7.95     |
| mean 100 episode reward | 1.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9565   |
| steps                   | 393345   |
| td_erros                | 0.4149   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 48700    |
| lives                   | 48700    |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 8.73     |
| mean 100 episode reward | 2        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9522   |
| steps                   | 394118   |
| td_erros                | 0.4111   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 48800    |
| lives                   | 48800    |
| mean 100 episode ei     | 4.72     |
| mean 100 episode length | 8.95     |
| mean 100 episode reward | 1.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9313   |
| steps                   | 394913   |
| td_erros                | 0.33     |
--------------------------------------
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 48900    |
| lives                   | 48900    |
| mean 100 episode ei     | 4.87     |
| mean 100 episode length | 9.18     |
| mean 100 episode reward | 1.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8349   |
| steps                   | 395731   |
| td_erros                | 0.2981   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 49000    |
| lives                   | 49000    |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 7.61     |
| mean 100 episode reward | 1.96     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7187   |
| steps                   | 396392   |
| td_erros                | 0.2228   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 49100    |
| lives                   | 49100    |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 8.44     |
| mean 100 episode reward | 2.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6947   |
| steps                   | 397136   |
| td_erros                | 0.2482   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 49200    |
| lives                   | 49200    |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 8.56     |
| mean 100 episode reward | 1.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.642    |
| steps                   | 397892   |
| td_erros                | 0.2222   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 49300    |
| lives                   | 49300    |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 9.11     |
| mean 100 episode reward | 1.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6306   |
| steps                   | 398703   |
| td_erros                | 0.2082   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 49400    |
| lives                   | 49400    |
| mean 100 episode ei     | 4.74     |
| mean 100 episode length | 8.52     |
| mean 100 episode reward | 1.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7203   |
| steps                   | 399455   |
| td_erros                | 0.2362   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 49500    |
| lives                   | 49500    |
| mean 100 episode ei     | 4.32     |
| mean 100 episode length | 8.42     |
| mean 100 episode reward | 1.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6877   |
| steps                   | 400197   |
| td_erros                | 0.2481   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 49600    |
| lives                   | 49600    |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 8.22     |
| mean 100 episode reward | 1.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7574   |
| steps                   | 400919   |
| td_erros                | 0.3108   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 49700    |
| lives                   | 49700    |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 8.74     |
| mean 100 episode reward | 1.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7707   |
| steps                   | 401693   |
| td_erros                | 0.336    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 49800    |
| lives                   | 49800    |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 8.16     |
| mean 100 episode reward | 1.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7175   |
| steps                   | 402409   |
| td_erros                | 0.2828   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 49900    |
| lives                   | 49900    |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 8.37     |
| mean 100 episode reward | 1.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8097   |
| steps                   | 403146   |
| td_erros                | 0.33     |
--------------------------------------
--------------------------------------
| % time spent exploring  | 75       |
| episodes                | 50000    |
| lives                   | 50000    |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 7.6      |
| mean 100 episode reward | 1.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8561   |
| steps                   | 403806   |
| td_erros                | 0.3853   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 50100    |
| lives                   | 50100    |
| mean 100 episode ei     | 4.46     |
| mean 100 episode length | 8.78     |
| mean 100 episode reward | 1.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7704   |
| steps                   | 404584   |
| td_erros                | 0.3758   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 50200    |
| lives                   | 50200    |
| mean 100 episode ei     | 4.49     |
| mean 100 episode length | 8.74     |
| mean 100 episode reward | 1.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7371   |
| steps                   | 405358   |
| td_erros                | 0.3664   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 50300    |
| lives                   | 50300    |
| mean 100 episode ei     | 4.46     |
| mean 100 episode length | 8.95     |
| mean 100 episode reward | 1.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7472   |
| steps                   | 406153   |
| td_erros                | 0.3799   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 50400    |
| lives                   | 50400    |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 8.78     |
| mean 100 episode reward | 1.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7261   |
| steps                   | 406931   |
| td_erros                | 0.3907   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 50500    |
| lives                   | 50500    |
| mean 100 episode ei     | 4.4      |
| mean 100 episode length | 8.19     |
| mean 100 episode reward | 2.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7413   |
| steps                   | 407650   |
| td_erros                | 0.4104   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 50600    |
| lives                   | 50600    |
| mean 100 episode ei     | 4.9      |
| mean 100 episode length | 8.73     |
| mean 100 episode reward | 1.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.805    |
| steps                   | 408423   |
| td_erros                | 0.3955   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 50700    |
| lives                   | 50700    |
| mean 100 episode ei     | 4.76     |
| mean 100 episode length | 8.44     |
| mean 100 episode reward | 1.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8999   |
| steps                   | 409167   |
| td_erros                | 0.4112   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 50800    |
| lives                   | 50800    |
| mean 100 episode ei     | 3.71     |
| mean 100 episode length | 7.41     |
| mean 100 episode reward | 1.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0034   |
| steps                   | 409808   |
| td_erros                | 0.4672   |
--------------------------------------
Saving model due to running mean reward increase: 1.5332 -> 1.767
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 50900    |
| lives                   | 50900    |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 7.45     |
| mean 100 episode reward | 1.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0571   |
| steps                   | 410453   |
| td_erros                | 0.5318   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 51000    |
| lives                   | 51000    |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 9.01     |
| mean 100 episode reward | 1.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0523   |
| steps                   | 411254   |
| td_erros                | 0.5227   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 51100    |
| lives                   | 51100    |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 7.84     |
| mean 100 episode reward | 2.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.0907   |
| steps                   | 411938   |
| td_erros                | 0.4813   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 51200    |
| lives                   | 51200    |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 8.22     |
| mean 100 episode reward | 1.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.063    |
| steps                   | 412660   |
| td_erros                | 0.4635   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 51300    |
| lives                   | 51300    |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 8.05     |
| mean 100 episode reward | 1.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 4.013    |
| steps                   | 413365   |
| td_erros                | 0.4873   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 51400    |
| lives                   | 51400    |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 8.12     |
| mean 100 episode reward | 1.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9074   |
| steps                   | 414077   |
| td_erros                | 0.4714   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 51500    |
| lives                   | 51500    |
| mean 100 episode ei     | 4.23     |
| mean 100 episode length | 8.29     |
| mean 100 episode reward | 1.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8661   |
| steps                   | 414806   |
| td_erros                | 0.4319   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 51600    |
| lives                   | 51600    |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 8.76     |
| mean 100 episode reward | 1.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7985   |
| steps                   | 415582   |
| td_erros                | 0.3942   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 51700    |
| lives                   | 51700    |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 8.37     |
| mean 100 episode reward | 1.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7835   |
| steps                   | 416319   |
| td_erros                | 0.4151   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 51800    |
| lives                   | 51800    |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 7.58     |
| mean 100 episode reward | 2.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7879   |
| steps                   | 416977   |
| td_erros                | 0.3943   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 51900    |
| lives                   | 51900    |
| mean 100 episode ei     | 4.32     |
| mean 100 episode length | 8.19     |
| mean 100 episode reward | 1.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7784   |
| steps                   | 417696   |
| td_erros                | 0.406    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 52000    |
| lives                   | 52000    |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 8.54     |
| mean 100 episode reward | 2.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7214   |
| steps                   | 418450   |
| td_erros                | 0.3775   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 52100    |
| lives                   | 52100    |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 7.99     |
| mean 100 episode reward | 2.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6852   |
| steps                   | 419149   |
| td_erros                | 0.3512   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 74       |
| episodes                | 52200    |
| lives                   | 52200    |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 8.54     |
| mean 100 episode reward | 0.965    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6201   |
| steps                   | 419903   |
| td_erros                | 0.3219   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 52300    |
| lives                   | 52300    |
| mean 100 episode ei     | 4.48     |
| mean 100 episode length | 8.21     |
| mean 100 episode reward | 1.99     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5695   |
| steps                   | 420624   |
| td_erros                | 0.2656   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 52400    |
| lives                   | 52400    |
| mean 100 episode ei     | 4.71     |
| mean 100 episode length | 8.42     |
| mean 100 episode reward | 2.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5454   |
| steps                   | 421366   |
| td_erros                | 0.2313   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 52500    |
| lives                   | 52500    |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 8.29     |
| mean 100 episode reward | 1.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4974   |
| steps                   | 422095   |
| td_erros                | 0.2244   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 52600    |
| lives                   | 52600    |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 8.06     |
| mean 100 episode reward | 2.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4748   |
| steps                   | 422801   |
| td_erros                | 0.2304   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 52700    |
| lives                   | 52700    |
| mean 100 episode ei     | 4.32     |
| mean 100 episode length | 7.82     |
| mean 100 episode reward | 2.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4978   |
| steps                   | 423483   |
| td_erros                | 0.2682   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 52800    |
| lives                   | 52800    |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 7.87     |
| mean 100 episode reward | 1.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5392   |
| steps                   | 424170   |
| td_erros                | 0.2655   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 52900    |
| lives                   | 52900    |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 7.72     |
| mean 100 episode reward | 2.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5146   |
| steps                   | 424842   |
| td_erros                | 0.2564   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 53000    |
| lives                   | 53000    |
| mean 100 episode ei     | 4.4      |
| mean 100 episode length | 8.3      |
| mean 100 episode reward | 2.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5367   |
| steps                   | 425572   |
| td_erros                | 0.2607   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 53100    |
| lives                   | 53100    |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 8.22     |
| mean 100 episode reward | 2.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4747   |
| steps                   | 426294   |
| td_erros                | 0.2535   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 53200    |
| lives                   | 53200    |
| mean 100 episode ei     | 4.48     |
| mean 100 episode length | 8.34     |
| mean 100 episode reward | 1.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4426   |
| steps                   | 427028   |
| td_erros                | 0.2412   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 53300    |
| lives                   | 53300    |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 8.29     |
| mean 100 episode reward | 1.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5237   |
| steps                   | 427757   |
| td_erros                | 0.2579   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 53400    |
| lives                   | 53400    |
| mean 100 episode ei     | 4.46     |
| mean 100 episode length | 8.5      |
| mean 100 episode reward | 0.814    |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.527    |
| steps                   | 428507   |
| td_erros                | 0.2584   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 53500    |
| lives                   | 53500    |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 9.02     |
| mean 100 episode reward | 1.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.573    |
| steps                   | 429309   |
| td_erros                | 0.2658   |
--------------------------------------
Saving model due to running mean reward increase: 1.0597 -> 1.452
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 53600    |
| lives                   | 53600    |
| mean 100 episode ei     | 4.39     |
| mean 100 episode length | 8.83     |
| mean 100 episode reward | 1.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5524   |
| steps                   | 430092   |
| td_erros                | 0.24     |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 53700    |
| lives                   | 53700    |
| mean 100 episode ei     | 4.41     |
| mean 100 episode length | 8.11     |
| mean 100 episode reward | 2.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6624   |
| steps                   | 430803   |
| td_erros                | 0.2872   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 53800    |
| lives                   | 53800    |
| mean 100 episode ei     | 4.89     |
| mean 100 episode length | 8.68     |
| mean 100 episode reward | 2.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.748    |
| steps                   | 431571   |
| td_erros                | 0.2975   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 53900    |
| lives                   | 53900    |
| mean 100 episode ei     | 4.41     |
| mean 100 episode length | 8.18     |
| mean 100 episode reward | 2.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7976   |
| steps                   | 432289   |
| td_erros                | 0.3239   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 54000    |
| lives                   | 54000    |
| mean 100 episode ei     | 4.51     |
| mean 100 episode length | 8.45     |
| mean 100 episode reward | 1.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8161   |
| steps                   | 433034   |
| td_erros                | 0.3379   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 54100    |
| lives                   | 54100    |
| mean 100 episode ei     | 4.21     |
| mean 100 episode length | 8.33     |
| mean 100 episode reward | 1.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9236   |
| steps                   | 433767   |
| td_erros                | 0.3883   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 54200    |
| lives                   | 54200    |
| mean 100 episode ei     | 4.48     |
| mean 100 episode length | 8.25     |
| mean 100 episode reward | 1.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9811   |
| steps                   | 434492   |
| td_erros                | 0.4522   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 54300    |
| lives                   | 54300    |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 8.08     |
| mean 100 episode reward | 1.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9978   |
| steps                   | 435200   |
| td_erros                | 0.4898   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 73       |
| episodes                | 54400    |
| lives                   | 54400    |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 8.71     |
| mean 100 episode reward | 2.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9259   |
| steps                   | 435971   |
| td_erros                | 0.4292   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 54500    |
| lives                   | 54500    |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 8.45     |
| mean 100 episode reward | 1.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8588   |
| steps                   | 436716   |
| td_erros                | 0.4215   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 54600    |
| lives                   | 54600    |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 8.48     |
| mean 100 episode reward | 2.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7671   |
| steps                   | 437464   |
| td_erros                | 0.401    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 54700    |
| lives                   | 54700    |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 8.2      |
| mean 100 episode reward | 1.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7281   |
| steps                   | 438184   |
| td_erros                | 0.3547   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 54800    |
| lives                   | 54800    |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 7.42     |
| mean 100 episode reward | 1.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7396   |
| steps                   | 438826   |
| td_erros                | 0.3657   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 54900    |
| lives                   | 54900    |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 7.99     |
| mean 100 episode reward | 2.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7463   |
| steps                   | 439525   |
| td_erros                | 0.3887   |
--------------------------------------
Saving model due to running mean reward increase: 1.7505 -> 1.9129
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 55000    |
| lives                   | 55000    |
| mean 100 episode ei     | 4.47     |
| mean 100 episode length | 8.62     |
| mean 100 episode reward | 1.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6904   |
| steps                   | 440287   |
| td_erros                | 0.3706   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 55100    |
| lives                   | 55100    |
| mean 100 episode ei     | 4.24     |
| mean 100 episode length | 8.1      |
| mean 100 episode reward | 1.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.664    |
| steps                   | 440997   |
| td_erros                | 0.3646   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 55200    |
| lives                   | 55200    |
| mean 100 episode ei     | 5.12     |
| mean 100 episode length | 9.55     |
| mean 100 episode reward | 1.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6616   |
| steps                   | 441852   |
| td_erros                | 0.3608   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 55300    |
| lives                   | 55300    |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 8        |
| mean 100 episode reward | 1.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7306   |
| steps                   | 442552   |
| td_erros                | 0.3674   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 55400    |
| lives                   | 55400    |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 7.89     |
| mean 100 episode reward | 1.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8585   |
| steps                   | 443241   |
| td_erros                | 0.4777   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 55500    |
| lives                   | 55500    |
| mean 100 episode ei     | 4.48     |
| mean 100 episode length | 8.18     |
| mean 100 episode reward | 1.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8899   |
| steps                   | 443959   |
| td_erros                | 0.4831   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 55600    |
| lives                   | 55600    |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 7.38     |
| mean 100 episode reward | 2        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.844    |
| steps                   | 444597   |
| td_erros                | 0.4697   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 55700    |
| lives                   | 55700    |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 7.78     |
| mean 100 episode reward | 1.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8007   |
| steps                   | 445275   |
| td_erros                | 0.4609   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 55800    |
| lives                   | 55800    |
| mean 100 episode ei     | 4.77     |
| mean 100 episode length | 8.48     |
| mean 100 episode reward | 1.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8759   |
| steps                   | 446023   |
| td_erros                | 0.4733   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 55900    |
| lives                   | 55900    |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 7.73     |
| mean 100 episode reward | 1.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9188   |
| steps                   | 446696   |
| td_erros                | 0.5093   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 56000    |
| lives                   | 56000    |
| mean 100 episode ei     | 4.42     |
| mean 100 episode length | 8.57     |
| mean 100 episode reward | 1.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8692   |
| steps                   | 447453   |
| td_erros                | 0.5156   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 56100    |
| lives                   | 56100    |
| mean 100 episode ei     | 4.52     |
| mean 100 episode length | 8.91     |
| mean 100 episode reward | 1.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7869   |
| steps                   | 448244   |
| td_erros                | 0.4479   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 56200    |
| lives                   | 56200    |
| mean 100 episode ei     | 4.93     |
| mean 100 episode length | 8.24     |
| mean 100 episode reward | 2.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7642   |
| steps                   | 448968   |
| td_erros                | 0.4056   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 56300    |
| lives                   | 56300    |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 7.32     |
| mean 100 episode reward | 2.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7597   |
| steps                   | 449600   |
| td_erros                | 0.3838   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 56400    |
| lives                   | 56400    |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 8.31     |
| mean 100 episode reward | 1.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7463   |
| steps                   | 450331   |
| td_erros                | 0.3794   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 56500    |
| lives                   | 56500    |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 7.63     |
| mean 100 episode reward | 1.69     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7655   |
| steps                   | 450994   |
| td_erros                | 0.3971   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 56600    |
| lives                   | 56600    |
| mean 100 episode ei     | 3.6      |
| mean 100 episode length | 7.27     |
| mean 100 episode reward | 1.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7505   |
| steps                   | 451621   |
| td_erros                | 0.412    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 72       |
| episodes                | 56700    |
| lives                   | 56700    |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 8.38     |
| mean 100 episode reward | 1.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7417   |
| steps                   | 452359   |
| td_erros                | 0.4058   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 56800    |
| lives                   | 56800    |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 7.71     |
| mean 100 episode reward | 2.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7786   |
| steps                   | 453030   |
| td_erros                | 0.4427   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 56900    |
| lives                   | 56900    |
| mean 100 episode ei     | 4.32     |
| mean 100 episode length | 8.22     |
| mean 100 episode reward | 1.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8608   |
| steps                   | 453752   |
| td_erros                | 0.4947   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 57000    |
| lives                   | 57000    |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 7.93     |
| mean 100 episode reward | 2.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8217   |
| steps                   | 454445   |
| td_erros                | 0.5126   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 57100    |
| lives                   | 57100    |
| mean 100 episode ei     | 4.32     |
| mean 100 episode length | 8.08     |
| mean 100 episode reward | 1.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8548   |
| steps                   | 455153   |
| td_erros                | 0.5067   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 57200    |
| lives                   | 57200    |
| mean 100 episode ei     | 4.41     |
| mean 100 episode length | 8.41     |
| mean 100 episode reward | 1.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8566   |
| steps                   | 455894   |
| td_erros                | 0.5232   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 57300    |
| lives                   | 57300    |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 7.91     |
| mean 100 episode reward | 2.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8444   |
| steps                   | 456585   |
| td_erros                | 0.4706   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 57400    |
| lives                   | 57400    |
| mean 100 episode ei     | 4.43     |
| mean 100 episode length | 8.76     |
| mean 100 episode reward | 1.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8526   |
| steps                   | 457361   |
| td_erros                | 0.4512   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 57500    |
| lives                   | 57500    |
| mean 100 episode ei     | 4.45     |
| mean 100 episode length | 8.11     |
| mean 100 episode reward | 1.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8154   |
| steps                   | 458072   |
| td_erros                | 0.3829   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 57600    |
| lives                   | 57600    |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 8.3      |
| mean 100 episode reward | 1.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8703   |
| steps                   | 458802   |
| td_erros                | 0.3902   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 57700    |
| lives                   | 57700    |
| mean 100 episode ei     | 4.33     |
| mean 100 episode length | 7.78     |
| mean 100 episode reward | 1.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9325   |
| steps                   | 459480   |
| td_erros                | 0.411    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 57800    |
| lives                   | 57800    |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 8.01     |
| mean 100 episode reward | 1.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9982   |
| steps                   | 460181   |
| td_erros                | 0.4226   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 57900    |
| lives                   | 57900    |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 8.22     |
| mean 100 episode reward | 1.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.9338   |
| steps                   | 460903   |
| td_erros                | 0.4445   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 58000    |
| lives                   | 58000    |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 9.03     |
| mean 100 episode reward | 1.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.807    |
| steps                   | 461706   |
| td_erros                | 0.4043   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 58100    |
| lives                   | 58100    |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 8.06     |
| mean 100 episode reward | 1.96     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7482   |
| steps                   | 462412   |
| td_erros                | 0.3462   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 58200    |
| lives                   | 58200    |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 8.01     |
| mean 100 episode reward | 2.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7242   |
| steps                   | 463113   |
| td_erros                | 0.3579   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 58300    |
| lives                   | 58300    |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 7.85     |
| mean 100 episode reward | 1.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7813   |
| steps                   | 463798   |
| td_erros                | 0.3912   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 58400    |
| lives                   | 58400    |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 7.9      |
| mean 100 episode reward | 1.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6993   |
| steps                   | 464488   |
| td_erros                | 0.3543   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 58500    |
| lives                   | 58500    |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 7.33     |
| mean 100 episode reward | 2.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.703    |
| steps                   | 465121   |
| td_erros                | 0.3513   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 58600    |
| lives                   | 58600    |
| mean 100 episode ei     | 4.21     |
| mean 100 episode length | 8.12     |
| mean 100 episode reward | 2.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6369   |
| steps                   | 465833   |
| td_erros                | 0.3183   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 58700    |
| lives                   | 58700    |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 7.82     |
| mean 100 episode reward | 1.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5508   |
| steps                   | 466515   |
| td_erros                | 0.3211   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 58800    |
| lives                   | 58800    |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 8.17     |
| mean 100 episode reward | 1.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5206   |
| steps                   | 467232   |
| td_erros                | 0.3418   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 71       |
| episodes                | 58900    |
| lives                   | 58900    |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 8.62     |
| mean 100 episode reward | 1.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4663   |
| steps                   | 467994   |
| td_erros                | 0.2996   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 59000    |
| lives                   | 59000    |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 8.06     |
| mean 100 episode reward | 1.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4405   |
| steps                   | 468700   |
| td_erros                | 0.2923   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 59100    |
| lives                   | 59100    |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 8.28     |
| mean 100 episode reward | 1.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4978   |
| steps                   | 469428   |
| td_erros                | 0.3108   |
--------------------------------------
Saving model due to running mean reward increase: 1.6834 -> 1.718
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 59200    |
| lives                   | 59200    |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 7.92     |
| mean 100 episode reward | 1.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4875   |
| steps                   | 470120   |
| td_erros                | 0.2864   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 59300    |
| lives                   | 59300    |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 7.63     |
| mean 100 episode reward | 1.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4979   |
| steps                   | 470783   |
| td_erros                | 0.2918   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 59400    |
| lives                   | 59400    |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 8.15     |
| mean 100 episode reward | 1.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4848   |
| steps                   | 471498   |
| td_erros                | 0.2583   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 59500    |
| lives                   | 59500    |
| mean 100 episode ei     | 4.39     |
| mean 100 episode length | 8.47     |
| mean 100 episode reward | 1.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.516    |
| steps                   | 472245   |
| td_erros                | 0.2542   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 59600    |
| lives                   | 59600    |
| mean 100 episode ei     | 4.48     |
| mean 100 episode length | 8.38     |
| mean 100 episode reward | 2.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5499   |
| steps                   | 472983   |
| td_erros                | 0.2723   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 59700    |
| lives                   | 59700    |
| mean 100 episode ei     | 4.35     |
| mean 100 episode length | 7.99     |
| mean 100 episode reward | 2.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5931   |
| steps                   | 473682   |
| td_erros                | 0.2741   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 59800    |
| lives                   | 59800    |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 8.01     |
| mean 100 episode reward | 1.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6504   |
| steps                   | 474383   |
| td_erros                | 0.3074   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 59900    |
| lives                   | 59900    |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 7.66     |
| mean 100 episode reward | 1.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6722   |
| steps                   | 475049   |
| td_erros                | 0.3294   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 60000    |
| lives                   | 60000    |
| mean 100 episode ei     | 4.45     |
| mean 100 episode length | 8.22     |
| mean 100 episode reward | 1.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7169   |
| steps                   | 475771   |
| td_erros                | 0.3744   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 60100    |
| lives                   | 60100    |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 8.32     |
| mean 100 episode reward | 1.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6781   |
| steps                   | 476503   |
| td_erros                | 0.3324   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 60200    |
| lives                   | 60200    |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 7.5      |
| mean 100 episode reward | 1.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7688   |
| steps                   | 477153   |
| td_erros                | 0.3659   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 60300    |
| lives                   | 60300    |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 7.35     |
| mean 100 episode reward | 2.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.8324   |
| steps                   | 477788   |
| td_erros                | 0.3816   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 60400    |
| lives                   | 60400    |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 7.93     |
| mean 100 episode reward | 2.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.85     |
| steps                   | 478481   |
| td_erros                | 0.411    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 60500    |
| lives                   | 60500    |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 7.37     |
| mean 100 episode reward | 2.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.82     |
| steps                   | 479118   |
| td_erros                | 0.4043   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 60600    |
| lives                   | 60600    |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 8.35     |
| mean 100 episode reward | 1.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.7073   |
| steps                   | 479853   |
| td_erros                | 0.3805   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 60700    |
| lives                   | 60700    |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 8.21     |
| mean 100 episode reward | 1.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6076   |
| steps                   | 480574   |
| td_erros                | 0.3505   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 60800    |
| lives                   | 60800    |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 7.88     |
| mean 100 episode reward | 1.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.528    |
| steps                   | 481262   |
| td_erros                | 0.3609   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 60900    |
| lives                   | 60900    |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 7.68     |
| mean 100 episode reward | 1.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5011   |
| steps                   | 481930   |
| td_erros                | 0.3706   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 61000    |
| lives                   | 61000    |
| mean 100 episode ei     | 4.39     |
| mean 100 episode length | 8.54     |
| mean 100 episode reward | 1.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3964   |
| steps                   | 482684   |
| td_erros                | 0.3362   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 61100    |
| lives                   | 61100    |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 7.97     |
| mean 100 episode reward | 1.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3971   |
| steps                   | 483381   |
| td_erros                | 0.3023   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 61200    |
| lives                   | 61200    |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 7.54     |
| mean 100 episode reward | 1.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3507   |
| steps                   | 484035   |
| td_erros                | 0.298    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 70       |
| episodes                | 61300    |
| lives                   | 61300    |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 7.86     |
| mean 100 episode reward | 2.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3191   |
| steps                   | 484721   |
| td_erros                | 0.2794   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 61400    |
| lives                   | 61400    |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 7.48     |
| mean 100 episode reward | 1.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3361   |
| steps                   | 485369   |
| td_erros                | 0.2807   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 61500    |
| lives                   | 61500    |
| mean 100 episode ei     | 4.21     |
| mean 100 episode length | 8.07     |
| mean 100 episode reward | 1.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3314   |
| steps                   | 486076   |
| td_erros                | 0.2783   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 61600    |
| lives                   | 61600    |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 8.24     |
| mean 100 episode reward | 1.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2908   |
| steps                   | 486800   |
| td_erros                | 0.2528   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 61700    |
| lives                   | 61700    |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 7.41     |
| mean 100 episode reward | 2.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2987   |
| steps                   | 487441   |
| td_erros                | 0.2619   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 61800    |
| lives                   | 61800    |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 7.61     |
| mean 100 episode reward | 1.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3437   |
| steps                   | 488102   |
| td_erros                | 0.284    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 61900    |
| lives                   | 61900    |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 7.72     |
| mean 100 episode reward | 1.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3384   |
| steps                   | 488774   |
| td_erros                | 0.2697   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 62000    |
| lives                   | 62000    |
| mean 100 episode ei     | 5.06     |
| mean 100 episode length | 8.78     |
| mean 100 episode reward | 2.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3163   |
| steps                   | 489552   |
| td_erros                | 0.2199   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 62100    |
| lives                   | 62100    |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 7.74     |
| mean 100 episode reward | 1.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3322   |
| steps                   | 490226   |
| td_erros                | 0.2037   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 62200    |
| lives                   | 62200    |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 7.22     |
| mean 100 episode reward | 2.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3696   |
| steps                   | 490848   |
| td_erros                | 0.2186   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 62300    |
| lives                   | 62300    |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 7.86     |
| mean 100 episode reward | 1.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3981   |
| steps                   | 491534   |
| td_erros                | 0.2221   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 62400    |
| lives                   | 62400    |
| mean 100 episode ei     | 4.52     |
| mean 100 episode length | 8.02     |
| mean 100 episode reward | 1.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3454   |
| steps                   | 492236   |
| td_erros                | 0.1811   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 62500    |
| lives                   | 62500    |
| mean 100 episode ei     | 4.41     |
| mean 100 episode length | 8.06     |
| mean 100 episode reward | 1.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3601   |
| steps                   | 492942   |
| td_erros                | 0.203    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 62600    |
| lives                   | 62600    |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 7.64     |
| mean 100 episode reward | 1.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3827   |
| steps                   | 493606   |
| td_erros                | 0.2053   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 62700    |
| lives                   | 62700    |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 7.28     |
| mean 100 episode reward | 2.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3787   |
| steps                   | 494234   |
| td_erros                | 0.2242   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 62800    |
| lives                   | 62800    |
| mean 100 episode ei     | 4.69     |
| mean 100 episode length | 8.84     |
| mean 100 episode reward | 1.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4172   |
| steps                   | 495018   |
| td_erros                | 0.2006   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 62900    |
| lives                   | 62900    |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 8.06     |
| mean 100 episode reward | 1.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.474    |
| steps                   | 495724   |
| td_erros                | 0.2424   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 63000    |
| lives                   | 63000    |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 8.31     |
| mean 100 episode reward | 1.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4342   |
| steps                   | 496455   |
| td_erros                | 0.1793   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 63100    |
| lives                   | 63100    |
| mean 100 episode ei     | 4.21     |
| mean 100 episode length | 8.44     |
| mean 100 episode reward | 1.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3782   |
| steps                   | 497199   |
| td_erros                | 0.1839   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 63200    |
| lives                   | 63200    |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 8.6      |
| mean 100 episode reward | 2        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.335    |
| steps                   | 497959   |
| td_erros                | 0.1648   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 63300    |
| lives                   | 63300    |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 7.69     |
| mean 100 episode reward | 1.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3811   |
| steps                   | 498628   |
| td_erros                | 0.1968   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 63400    |
| lives                   | 63400    |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 7.88     |
| mean 100 episode reward | 2.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3536   |
| steps                   | 499316   |
| td_erros                | 0.2099   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 63500    |
| lives                   | 63500    |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 7.69     |
| mean 100 episode reward | 2.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3546   |
| steps                   | 499985   |
| td_erros                | 0.2284   |
--------------------------------------
Saving model due to mean reward increase: 1.9431 -> 2.2663
--------------------------------------
| % time spent exploring  | 69       |
| episodes                | 63600    |
| lives                   | 63600    |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 7.29     |
| mean 100 episode reward | 2.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3429   |
| steps                   | 500614   |
| td_erros                | 0.2367   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 63700    |
| lives                   | 63700    |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 7.85     |
| mean 100 episode reward | 2.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3473   |
| steps                   | 501299   |
| td_erros                | 0.2279   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 63800    |
| lives                   | 63800    |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 7.55     |
| mean 100 episode reward | 1.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3779   |
| steps                   | 501954   |
| td_erros                | 0.2292   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 63900    |
| lives                   | 63900    |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 8.07     |
| mean 100 episode reward | 1.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3223   |
| steps                   | 502661   |
| td_erros                | 0.196    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 64000    |
| lives                   | 64000    |
| mean 100 episode ei     | 4.42     |
| mean 100 episode length | 8.21     |
| mean 100 episode reward | 1.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3306   |
| steps                   | 503382   |
| td_erros                | 0.1839   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 64100    |
| lives                   | 64100    |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 7.39     |
| mean 100 episode reward | 2.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3185   |
| steps                   | 504021   |
| td_erros                | 0.1631   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 64200    |
| lives                   | 64200    |
| mean 100 episode ei     | 3.64     |
| mean 100 episode length | 7.07     |
| mean 100 episode reward | 1.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3053   |
| steps                   | 504628   |
| td_erros                | 0.1727   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 64300    |
| lives                   | 64300    |
| mean 100 episode ei     | 4.47     |
| mean 100 episode length | 8.17     |
| mean 100 episode reward | 2.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3064   |
| steps                   | 505345   |
| td_erros                | 0.1788   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 64400    |
| lives                   | 64400    |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 8.81     |
| mean 100 episode reward | 1.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.246    |
| steps                   | 506126   |
| td_erros                | 0.1368   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 64500    |
| lives                   | 64500    |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 7.49     |
| mean 100 episode reward | 2.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2659   |
| steps                   | 506775   |
| td_erros                | 0.1441   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 64600    |
| lives                   | 64600    |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 7.8      |
| mean 100 episode reward | 2.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2545   |
| steps                   | 507455   |
| td_erros                | 0.1837   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 64700    |
| lives                   | 64700    |
| mean 100 episode ei     | 3.69     |
| mean 100 episode length | 7        |
| mean 100 episode reward | 2.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2788   |
| steps                   | 508055   |
| td_erros                | 0.2199   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 64800    |
| lives                   | 64800    |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 7.84     |
| mean 100 episode reward | 1.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2346   |
| steps                   | 508739   |
| td_erros                | 0.2607   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 64900    |
| lives                   | 64900    |
| mean 100 episode ei     | 4.83     |
| mean 100 episode length | 8.14     |
| mean 100 episode reward | 1.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2104   |
| steps                   | 509453   |
| td_erros                | 0.2464   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 65000    |
| lives                   | 65000    |
| mean 100 episode ei     | 4.32     |
| mean 100 episode length | 7.85     |
| mean 100 episode reward | 1.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2017   |
| steps                   | 510138   |
| td_erros                | 0.2316   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 65100    |
| lives                   | 65100    |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 8.47     |
| mean 100 episode reward | 2.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3049   |
| steps                   | 510885   |
| td_erros                | 0.2765   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 65200    |
| lives                   | 65200    |
| mean 100 episode ei     | 4.42     |
| mean 100 episode length | 8.76     |
| mean 100 episode reward | 2.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4476   |
| steps                   | 511661   |
| td_erros                | 0.339    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 65300    |
| lives                   | 65300    |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 8.33     |
| mean 100 episode reward | 1.57     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4962   |
| steps                   | 512394   |
| td_erros                | 0.3489   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 65400    |
| lives                   | 65400    |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 8.36     |
| mean 100 episode reward | 1.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4937   |
| steps                   | 513130   |
| td_erros                | 0.3474   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 65500    |
| lives                   | 65500    |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 7.99     |
| mean 100 episode reward | 2.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6052   |
| steps                   | 513829   |
| td_erros                | 0.3616   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 65600    |
| lives                   | 65600    |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 7.65     |
| mean 100 episode reward | 2.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6062   |
| steps                   | 514494   |
| td_erros                | 0.3818   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 65700    |
| lives                   | 65700    |
| mean 100 episode ei     | 4.35     |
| mean 100 episode length | 7.91     |
| mean 100 episode reward | 2.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5437   |
| steps                   | 515185   |
| td_erros                | 0.321    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 65800    |
| lives                   | 65800    |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 7.5      |
| mean 100 episode reward | 1.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5467   |
| steps                   | 515835   |
| td_erros                | 0.309    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 68       |
| episodes                | 65900    |
| lives                   | 65900    |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 8.41     |
| mean 100 episode reward | 1.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5121   |
| steps                   | 516576   |
| td_erros                | 0.2942   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 66000    |
| lives                   | 66000    |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 8        |
| mean 100 episode reward | 1.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4771   |
| steps                   | 517276   |
| td_erros                | 0.2871   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 66100    |
| lives                   | 66100    |
| mean 100 episode ei     | 3.79     |
| mean 100 episode length | 7.45     |
| mean 100 episode reward | 2.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4217   |
| steps                   | 517921   |
| td_erros                | 0.2482   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 66200    |
| lives                   | 66200    |
| mean 100 episode ei     | 4.69     |
| mean 100 episode length | 8.58     |
| mean 100 episode reward | 2.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3267   |
| steps                   | 518679   |
| td_erros                | 0.2094   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 66300    |
| lives                   | 66300    |
| mean 100 episode ei     | 4.47     |
| mean 100 episode length | 8.14     |
| mean 100 episode reward | 2.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2628   |
| steps                   | 519393   |
| td_erros                | 0.1926   |
--------------------------------------
Saving model due to mean reward increase: 2.2663 -> 2.3812
Saving model due to running mean reward increase: 2.1795 -> 2.3812
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 66400    |
| lives                   | 66400    |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 7.39     |
| mean 100 episode reward | 2.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2575   |
| steps                   | 520032   |
| td_erros                | 0.1933   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 66500    |
| lives                   | 66500    |
| mean 100 episode ei     | 4.35     |
| mean 100 episode length | 8.03     |
| mean 100 episode reward | 2.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2307   |
| steps                   | 520735   |
| td_erros                | 0.1788   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 66600    |
| lives                   | 66600    |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 8.22     |
| mean 100 episode reward | 2.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1865   |
| steps                   | 521457   |
| td_erros                | 0.1726   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 66700    |
| lives                   | 66700    |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 7.36     |
| mean 100 episode reward | 2.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2441   |
| steps                   | 522093   |
| td_erros                | 0.1714   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 66800    |
| lives                   | 66800    |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 8.06     |
| mean 100 episode reward | 2.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2626   |
| steps                   | 522799   |
| td_erros                | 0.1754   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 66900    |
| lives                   | 66900    |
| mean 100 episode ei     | 4.7      |
| mean 100 episode length | 8.25     |
| mean 100 episode reward | 2.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2644   |
| steps                   | 523524   |
| td_erros                | 0.1896   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 67000    |
| lives                   | 67000    |
| mean 100 episode ei     | 4.39     |
| mean 100 episode length | 8.4      |
| mean 100 episode reward | 2.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2971   |
| steps                   | 524264   |
| td_erros                | 0.1844   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 67100    |
| lives                   | 67100    |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 8.09     |
| mean 100 episode reward | 1.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2646   |
| steps                   | 524973   |
| td_erros                | 0.2095   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 67200    |
| lives                   | 67200    |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 7.58     |
| mean 100 episode reward | 1.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3274   |
| steps                   | 525631   |
| td_erros                | 0.2179   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 67300    |
| lives                   | 67300    |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 8.24     |
| mean 100 episode reward | 1.99     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4419   |
| steps                   | 526355   |
| td_erros                | 0.2739   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 67400    |
| lives                   | 67400    |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 8.47     |
| mean 100 episode reward | 2.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4609   |
| steps                   | 527102   |
| td_erros                | 0.2915   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 67500    |
| lives                   | 67500    |
| mean 100 episode ei     | 4.63     |
| mean 100 episode length | 8.4      |
| mean 100 episode reward | 2.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4773   |
| steps                   | 527842   |
| td_erros                | 0.2859   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 67600    |
| lives                   | 67600    |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 7.98     |
| mean 100 episode reward | 1.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4785   |
| steps                   | 528540   |
| td_erros                | 0.2673   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 67700    |
| lives                   | 67700    |
| mean 100 episode ei     | 4.49     |
| mean 100 episode length | 8.59     |
| mean 100 episode reward | 2.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.461    |
| steps                   | 529299   |
| td_erros                | 0.2891   |
--------------------------------------
Saving model due to mean reward increase: 2.3812 -> 2.4301
Saving model due to running mean reward increase: 2.2121 -> 2.4301
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 67800    |
| lives                   | 67800    |
| mean 100 episode ei     | 4.81     |
| mean 100 episode length | 8.6      |
| mean 100 episode reward | 2.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4145   |
| steps                   | 530059   |
| td_erros                | 0.2153   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 67900    |
| lives                   | 67900    |
| mean 100 episode ei     | 4.43     |
| mean 100 episode length | 8.26     |
| mean 100 episode reward | 1.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3867   |
| steps                   | 530785   |
| td_erros                | 0.2132   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 68000    |
| lives                   | 68000    |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 7.75     |
| mean 100 episode reward | 2.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3346   |
| steps                   | 531460   |
| td_erros                | 0.1623   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 68100    |
| lives                   | 68100    |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 7.88     |
| mean 100 episode reward | 2.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2859   |
| steps                   | 532148   |
| td_erros                | 0.1703   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 67       |
| episodes                | 68200    |
| lives                   | 68200    |
| mean 100 episode ei     | 4.41     |
| mean 100 episode length | 7.82     |
| mean 100 episode reward | 2.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.285    |
| steps                   | 532830   |
| td_erros                | 0.1968   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 68300    |
| lives                   | 68300    |
| mean 100 episode ei     | 3.7      |
| mean 100 episode length | 7.28     |
| mean 100 episode reward | 1.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2119   |
| steps                   | 533458   |
| td_erros                | 0.1907   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 68400    |
| lives                   | 68400    |
| mean 100 episode ei     | 4.23     |
| mean 100 episode length | 8.01     |
| mean 100 episode reward | 2.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2282   |
| steps                   | 534159   |
| td_erros                | 0.229    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 68500    |
| lives                   | 68500    |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 8.03     |
| mean 100 episode reward | 2.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2844   |
| steps                   | 534862   |
| td_erros                | 0.2456   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 68600    |
| lives                   | 68600    |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 7.51     |
| mean 100 episode reward | 2.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3246   |
| steps                   | 535513   |
| td_erros                | 0.2641   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 68700    |
| lives                   | 68700    |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 8.05     |
| mean 100 episode reward | 2.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3208   |
| steps                   | 536218   |
| td_erros                | 0.2813   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 68800    |
| lives                   | 68800    |
| mean 100 episode ei     | 4.52     |
| mean 100 episode length | 8.47     |
| mean 100 episode reward | 2.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2502   |
| steps                   | 536965   |
| td_erros                | 0.2516   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 68900    |
| lives                   | 68900    |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 8.31     |
| mean 100 episode reward | 1.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2227   |
| steps                   | 537696   |
| td_erros                | 0.2097   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 69000    |
| lives                   | 69000    |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 8.48     |
| mean 100 episode reward | 1.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2292   |
| steps                   | 538444   |
| td_erros                | 0.1905   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 69100    |
| lives                   | 69100    |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 7.36     |
| mean 100 episode reward | 1.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2704   |
| steps                   | 539080   |
| td_erros                | 0.1586   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 69200    |
| lives                   | 69200    |
| mean 100 episode ei     | 3.65     |
| mean 100 episode length | 7.03     |
| mean 100 episode reward | 1.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3262   |
| steps                   | 539683   |
| td_erros                | 0.198    |
--------------------------------------
Saving model due to running mean reward increase: 1.3221 -> 1.8617
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 69300    |
| lives                   | 69300    |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 7.63     |
| mean 100 episode reward | 1.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3289   |
| steps                   | 540346   |
| td_erros                | 0.2155   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 69400    |
| lives                   | 69400    |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 7.8      |
| mean 100 episode reward | 2.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3887   |
| steps                   | 541026   |
| td_erros                | 0.2621   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 69500    |
| lives                   | 69500    |
| mean 100 episode ei     | 3.66     |
| mean 100 episode length | 7.65     |
| mean 100 episode reward | 1.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3939   |
| steps                   | 541691   |
| td_erros                | 0.2855   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 69600    |
| lives                   | 69600    |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 7.58     |
| mean 100 episode reward | 2.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.431    |
| steps                   | 542349   |
| td_erros                | 0.3312   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 69700    |
| lives                   | 69700    |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 8.1      |
| mean 100 episode reward | 2.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4521   |
| steps                   | 543059   |
| td_erros                | 0.3513   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 69800    |
| lives                   | 69800    |
| mean 100 episode ei     | 4.35     |
| mean 100 episode length | 8.07     |
| mean 100 episode reward | 1.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3702   |
| steps                   | 543766   |
| td_erros                | 0.3172   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 69900    |
| lives                   | 69900    |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 8.08     |
| mean 100 episode reward | 1.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.275    |
| steps                   | 544474   |
| td_erros                | 0.2955   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 70000    |
| lives                   | 70000    |
| mean 100 episode ei     | 3.41     |
| mean 100 episode length | 6.96     |
| mean 100 episode reward | 2.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2178   |
| steps                   | 545070   |
| td_erros                | 0.2816   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 70100    |
| lives                   | 70100    |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 7.91     |
| mean 100 episode reward | 2.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1839   |
| steps                   | 545761   |
| td_erros                | 0.2273   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 70200    |
| lives                   | 70200    |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 7.32     |
| mean 100 episode reward | 1.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1647   |
| steps                   | 546393   |
| td_erros                | 0.217    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 70300    |
| lives                   | 70300    |
| mean 100 episode ei     | 3.83     |
| mean 100 episode length | 7.5      |
| mean 100 episode reward | 1.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1824   |
| steps                   | 547043   |
| td_erros                | 0.2315   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 70400    |
| lives                   | 70400    |
| mean 100 episode ei     | 3.74     |
| mean 100 episode length | 6.89     |
| mean 100 episode reward | 2.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2096   |
| steps                   | 547632   |
| td_erros                | 0.2658   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 70500    |
| lives                   | 70500    |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 7.74     |
| mean 100 episode reward | 1.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2053   |
| steps                   | 548306   |
| td_erros                | 0.2996   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 66       |
| episodes                | 70600    |
| lives                   | 70600    |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 7.89     |
| mean 100 episode reward | 1.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.144    |
| steps                   | 548995   |
| td_erros                | 0.2686   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 70700    |
| lives                   | 70700    |
| mean 100 episode ei     | 3.72     |
| mean 100 episode length | 7.45     |
| mean 100 episode reward | 1.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0513   |
| steps                   | 549640   |
| td_erros                | 0.256    |
--------------------------------------
Saving model due to running mean reward increase: 1.3854 -> 1.6778
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 70800    |
| lives                   | 70800    |
| mean 100 episode ei     | 4.32     |
| mean 100 episode length | 8.14     |
| mean 100 episode reward | 1.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9937   |
| steps                   | 550354   |
| td_erros                | 0.2221   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 70900    |
| lives                   | 70900    |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 7.26     |
| mean 100 episode reward | 1.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0367   |
| steps                   | 550980   |
| td_erros                | 0.2066   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 71000    |
| lives                   | 71000    |
| mean 100 episode ei     | 3.64     |
| mean 100 episode length | 7.43     |
| mean 100 episode reward | 1.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9999   |
| steps                   | 551623   |
| td_erros                | 0.1712   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 71100    |
| lives                   | 71100    |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 8.25     |
| mean 100 episode reward | 1.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0316   |
| steps                   | 552348   |
| td_erros                | 0.1598   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 71200    |
| lives                   | 71200    |
| mean 100 episode ei     | 3.63     |
| mean 100 episode length | 7.13     |
| mean 100 episode reward | 2.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0854   |
| steps                   | 552961   |
| td_erros                | 0.1482   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 71300    |
| lives                   | 71300    |
| mean 100 episode ei     | 3.8      |
| mean 100 episode length | 7.42     |
| mean 100 episode reward | 1.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1042   |
| steps                   | 553603   |
| td_erros                | 0.1364   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 71400    |
| lives                   | 71400    |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 7.42     |
| mean 100 episode reward | 2.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1177   |
| steps                   | 554245   |
| td_erros                | 0.1771   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 71500    |
| lives                   | 71500    |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 7.75     |
| mean 100 episode reward | 2.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1208   |
| steps                   | 554920   |
| td_erros                | 0.1581   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 71600    |
| lives                   | 71600    |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 7.87     |
| mean 100 episode reward | 1.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1005   |
| steps                   | 555607   |
| td_erros                | 0.1871   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 71700    |
| lives                   | 71700    |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 7.8      |
| mean 100 episode reward | 1.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9803   |
| steps                   | 556287   |
| td_erros                | 0.1523   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 71800    |
| lives                   | 71800    |
| mean 100 episode ei     | 3.83     |
| mean 100 episode length | 6.76     |
| mean 100 episode reward | 2.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0134   |
| steps                   | 556863   |
| td_erros                | 0.1875   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 71900    |
| lives                   | 71900    |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 7.24     |
| mean 100 episode reward | 2.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0479   |
| steps                   | 557487   |
| td_erros                | 0.2272   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 72000    |
| lives                   | 72000    |
| mean 100 episode ei     | 4.24     |
| mean 100 episode length | 7.39     |
| mean 100 episode reward | 2.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1476   |
| steps                   | 558126   |
| td_erros                | 0.241    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 72100    |
| lives                   | 72100    |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 7.86     |
| mean 100 episode reward | 1.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1874   |
| steps                   | 558812   |
| td_erros                | 0.2773   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 72200    |
| lives                   | 72200    |
| mean 100 episode ei     | 4.51     |
| mean 100 episode length | 8.71     |
| mean 100 episode reward | 1.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2563   |
| steps                   | 559583   |
| td_erros                | 0.2637   |
--------------------------------------
Saving model due to running mean reward increase: 1.8567 -> 1.9327
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 72300    |
| lives                   | 72300    |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 7.57     |
| mean 100 episode reward | 1.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4095   |
| steps                   | 560240   |
| td_erros                | 0.3271   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 72400    |
| lives                   | 72400    |
| mean 100 episode ei     | 3.5      |
| mean 100 episode length | 6.97     |
| mean 100 episode reward | 1.57     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4848   |
| steps                   | 560837   |
| td_erros                | 0.3662   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 72500    |
| lives                   | 72500    |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 7.37     |
| mean 100 episode reward | 1.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4631   |
| steps                   | 561474   |
| td_erros                | 0.3513   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 72600    |
| lives                   | 72600    |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 7.39     |
| mean 100 episode reward | 1.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4853   |
| steps                   | 562113   |
| td_erros                | 0.3676   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 72700    |
| lives                   | 72700    |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 7.82     |
| mean 100 episode reward | 2.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4098   |
| steps                   | 562795   |
| td_erros                | 0.3262   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 72800    |
| lives                   | 72800    |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 7.22     |
| mean 100 episode reward | 2.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3769   |
| steps                   | 563417   |
| td_erros                | 0.3134   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 72900    |
| lives                   | 72900    |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 7.71     |
| mean 100 episode reward | 1.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3844   |
| steps                   | 564088   |
| td_erros                | 0.3181   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 73000    |
| lives                   | 73000    |
| mean 100 episode ei     | 3.7      |
| mean 100 episode length | 7.33     |
| mean 100 episode reward | 1.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.323    |
| steps                   | 564721   |
| td_erros                | 0.2955   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 65       |
| episodes                | 73100    |
| lives                   | 73100    |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 7.82     |
| mean 100 episode reward | 2.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2555   |
| steps                   | 565403   |
| td_erros                | 0.2678   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 73200    |
| lives                   | 73200    |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 7.65     |
| mean 100 episode reward | 2.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1629   |
| steps                   | 566068   |
| td_erros                | 0.2447   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 73300    |
| lives                   | 73300    |
| mean 100 episode ei     | 3.72     |
| mean 100 episode length | 6.33     |
| mean 100 episode reward | 2.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1271   |
| steps                   | 566601   |
| td_erros                | 0.2048   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 73400    |
| lives                   | 73400    |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 7.22     |
| mean 100 episode reward | 2.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1239   |
| steps                   | 567223   |
| td_erros                | 0.2057   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 73500    |
| lives                   | 73500    |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 7.39     |
| mean 100 episode reward | 2.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1058   |
| steps                   | 567862   |
| td_erros                | 0.2089   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 73600    |
| lives                   | 73600    |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 7.85     |
| mean 100 episode reward | 2.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1526   |
| steps                   | 568547   |
| td_erros                | 0.1942   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 73700    |
| lives                   | 73700    |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 7.58     |
| mean 100 episode reward | 2        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1166   |
| steps                   | 569205   |
| td_erros                | 0.1993   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 73800    |
| lives                   | 73800    |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 7.46     |
| mean 100 episode reward | 1.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1496   |
| steps                   | 569851   |
| td_erros                | 0.2159   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 73900    |
| lives                   | 73900    |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 8.12     |
| mean 100 episode reward | 1.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2126   |
| steps                   | 570563   |
| td_erros                | 0.225    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 74000    |
| lives                   | 74000    |
| mean 100 episode ei     | 4.84     |
| mean 100 episode length | 8.24     |
| mean 100 episode reward | 1.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2885   |
| steps                   | 571287   |
| td_erros                | 0.2331   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 74100    |
| lives                   | 74100    |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 8.15     |
| mean 100 episode reward | 1.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2708   |
| steps                   | 572002   |
| td_erros                | 0.2178   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 74200    |
| lives                   | 74200    |
| mean 100 episode ei     | 4.8      |
| mean 100 episode length | 8.23     |
| mean 100 episode reward | 1.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.268    |
| steps                   | 572725   |
| td_erros                | 0.2087   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 74300    |
| lives                   | 74300    |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 8.25     |
| mean 100 episode reward | 2.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2727   |
| steps                   | 573450   |
| td_erros                | 0.2219   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 74400    |
| lives                   | 74400    |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 8.39     |
| mean 100 episode reward | 1.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3212   |
| steps                   | 574189   |
| td_erros                | 0.2068   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 74500    |
| lives                   | 74500    |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 7.92     |
| mean 100 episode reward | 2.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4076   |
| steps                   | 574881   |
| td_erros                | 0.2221   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 74600    |
| lives                   | 74600    |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 7.53     |
| mean 100 episode reward | 2.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5153   |
| steps                   | 575534   |
| td_erros                | 0.2221   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 74700    |
| lives                   | 74700    |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 7.9      |
| mean 100 episode reward | 1.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5983   |
| steps                   | 576224   |
| td_erros                | 0.2815   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 74800    |
| lives                   | 74800    |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 7.73     |
| mean 100 episode reward | 2.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5752   |
| steps                   | 576897   |
| td_erros                | 0.3018   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 74900    |
| lives                   | 74900    |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 7.21     |
| mean 100 episode reward | 1.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4984   |
| steps                   | 577518   |
| td_erros                | 0.2914   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 75000    |
| lives                   | 75000    |
| mean 100 episode ei     | 3.69     |
| mean 100 episode length | 6.85     |
| mean 100 episode reward | 1.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5467   |
| steps                   | 578103   |
| td_erros                | 0.3611   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 75100    |
| lives                   | 75100    |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 7.68     |
| mean 100 episode reward | 1.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.6148   |
| steps                   | 578771   |
| td_erros                | 0.3995   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 75200    |
| lives                   | 75200    |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 7.9      |
| mean 100 episode reward | 1.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5974   |
| steps                   | 579461   |
| td_erros                | 0.4136   |
--------------------------------------
Saving model due to running mean reward increase: 1.8173 -> 2.1471
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 75300    |
| lives                   | 75300    |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 7.97     |
| mean 100 episode reward | 2.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.5838   |
| steps                   | 580158   |
| td_erros                | 0.4033   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 75400    |
| lives                   | 75400    |
| mean 100 episode ei     | 4.33     |
| mean 100 episode length | 8.24     |
| mean 100 episode reward | 1.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4914   |
| steps                   | 580882   |
| td_erros                | 0.3906   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 64       |
| episodes                | 75500    |
| lives                   | 75500    |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 8.03     |
| mean 100 episode reward | 2.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.4204   |
| steps                   | 581585   |
| td_erros                | 0.3595   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 75600    |
| lives                   | 75600    |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 7.79     |
| mean 100 episode reward | 2.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3867   |
| steps                   | 582264   |
| td_erros                | 0.324    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 75700    |
| lives                   | 75700    |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 7.57     |
| mean 100 episode reward | 2.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3382   |
| steps                   | 582921   |
| td_erros                | 0.2702   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 75800    |
| lives                   | 75800    |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 7.79     |
| mean 100 episode reward | 2.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.244    |
| steps                   | 583600   |
| td_erros                | 0.2513   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 75900    |
| lives                   | 75900    |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 8.01     |
| mean 100 episode reward | 2.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1622   |
| steps                   | 584301   |
| td_erros                | 0.1963   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 76000    |
| lives                   | 76000    |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 8.12     |
| mean 100 episode reward | 2.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1277   |
| steps                   | 585013   |
| td_erros                | 0.1578   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 76100    |
| lives                   | 76100    |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 7.92     |
| mean 100 episode reward | 2.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0921   |
| steps                   | 585705   |
| td_erros                | 0.142    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 76200    |
| lives                   | 76200    |
| mean 100 episode ei     | 4.72     |
| mean 100 episode length | 8.09     |
| mean 100 episode reward | 2.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0703   |
| steps                   | 586414   |
| td_erros                | 0.1369   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 76300    |
| lives                   | 76300    |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 7.7      |
| mean 100 episode reward | 2.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0727   |
| steps                   | 587084   |
| td_erros                | 0.1225   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 76400    |
| lives                   | 76400    |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 7.71     |
| mean 100 episode reward | 2.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0964   |
| steps                   | 587755   |
| td_erros                | 0.1285   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 76500    |
| lives                   | 76500    |
| mean 100 episode ei     | 4.61     |
| mean 100 episode length | 7.89     |
| mean 100 episode reward | 2.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1091   |
| steps                   | 588444   |
| td_erros                | 0.1123   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 76600    |
| lives                   | 76600    |
| mean 100 episode ei     | 4.46     |
| mean 100 episode length | 7.34     |
| mean 100 episode reward | 2.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1106   |
| steps                   | 589078   |
| td_erros                | 0.131    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 76700    |
| lives                   | 76700    |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 7.56     |
| mean 100 episode reward | 2.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1505   |
| steps                   | 589734   |
| td_erros                | 0.1184   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 76800    |
| lives                   | 76800    |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 7.17     |
| mean 100 episode reward | 2.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1829   |
| steps                   | 590351   |
| td_erros                | 0.1462   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 76900    |
| lives                   | 76900    |
| mean 100 episode ei     | 4.43     |
| mean 100 episode length | 7.9      |
| mean 100 episode reward | 2.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1998   |
| steps                   | 591041   |
| td_erros                | 0.1375   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 77000    |
| lives                   | 77000    |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 7.65     |
| mean 100 episode reward | 2.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1796   |
| steps                   | 591706   |
| td_erros                | 0.1497   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 77100    |
| lives                   | 77100    |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 8.01     |
| mean 100 episode reward | 1.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1673   |
| steps                   | 592407   |
| td_erros                | 0.1507   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 77200    |
| lives                   | 77200    |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 8.05     |
| mean 100 episode reward | 2.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1509   |
| steps                   | 593112   |
| td_erros                | 0.1823   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 77300    |
| lives                   | 77300    |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 7.96     |
| mean 100 episode reward | 2.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1773   |
| steps                   | 593808   |
| td_erros                | 0.2047   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 77400    |
| lives                   | 77400    |
| mean 100 episode ei     | 4.36     |
| mean 100 episode length | 8.12     |
| mean 100 episode reward | 2.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1509   |
| steps                   | 594520   |
| td_erros                | 0.211    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 77500    |
| lives                   | 77500    |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 8.03     |
| mean 100 episode reward | 1.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.148    |
| steps                   | 595223   |
| td_erros                | 0.2044   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 77600    |
| lives                   | 77600    |
| mean 100 episode ei     | 4.24     |
| mean 100 episode length | 8.01     |
| mean 100 episode reward | 1.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1042   |
| steps                   | 595924   |
| td_erros                | 0.1669   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 77700    |
| lives                   | 77700    |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 7.6      |
| mean 100 episode reward | 2.57     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2407   |
| steps                   | 596584   |
| td_erros                | 0.2309   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 63       |
| episodes                | 77800    |
| lives                   | 77800    |
| mean 100 episode ei     | 4.77     |
| mean 100 episode length | 8.3      |
| mean 100 episode reward | 2.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2709   |
| steps                   | 597314   |
| td_erros                | 0.2399   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 77900    |
| lives                   | 77900    |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 8.19     |
| mean 100 episode reward | 2        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2699   |
| steps                   | 598033   |
| td_erros                | 0.2202   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 78000    |
| lives                   | 78000    |
| mean 100 episode ei     | 3.83     |
| mean 100 episode length | 8        |
| mean 100 episode reward | 2.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3331   |
| steps                   | 598733   |
| td_erros                | 0.2438   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 78100    |
| lives                   | 78100    |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 7.58     |
| mean 100 episode reward | 2.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.358    |
| steps                   | 599391   |
| td_erros                | 0.2653   |
--------------------------------------
Saving model due to running mean reward increase: 2.2288 -> 2.2705
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 78200    |
| lives                   | 78200    |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 8.17     |
| mean 100 episode reward | 2.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3426   |
| steps                   | 600108   |
| td_erros                | 0.2631   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 78300    |
| lives                   | 78300    |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 8.26     |
| mean 100 episode reward | 2.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.3189   |
| steps                   | 600834   |
| td_erros                | 0.254    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 78400    |
| lives                   | 78400    |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 7.46     |
| mean 100 episode reward | 2.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2787   |
| steps                   | 601480   |
| td_erros                | 0.2429   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 78500    |
| lives                   | 78500    |
| mean 100 episode ei     | 3.75     |
| mean 100 episode length | 7.25     |
| mean 100 episode reward | 2.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2422   |
| steps                   | 602105   |
| td_erros                | 0.2485   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 78600    |
| lives                   | 78600    |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 8.5      |
| mean 100 episode reward | 2.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.115    |
| steps                   | 602855   |
| td_erros                | 0.1709   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 78700    |
| lives                   | 78700    |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 7.84     |
| mean 100 episode reward | 2.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0706   |
| steps                   | 603539   |
| td_erros                | 0.1661   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 78800    |
| lives                   | 78800    |
| mean 100 episode ei     | 4.41     |
| mean 100 episode length | 7.53     |
| mean 100 episode reward | 2.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0913   |
| steps                   | 604192   |
| td_erros                | 0.1618   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 78900    |
| lives                   | 78900    |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 7.99     |
| mean 100 episode reward | 2.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1551   |
| steps                   | 604891   |
| td_erros                | 0.1771   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 79000    |
| lives                   | 79000    |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 7.26     |
| mean 100 episode reward | 2.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1933   |
| steps                   | 605517   |
| td_erros                | 0.1816   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 79100    |
| lives                   | 79100    |
| mean 100 episode ei     | 3.75     |
| mean 100 episode length | 7.23     |
| mean 100 episode reward | 2.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2463   |
| steps                   | 606140   |
| td_erros                | 0.1994   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 79200    |
| lives                   | 79200    |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 8.04     |
| mean 100 episode reward | 1.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2227   |
| steps                   | 606844   |
| td_erros                | 0.1996   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 79300    |
| lives                   | 79300    |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 7.56     |
| mean 100 episode reward | 1.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1876   |
| steps                   | 607500   |
| td_erros                | 0.1933   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 79400    |
| lives                   | 79400    |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 8.17     |
| mean 100 episode reward | 1.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1513   |
| steps                   | 608217   |
| td_erros                | 0.1779   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 79500    |
| lives                   | 79500    |
| mean 100 episode ei     | 4.33     |
| mean 100 episode length | 7.33     |
| mean 100 episode reward | 2.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0763   |
| steps                   | 608850   |
| td_erros                | 0.1329   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 79600    |
| lives                   | 79600    |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 7.23     |
| mean 100 episode reward | 1.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0077   |
| steps                   | 609473   |
| td_erros                | 0.112    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 79700    |
| lives                   | 79700    |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 8.22     |
| mean 100 episode reward | 1.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9744   |
| steps                   | 610195   |
| td_erros                | 0.0989   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 79800    |
| lives                   | 79800    |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 7.77     |
| mean 100 episode reward | 1.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9537   |
| steps                   | 610872   |
| td_erros                | 0.0765   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 79900    |
| lives                   | 79900    |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 7.33     |
| mean 100 episode reward | 2.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9745   |
| steps                   | 611505   |
| td_erros                | 0.0885   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 80000    |
| lives                   | 80000    |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 7.06     |
| mean 100 episode reward | 2.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0493   |
| steps                   | 612111   |
| td_erros                | 0.14     |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 80100    |
| lives                   | 80100    |
| mean 100 episode ei     | 3.66     |
| mean 100 episode length | 7.02     |
| mean 100 episode reward | 2.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1354   |
| steps                   | 612713   |
| td_erros                | 0.1789   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 80200    |
| lives                   | 80200    |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 7.62     |
| mean 100 episode reward | 2.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1667   |
| steps                   | 613375   |
| td_erros                | 0.2239   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 62       |
| episodes                | 80300    |
| lives                   | 80300    |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 7.48     |
| mean 100 episode reward | 2.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1735   |
| steps                   | 614023   |
| td_erros                | 0.2252   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 80400    |
| lives                   | 80400    |
| mean 100 episode ei     | 4.51     |
| mean 100 episode length | 8.48     |
| mean 100 episode reward | 2.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2322   |
| steps                   | 614771   |
| td_erros                | 0.2412   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 80500    |
| lives                   | 80500    |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 8.45     |
| mean 100 episode reward | 1.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1878   |
| steps                   | 615516   |
| td_erros                | 0.2017   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 80600    |
| lives                   | 80600    |
| mean 100 episode ei     | 4.46     |
| mean 100 episode length | 7.96     |
| mean 100 episode reward | 2.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2059   |
| steps                   | 616212   |
| td_erros                | 0.1791   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 80700    |
| lives                   | 80700    |
| mean 100 episode ei     | 4.46     |
| mean 100 episode length | 8.45     |
| mean 100 episode reward | 1.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2069   |
| steps                   | 616957   |
| td_erros                | 0.1552   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 80800    |
| lives                   | 80800    |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 8.2      |
| mean 100 episode reward | 1.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1993   |
| steps                   | 617677   |
| td_erros                | 0.1497   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 80900    |
| lives                   | 80900    |
| mean 100 episode ei     | 4.73     |
| mean 100 episode length | 8.35     |
| mean 100 episode reward | 2.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2189   |
| steps                   | 618412   |
| td_erros                | 0.1132   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 81000    |
| lives                   | 81000    |
| mean 100 episode ei     | 4.41     |
| mean 100 episode length | 7.96     |
| mean 100 episode reward | 3.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2323   |
| steps                   | 619108   |
| td_erros                | 0.1027   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 81100    |
| lives                   | 81100    |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 7.57     |
| mean 100 episode reward | 2.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.208    |
| steps                   | 619765   |
| td_erros                | 0.1092   |
--------------------------------------
Saving model due to mean reward increase: 2.4301 -> 2.78
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 81200    |
| lives                   | 81200    |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 7.78     |
| mean 100 episode reward | 2.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.219    |
| steps                   | 620443   |
| td_erros                | 0.1209   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 81300    |
| lives                   | 81300    |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 7.84     |
| mean 100 episode reward | 2.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2035   |
| steps                   | 621127   |
| td_erros                | 0.1133   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 81400    |
| lives                   | 81400    |
| mean 100 episode ei     | 4.42     |
| mean 100 episode length | 8.25     |
| mean 100 episode reward | 2.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1837   |
| steps                   | 621852   |
| td_erros                | 0.1236   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 81500    |
| lives                   | 81500    |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 7.51     |
| mean 100 episode reward | 1.99     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2239   |
| steps                   | 622503   |
| td_erros                | 0.1257   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 81600    |
| lives                   | 81600    |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 7.85     |
| mean 100 episode reward | 2.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2344   |
| steps                   | 623188   |
| td_erros                | 0.1256   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 81700    |
| lives                   | 81700    |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 7.6      |
| mean 100 episode reward | 1.96     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2733   |
| steps                   | 623848   |
| td_erros                | 0.152    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 81800    |
| lives                   | 81800    |
| mean 100 episode ei     | 4.41     |
| mean 100 episode length | 7.29     |
| mean 100 episode reward | 2.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2275   |
| steps                   | 624477   |
| td_erros                | 0.1343   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 81900    |
| lives                   | 81900    |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 7.69     |
| mean 100 episode reward | 2.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1716   |
| steps                   | 625146   |
| td_erros                | 0.1414   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 82000    |
| lives                   | 82000    |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 7.9      |
| mean 100 episode reward | 1.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0984   |
| steps                   | 625836   |
| td_erros                | 0.1189   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 82100    |
| lives                   | 82100    |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 8.27     |
| mean 100 episode reward | 1.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0779   |
| steps                   | 626563   |
| td_erros                | 0.098    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 82200    |
| lives                   | 82200    |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 7.95     |
| mean 100 episode reward | 2.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0323   |
| steps                   | 627258   |
| td_erros                | 0.0917   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 82300    |
| lives                   | 82300    |
| mean 100 episode ei     | 3.53     |
| mean 100 episode length | 7.27     |
| mean 100 episode reward | 2.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9381   |
| steps                   | 627885   |
| td_erros                | 0.0973   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 82400    |
| lives                   | 82400    |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 7.74     |
| mean 100 episode reward | 2.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8854   |
| steps                   | 628559   |
| td_erros                | 0.0723   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 82500    |
| lives                   | 82500    |
| mean 100 episode ei     | 4.4      |
| mean 100 episode length | 7.72     |
| mean 100 episode reward | 2.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8429   |
| steps                   | 629231   |
| td_erros                | 0.0762   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 61       |
| episodes                | 82600    |
| lives                   | 82600    |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 7.51     |
| mean 100 episode reward | 2.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8074   |
| steps                   | 629882   |
| td_erros                | 0.0536   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 82700    |
| lives                   | 82700    |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 7.34     |
| mean 100 episode reward | 2.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8573   |
| steps                   | 630516   |
| td_erros                | 0.0576   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 82800    |
| lives                   | 82800    |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 7.46     |
| mean 100 episode reward | 2.96     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9267   |
| steps                   | 631162   |
| td_erros                | 0.0858   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 82900    |
| lives                   | 82900    |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 6.85     |
| mean 100 episode reward | 2.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9383   |
| steps                   | 631747   |
| td_erros                | 0.1062   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 83000    |
| lives                   | 83000    |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 7.38     |
| mean 100 episode reward | 2.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0004   |
| steps                   | 632385   |
| td_erros                | 0.1159   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 83100    |
| lives                   | 83100    |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 7.54     |
| mean 100 episode reward | 2.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0116   |
| steps                   | 633039   |
| td_erros                | 0.1215   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 83200    |
| lives                   | 83200    |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 7.7      |
| mean 100 episode reward | 2.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0892   |
| steps                   | 633709   |
| td_erros                | 0.1283   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 83300    |
| lives                   | 83300    |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 8.03     |
| mean 100 episode reward | 2.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0368   |
| steps                   | 634412   |
| td_erros                | 0.1066   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 83400    |
| lives                   | 83400    |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 7.76     |
| mean 100 episode reward | 2.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0092   |
| steps                   | 635088   |
| td_erros                | 0.1042   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 83500    |
| lives                   | 83500    |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 7.2      |
| mean 100 episode reward | 2.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0169   |
| steps                   | 635708   |
| td_erros                | 0.1256   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 83600    |
| lives                   | 83600    |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 7.58     |
| mean 100 episode reward | 2.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0383   |
| steps                   | 636366   |
| td_erros                | 0.1208   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 83700    |
| lives                   | 83700    |
| mean 100 episode ei     | 4.79     |
| mean 100 episode length | 8.52     |
| mean 100 episode reward | 1.99     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9528   |
| steps                   | 637118   |
| td_erros                | 0.1054   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 83800    |
| lives                   | 83800    |
| mean 100 episode ei     | 4.51     |
| mean 100 episode length | 7.94     |
| mean 100 episode reward | 1.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9176   |
| steps                   | 637812   |
| td_erros                | 0.0726   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 83900    |
| lives                   | 83900    |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 7.26     |
| mean 100 episode reward | 2.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9989   |
| steps                   | 638438   |
| td_erros                | 0.0854   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 84000    |
| lives                   | 84000    |
| mean 100 episode ei     | 3.66     |
| mean 100 episode length | 6.69     |
| mean 100 episode reward | 2.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0783   |
| steps                   | 639007   |
| td_erros                | 0.1409   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 84100    |
| lives                   | 84100    |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 7.48     |
| mean 100 episode reward | 2.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0718   |
| steps                   | 639655   |
| td_erros                | 0.1715   |
--------------------------------------
Saving model due to running mean reward increase: 1.8552 -> 2.4658
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 84200    |
| lives                   | 84200    |
| mean 100 episode ei     | 4.21     |
| mean 100 episode length | 7.32     |
| mean 100 episode reward | 2.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.121    |
| steps                   | 640287   |
| td_erros                | 0.1753   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 84300    |
| lives                   | 84300    |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 8.12     |
| mean 100 episode reward | 2.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1181   |
| steps                   | 640999   |
| td_erros                | 0.1679   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 84400    |
| lives                   | 84400    |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 7.97     |
| mean 100 episode reward | 2.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1608   |
| steps                   | 641696   |
| td_erros                | 0.1738   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 84500    |
| lives                   | 84500    |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 7.71     |
| mean 100 episode reward | 2.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2121   |
| steps                   | 642367   |
| td_erros                | 0.2083   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 84600    |
| lives                   | 84600    |
| mean 100 episode ei     | 4.36     |
| mean 100 episode length | 8.12     |
| mean 100 episode reward | 2.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1838   |
| steps                   | 643079   |
| td_erros                | 0.2243   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 84700    |
| lives                   | 84700    |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 7.76     |
| mean 100 episode reward | 2.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1711   |
| steps                   | 643755   |
| td_erros                | 0.2143   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 84800    |
| lives                   | 84800    |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 7.12     |
| mean 100 episode reward | 2.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1099   |
| steps                   | 644367   |
| td_erros                | 0.1686   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 84900    |
| lives                   | 84900    |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 7.58     |
| mean 100 episode reward | 2.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.05     |
| steps                   | 645025   |
| td_erros                | 0.162    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 85000    |
| lives                   | 85000    |
| mean 100 episode ei     | 4.36     |
| mean 100 episode length | 7.9      |
| mean 100 episode reward | 2.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0115   |
| steps                   | 645715   |
| td_erros                | 0.1338   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 60       |
| episodes                | 85100    |
| lives                   | 85100    |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 7.88     |
| mean 100 episode reward | 2.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9914   |
| steps                   | 646403   |
| td_erros                | 0.1313   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 85200    |
| lives                   | 85200    |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 7.91     |
| mean 100 episode reward | 1.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0221   |
| steps                   | 647094   |
| td_erros                | 0.1189   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 85300    |
| lives                   | 85300    |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 6.98     |
| mean 100 episode reward | 2.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9934   |
| steps                   | 647692   |
| td_erros                | 0.1295   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 85400    |
| lives                   | 85400    |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 7.33     |
| mean 100 episode reward | 2.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0144   |
| steps                   | 648325   |
| td_erros                | 0.129    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 85500    |
| lives                   | 85500    |
| mean 100 episode ei     | 3.59     |
| mean 100 episode length | 7.14     |
| mean 100 episode reward | 1.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0993   |
| steps                   | 648939   |
| td_erros                | 0.141    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 85600    |
| lives                   | 85600    |
| mean 100 episode ei     | 4.24     |
| mean 100 episode length | 7.77     |
| mean 100 episode reward | 2.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0318   |
| steps                   | 649616   |
| td_erros                | 0.1319   |
--------------------------------------
Saving model due to running mean reward increase: 2.1611 -> 2.331
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 85700    |
| lives                   | 85700    |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 7.58     |
| mean 100 episode reward | 2.57     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0435   |
| steps                   | 650274   |
| td_erros                | 0.1494   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 85800    |
| lives                   | 85800    |
| mean 100 episode ei     | 4.43     |
| mean 100 episode length | 8.37     |
| mean 100 episode reward | 2.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0704   |
| steps                   | 651011   |
| td_erros                | 0.163    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 85900    |
| lives                   | 85900    |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 7.45     |
| mean 100 episode reward | 2.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1315   |
| steps                   | 651656   |
| td_erros                | 0.1796   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 86000    |
| lives                   | 86000    |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 8.32     |
| mean 100 episode reward | 2.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.177    |
| steps                   | 652388   |
| td_erros                | 0.1825   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 86100    |
| lives                   | 86100    |
| mean 100 episode ei     | 4.48     |
| mean 100 episode length | 8.08     |
| mean 100 episode reward | 2.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1995   |
| steps                   | 653096   |
| td_erros                | 0.1659   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 86200    |
| lives                   | 86200    |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 7.75     |
| mean 100 episode reward | 2.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2051   |
| steps                   | 653771   |
| td_erros                | 0.1871   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 86300    |
| lives                   | 86300    |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 7.82     |
| mean 100 episode reward | 2.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.191    |
| steps                   | 654453   |
| td_erros                | 0.1577   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 86400    |
| lives                   | 86400    |
| mean 100 episode ei     | 4.32     |
| mean 100 episode length | 8.15     |
| mean 100 episode reward | 2.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1745   |
| steps                   | 655168   |
| td_erros                | 0.165    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 86500    |
| lives                   | 86500    |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 7.6      |
| mean 100 episode reward | 2.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1753   |
| steps                   | 655828   |
| td_erros                | 0.1371   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 86600    |
| lives                   | 86600    |
| mean 100 episode ei     | 3.69     |
| mean 100 episode length | 7.24     |
| mean 100 episode reward | 2.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1931   |
| steps                   | 656452   |
| td_erros                | 0.1737   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 86700    |
| lives                   | 86700    |
| mean 100 episode ei     | 4.21     |
| mean 100 episode length | 8.28     |
| mean 100 episode reward | 2.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2035   |
| steps                   | 657180   |
| td_erros                | 0.1598   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 86800    |
| lives                   | 86800    |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 7.41     |
| mean 100 episode reward | 2.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2088   |
| steps                   | 657821   |
| td_erros                | 0.1429   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 86900    |
| lives                   | 86900    |
| mean 100 episode ei     | 4.41     |
| mean 100 episode length | 7.69     |
| mean 100 episode reward | 2.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2335   |
| steps                   | 658490   |
| td_erros                | 0.126    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 87000    |
| lives                   | 87000    |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 7.6      |
| mean 100 episode reward | 2.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.2377   |
| steps                   | 659150   |
| td_erros                | 0.104    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 87100    |
| lives                   | 87100    |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 7.24     |
| mean 100 episode reward | 2        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1885   |
| steps                   | 659774   |
| td_erros                | 0.0775   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 87200    |
| lives                   | 87200    |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 8.33     |
| mean 100 episode reward | 2.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1411   |
| steps                   | 660507   |
| td_erros                | 0.0931   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 87300    |
| lives                   | 87300    |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 8.39     |
| mean 100 episode reward | 2.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0719   |
| steps                   | 661246   |
| td_erros                | 0.0352   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 59       |
| episodes                | 87400    |
| lives                   | 87400    |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 7.81     |
| mean 100 episode reward | 2.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0673   |
| steps                   | 661927   |
| td_erros                | 0.0225   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 87500    |
| lives                   | 87500    |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 8.03     |
| mean 100 episode reward | 2.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0471   |
| steps                   | 662630   |
| td_erros                | 0.0374   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 87600    |
| lives                   | 87600    |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 7.84     |
| mean 100 episode reward | 2.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9905   |
| steps                   | 663314   |
| td_erros                | 0.034    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 87700    |
| lives                   | 87700    |
| mean 100 episode ei     | 4.23     |
| mean 100 episode length | 7.76     |
| mean 100 episode reward | 3.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9756   |
| steps                   | 663990   |
| td_erros                | 0.0509   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 87800    |
| lives                   | 87800    |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 7.48     |
| mean 100 episode reward | 2.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9915   |
| steps                   | 664638   |
| td_erros                | 0.0631   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 87900    |
| lives                   | 87900    |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 7.03     |
| mean 100 episode reward | 2.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9823   |
| steps                   | 665241   |
| td_erros                | 0.0731   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 88000    |
| lives                   | 88000    |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 7.11     |
| mean 100 episode reward | 2.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0036   |
| steps                   | 665852   |
| td_erros                | 0.1234   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 88100    |
| lives                   | 88100    |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 7.34     |
| mean 100 episode reward | 2.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.023    |
| steps                   | 666486   |
| td_erros                | 0.1331   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 88200    |
| lives                   | 88200    |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 7.62     |
| mean 100 episode reward | 2.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0052   |
| steps                   | 667148   |
| td_erros                | 0.1217   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 88300    |
| lives                   | 88300    |
| mean 100 episode ei     | 3.67     |
| mean 100 episode length | 7.17     |
| mean 100 episode reward | 1.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0078   |
| steps                   | 667765   |
| td_erros                | 0.1135   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 88400    |
| lives                   | 88400    |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 7.43     |
| mean 100 episode reward | 2.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9291   |
| steps                   | 668408   |
| td_erros                | 0.0711   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 88500    |
| lives                   | 88500    |
| mean 100 episode ei     | 4.39     |
| mean 100 episode length | 7.86     |
| mean 100 episode reward | 2.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8612   |
| steps                   | 669094   |
| td_erros                | 0.0528   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 88600    |
| lives                   | 88600    |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 7.53     |
| mean 100 episode reward | 1.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8077   |
| steps                   | 669747   |
| td_erros                | 0.0167   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 88700    |
| lives                   | 88700    |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 7.7      |
| mean 100 episode reward | 2.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7627   |
| steps                   | 670417   |
| td_erros                | 0.0109   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 88800    |
| lives                   | 88800    |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 8.02     |
| mean 100 episode reward | 2.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6929   |
| steps                   | 671119   |
| td_erros                | -0.008   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 88900    |
| lives                   | 88900    |
| mean 100 episode ei     | 4.21     |
| mean 100 episode length | 7.64     |
| mean 100 episode reward | 2.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6284   |
| steps                   | 671783   |
| td_erros                | -0.0342  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 89000    |
| lives                   | 89000    |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 7.76     |
| mean 100 episode reward | 2.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6682   |
| steps                   | 672459   |
| td_erros                | -0.0213  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 89100    |
| lives                   | 89100    |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 7.13     |
| mean 100 episode reward | 2.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7165   |
| steps                   | 673072   |
| td_erros                | 0.0095   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 89200    |
| lives                   | 89200    |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 7.32     |
| mean 100 episode reward | 2.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8081   |
| steps                   | 673704   |
| td_erros                | 0.0556   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 89300    |
| lives                   | 89300    |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 8        |
| mean 100 episode reward | 2.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8623   |
| steps                   | 674404   |
| td_erros                | 0.0496   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 89400    |
| lives                   | 89400    |
| mean 100 episode ei     | 3.46     |
| mean 100 episode length | 6.97     |
| mean 100 episode reward | 2.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9035   |
| steps                   | 675001   |
| td_erros                | 0.106    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 89500    |
| lives                   | 89500    |
| mean 100 episode ei     | 3.79     |
| mean 100 episode length | 7.32     |
| mean 100 episode reward | 2.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8922   |
| steps                   | 675633   |
| td_erros                | 0.1031   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 89600    |
| lives                   | 89600    |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 7.43     |
| mean 100 episode reward | 2.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9214   |
| steps                   | 676276   |
| td_erros                | 0.0827   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 89700    |
| lives                   | 89700    |
| mean 100 episode ei     | 4.46     |
| mean 100 episode length | 7.65     |
| mean 100 episode reward | 3.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8827   |
| steps                   | 676941   |
| td_erros                | 0.0659   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 89800    |
| lives                   | 89800    |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 7.77     |
| mean 100 episode reward | 2.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8347   |
| steps                   | 677618   |
| td_erros                | 0.0647   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 58       |
| episodes                | 89900    |
| lives                   | 89900    |
| mean 100 episode ei     | 4.21     |
| mean 100 episode length | 7.49     |
| mean 100 episode reward | 2.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8078   |
| steps                   | 678267   |
| td_erros                | 0.0524   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 90000    |
| lives                   | 90000    |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 7.12     |
| mean 100 episode reward | 2.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8078   |
| steps                   | 678879   |
| td_erros                | 0.0554   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 90100    |
| lives                   | 90100    |
| mean 100 episode ei     | 4.69     |
| mean 100 episode length | 7.96     |
| mean 100 episode reward | 2.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8209   |
| steps                   | 679575   |
| td_erros                | 0.0684   |
--------------------------------------
Saving model due to running mean reward increase: 2.5379 -> 2.5751
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 90200    |
| lives                   | 90200    |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 7.8      |
| mean 100 episode reward | 2.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.822    |
| steps                   | 680255   |
| td_erros                | 0.0487   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 90300    |
| lives                   | 90300    |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 7.97     |
| mean 100 episode reward | 2.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8421   |
| steps                   | 680952   |
| td_erros                | 0.0222   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 90400    |
| lives                   | 90400    |
| mean 100 episode ei     | 4.32     |
| mean 100 episode length | 7.9      |
| mean 100 episode reward | 2.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8661   |
| steps                   | 681642   |
| td_erros                | 0.0178   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 90500    |
| lives                   | 90500    |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 7.85     |
| mean 100 episode reward | 2.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9057   |
| steps                   | 682327   |
| td_erros                | 0.033    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 90600    |
| lives                   | 90600    |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 7.65     |
| mean 100 episode reward | 2.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9089   |
| steps                   | 682992   |
| td_erros                | 0.0239   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 90700    |
| lives                   | 90700    |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 7.41     |
| mean 100 episode reward | 2.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8979   |
| steps                   | 683633   |
| td_erros                | 0.0271   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 90800    |
| lives                   | 90800    |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 7.72     |
| mean 100 episode reward | 2.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9403   |
| steps                   | 684305   |
| td_erros                | 0.0214   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 90900    |
| lives                   | 90900    |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 7.32     |
| mean 100 episode reward | 2.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9846   |
| steps                   | 684937   |
| td_erros                | 0.0615   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 91000    |
| lives                   | 91000    |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 7.99     |
| mean 100 episode reward | 2.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9331   |
| steps                   | 685636   |
| td_erros                | 0.0589   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 91100    |
| lives                   | 91100    |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 7.06     |
| mean 100 episode reward | 2.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.915    |
| steps                   | 686242   |
| td_erros                | 0.0723   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 91200    |
| lives                   | 91200    |
| mean 100 episode ei     | 3.71     |
| mean 100 episode length | 7.19     |
| mean 100 episode reward | 2.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8856   |
| steps                   | 686861   |
| td_erros                | 0.0886   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 91300    |
| lives                   | 91300    |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 7.29     |
| mean 100 episode reward | 2.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8351   |
| steps                   | 687490   |
| td_erros                | 0.0868   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 91400    |
| lives                   | 91400    |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 7.69     |
| mean 100 episode reward | 2.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.824    |
| steps                   | 688159   |
| td_erros                | 0.0919   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 91500    |
| lives                   | 91500    |
| mean 100 episode ei     | 3.57     |
| mean 100 episode length | 7.12     |
| mean 100 episode reward | 2.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8072   |
| steps                   | 688771   |
| td_erros                | 0.0896   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 91600    |
| lives                   | 91600    |
| mean 100 episode ei     | 3.57     |
| mean 100 episode length | 7.25     |
| mean 100 episode reward | 2.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7882   |
| steps                   | 689396   |
| td_erros                | 0.0798   |
--------------------------------------
Saving model due to running mean reward increase: 2.5411 -> 2.5488
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 91700    |
| lives                   | 91700    |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 7.4      |
| mean 100 episode reward | 2.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7298   |
| steps                   | 690036   |
| td_erros                | 0.1035   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 91800    |
| lives                   | 91800    |
| mean 100 episode ei     | 3.61     |
| mean 100 episode length | 7.44     |
| mean 100 episode reward | 2.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6652   |
| steps                   | 690680   |
| td_erros                | 0.0398   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 91900    |
| lives                   | 91900    |
| mean 100 episode ei     | 4.24     |
| mean 100 episode length | 7.92     |
| mean 100 episode reward | 3.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5843   |
| steps                   | 691372   |
| td_erros                | 0.0234   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 92000    |
| lives                   | 92000    |
| mean 100 episode ei     | 4.35     |
| mean 100 episode length | 7.49     |
| mean 100 episode reward | 2.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5666   |
| steps                   | 692021   |
| td_erros                | 0.0065   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 92100    |
| lives                   | 92100    |
| mean 100 episode ei     | 4.66     |
| mean 100 episode length | 7.7      |
| mean 100 episode reward | 2.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.511    |
| steps                   | 692691   |
| td_erros                | -0.0526  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 92200    |
| lives                   | 92200    |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 7.54     |
| mean 100 episode reward | 2        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5333   |
| steps                   | 693345   |
| td_erros                | -0.0464  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 92300    |
| lives                   | 92300    |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 7.63     |
| mean 100 episode reward | 2.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5687   |
| steps                   | 694008   |
| td_erros                | -0.0445  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 57       |
| episodes                | 92400    |
| lives                   | 92400    |
| mean 100 episode ei     | 4.24     |
| mean 100 episode length | 7.42     |
| mean 100 episode reward | 2.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6624   |
| steps                   | 694650   |
| td_erros                | -0.0498  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 92500    |
| lives                   | 92500    |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 7.25     |
| mean 100 episode reward | 2.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7831   |
| steps                   | 695275   |
| td_erros                | -0.0038  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 92600    |
| lives                   | 92600    |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 7.61     |
| mean 100 episode reward | 2.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8889   |
| steps                   | 695936   |
| td_erros                | 0.0292   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 92700    |
| lives                   | 92700    |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 8.25     |
| mean 100 episode reward | 2.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9565   |
| steps                   | 696661   |
| td_erros                | 0.0427   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 92800    |
| lives                   | 92800    |
| mean 100 episode ei     | 3.83     |
| mean 100 episode length | 7.19     |
| mean 100 episode reward | 2.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9127   |
| steps                   | 697280   |
| td_erros                | 0.0565   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 92900    |
| lives                   | 92900    |
| mean 100 episode ei     | 3.55     |
| mean 100 episode length | 6.78     |
| mean 100 episode reward | 2.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9199   |
| steps                   | 697858   |
| td_erros                | 0.0623   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 93000    |
| lives                   | 93000    |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 7.53     |
| mean 100 episode reward | 2.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9921   |
| steps                   | 698511   |
| td_erros                | 0.1281   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 93100    |
| lives                   | 93100    |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 7.9      |
| mean 100 episode reward | 2.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9035   |
| steps                   | 699201   |
| td_erros                | 0.1007   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 93200    |
| lives                   | 93200    |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 7.89     |
| mean 100 episode reward | 2.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8821   |
| steps                   | 699890   |
| td_erros                | 0.1023   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 93300    |
| lives                   | 93300    |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 7.25     |
| mean 100 episode reward | 2.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8661   |
| steps                   | 700515   |
| td_erros                | 0.1134   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 93400    |
| lives                   | 93400    |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 7.75     |
| mean 100 episode reward | 2.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8558   |
| steps                   | 701190   |
| td_erros                | 0.1064   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 93500    |
| lives                   | 93500    |
| mean 100 episode ei     | 4.72     |
| mean 100 episode length | 8.22     |
| mean 100 episode reward | 2.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8543   |
| steps                   | 701912   |
| td_erros                | 0.1172   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 93600    |
| lives                   | 93600    |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 7.46     |
| mean 100 episode reward | 2.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9806   |
| steps                   | 702558   |
| td_erros                | 0.1176   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 93700    |
| lives                   | 93700    |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 7.13     |
| mean 100 episode reward | 2.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.09     |
| steps                   | 703171   |
| td_erros                | 0.1645   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 93800    |
| lives                   | 93800    |
| mean 100 episode ei     | 3.58     |
| mean 100 episode length | 7.13     |
| mean 100 episode reward | 1.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1802   |
| steps                   | 703784   |
| td_erros                | 0.1904   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 93900    |
| lives                   | 93900    |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 7.31     |
| mean 100 episode reward | 2.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1987   |
| steps                   | 704415   |
| td_erros                | 0.2133   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 94000    |
| lives                   | 94000    |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 7.69     |
| mean 100 episode reward | 2.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1658   |
| steps                   | 705084   |
| td_erros                | 0.1828   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 94100    |
| lives                   | 94100    |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 6.91     |
| mean 100 episode reward | 2.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1458   |
| steps                   | 705675   |
| td_erros                | 0.1715   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 94200    |
| lives                   | 94200    |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 7.63     |
| mean 100 episode reward | 2.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1402   |
| steps                   | 706338   |
| td_erros                | 0.1544   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 94300    |
| lives                   | 94300    |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 7.23     |
| mean 100 episode reward | 2.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1162   |
| steps                   | 706961   |
| td_erros                | 0.155    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 94400    |
| lives                   | 94400    |
| mean 100 episode ei     | 3.68     |
| mean 100 episode length | 6.82     |
| mean 100 episode reward | 2.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0286   |
| steps                   | 707543   |
| td_erros                | 0.1509   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 94500    |
| lives                   | 94500    |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 7.6      |
| mean 100 episode reward | 2.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8759   |
| steps                   | 708203   |
| td_erros                | 0.1015   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 94600    |
| lives                   | 94600    |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 7.82     |
| mean 100 episode reward | 2.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8831   |
| steps                   | 708885   |
| td_erros                | 0.1132   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 94700    |
| lives                   | 94700    |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 7.73     |
| mean 100 episode reward | 2.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8865   |
| steps                   | 709558   |
| td_erros                | 0.1311   |
--------------------------------------
Saving model due to running mean reward increase: 2.1845 -> 2.4175
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 94800    |
| lives                   | 94800    |
| mean 100 episode ei     | 4.47     |
| mean 100 episode length | 7.65     |
| mean 100 episode reward | 2.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8196   |
| steps                   | 710223   |
| td_erros                | 0.0984   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 56       |
| episodes                | 94900    |
| lives                   | 94900    |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 7.01     |
| mean 100 episode reward | 1.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8419   |
| steps                   | 710824   |
| td_erros                | 0.0838   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 95000    |
| lives                   | 95000    |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 7.13     |
| mean 100 episode reward | 2.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8598   |
| steps                   | 711437   |
| td_erros                | 0.1099   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 95100    |
| lives                   | 95100    |
| mean 100 episode ei     | 4.47     |
| mean 100 episode length | 8.56     |
| mean 100 episode reward | 2.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8964   |
| steps                   | 712193   |
| td_erros                | 0.12     |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 95200    |
| lives                   | 95200    |
| mean 100 episode ei     | 3.7      |
| mean 100 episode length | 7.42     |
| mean 100 episode reward | 2.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.917    |
| steps                   | 712835   |
| td_erros                | 0.129    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 95300    |
| lives                   | 95300    |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 7.13     |
| mean 100 episode reward | 3.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9208   |
| steps                   | 713448   |
| td_erros                | 0.1342   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 95400    |
| lives                   | 95400    |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 7.28     |
| mean 100 episode reward | 3.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9289   |
| steps                   | 714076   |
| td_erros                | 0.1148   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 95500    |
| lives                   | 95500    |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 7.43     |
| mean 100 episode reward | 2.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9412   |
| steps                   | 714719   |
| td_erros                | 0.0992   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 95600    |
| lives                   | 95600    |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 8.03     |
| mean 100 episode reward | 2.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9267   |
| steps                   | 715422   |
| td_erros                | 0.1001   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 95700    |
| lives                   | 95700    |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 8.32     |
| mean 100 episode reward | 2.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8537   |
| steps                   | 716154   |
| td_erros                | 0.0672   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 95800    |
| lives                   | 95800    |
| mean 100 episode ei     | 3.2      |
| mean 100 episode length | 6.59     |
| mean 100 episode reward | 2.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8015   |
| steps                   | 716713   |
| td_erros                | 0.05     |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 95900    |
| lives                   | 95900    |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 7.65     |
| mean 100 episode reward | 2.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7643   |
| steps                   | 717378   |
| td_erros                | 0.0328   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 96000    |
| lives                   | 96000    |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 8.12     |
| mean 100 episode reward | 2.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6799   |
| steps                   | 718090   |
| td_erros                | -0.0025  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 96100    |
| lives                   | 96100    |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 8.34     |
| mean 100 episode reward | 2.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6243   |
| steps                   | 718824   |
| td_erros                | -0.0139  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 96200    |
| lives                   | 96200    |
| mean 100 episode ei     | 4.86     |
| mean 100 episode length | 7.7      |
| mean 100 episode reward | 3.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.599    |
| steps                   | 719494   |
| td_erros                | -0.0174  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 96300    |
| lives                   | 96300    |
| mean 100 episode ei     | 4.95     |
| mean 100 episode length | 7.5      |
| mean 100 episode reward | 2.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6299   |
| steps                   | 720144   |
| td_erros                | -0.0115  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 96400    |
| lives                   | 96400    |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 7.58     |
| mean 100 episode reward | 2.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6363   |
| steps                   | 720802   |
| td_erros                | -0.0114  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 96500    |
| lives                   | 96500    |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 6.94     |
| mean 100 episode reward | 3.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7728   |
| steps                   | 721396   |
| td_erros                | -0.0091  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 96600    |
| lives                   | 96600    |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 7.19     |
| mean 100 episode reward | 2.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8306   |
| steps                   | 722015   |
| td_erros                | 0.0045   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 96700    |
| lives                   | 96700    |
| mean 100 episode ei     | 4.55     |
| mean 100 episode length | 7.33     |
| mean 100 episode reward | 3.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9216   |
| steps                   | 722648   |
| td_erros                | 0.0386   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 96800    |
| lives                   | 96800    |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 6.92     |
| mean 100 episode reward | 3.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0234   |
| steps                   | 723240   |
| td_erros                | 0.0927   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 96900    |
| lives                   | 96900    |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 7.08     |
| mean 100 episode reward | 3.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1087   |
| steps                   | 723848   |
| td_erros                | 0.1189   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 97000    |
| lives                   | 97000    |
| mean 100 episode ei     | 4.41     |
| mean 100 episode length | 7.75     |
| mean 100 episode reward | 3.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.173    |
| steps                   | 724523   |
| td_erros                | 0.1369   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 97100    |
| lives                   | 97100    |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 7.76     |
| mean 100 episode reward | 2.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.1769   |
| steps                   | 725199   |
| td_erros                | 0.1554   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 97200    |
| lives                   | 97200    |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 7.98     |
| mean 100 episode reward | 2.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.123    |
| steps                   | 725897   |
| td_erros                | 0.1476   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 97300    |
| lives                   | 97300    |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 7.9      |
| mean 100 episode reward | 2.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0664   |
| steps                   | 726587   |
| td_erros                | 0.1265   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 55       |
| episodes                | 97400    |
| lives                   | 97400    |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 7.73     |
| mean 100 episode reward | 2.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0389   |
| steps                   | 727260   |
| td_erros                | 0.127    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 97500    |
| lives                   | 97500    |
| mean 100 episode ei     | 4.45     |
| mean 100 episode length | 7.76     |
| mean 100 episode reward | 2.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 3.0006   |
| steps                   | 727936   |
| td_erros                | 0.1354   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 97600    |
| lives                   | 97600    |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 7.85     |
| mean 100 episode reward | 2.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9457   |
| steps                   | 728621   |
| td_erros                | 0.1162   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 97700    |
| lives                   | 97700    |
| mean 100 episode ei     | 4.23     |
| mean 100 episode length | 8.08     |
| mean 100 episode reward | 2.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.842    |
| steps                   | 729329   |
| td_erros                | 0.0792   |
--------------------------------------
Saving model due to mean reward increase: 2.78 -> 3.0312
Saving model due to running mean reward increase: 2.1957 -> 3.0312
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 97800    |
| lives                   | 97800    |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 8.2      |
| mean 100 episode reward | 3.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7843   |
| steps                   | 730049   |
| td_erros                | 0.0505   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 97900    |
| lives                   | 97900    |
| mean 100 episode ei     | 4.23     |
| mean 100 episode length | 7.67     |
| mean 100 episode reward | 3.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7827   |
| steps                   | 730716   |
| td_erros                | 0.0462   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 98000    |
| lives                   | 98000    |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 7.73     |
| mean 100 episode reward | 3.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7751   |
| steps                   | 731389   |
| td_erros                | 0.0552   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 98100    |
| lives                   | 98100    |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 7.67     |
| mean 100 episode reward | 2.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7812   |
| steps                   | 732056   |
| td_erros                | 0.0719   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 98200    |
| lives                   | 98200    |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 7.73     |
| mean 100 episode reward | 2.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8495   |
| steps                   | 732729   |
| td_erros                | 0.0796   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 98300    |
| lives                   | 98300    |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 7.14     |
| mean 100 episode reward | 2.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.909    |
| steps                   | 733343   |
| td_erros                | 0.1161   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 98400    |
| lives                   | 98400    |
| mean 100 episode ei     | 3.8      |
| mean 100 episode length | 7.31     |
| mean 100 episode reward | 2.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8956   |
| steps                   | 733974   |
| td_erros                | 0.1134   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 98500    |
| lives                   | 98500    |
| mean 100 episode ei     | 4.33     |
| mean 100 episode length | 7.44     |
| mean 100 episode reward | 2.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8735   |
| steps                   | 734618   |
| td_erros                | 0.1078   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 98600    |
| lives                   | 98600    |
| mean 100 episode ei     | 4.33     |
| mean 100 episode length | 7.63     |
| mean 100 episode reward | 2.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8551   |
| steps                   | 735281   |
| td_erros                | 0.0897   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 98700    |
| lives                   | 98700    |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 7.6      |
| mean 100 episode reward | 2.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8444   |
| steps                   | 735941   |
| td_erros                | 0.0709   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 98800    |
| lives                   | 98800    |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 7.86     |
| mean 100 episode reward | 2.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7916   |
| steps                   | 736627   |
| td_erros                | 0.0403   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 98900    |
| lives                   | 98900    |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 7.51     |
| mean 100 episode reward | 2.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7259   |
| steps                   | 737278   |
| td_erros                | 0.0074   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 99000    |
| lives                   | 99000    |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 7.32     |
| mean 100 episode reward | 2.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6697   |
| steps                   | 737910   |
| td_erros                | -0.0125  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 99100    |
| lives                   | 99100    |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 7.5      |
| mean 100 episode reward | 2.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6776   |
| steps                   | 738560   |
| td_erros                | -0.0107  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 99200    |
| lives                   | 99200    |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 7.2      |
| mean 100 episode reward | 3        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6684   |
| steps                   | 739180   |
| td_erros                | 0.0079   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 99300    |
| lives                   | 99300    |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 7.58     |
| mean 100 episode reward | 2.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6621   |
| steps                   | 739838   |
| td_erros                | -0.0018  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 99400    |
| lives                   | 99400    |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 7.3      |
| mean 100 episode reward | 2.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6504   |
| steps                   | 740468   |
| td_erros                | 0.0078   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 99500    |
| lives                   | 99500    |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 7.61     |
| mean 100 episode reward | 2.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6836   |
| steps                   | 741129   |
| td_erros                | 0.0222   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 99600    |
| lives                   | 99600    |
| mean 100 episode ei     | 4.93     |
| mean 100 episode length | 8.31     |
| mean 100 episode reward | 2.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6849   |
| steps                   | 741860   |
| td_erros                | 0.0072   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 99700    |
| lives                   | 99700    |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 7.28     |
| mean 100 episode reward | 2.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7188   |
| steps                   | 742488   |
| td_erros                | 1e-04    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 54       |
| episodes                | 99800    |
| lives                   | 99800    |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 7.19     |
| mean 100 episode reward | 3.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7678   |
| steps                   | 743107   |
| td_erros                | 0.0289   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 99900    |
| lives                   | 99900    |
| mean 100 episode ei     | 3.68     |
| mean 100 episode length | 6.48     |
| mean 100 episode reward | 2.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7684   |
| steps                   | 743655   |
| td_erros                | 0.0377   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 100000   |
| lives                   | 100000   |
| mean 100 episode ei     | 3.58     |
| mean 100 episode length | 6.85     |
| mean 100 episode reward | 2.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7637   |
| steps                   | 744240   |
| td_erros                | 0.0208   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 100100   |
| lives                   | 100100   |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 7.35     |
| mean 100 episode reward | 2.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7269   |
| steps                   | 744875   |
| td_erros                | -0.0091  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 100200   |
| lives                   | 100200   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 7.4      |
| mean 100 episode reward | 2.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7257   |
| steps                   | 745515   |
| td_erros                | 0.0005   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 100300   |
| lives                   | 100300   |
| mean 100 episode ei     | 4.52     |
| mean 100 episode length | 7.66     |
| mean 100 episode reward | 2.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7499   |
| steps                   | 746181   |
| td_erros                | 0.0035   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 100400   |
| lives                   | 100400   |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 7.97     |
| mean 100 episode reward | 2.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6772   |
| steps                   | 746878   |
| td_erros                | -0.002   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 100500   |
| lives                   | 100500   |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 7.57     |
| mean 100 episode reward | 2.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6328   |
| steps                   | 747535   |
| td_erros                | -0.0356  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 100600   |
| lives                   | 100600   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 7.68     |
| mean 100 episode reward | 2.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6201   |
| steps                   | 748203   |
| td_erros                | -0.0539  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 100700   |
| lives                   | 100700   |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 7.76     |
| mean 100 episode reward | 3.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6343   |
| steps                   | 748879   |
| td_erros                | -0.0511  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 100800   |
| lives                   | 100800   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 7.03     |
| mean 100 episode reward | 2.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.711    |
| steps                   | 749482   |
| td_erros                | -0.0025  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 100900   |
| lives                   | 100900   |
| mean 100 episode ei     | 4.4      |
| mean 100 episode length | 7.56     |
| mean 100 episode reward | 1.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7135   |
| steps                   | 750138   |
| td_erros                | -0.0289  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 101000   |
| lives                   | 101000   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 7.29     |
| mean 100 episode reward | 2.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7165   |
| steps                   | 750767   |
| td_erros                | -0.0316  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 101100   |
| lives                   | 101100   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 7.02     |
| mean 100 episode reward | 3.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7305   |
| steps                   | 751369   |
| td_erros                | -0.0317  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 101200   |
| lives                   | 101200   |
| mean 100 episode ei     | 3.45     |
| mean 100 episode length | 6.92     |
| mean 100 episode reward | 2.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7074   |
| steps                   | 751961   |
| td_erros                | -0.044   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 101300   |
| lives                   | 101300   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 7.56     |
| mean 100 episode reward | 3.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6577   |
| steps                   | 752617   |
| td_erros                | -0.0397  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 101400   |
| lives                   | 101400   |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 7.15     |
| mean 100 episode reward | 2.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6401   |
| steps                   | 753232   |
| td_erros                | -0.0252  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 101500   |
| lives                   | 101500   |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 7.75     |
| mean 100 episode reward | 1.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5966   |
| steps                   | 753907   |
| td_erros                | -0.0578  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 101600   |
| lives                   | 101600   |
| mean 100 episode ei     | 4.8      |
| mean 100 episode length | 7.66     |
| mean 100 episode reward | 2.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5318   |
| steps                   | 754573   |
| td_erros                | -0.1009  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 101700   |
| lives                   | 101700   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 6.87     |
| mean 100 episode reward | 2.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5543   |
| steps                   | 755160   |
| td_erros                | -0.078   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 101800   |
| lives                   | 101800   |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 7.77     |
| mean 100 episode reward | 2.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5133   |
| steps                   | 755837   |
| td_erros                | -0.0694  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 101900   |
| lives                   | 101900   |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 7.27     |
| mean 100 episode reward | 2.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5266   |
| steps                   | 756464   |
| td_erros                | -0.0547  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 102000   |
| lives                   | 102000   |
| mean 100 episode ei     | 3.49     |
| mean 100 episode length | 6.65     |
| mean 100 episode reward | 2.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5274   |
| steps                   | 757029   |
| td_erros                | -0.0685  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 102100   |
| lives                   | 102100   |
| mean 100 episode ei     | 3.6      |
| mean 100 episode length | 6.7      |
| mean 100 episode reward | 2.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5198   |
| steps                   | 757599   |
| td_erros                | -0.04    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 102200   |
| lives                   | 102200   |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 7.32     |
| mean 100 episode reward | 3        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5942   |
| steps                   | 758231   |
| td_erros                | -0.0109  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 102300   |
| lives                   | 102300   |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 7.77     |
| mean 100 episode reward | 2.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6515   |
| steps                   | 758908   |
| td_erros                | 0.0098   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 53       |
| episodes                | 102400   |
| lives                   | 102400   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 7.44     |
| mean 100 episode reward | 2.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6638   |
| steps                   | 759552   |
| td_erros                | 0.0455   |
--------------------------------------
Saving model due to running mean reward increase: 2.2763 -> 2.916
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 102500   |
| lives                   | 102500   |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 7.47     |
| mean 100 episode reward | 2.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7031   |
| steps                   | 760199   |
| td_erros                | 0.0757   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 102600   |
| lives                   | 102600   |
| mean 100 episode ei     | 3.53     |
| mean 100 episode length | 6.81     |
| mean 100 episode reward | 2.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7171   |
| steps                   | 760780   |
| td_erros                | 0.0831   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 102700   |
| lives                   | 102700   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 7.45     |
| mean 100 episode reward | 2.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7186   |
| steps                   | 761425   |
| td_erros                | 0.0808   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 102800   |
| lives                   | 102800   |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 7.18     |
| mean 100 episode reward | 2.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6494   |
| steps                   | 762043   |
| td_erros                | 0.0264   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 102900   |
| lives                   | 102900   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 7.59     |
| mean 100 episode reward | 2.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6386   |
| steps                   | 762702   |
| td_erros                | 0.0092   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 103000   |
| lives                   | 103000   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 7.54     |
| mean 100 episode reward | 2.57     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6481   |
| steps                   | 763356   |
| td_erros                | -0.0004  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 103100   |
| lives                   | 103100   |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 7.5      |
| mean 100 episode reward | 3.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6206   |
| steps                   | 764006   |
| td_erros                | -0.0205  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 103200   |
| lives                   | 103200   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 7.28     |
| mean 100 episode reward | 2.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6147   |
| steps                   | 764634   |
| td_erros                | -0.0057  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 103300   |
| lives                   | 103300   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 6.88     |
| mean 100 episode reward | 2.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6072   |
| steps                   | 765222   |
| td_erros                | -0.0241  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 103400   |
| lives                   | 103400   |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 7.27     |
| mean 100 episode reward | 2.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5869   |
| steps                   | 765849   |
| td_erros                | -0.0293  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 103500   |
| lives                   | 103500   |
| mean 100 episode ei     | 4.83     |
| mean 100 episode length | 7.79     |
| mean 100 episode reward | 2.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5636   |
| steps                   | 766528   |
| td_erros                | -0.0495  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 103600   |
| lives                   | 103600   |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 7.45     |
| mean 100 episode reward | 2.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6085   |
| steps                   | 767173   |
| td_erros                | -0.0309  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 103700   |
| lives                   | 103700   |
| mean 100 episode ei     | 4.43     |
| mean 100 episode length | 7.59     |
| mean 100 episode reward | 2.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.621    |
| steps                   | 767832   |
| td_erros                | -0.0415  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 103800   |
| lives                   | 103800   |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 7.68     |
| mean 100 episode reward | 2.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.664    |
| steps                   | 768500   |
| td_erros                | -0.0346  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 103900   |
| lives                   | 103900   |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 7.42     |
| mean 100 episode reward | 2.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7054   |
| steps                   | 769142   |
| td_erros                | -0.0293  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 104000   |
| lives                   | 104000   |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 7.36     |
| mean 100 episode reward | 2.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7089   |
| steps                   | 769778   |
| td_erros                | -0.0229  |
--------------------------------------
Saving model due to running mean reward increase: 2.5272 -> 2.7954
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 104100   |
| lives                   | 104100   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 7.72     |
| mean 100 episode reward | 3.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6907   |
| steps                   | 770450   |
| td_erros                | -0.0204  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 104200   |
| lives                   | 104200   |
| mean 100 episode ei     | 4.48     |
| mean 100 episode length | 7.9      |
| mean 100 episode reward | 3.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6456   |
| steps                   | 771140   |
| td_erros                | -0.0583  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 104300   |
| lives                   | 104300   |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 7.5      |
| mean 100 episode reward | 3.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6709   |
| steps                   | 771790   |
| td_erros                | -0.0442  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 104400   |
| lives                   | 104400   |
| mean 100 episode ei     | 4.36     |
| mean 100 episode length | 7.82     |
| mean 100 episode reward | 3.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6977   |
| steps                   | 772472   |
| td_erros                | -0.0245  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 104500   |
| lives                   | 104500   |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 7.26     |
| mean 100 episode reward | 3.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6623   |
| steps                   | 773098   |
| td_erros                | -0.0378  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 104600   |
| lives                   | 104600   |
| mean 100 episode ei     | 4.4      |
| mean 100 episode length | 7.46     |
| mean 100 episode reward | 3.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6505   |
| steps                   | 773744   |
| td_erros                | -0.0396  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 104700   |
| lives                   | 104700   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 7.43     |
| mean 100 episode reward | 2.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6693   |
| steps                   | 774387   |
| td_erros                | -0.0475  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 104800   |
| lives                   | 104800   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 7.25     |
| mean 100 episode reward | 2.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6839   |
| steps                   | 775012   |
| td_erros                | -0.0492  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 52       |
| episodes                | 104900   |
| lives                   | 104900   |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 7.47     |
| mean 100 episode reward | 2.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.711    |
| steps                   | 775659   |
| td_erros                | -0.0218  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 105000   |
| lives                   | 105000   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 7.55     |
| mean 100 episode reward | 2.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6763   |
| steps                   | 776314   |
| td_erros                | -0.0309  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 105100   |
| lives                   | 105100   |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 7.75     |
| mean 100 episode reward | 3.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6752   |
| steps                   | 776989   |
| td_erros                | -0.0614  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 105200   |
| lives                   | 105200   |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 7.52     |
| mean 100 episode reward | 2.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.661    |
| steps                   | 777641   |
| td_erros                | -0.0829  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 105300   |
| lives                   | 105300   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 6.97     |
| mean 100 episode reward | 2.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6734   |
| steps                   | 778238   |
| td_erros                | -0.0714  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 105400   |
| lives                   | 105400   |
| mean 100 episode ei     | 4.35     |
| mean 100 episode length | 7.38     |
| mean 100 episode reward | 2.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6598   |
| steps                   | 778876   |
| td_erros                | -0.0815  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 105500   |
| lives                   | 105500   |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 7.18     |
| mean 100 episode reward | 2.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6562   |
| steps                   | 779494   |
| td_erros                | -0.0821  |
--------------------------------------
Saving model due to running mean reward increase: 2.0145 -> 2.4488
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 105600   |
| lives                   | 105600   |
| mean 100 episode ei     | 4.43     |
| mean 100 episode length | 7.14     |
| mean 100 episode reward | 2.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6653   |
| steps                   | 780108   |
| td_erros                | -0.0908  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 105700   |
| lives                   | 105700   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 7.29     |
| mean 100 episode reward | 3.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6546   |
| steps                   | 780737   |
| td_erros                | -0.0868  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 105800   |
| lives                   | 105800   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 7.41     |
| mean 100 episode reward | 2.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6726   |
| steps                   | 781378   |
| td_erros                | -0.0651  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 105900   |
| lives                   | 105900   |
| mean 100 episode ei     | 3.63     |
| mean 100 episode length | 6.83     |
| mean 100 episode reward | 2.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.623    |
| steps                   | 781961   |
| td_erros                | -0.0712  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 106000   |
| lives                   | 106000   |
| mean 100 episode ei     | 3.7      |
| mean 100 episode length | 7.43     |
| mean 100 episode reward | 2.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5924   |
| steps                   | 782604   |
| td_erros                | -0.0638  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 106100   |
| lives                   | 106100   |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 7.59     |
| mean 100 episode reward | 2.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5675   |
| steps                   | 783263   |
| td_erros                | -0.052   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 106200   |
| lives                   | 106200   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 7.16     |
| mean 100 episode reward | 3.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5654   |
| steps                   | 783879   |
| td_erros                | -0.0514  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 106300   |
| lives                   | 106300   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 7.29     |
| mean 100 episode reward | 3.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5243   |
| steps                   | 784508   |
| td_erros                | -0.045   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 106400   |
| lives                   | 106400   |
| mean 100 episode ei     | 4.24     |
| mean 100 episode length | 7.91     |
| mean 100 episode reward | 2.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4923   |
| steps                   | 785199   |
| td_erros                | -0.0246  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 106500   |
| lives                   | 106500   |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 7.44     |
| mean 100 episode reward | 2.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4862   |
| steps                   | 785843   |
| td_erros                | -0.0323  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 106600   |
| lives                   | 106600   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 7.38     |
| mean 100 episode reward | 3.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4768   |
| steps                   | 786481   |
| td_erros                | -0.0535  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 106700   |
| lives                   | 106700   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 6.77     |
| mean 100 episode reward | 3.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5299   |
| steps                   | 787058   |
| td_erros                | -0.0185  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 106800   |
| lives                   | 106800   |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 6.79     |
| mean 100 episode reward | 3.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5384   |
| steps                   | 787637   |
| td_erros                | -0.029   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 106900   |
| lives                   | 106900   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 7.38     |
| mean 100 episode reward | 2.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5389   |
| steps                   | 788275   |
| td_erros                | -0.0432  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 107000   |
| lives                   | 107000   |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 6.57     |
| mean 100 episode reward | 3.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5528   |
| steps                   | 788832   |
| td_erros                | -0.0292  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 107100   |
| lives                   | 107100   |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 6.89     |
| mean 100 episode reward | 2.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5597   |
| steps                   | 789421   |
| td_erros                | -0.0095  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 107200   |
| lives                   | 107200   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 6.92     |
| mean 100 episode reward | 2.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6236   |
| steps                   | 790013   |
| td_erros                | 0.0077   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 107300   |
| lives                   | 107300   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 6.7      |
| mean 100 episode reward | 2.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.636    |
| steps                   | 790583   |
| td_erros                | -0.0149  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 107400   |
| lives                   | 107400   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 7.05     |
| mean 100 episode reward | 2.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6684   |
| steps                   | 791188   |
| td_erros                | 0.0049   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 51       |
| episodes                | 107500   |
| lives                   | 107500   |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 6.74     |
| mean 100 episode reward | 2.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6406   |
| steps                   | 791762   |
| td_erros                | 0.0037   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 107600   |
| lives                   | 107600   |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 7.36     |
| mean 100 episode reward | 2.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6548   |
| steps                   | 792398   |
| td_erros                | 0.0061   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 107700   |
| lives                   | 107700   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 7.02     |
| mean 100 episode reward | 2.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.649    |
| steps                   | 793000   |
| td_erros                | 0.0134   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 107800   |
| lives                   | 107800   |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 6.68     |
| mean 100 episode reward | 3.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6581   |
| steps                   | 793568   |
| td_erros                | 0.0021   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 107900   |
| lives                   | 107900   |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 6.75     |
| mean 100 episode reward | 3.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6318   |
| steps                   | 794143   |
| td_erros                | -0.0076  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 108000   |
| lives                   | 108000   |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 7.3      |
| mean 100 episode reward | 2.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5358   |
| steps                   | 794773   |
| td_erros                | -0.0481  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 108100   |
| lives                   | 108100   |
| mean 100 episode ei     | 3.8      |
| mean 100 episode length | 6.58     |
| mean 100 episode reward | 2.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5014   |
| steps                   | 795331   |
| td_erros                | -0.0346  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 108200   |
| lives                   | 108200   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 7.34     |
| mean 100 episode reward | 2.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4761   |
| steps                   | 795965   |
| td_erros                | -0.0517  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 108300   |
| lives                   | 108300   |
| mean 100 episode ei     | 3.63     |
| mean 100 episode length | 6.49     |
| mean 100 episode reward | 2.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4536   |
| steps                   | 796514   |
| td_erros                | -0.0751  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 108400   |
| lives                   | 108400   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 7.33     |
| mean 100 episode reward | 2.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4566   |
| steps                   | 797147   |
| td_erros                | -0.0469  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 108500   |
| lives                   | 108500   |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 7.32     |
| mean 100 episode reward | 2.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4531   |
| steps                   | 797779   |
| td_erros                | -0.0495  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 108600   |
| lives                   | 108600   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 7.86     |
| mean 100 episode reward | 2.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4441   |
| steps                   | 798465   |
| td_erros                | -0.0491  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 108700   |
| lives                   | 108700   |
| mean 100 episode ei     | 4.23     |
| mean 100 episode length | 7.59     |
| mean 100 episode reward | 2.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4411   |
| steps                   | 799124   |
| td_erros                | -0.0618  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 108800   |
| lives                   | 108800   |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 7.57     |
| mean 100 episode reward | 3.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4307   |
| steps                   | 799781   |
| td_erros                | -0.1033  |
--------------------------------------
Saving model due to mean reward increase: 3.0312 -> 3.3476
Saving model due to running mean reward increase: 2.5401 -> 3.3476
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 108900   |
| lives                   | 108900   |
| mean 100 episode ei     | 3.75     |
| mean 100 episode length | 7.06     |
| mean 100 episode reward | 2.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4507   |
| steps                   | 800387   |
| td_erros                | -0.1013  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 109000   |
| lives                   | 109000   |
| mean 100 episode ei     | 3.8      |
| mean 100 episode length | 6.97     |
| mean 100 episode reward | 3.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5018   |
| steps                   | 800984   |
| td_erros                | -0.0887  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 109100   |
| lives                   | 109100   |
| mean 100 episode ei     | 4.52     |
| mean 100 episode length | 7.85     |
| mean 100 episode reward | 2.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5105   |
| steps                   | 801669   |
| td_erros                | -0.1005  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 109200   |
| lives                   | 109200   |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 7.1      |
| mean 100 episode reward | 2.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5508   |
| steps                   | 802279   |
| td_erros                | -0.1075  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 109300   |
| lives                   | 109300   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 7.16     |
| mean 100 episode reward | 3.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5382   |
| steps                   | 802895   |
| td_erros                | -0.1141  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 109400   |
| lives                   | 109400   |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 7.59     |
| mean 100 episode reward | 3.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5201   |
| steps                   | 803554   |
| td_erros                | -0.1338  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 109500   |
| lives                   | 109500   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 6.9      |
| mean 100 episode reward | 3.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5405   |
| steps                   | 804144   |
| td_erros                | -0.0909  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 109600   |
| lives                   | 109600   |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 7.33     |
| mean 100 episode reward | 3.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5145   |
| steps                   | 804777   |
| td_erros                | -0.0919  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 109700   |
| lives                   | 109700   |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 6.69     |
| mean 100 episode reward | 2.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5062   |
| steps                   | 805346   |
| td_erros                | -0.0585  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 109800   |
| lives                   | 109800   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 6.85     |
| mean 100 episode reward | 2.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5624   |
| steps                   | 805931   |
| td_erros                | -0.032   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 109900   |
| lives                   | 109900   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 7.4      |
| mean 100 episode reward | 3.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5767   |
| steps                   | 806571   |
| td_erros                | -0.0139  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 110000   |
| lives                   | 110000   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 6.98     |
| mean 100 episode reward | 3.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6047   |
| steps                   | 807169   |
| td_erros                | -0.0038  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 50       |
| episodes                | 110100   |
| lives                   | 110100   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 6.42     |
| mean 100 episode reward | 2.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6066   |
| steps                   | 807711   |
| td_erros                | 0.0175   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 110200   |
| lives                   | 110200   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 6.83     |
| mean 100 episode reward | 2.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6484   |
| steps                   | 808294   |
| td_erros                | 0.0263   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 110300   |
| lives                   | 110300   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 6.85     |
| mean 100 episode reward | 2.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.663    |
| steps                   | 808879   |
| td_erros                | 0.0319   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 110400   |
| lives                   | 110400   |
| mean 100 episode ei     | 4.23     |
| mean 100 episode length | 7.03     |
| mean 100 episode reward | 3.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6483   |
| steps                   | 809482   |
| td_erros                | 0.0336   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 110500   |
| lives                   | 110500   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 7.66     |
| mean 100 episode reward | 2.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7095   |
| steps                   | 810148   |
| td_erros                | 0.0461   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 110600   |
| lives                   | 110600   |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 7.77     |
| mean 100 episode reward | 2.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6507   |
| steps                   | 810825   |
| td_erros                | 0.0277   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 110700   |
| lives                   | 110700   |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 6.79     |
| mean 100 episode reward | 2.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6805   |
| steps                   | 811404   |
| td_erros                | 0.059    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 110800   |
| lives                   | 110800   |
| mean 100 episode ei     | 3.52     |
| mean 100 episode length | 7.19     |
| mean 100 episode reward | 2.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7023   |
| steps                   | 812023   |
| td_erros                | 0.0748   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 110900   |
| lives                   | 110900   |
| mean 100 episode ei     | 3.49     |
| mean 100 episode length | 7.13     |
| mean 100 episode reward | 2.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6975   |
| steps                   | 812636   |
| td_erros                | 0.0749   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 111000   |
| lives                   | 111000   |
| mean 100 episode ei     | 3.7      |
| mean 100 episode length | 7.41     |
| mean 100 episode reward | 2.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6889   |
| steps                   | 813277   |
| td_erros                | 0.085    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 111100   |
| lives                   | 111100   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 7.03     |
| mean 100 episode reward | 2.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6761   |
| steps                   | 813880   |
| td_erros                | 0.087    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 111200   |
| lives                   | 111200   |
| mean 100 episode ei     | 3.57     |
| mean 100 episode length | 6.6      |
| mean 100 episode reward | 3.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6295   |
| steps                   | 814440   |
| td_erros                | 0.0728   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 111300   |
| lives                   | 111300   |
| mean 100 episode ei     | 3.68     |
| mean 100 episode length | 7.03     |
| mean 100 episode reward | 2.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6341   |
| steps                   | 815043   |
| td_erros                | 0.058    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 111400   |
| lives                   | 111400   |
| mean 100 episode ei     | 4.56     |
| mean 100 episode length | 7.65     |
| mean 100 episode reward | 2.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.628    |
| steps                   | 815708   |
| td_erros                | 0.0836   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 111500   |
| lives                   | 111500   |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 7.6      |
| mean 100 episode reward | 3.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6039   |
| steps                   | 816368   |
| td_erros                | 0.0589   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 111600   |
| lives                   | 111600   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 6.94     |
| mean 100 episode reward | 2.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6275   |
| steps                   | 816962   |
| td_erros                | 0.0334   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 111700   |
| lives                   | 111700   |
| mean 100 episode ei     | 3.3      |
| mean 100 episode length | 6.29     |
| mean 100 episode reward | 2.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6577   |
| steps                   | 817491   |
| td_erros                | 0.061    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 111800   |
| lives                   | 111800   |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 6.94     |
| mean 100 episode reward | 2.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6357   |
| steps                   | 818085   |
| td_erros                | 0.0624   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 111900   |
| lives                   | 111900   |
| mean 100 episode ei     | 3.79     |
| mean 100 episode length | 7.48     |
| mean 100 episode reward | 2.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6687   |
| steps                   | 818733   |
| td_erros                | 0.0773   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 112000   |
| lives                   | 112000   |
| mean 100 episode ei     | 3.69     |
| mean 100 episode length | 7.67     |
| mean 100 episode reward | 2.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.595    |
| steps                   | 819400   |
| td_erros                | 0.0667   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 112100   |
| lives                   | 112100   |
| mean 100 episode ei     | 3.35     |
| mean 100 episode length | 6.32     |
| mean 100 episode reward | 2.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5571   |
| steps                   | 819932   |
| td_erros                | 0.0452   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 112200   |
| lives                   | 112200   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 7.18     |
| mean 100 episode reward | 3.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5818   |
| steps                   | 820550   |
| td_erros                | 0.0654   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 112300   |
| lives                   | 112300   |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 7.7      |
| mean 100 episode reward | 2.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5294   |
| steps                   | 821220   |
| td_erros                | 0.0668   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 112400   |
| lives                   | 112400   |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 7.44     |
| mean 100 episode reward | 2.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5404   |
| steps                   | 821864   |
| td_erros                | 0.0503   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 112500   |
| lives                   | 112500   |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 6.71     |
| mean 100 episode reward | 2.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5983   |
| steps                   | 822435   |
| td_erros                | 0.0757   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 112600   |
| lives                   | 112600   |
| mean 100 episode ei     | 4.41     |
| mean 100 episode length | 7.43     |
| mean 100 episode reward | 2.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6186   |
| steps                   | 823078   |
| td_erros                | 0.0444   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 49       |
| episodes                | 112700   |
| lives                   | 112700   |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 7.37     |
| mean 100 episode reward | 2.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6129   |
| steps                   | 823715   |
| td_erros                | 0.0223   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 112800   |
| lives                   | 112800   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 7.17     |
| mean 100 episode reward | 3.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6051   |
| steps                   | 824332   |
| td_erros                | 0.0023   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 112900   |
| lives                   | 112900   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 7.25     |
| mean 100 episode reward | 3.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6002   |
| steps                   | 824957   |
| td_erros                | -0.0125  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 113000   |
| lives                   | 113000   |
| mean 100 episode ei     | 4.4      |
| mean 100 episode length | 7.29     |
| mean 100 episode reward | 3.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.591    |
| steps                   | 825586   |
| td_erros                | -0.0263  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 113100   |
| lives                   | 113100   |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 7.12     |
| mean 100 episode reward | 3.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6172   |
| steps                   | 826198   |
| td_erros                | -0.0396  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 113200   |
| lives                   | 113200   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 7.25     |
| mean 100 episode reward | 3.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6427   |
| steps                   | 826823   |
| td_erros                | -0.0094  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 113300   |
| lives                   | 113300   |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 7.7      |
| mean 100 episode reward | 3.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6941   |
| steps                   | 827493   |
| td_erros                | -0.001   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 113400   |
| lives                   | 113400   |
| mean 100 episode ei     | 4.23     |
| mean 100 episode length | 6.65     |
| mean 100 episode reward | 1.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.9859   |
| steps                   | 828058   |
| td_erros                | 0.1664   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 113500   |
| lives                   | 113500   |
| mean 100 episode ei     | 3.37     |
| mean 100 episode length | 6.48     |
| mean 100 episode reward | 1.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.8083   |
| steps                   | 828606   |
| td_erros                | 0.0724   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 113600   |
| lives                   | 113600   |
| mean 100 episode ei     | 3.71     |
| mean 100 episode length | 6.65     |
| mean 100 episode reward | 1.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7822   |
| steps                   | 829171   |
| td_erros                | 0.0593   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 113700   |
| lives                   | 113700   |
| mean 100 episode ei     | 3.59     |
| mean 100 episode length | 6.71     |
| mean 100 episode reward | 1.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7707   |
| steps                   | 829742   |
| td_erros                | 0.0695   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 113800   |
| lives                   | 113800   |
| mean 100 episode ei     | 2.79     |
| mean 100 episode length | 6.17     |
| mean 100 episode reward | 1.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7609   |
| steps                   | 830259   |
| td_erros                | 0.1036   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 113900   |
| lives                   | 113900   |
| mean 100 episode ei     | 3.33     |
| mean 100 episode length | 6.94     |
| mean 100 episode reward | 1.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.7237   |
| steps                   | 830853   |
| td_erros                | 0.0973   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 114000   |
| lives                   | 114000   |
| mean 100 episode ei     | 3.32     |
| mean 100 episode length | 6.93     |
| mean 100 episode reward | 1.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.6569   |
| steps                   | 831446   |
| td_erros                | 0.0686   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 114100   |
| lives                   | 114100   |
| mean 100 episode ei     | 3.44     |
| mean 100 episode length | 7.45     |
| mean 100 episode reward | 1.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5231   |
| steps                   | 832091   |
| td_erros                | 0.0306   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 114200   |
| lives                   | 114200   |
| mean 100 episode ei     | 3.49     |
| mean 100 episode length | 6.45     |
| mean 100 episode reward | 2.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4088   |
| steps                   | 832636   |
| td_erros                | -0.0135  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 114300   |
| lives                   | 114300   |
| mean 100 episode ei     | 3.4      |
| mean 100 episode length | 6.92     |
| mean 100 episode reward | 2.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3651   |
| steps                   | 833228   |
| td_erros                | -0.0387  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 114400   |
| lives                   | 114400   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 7.39     |
| mean 100 episode reward | 3.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.308    |
| steps                   | 833867   |
| td_erros                | -0.0426  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 114500   |
| lives                   | 114500   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 7.22     |
| mean 100 episode reward | 3.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2516   |
| steps                   | 834489   |
| td_erros                | -0.0848  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 114600   |
| lives                   | 114600   |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 7.72     |
| mean 100 episode reward | 3.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2465   |
| steps                   | 835161   |
| td_erros                | -0.0903  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 114700   |
| lives                   | 114700   |
| mean 100 episode ei     | 4.36     |
| mean 100 episode length | 7.24     |
| mean 100 episode reward | 3.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2787   |
| steps                   | 835785   |
| td_erros                | -0.1077  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 114800   |
| lives                   | 114800   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 7.01     |
| mean 100 episode reward | 3.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2779   |
| steps                   | 836386   |
| td_erros                | -0.1165  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 114900   |
| lives                   | 114900   |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 7.34     |
| mean 100 episode reward | 2.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.307    |
| steps                   | 837020   |
| td_erros                | -0.1429  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 115000   |
| lives                   | 115000   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 6.55     |
| mean 100 episode reward | 1.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3811   |
| steps                   | 837575   |
| td_erros                | -0.1026  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 115100   |
| lives                   | 115100   |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 7.31     |
| mean 100 episode reward | 2.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4183   |
| steps                   | 838206   |
| td_erros                | -0.1237  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 115200   |
| lives                   | 115200   |
| mean 100 episode ei     | 3.64     |
| mean 100 episode length | 5.87     |
| mean 100 episode reward | 3.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4727   |
| steps                   | 838693   |
| td_erros                | -0.1194  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 115300   |
| lives                   | 115300   |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 6.47     |
| mean 100 episode reward | 2.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5044   |
| steps                   | 839240   |
| td_erros                | -0.0777  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 48       |
| episodes                | 115400   |
| lives                   | 115400   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 6.86     |
| mean 100 episode reward | 2.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5072   |
| steps                   | 839826   |
| td_erros                | -0.0665  |
--------------------------------------
Saving model due to running mean reward increase: 2.6292 -> 2.9232
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 115500   |
| lives                   | 115500   |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 7.35     |
| mean 100 episode reward | 3.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.473    |
| steps                   | 840461   |
| td_erros                | -0.0635  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 115600   |
| lives                   | 115600   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 7.36     |
| mean 100 episode reward | 3.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4487   |
| steps                   | 841097   |
| td_erros                | -0.0702  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 115700   |
| lives                   | 115700   |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 7.7      |
| mean 100 episode reward | 3.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4272   |
| steps                   | 841767   |
| td_erros                | -0.0851  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 115800   |
| lives                   | 115800   |
| mean 100 episode ei     | 4.21     |
| mean 100 episode length | 7.36     |
| mean 100 episode reward | 2.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4309   |
| steps                   | 842403   |
| td_erros                | -0.0696  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 115900   |
| lives                   | 115900   |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 7.55     |
| mean 100 episode reward | 3.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3658   |
| steps                   | 843058   |
| td_erros                | -0.0778  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 116000   |
| lives                   | 116000   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 6.42     |
| mean 100 episode reward | 2.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3967   |
| steps                   | 843600   |
| td_erros                | -0.0733  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 116100   |
| lives                   | 116100   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 6.47     |
| mean 100 episode reward | 2.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4745   |
| steps                   | 844147   |
| td_erros                | -0.0729  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 116200   |
| lives                   | 116200   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 7.08     |
| mean 100 episode reward | 3.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4655   |
| steps                   | 844755   |
| td_erros                | -0.0975  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 116300   |
| lives                   | 116300   |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 7.04     |
| mean 100 episode reward | 2.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.413    |
| steps                   | 845359   |
| td_erros                | -0.1055  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 116400   |
| lives                   | 116400   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 7.09     |
| mean 100 episode reward | 3.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3884   |
| steps                   | 845968   |
| td_erros                | -0.1367  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 116500   |
| lives                   | 116500   |
| mean 100 episode ei     | 3.57     |
| mean 100 episode length | 6.7      |
| mean 100 episode reward | 2.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3406   |
| steps                   | 846538   |
| td_erros                | -0.1352  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 116600   |
| lives                   | 116600   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 6.91     |
| mean 100 episode reward | 2.69     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3815   |
| steps                   | 847129   |
| td_erros                | -0.1245  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 116700   |
| lives                   | 116700   |
| mean 100 episode ei     | 3.55     |
| mean 100 episode length | 7.03     |
| mean 100 episode reward | 2.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3256   |
| steps                   | 847732   |
| td_erros                | -0.1219  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 116800   |
| lives                   | 116800   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 7.61     |
| mean 100 episode reward | 2.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2829   |
| steps                   | 848393   |
| td_erros                | -0.1121  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 116900   |
| lives                   | 116900   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 7.94     |
| mean 100 episode reward | 2.57     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2742   |
| steps                   | 849087   |
| td_erros                | -0.1157  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 117000   |
| lives                   | 117000   |
| mean 100 episode ei     | 3.55     |
| mean 100 episode length | 7.3      |
| mean 100 episode reward | 2.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2473   |
| steps                   | 849717   |
| td_erros                | -0.1091  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 117100   |
| lives                   | 117100   |
| mean 100 episode ei     | 3.26     |
| mean 100 episode length | 6.83     |
| mean 100 episode reward | 1.96     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2526   |
| steps                   | 850300   |
| td_erros                | -0.0927  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 117200   |
| lives                   | 117200   |
| mean 100 episode ei     | 3.83     |
| mean 100 episode length | 7.84     |
| mean 100 episode reward | 2.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.252    |
| steps                   | 850984   |
| td_erros                | -0.0896  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 117300   |
| lives                   | 117300   |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 7.29     |
| mean 100 episode reward | 3.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2362   |
| steps                   | 851613   |
| td_erros                | -0.0999  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 117400   |
| lives                   | 117400   |
| mean 100 episode ei     | 3.79     |
| mean 100 episode length | 6.68     |
| mean 100 episode reward | 3.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2286   |
| steps                   | 852181   |
| td_erros                | -0.1055  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 117500   |
| lives                   | 117500   |
| mean 100 episode ei     | 3.75     |
| mean 100 episode length | 7.3      |
| mean 100 episode reward | 2.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2268   |
| steps                   | 852811   |
| td_erros                | -0.0894  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 117600   |
| lives                   | 117600   |
| mean 100 episode ei     | 3.29     |
| mean 100 episode length | 6.29     |
| mean 100 episode reward | 3        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2718   |
| steps                   | 853340   |
| td_erros                | -0.0464  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 117700   |
| lives                   | 117700   |
| mean 100 episode ei     | 3.3      |
| mean 100 episode length | 7.12     |
| mean 100 episode reward | 2.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2882   |
| steps                   | 853952   |
| td_erros                | -0.0299  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 117800   |
| lives                   | 117800   |
| mean 100 episode ei     | 3.32     |
| mean 100 episode length | 7.08     |
| mean 100 episode reward | 2.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2727   |
| steps                   | 854560   |
| td_erros                | -0.0113  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 117900   |
| lives                   | 117900   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 7.25     |
| mean 100 episode reward | 3.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2628   |
| steps                   | 855185   |
| td_erros                | -0.0337  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 118000   |
| lives                   | 118000   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 7.01     |
| mean 100 episode reward | 3.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.239    |
| steps                   | 855786   |
| td_erros                | -0.0681  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 47       |
| episodes                | 118100   |
| lives                   | 118100   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 7.5      |
| mean 100 episode reward | 2.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2171   |
| steps                   | 856436   |
| td_erros                | -0.0855  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 118200   |
| lives                   | 118200   |
| mean 100 episode ei     | 4.65     |
| mean 100 episode length | 7.56     |
| mean 100 episode reward | 2.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2437   |
| steps                   | 857092   |
| td_erros                | -0.1215  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 118300   |
| lives                   | 118300   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 7.03     |
| mean 100 episode reward | 2.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2157   |
| steps                   | 857695   |
| td_erros                | -0.1656  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 118400   |
| lives                   | 118400   |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 7.68     |
| mean 100 episode reward | 2.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1755   |
| steps                   | 858363   |
| td_erros                | -0.2035  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 118500   |
| lives                   | 118500   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 7.19     |
| mean 100 episode reward | 3.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.168    |
| steps                   | 858982   |
| td_erros                | -0.2187  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 118600   |
| lives                   | 118600   |
| mean 100 episode ei     | 3.65     |
| mean 100 episode length | 6.57     |
| mean 100 episode reward | 2.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2345   |
| steps                   | 859539   |
| td_erros                | -0.1727  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 118700   |
| lives                   | 118700   |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 7.09     |
| mean 100 episode reward | 3.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2738   |
| steps                   | 860148   |
| td_erros                | -0.159   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 118800   |
| lives                   | 118800   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 7.23     |
| mean 100 episode reward | 2.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.294    |
| steps                   | 860771   |
| td_erros                | -0.1453  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 118900   |
| lives                   | 118900   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 7.4      |
| mean 100 episode reward | 3.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3287   |
| steps                   | 861411   |
| td_erros                | -0.1266  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 119000   |
| lives                   | 119000   |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 7.41     |
| mean 100 episode reward | 3.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3495   |
| steps                   | 862052   |
| td_erros                | -0.0993  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 119100   |
| lives                   | 119100   |
| mean 100 episode ei     | 4.42     |
| mean 100 episode length | 7.19     |
| mean 100 episode reward | 3.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4023   |
| steps                   | 862671   |
| td_erros                | -0.0687  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 119200   |
| lives                   | 119200   |
| mean 100 episode ei     | 4.36     |
| mean 100 episode length | 6.83     |
| mean 100 episode reward | 2.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4689   |
| steps                   | 863254   |
| td_erros                | -0.0506  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 119300   |
| lives                   | 119300   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 6.25     |
| mean 100 episode reward | 3.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5397   |
| steps                   | 863779   |
| td_erros                | -0.0516  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 119400   |
| lives                   | 119400   |
| mean 100 episode ei     | 3.65     |
| mean 100 episode length | 6.19     |
| mean 100 episode reward | 3.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5669   |
| steps                   | 864298   |
| td_erros                | -0.0163  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 119500   |
| lives                   | 119500   |
| mean 100 episode ei     | 3.64     |
| mean 100 episode length | 6.46     |
| mean 100 episode reward | 3.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5737   |
| steps                   | 864844   |
| td_erros                | -0.026   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 119600   |
| lives                   | 119600   |
| mean 100 episode ei     | 4.21     |
| mean 100 episode length | 7.31     |
| mean 100 episode reward | 3.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5751   |
| steps                   | 865475   |
| td_erros                | -0.0498  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 119700   |
| lives                   | 119700   |
| mean 100 episode ei     | 3.39     |
| mean 100 episode length | 6.58     |
| mean 100 episode reward | 3.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5227   |
| steps                   | 866033   |
| td_erros                | -0.0559  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 119800   |
| lives                   | 119800   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 7.27     |
| mean 100 episode reward | 2.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4864   |
| steps                   | 866660   |
| td_erros                | -0.0437  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 119900   |
| lives                   | 119900   |
| mean 100 episode ei     | 3.16     |
| mean 100 episode length | 6.19     |
| mean 100 episode reward | 2.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4299   |
| steps                   | 867179   |
| td_erros                | -0.0721  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 120000   |
| lives                   | 120000   |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 7.66     |
| mean 100 episode reward | 3.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4143   |
| steps                   | 867845   |
| td_erros                | -0.0736  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 120100   |
| lives                   | 120100   |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 7.25     |
| mean 100 episode reward | 3.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3741   |
| steps                   | 868470   |
| td_erros                | -0.0931  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 120200   |
| lives                   | 120200   |
| mean 100 episode ei     | 4.64     |
| mean 100 episode length | 7.53     |
| mean 100 episode reward | 3.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3258   |
| steps                   | 869123   |
| td_erros                | -0.0892  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 120300   |
| lives                   | 120300   |
| mean 100 episode ei     | 4.47     |
| mean 100 episode length | 7.18     |
| mean 100 episode reward | 2.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3045   |
| steps                   | 869741   |
| td_erros                | -0.1143  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 120400   |
| lives                   | 120400   |
| mean 100 episode ei     | 4.6      |
| mean 100 episode length | 7.13     |
| mean 100 episode reward | 2.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3129   |
| steps                   | 870354   |
| td_erros                | -0.1359  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 120500   |
| lives                   | 120500   |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 7.24     |
| mean 100 episode reward | 3.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3271   |
| steps                   | 870978   |
| td_erros                | -0.1288  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 120600   |
| lives                   | 120600   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 6.61     |
| mean 100 episode reward | 3        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3835   |
| steps                   | 871539   |
| td_erros                | -0.1235  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 120700   |
| lives                   | 120700   |
| mean 100 episode ei     | 3.83     |
| mean 100 episode length | 6.5      |
| mean 100 episode reward | 3.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4476   |
| steps                   | 872089   |
| td_erros                | -0.0962  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 46       |
| episodes                | 120800   |
| lives                   | 120800   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 6.58     |
| mean 100 episode reward | 3.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5085   |
| steps                   | 872647   |
| td_erros                | -0.0726  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 120900   |
| lives                   | 120900   |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 6.37     |
| mean 100 episode reward | 2.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5458   |
| steps                   | 873184   |
| td_erros                | -0.0473  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 121000   |
| lives                   | 121000   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 7.15     |
| mean 100 episode reward | 2.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5233   |
| steps                   | 873799   |
| td_erros                | -0.0323  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 121100   |
| lives                   | 121100   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 6.72     |
| mean 100 episode reward | 3.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5496   |
| steps                   | 874371   |
| td_erros                | -0.0389  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 121200   |
| lives                   | 121200   |
| mean 100 episode ei     | 3.55     |
| mean 100 episode length | 6.71     |
| mean 100 episode reward | 2.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5381   |
| steps                   | 874942   |
| td_erros                | -0.0301  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 121300   |
| lives                   | 121300   |
| mean 100 episode ei     | 3.53     |
| mean 100 episode length | 6.67     |
| mean 100 episode reward | 3.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4822   |
| steps                   | 875509   |
| td_erros                | -0.0275  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 121400   |
| lives                   | 121400   |
| mean 100 episode ei     | 3.72     |
| mean 100 episode length | 7.06     |
| mean 100 episode reward | 2.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4138   |
| steps                   | 876115   |
| td_erros                | -0.0277  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 121500   |
| lives                   | 121500   |
| mean 100 episode ei     | 3.75     |
| mean 100 episode length | 7.19     |
| mean 100 episode reward | 3.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3385   |
| steps                   | 876734   |
| td_erros                | -0.0495  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 121600   |
| lives                   | 121600   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 7.67     |
| mean 100 episode reward | 3.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2945   |
| steps                   | 877401   |
| td_erros                | -0.0637  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 121700   |
| lives                   | 121700   |
| mean 100 episode ei     | 3.5      |
| mean 100 episode length | 6.93     |
| mean 100 episode reward | 2.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2611   |
| steps                   | 877994   |
| td_erros                | -0.0715  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 121800   |
| lives                   | 121800   |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 7.56     |
| mean 100 episode reward | 3.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2787   |
| steps                   | 878650   |
| td_erros                | -0.056   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 121900   |
| lives                   | 121900   |
| mean 100 episode ei     | 3.7      |
| mean 100 episode length | 6.78     |
| mean 100 episode reward | 2.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2986   |
| steps                   | 879228   |
| td_erros                | -0.04    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 122000   |
| lives                   | 122000   |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 6.99     |
| mean 100 episode reward | 2.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2705   |
| steps                   | 879827   |
| td_erros                | -0.0686  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 122100   |
| lives                   | 122100   |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 7.33     |
| mean 100 episode reward | 2.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2849   |
| steps                   | 880460   |
| td_erros                | -0.0749  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 122200   |
| lives                   | 122200   |
| mean 100 episode ei     | 3.6      |
| mean 100 episode length | 6.65     |
| mean 100 episode reward | 2.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2879   |
| steps                   | 881025   |
| td_erros                | -0.0824  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 122300   |
| lives                   | 122300   |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 6.68     |
| mean 100 episode reward | 3        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3406   |
| steps                   | 881593   |
| td_erros                | -0.0448  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 122400   |
| lives                   | 122400   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 7.27     |
| mean 100 episode reward | 2.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3506   |
| steps                   | 882220   |
| td_erros                | -0.0435  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 122500   |
| lives                   | 122500   |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 6.97     |
| mean 100 episode reward | 3.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3762   |
| steps                   | 882817   |
| td_erros                | -0.0514  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 122600   |
| lives                   | 122600   |
| mean 100 episode ei     | 4.52     |
| mean 100 episode length | 6.97     |
| mean 100 episode reward | 3.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.448    |
| steps                   | 883414   |
| td_erros                | -0.0382  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 122700   |
| lives                   | 122700   |
| mean 100 episode ei     | 4.33     |
| mean 100 episode length | 7.66     |
| mean 100 episode reward | 3.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5262   |
| steps                   | 884080   |
| td_erros                | -0.0325  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 122800   |
| lives                   | 122800   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 7.24     |
| mean 100 episode reward | 3.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5833   |
| steps                   | 884704   |
| td_erros                | -0.0244  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 122900   |
| lives                   | 122900   |
| mean 100 episode ei     | 3.7      |
| mean 100 episode length | 6.86     |
| mean 100 episode reward | 3.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.586    |
| steps                   | 885290   |
| td_erros                | -0.0152  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 123000   |
| lives                   | 123000   |
| mean 100 episode ei     | 3.6      |
| mean 100 episode length | 6.65     |
| mean 100 episode reward | 3.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5619   |
| steps                   | 885855   |
| td_erros                | -0.0036  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 123100   |
| lives                   | 123100   |
| mean 100 episode ei     | 3.59     |
| mean 100 episode length | 7.01     |
| mean 100 episode reward | 2.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5252   |
| steps                   | 886456   |
| td_erros                | -0.052   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 123200   |
| lives                   | 123200   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 7.42     |
| mean 100 episode reward | 3.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5153   |
| steps                   | 887098   |
| td_erros                | -0.0412  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 123300   |
| lives                   | 123300   |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 7.08     |
| mean 100 episode reward | 3.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.53     |
| steps                   | 887706   |
| td_erros                | -0.0429  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 45       |
| episodes                | 123400   |
| lives                   | 123400   |
| mean 100 episode ei     | 4.68     |
| mean 100 episode length | 7.24     |
| mean 100 episode reward | 3.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4789   |
| steps                   | 888330   |
| td_erros                | -0.0703  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 123500   |
| lives                   | 123500   |
| mean 100 episode ei     | 4.39     |
| mean 100 episode length | 6.99     |
| mean 100 episode reward | 3.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4329   |
| steps                   | 888929   |
| td_erros                | -0.1106  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 123600   |
| lives                   | 123600   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 6.33     |
| mean 100 episode reward | 2.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5644   |
| steps                   | 889462   |
| td_erros                | -0.0736  |
--------------------------------------
Saving model due to running mean reward increase: 2.8519 -> 2.9462
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 123700   |
| lives                   | 123700   |
| mean 100 episode ei     | 3.59     |
| mean 100 episode length | 6.98     |
| mean 100 episode reward | 3        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4995   |
| steps                   | 890060   |
| td_erros                | -0.068   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 123800   |
| lives                   | 123800   |
| mean 100 episode ei     | 3.64     |
| mean 100 episode length | 7.08     |
| mean 100 episode reward | 2.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4482   |
| steps                   | 890668   |
| td_erros                | -0.0997  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 123900   |
| lives                   | 123900   |
| mean 100 episode ei     | 3.47     |
| mean 100 episode length | 7        |
| mean 100 episode reward | 2.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4064   |
| steps                   | 891268   |
| td_erros                | -0.084   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 124000   |
| lives                   | 124000   |
| mean 100 episode ei     | 3.69     |
| mean 100 episode length | 7.06     |
| mean 100 episode reward | 3.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3968   |
| steps                   | 891874   |
| td_erros                | -0.0924  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 124100   |
| lives                   | 124100   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 7.04     |
| mean 100 episode reward | 3.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3774   |
| steps                   | 892478   |
| td_erros                | -0.088   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 124200   |
| lives                   | 124200   |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 7.29     |
| mean 100 episode reward | 3.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3683   |
| steps                   | 893107   |
| td_erros                | -0.0864  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 124300   |
| lives                   | 124300   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 6.86     |
| mean 100 episode reward | 3.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.341    |
| steps                   | 893693   |
| td_erros                | -0.0882  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 124400   |
| lives                   | 124400   |
| mean 100 episode ei     | 3.68     |
| mean 100 episode length | 6.72     |
| mean 100 episode reward | 3        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3051   |
| steps                   | 894265   |
| td_erros                | -0.0785  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 124500   |
| lives                   | 124500   |
| mean 100 episode ei     | 3.83     |
| mean 100 episode length | 7.37     |
| mean 100 episode reward | 3.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2599   |
| steps                   | 894902   |
| td_erros                | -0.0761  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 124600   |
| lives                   | 124600   |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 7.31     |
| mean 100 episode reward | 3.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2359   |
| steps                   | 895533   |
| td_erros                | -0.1071  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 124700   |
| lives                   | 124700   |
| mean 100 episode ei     | 4.21     |
| mean 100 episode length | 7.02     |
| mean 100 episode reward | 2.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3209   |
| steps                   | 896135   |
| td_erros                | -0.0821  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 124800   |
| lives                   | 124800   |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 7.24     |
| mean 100 episode reward | 3.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3467   |
| steps                   | 896759   |
| td_erros                | -0.0897  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 124900   |
| lives                   | 124900   |
| mean 100 episode ei     | 4.46     |
| mean 100 episode length | 6.79     |
| mean 100 episode reward | 3.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4133   |
| steps                   | 897338   |
| td_erros                | -0.0988  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 125000   |
| lives                   | 125000   |
| mean 100 episode ei     | 3.53     |
| mean 100 episode length | 6.42     |
| mean 100 episode reward | 3.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4587   |
| steps                   | 897880   |
| td_erros                | -0.0688  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 125100   |
| lives                   | 125100   |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 7.2      |
| mean 100 episode reward | 3.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4674   |
| steps                   | 898500   |
| td_erros                | -0.0527  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 125200   |
| lives                   | 125200   |
| mean 100 episode ei     | 3.61     |
| mean 100 episode length | 6.53     |
| mean 100 episode reward | 3.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5022   |
| steps                   | 899053   |
| td_erros                | -0.0548  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 125300   |
| lives                   | 125300   |
| mean 100 episode ei     | 4.4      |
| mean 100 episode length | 7.38     |
| mean 100 episode reward | 3.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5251   |
| steps                   | 899691   |
| td_erros                | -0.0583  |
--------------------------------------
Saving model due to mean reward increase: 3.3476 -> 3.5249
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 125400   |
| lives                   | 125400   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 6.97     |
| mean 100 episode reward | 3.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5639   |
| steps                   | 900288   |
| td_erros                | -0.0425  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 125500   |
| lives                   | 125500   |
| mean 100 episode ei     | 3.74     |
| mean 100 episode length | 6.96     |
| mean 100 episode reward | 2.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5271   |
| steps                   | 900884   |
| td_erros                | -0.0432  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 125600   |
| lives                   | 125600   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 7.22     |
| mean 100 episode reward | 3.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5044   |
| steps                   | 901506   |
| td_erros                | -0.0351  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 125700   |
| lives                   | 125700   |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 7.25     |
| mean 100 episode reward | 3.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.481    |
| steps                   | 902131   |
| td_erros                | -0.0544  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 125800   |
| lives                   | 125800   |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 6.88     |
| mean 100 episode reward | 2.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4458   |
| steps                   | 902719   |
| td_erros                | -0.0371  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 125900   |
| lives                   | 125900   |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 6.98     |
| mean 100 episode reward | 2.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.402    |
| steps                   | 903317   |
| td_erros                | -0.0672  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 126000   |
| lives                   | 126000   |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 7.12     |
| mean 100 episode reward | 2.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4229   |
| steps                   | 903929   |
| td_erros                | -0.0962  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 44       |
| episodes                | 126100   |
| lives                   | 126100   |
| mean 100 episode ei     | 3.54     |
| mean 100 episode length | 6.34     |
| mean 100 episode reward | 2.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4127   |
| steps                   | 904463   |
| td_erros                | -0.0698  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 126200   |
| lives                   | 126200   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 7.2      |
| mean 100 episode reward | 3.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3981   |
| steps                   | 905083   |
| td_erros                | -0.0548  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 126300   |
| lives                   | 126300   |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 7.51     |
| mean 100 episode reward | 3.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3938   |
| steps                   | 905734   |
| td_erros                | -0.0768  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 126400   |
| lives                   | 126400   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 6.9      |
| mean 100 episode reward | 3.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4394   |
| steps                   | 906324   |
| td_erros                | -0.0353  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 126500   |
| lives                   | 126500   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 6.83     |
| mean 100 episode reward | 3.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4834   |
| steps                   | 906907   |
| td_erros                | -0.0407  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 126600   |
| lives                   | 126600   |
| mean 100 episode ei     | 3.75     |
| mean 100 episode length | 6.55     |
| mean 100 episode reward | 3.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.5107   |
| steps                   | 907462   |
| td_erros                | -0.0337  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 126700   |
| lives                   | 126700   |
| mean 100 episode ei     | 3.54     |
| mean 100 episode length | 6.66     |
| mean 100 episode reward | 3.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4821   |
| steps                   | 908028   |
| td_erros                | -0.0555  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 126800   |
| lives                   | 126800   |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 7.52     |
| mean 100 episode reward | 3.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4521   |
| steps                   | 908680   |
| td_erros                | -0.044   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 126900   |
| lives                   | 126900   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 7.03     |
| mean 100 episode reward | 3.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3941   |
| steps                   | 909283   |
| td_erros                | -0.0283  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 127000   |
| lives                   | 127000   |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 6.84     |
| mean 100 episode reward | 3.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3841   |
| steps                   | 909867   |
| td_erros                | -0.0859  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 127100   |
| lives                   | 127100   |
| mean 100 episode ei     | 4.58     |
| mean 100 episode length | 7.08     |
| mean 100 episode reward | 3.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3548   |
| steps                   | 910475   |
| td_erros                | -0.1004  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 127200   |
| lives                   | 127200   |
| mean 100 episode ei     | 4.49     |
| mean 100 episode length | 6.94     |
| mean 100 episode reward | 3.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3603   |
| steps                   | 911069   |
| td_erros                | -0.1195  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 127300   |
| lives                   | 127300   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 6.77     |
| mean 100 episode reward | 3.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3648   |
| steps                   | 911646   |
| td_erros                | -0.0977  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 127400   |
| lives                   | 127400   |
| mean 100 episode ei     | 3.69     |
| mean 100 episode length | 6.8      |
| mean 100 episode reward | 2.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3264   |
| steps                   | 912226   |
| td_erros                | -0.1045  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 127500   |
| lives                   | 127500   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 7.47     |
| mean 100 episode reward | 3.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2597   |
| steps                   | 912873   |
| td_erros                | -0.1295  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 127600   |
| lives                   | 127600   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 7.38     |
| mean 100 episode reward | 2.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2543   |
| steps                   | 913511   |
| td_erros                | -0.1263  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 127700   |
| lives                   | 127700   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 7.09     |
| mean 100 episode reward | 3.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3011   |
| steps                   | 914120   |
| td_erros                | -0.1339  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 127800   |
| lives                   | 127800   |
| mean 100 episode ei     | 4.23     |
| mean 100 episode length | 7.34     |
| mean 100 episode reward | 3.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3215   |
| steps                   | 914754   |
| td_erros                | -0.1514  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 127900   |
| lives                   | 127900   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 7.17     |
| mean 100 episode reward | 3.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3547   |
| steps                   | 915371   |
| td_erros                | -0.124   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 128000   |
| lives                   | 128000   |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 6.46     |
| mean 100 episode reward | 3.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3731   |
| steps                   | 915917   |
| td_erros                | -0.0943  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 128100   |
| lives                   | 128100   |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 6.21     |
| mean 100 episode reward | 2.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3488   |
| steps                   | 916438   |
| td_erros                | -0.0988  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 128200   |
| lives                   | 128200   |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 6.53     |
| mean 100 episode reward | 3.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3657   |
| steps                   | 916991   |
| td_erros                | -0.1139  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 128300   |
| lives                   | 128300   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 6.55     |
| mean 100 episode reward | 2.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3868   |
| steps                   | 917546   |
| td_erros                | -0.1206  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 128400   |
| lives                   | 128400   |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 6.99     |
| mean 100 episode reward | 3.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.367    |
| steps                   | 918145   |
| td_erros                | -0.1411  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 128500   |
| lives                   | 128500   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 7.23     |
| mean 100 episode reward | 2.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3537   |
| steps                   | 918768   |
| td_erros                | -0.1498  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 128600   |
| lives                   | 128600   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 6.92     |
| mean 100 episode reward | 3        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.321    |
| steps                   | 919360   |
| td_erros                | -0.1437  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 128700   |
| lives                   | 128700   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 6.91     |
| mean 100 episode reward | 3.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3356   |
| steps                   | 919951   |
| td_erros                | -0.1355  |
--------------------------------------
Saving model due to running mean reward increase: 2.9341 -> 3.3658
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 128800   |
| lives                   | 128800   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 6.89     |
| mean 100 episode reward | 3.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3695   |
| steps                   | 920540   |
| td_erros                | -0.1249  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 43       |
| episodes                | 128900   |
| lives                   | 128900   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 7.07     |
| mean 100 episode reward | 3.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3519   |
| steps                   | 921147   |
| td_erros                | -0.1322  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 129000   |
| lives                   | 129000   |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 7.56     |
| mean 100 episode reward | 4.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3355   |
| steps                   | 921803   |
| td_erros                | -0.132   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 129100   |
| lives                   | 129100   |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 6.86     |
| mean 100 episode reward | 3.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3278   |
| steps                   | 922389   |
| td_erros                | -0.1147  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 129200   |
| lives                   | 129200   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 6.65     |
| mean 100 episode reward | 3.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3759   |
| steps                   | 922954   |
| td_erros                | -0.11    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 129300   |
| lives                   | 129300   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 6.59     |
| mean 100 episode reward | 2.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3862   |
| steps                   | 923513   |
| td_erros                | -0.1065  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 129400   |
| lives                   | 129400   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 6.81     |
| mean 100 episode reward | 3.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3535   |
| steps                   | 924094   |
| td_erros                | -0.1292  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 129500   |
| lives                   | 129500   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 6.26     |
| mean 100 episode reward | 4.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3568   |
| steps                   | 924620   |
| td_erros                | -0.1345  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 129600   |
| lives                   | 129600   |
| mean 100 episode ei     | 3.6      |
| mean 100 episode length | 6.34     |
| mean 100 episode reward | 3.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3725   |
| steps                   | 925154   |
| td_erros                | -0.0927  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 129700   |
| lives                   | 129700   |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 6.48     |
| mean 100 episode reward | 3.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3063   |
| steps                   | 925702   |
| td_erros                | -0.1039  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 129800   |
| lives                   | 129800   |
| mean 100 episode ei     | 3.55     |
| mean 100 episode length | 6.52     |
| mean 100 episode reward | 3.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2605   |
| steps                   | 926254   |
| td_erros                | -0.1166  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 129900   |
| lives                   | 129900   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 7        |
| mean 100 episode reward | 3.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2499   |
| steps                   | 926854   |
| td_erros                | -0.1258  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 130000   |
| lives                   | 130000   |
| mean 100 episode ei     | 3.63     |
| mean 100 episode length | 7.19     |
| mean 100 episode reward | 2.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2274   |
| steps                   | 927473   |
| td_erros                | -0.1296  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 130100   |
| lives                   | 130100   |
| mean 100 episode ei     | 3.4      |
| mean 100 episode length | 7.19     |
| mean 100 episode reward | 2.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.162    |
| steps                   | 928092   |
| td_erros                | -0.1395  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 130200   |
| lives                   | 130200   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 7.17     |
| mean 100 episode reward | 3.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1153   |
| steps                   | 928709   |
| td_erros                | -0.1421  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 130300   |
| lives                   | 130300   |
| mean 100 episode ei     | 3.8      |
| mean 100 episode length | 6.81     |
| mean 100 episode reward | 3.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1129   |
| steps                   | 929290   |
| td_erros                | -0.1527  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 130400   |
| lives                   | 130400   |
| mean 100 episode ei     | 4.85     |
| mean 100 episode length | 7.87     |
| mean 100 episode reward | 3.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0541   |
| steps                   | 929977   |
| td_erros                | -0.185   |
--------------------------------------
Saving model due to mean reward increase: 3.5249 -> 3.6642
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 130500   |
| lives                   | 130500   |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 6.98     |
| mean 100 episode reward | 2.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0658   |
| steps                   | 930575   |
| td_erros                | -0.2145  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 130600   |
| lives                   | 130600   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 6.71     |
| mean 100 episode reward | 2.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0868   |
| steps                   | 931146   |
| td_erros                | -0.2121  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 130700   |
| lives                   | 130700   |
| mean 100 episode ei     | 3.68     |
| mean 100 episode length | 6.69     |
| mean 100 episode reward | 2.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1065   |
| steps                   | 931715   |
| td_erros                | -0.2164  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 130800   |
| lives                   | 130800   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 6.54     |
| mean 100 episode reward | 3.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1846   |
| steps                   | 932269   |
| td_erros                | -0.2009  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 130900   |
| lives                   | 130900   |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 6.86     |
| mean 100 episode reward | 3.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2141   |
| steps                   | 932855   |
| td_erros                | -0.1985  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 131000   |
| lives                   | 131000   |
| mean 100 episode ei     | 3.8      |
| mean 100 episode length | 6.45     |
| mean 100 episode reward | 3.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3058   |
| steps                   | 933400   |
| td_erros                | -0.1699  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 131100   |
| lives                   | 131100   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 6.92     |
| mean 100 episode reward | 2.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3267   |
| steps                   | 933992   |
| td_erros                | -0.1363  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 131200   |
| lives                   | 131200   |
| mean 100 episode ei     | 3.58     |
| mean 100 episode length | 6.95     |
| mean 100 episode reward | 2.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3667   |
| steps                   | 934587   |
| td_erros                | -0.1079  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 131300   |
| lives                   | 131300   |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 6.65     |
| mean 100 episode reward | 3.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3681   |
| steps                   | 935152   |
| td_erros                | -0.0909  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 131400   |
| lives                   | 131400   |
| mean 100 episode ei     | 3.27     |
| mean 100 episode length | 6.45     |
| mean 100 episode reward | 2.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3438   |
| steps                   | 935697   |
| td_erros                | -0.0659  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 131500   |
| lives                   | 131500   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 7.11     |
| mean 100 episode reward | 3.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2781   |
| steps                   | 936308   |
| td_erros                | -0.0932  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 42       |
| episodes                | 131600   |
| lives                   | 131600   |
| mean 100 episode ei     | 4.49     |
| mean 100 episode length | 7.35     |
| mean 100 episode reward | 3.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2743   |
| steps                   | 936943   |
| td_erros                | -0.1129  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 131700   |
| lives                   | 131700   |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 6.52     |
| mean 100 episode reward | 2.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2677   |
| steps                   | 937495   |
| td_erros                | -0.1233  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 131800   |
| lives                   | 131800   |
| mean 100 episode ei     | 3.6      |
| mean 100 episode length | 6.43     |
| mean 100 episode reward | 2.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2309   |
| steps                   | 938038   |
| td_erros                | -0.1345  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 131900   |
| lives                   | 131900   |
| mean 100 episode ei     | 3.24     |
| mean 100 episode length | 5.94     |
| mean 100 episode reward | 3.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.197    |
| steps                   | 938532   |
| td_erros                | -0.1498  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 132000   |
| lives                   | 132000   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 7.17     |
| mean 100 episode reward | 3.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2166   |
| steps                   | 939149   |
| td_erros                | -0.1139  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 132100   |
| lives                   | 132100   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 7.1      |
| mean 100 episode reward | 3.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1884   |
| steps                   | 939759   |
| td_erros                | -0.136   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 132200   |
| lives                   | 132200   |
| mean 100 episode ei     | 4.51     |
| mean 100 episode length | 7.33     |
| mean 100 episode reward | 3.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2426   |
| steps                   | 940392   |
| td_erros                | -0.1203  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 132300   |
| lives                   | 132300   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 6.89     |
| mean 100 episode reward | 3.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2401   |
| steps                   | 940981   |
| td_erros                | -0.1102  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 132400   |
| lives                   | 132400   |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 6.68     |
| mean 100 episode reward | 3.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3313   |
| steps                   | 941549   |
| td_erros                | -0.0875  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 132500   |
| lives                   | 132500   |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 7.13     |
| mean 100 episode reward | 3.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2995   |
| steps                   | 942162   |
| td_erros                | -0.0881  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 132600   |
| lives                   | 132600   |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 6.88     |
| mean 100 episode reward | 3.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.301    |
| steps                   | 942750   |
| td_erros                | -0.0833  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 132700   |
| lives                   | 132700   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 7        |
| mean 100 episode reward | 2.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2836   |
| steps                   | 943350   |
| td_erros                | -0.0999  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 132800   |
| lives                   | 132800   |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 7.11     |
| mean 100 episode reward | 4.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2705   |
| steps                   | 943961   |
| td_erros                | -0.1186  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 132900   |
| lives                   | 132900   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 6.67     |
| mean 100 episode reward | 3.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2871   |
| steps                   | 944528   |
| td_erros                | -0.1044  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 133000   |
| lives                   | 133000   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 6.86     |
| mean 100 episode reward | 3.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2921   |
| steps                   | 945114   |
| td_erros                | -0.1017  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 133100   |
| lives                   | 133100   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 6.8      |
| mean 100 episode reward | 3.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2843   |
| steps                   | 945694   |
| td_erros                | -0.0955  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 133200   |
| lives                   | 133200   |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 6.59     |
| mean 100 episode reward | 2.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.274    |
| steps                   | 946253   |
| td_erros                | -0.1111  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 133300   |
| lives                   | 133300   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 6.59     |
| mean 100 episode reward | 3        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3192   |
| steps                   | 946812   |
| td_erros                | -0.1011  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 133400   |
| lives                   | 133400   |
| mean 100 episode ei     | 3.63     |
| mean 100 episode length | 6.41     |
| mean 100 episode reward | 3.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.331    |
| steps                   | 947353   |
| td_erros                | -0.1001  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 133500   |
| lives                   | 133500   |
| mean 100 episode ei     | 3.65     |
| mean 100 episode length | 6.33     |
| mean 100 episode reward | 3.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2906   |
| steps                   | 947886   |
| td_erros                | -0.1067  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 133600   |
| lives                   | 133600   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 7.13     |
| mean 100 episode reward | 3.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2787   |
| steps                   | 948499   |
| td_erros                | -0.1217  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 133700   |
| lives                   | 133700   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 7.06     |
| mean 100 episode reward | 3.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2047   |
| steps                   | 949105   |
| td_erros                | -0.1405  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 133800   |
| lives                   | 133800   |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 7.96     |
| mean 100 episode reward | 3.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1647   |
| steps                   | 949801   |
| td_erros                | -0.1632  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 133900   |
| lives                   | 133900   |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 6.69     |
| mean 100 episode reward | 3.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.175    |
| steps                   | 950370   |
| td_erros                | -0.1446  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 134000   |
| lives                   | 134000   |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 7.18     |
| mean 100 episode reward | 4.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1711   |
| steps                   | 950988   |
| td_erros                | -0.1473  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 134100   |
| lives                   | 134100   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 7.39     |
| mean 100 episode reward | 3.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.199    |
| steps                   | 951627   |
| td_erros                | -0.1216  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 134200   |
| lives                   | 134200   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 6.89     |
| mean 100 episode reward | 3.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1994   |
| steps                   | 952216   |
| td_erros                | -0.1311  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 134300   |
| lives                   | 134300   |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 6.48     |
| mean 100 episode reward | 2.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2371   |
| steps                   | 952764   |
| td_erros                | -0.119   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 41       |
| episodes                | 134400   |
| lives                   | 134400   |
| mean 100 episode ei     | 4.49     |
| mean 100 episode length | 6.18     |
| mean 100 episode reward | 2.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3366   |
| steps                   | 953282   |
| td_erros                | -0.1059  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 134500   |
| lives                   | 134500   |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 6.49     |
| mean 100 episode reward | 2.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3546   |
| steps                   | 953831   |
| td_erros                | -0.1396  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 134600   |
| lives                   | 134600   |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 6.42     |
| mean 100 episode reward | 3.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3536   |
| steps                   | 954373   |
| td_erros                | -0.1509  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 134700   |
| lives                   | 134700   |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 6.96     |
| mean 100 episode reward | 3.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3512   |
| steps                   | 954969   |
| td_erros                | -0.1489  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 134800   |
| lives                   | 134800   |
| mean 100 episode ei     | 4.41     |
| mean 100 episode length | 7.36     |
| mean 100 episode reward | 3.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3564   |
| steps                   | 955605   |
| td_erros                | -0.147   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 134900   |
| lives                   | 134900   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 6.71     |
| mean 100 episode reward | 3.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3715   |
| steps                   | 956176   |
| td_erros                | -0.1652  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 135000   |
| lives                   | 135000   |
| mean 100 episode ei     | 3.62     |
| mean 100 episode length | 6.41     |
| mean 100 episode reward | 3.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4153   |
| steps                   | 956717   |
| td_erros                | -0.1625  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 135100   |
| lives                   | 135100   |
| mean 100 episode ei     | 3.7      |
| mean 100 episode length | 6.92     |
| mean 100 episode reward | 3.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.4678   |
| steps                   | 957309   |
| td_erros                | -0.1353  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 135200   |
| lives                   | 135200   |
| mean 100 episode ei     | 3.56     |
| mean 100 episode length | 6.68     |
| mean 100 episode reward | 3.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3963   |
| steps                   | 957877   |
| td_erros                | -0.1528  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 135300   |
| lives                   | 135300   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 6.77     |
| mean 100 episode reward | 3.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3586   |
| steps                   | 958454   |
| td_erros                | -0.139   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 135400   |
| lives                   | 135400   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 7.03     |
| mean 100 episode reward | 3.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3008   |
| steps                   | 959057   |
| td_erros                | -0.1221  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 135500   |
| lives                   | 135500   |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 7.35     |
| mean 100 episode reward | 3.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2605   |
| steps                   | 959692   |
| td_erros                | -0.1315  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 135600   |
| lives                   | 135600   |
| mean 100 episode ei     | 3.58     |
| mean 100 episode length | 6.18     |
| mean 100 episode reward | 3.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2512   |
| steps                   | 960210   |
| td_erros                | -0.1105  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 135700   |
| lives                   | 135700   |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 6.73     |
| mean 100 episode reward | 3.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.232    |
| steps                   | 960783   |
| td_erros                | -0.1186  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 135800   |
| lives                   | 135800   |
| mean 100 episode ei     | 3.71     |
| mean 100 episode length | 6.9      |
| mean 100 episode reward | 3.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2026   |
| steps                   | 961373   |
| td_erros                | -0.129   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 135900   |
| lives                   | 135900   |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 7.3      |
| mean 100 episode reward | 3.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1143   |
| steps                   | 962003   |
| td_erros                | -0.1568  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 136000   |
| lives                   | 136000   |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 7.5      |
| mean 100 episode reward | 3.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0523   |
| steps                   | 962653   |
| td_erros                | -0.1639  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 136100   |
| lives                   | 136100   |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 7.27     |
| mean 100 episode reward | 3.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.034    |
| steps                   | 963280   |
| td_erros                | -0.1756  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 136200   |
| lives                   | 136200   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 7.05     |
| mean 100 episode reward | 3.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0429   |
| steps                   | 963885   |
| td_erros                | -0.1674  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 136300   |
| lives                   | 136300   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 6.93     |
| mean 100 episode reward | 3.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0973   |
| steps                   | 964478   |
| td_erros                | -0.1522  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 136400   |
| lives                   | 136400   |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 6.42     |
| mean 100 episode reward | 3.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1216   |
| steps                   | 965020   |
| td_erros                | -0.1442  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 136500   |
| lives                   | 136500   |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 6.57     |
| mean 100 episode reward | 3.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1002   |
| steps                   | 965577   |
| td_erros                | -0.1509  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 136600   |
| lives                   | 136600   |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 7.08     |
| mean 100 episode reward | 3.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1155   |
| steps                   | 966185   |
| td_erros                | -0.1693  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 136700   |
| lives                   | 136700   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 6.59     |
| mean 100 episode reward | 3.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0947   |
| steps                   | 966744   |
| td_erros                | -0.1775  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 136800   |
| lives                   | 136800   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 6.74     |
| mean 100 episode reward | 3.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0856   |
| steps                   | 967318   |
| td_erros                | -0.1821  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 136900   |
| lives                   | 136900   |
| mean 100 episode ei     | 4.73     |
| mean 100 episode length | 7.13     |
| mean 100 episode reward | 3.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1116   |
| steps                   | 967931   |
| td_erros                | -0.2046  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 137000   |
| lives                   | 137000   |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 6.82     |
| mean 100 episode reward | 3.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1844   |
| steps                   | 968513   |
| td_erros                | -0.1781  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 137100   |
| lives                   | 137100   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 7        |
| mean 100 episode reward | 3.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.182    |
| steps                   | 969113   |
| td_erros                | -0.1666  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 40       |
| episodes                | 137200   |
| lives                   | 137200   |
| mean 100 episode ei     | 3.8      |
| mean 100 episode length | 6.62     |
| mean 100 episode reward | 3.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1988   |
| steps                   | 969675   |
| td_erros                | -0.1627  |
--------------------------------------
Saving model due to running mean reward increase: 3.2035 -> 3.6073
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 137300   |
| lives                   | 137300   |
| mean 100 episode ei     | 3.62     |
| mean 100 episode length | 6.58     |
| mean 100 episode reward | 3.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2455   |
| steps                   | 970233   |
| td_erros                | -0.1418  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 137400   |
| lives                   | 137400   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 6.55     |
| mean 100 episode reward | 3.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2804   |
| steps                   | 970788   |
| td_erros                | -0.1369  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 137500   |
| lives                   | 137500   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 6.86     |
| mean 100 episode reward | 3.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3301   |
| steps                   | 971374   |
| td_erros                | -0.119   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 137600   |
| lives                   | 137600   |
| mean 100 episode ei     | 3.6      |
| mean 100 episode length | 6.49     |
| mean 100 episode reward | 3.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3347   |
| steps                   | 971923   |
| td_erros                | -0.0928  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 137700   |
| lives                   | 137700   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 7.03     |
| mean 100 episode reward | 3.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3035   |
| steps                   | 972526   |
| td_erros                | -0.0919  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 137800   |
| lives                   | 137800   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 7.12     |
| mean 100 episode reward | 3.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2842   |
| steps                   | 973138   |
| td_erros                | -0.0879  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 137900   |
| lives                   | 137900   |
| mean 100 episode ei     | 4.51     |
| mean 100 episode length | 7.52     |
| mean 100 episode reward | 4.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2339   |
| steps                   | 973790   |
| td_erros                | -0.0998  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 138000   |
| lives                   | 138000   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 6.98     |
| mean 100 episode reward | 4.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1872   |
| steps                   | 974388   |
| td_erros                | -0.1196  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 138100   |
| lives                   | 138100   |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 6.68     |
| mean 100 episode reward | 4.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1819   |
| steps                   | 974956   |
| td_erros                | -0.1327  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 138200   |
| lives                   | 138200   |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 6.79     |
| mean 100 episode reward | 3.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1563   |
| steps                   | 975535   |
| td_erros                | -0.1537  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 138300   |
| lives                   | 138300   |
| mean 100 episode ei     | 3.65     |
| mean 100 episode length | 6.3      |
| mean 100 episode reward | 3.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1377   |
| steps                   | 976065   |
| td_erros                | -0.1544  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 138400   |
| lives                   | 138400   |
| mean 100 episode ei     | 4.36     |
| mean 100 episode length | 7.12     |
| mean 100 episode reward | 3.69     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1101   |
| steps                   | 976677   |
| td_erros                | -0.1716  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 138500   |
| lives                   | 138500   |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 6.37     |
| mean 100 episode reward | 3.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0894   |
| steps                   | 977214   |
| td_erros                | -0.1929  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 138600   |
| lives                   | 138600   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 6.28     |
| mean 100 episode reward | 3.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.108    |
| steps                   | 977742   |
| td_erros                | -0.1901  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 138700   |
| lives                   | 138700   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 6.07     |
| mean 100 episode reward | 3.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.163    |
| steps                   | 978249   |
| td_erros                | -0.2039  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 138800   |
| lives                   | 138800   |
| mean 100 episode ei     | 3.69     |
| mean 100 episode length | 6        |
| mean 100 episode reward | 3.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2049   |
| steps                   | 978749   |
| td_erros                | -0.2042  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 138900   |
| lives                   | 138900   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 6.68     |
| mean 100 episode reward | 2.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1703   |
| steps                   | 979317   |
| td_erros                | -0.2152  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 139000   |
| lives                   | 139000   |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 6.27     |
| mean 100 episode reward | 3.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1498   |
| steps                   | 979844   |
| td_erros                | -0.2283  |
--------------------------------------
Saving model due to mean reward increase: 3.6642 -> 3.727
Saving model due to running mean reward increase: 2.7536 -> 3.727
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 139100   |
| lives                   | 139100   |
| mean 100 episode ei     | 3.46     |
| mean 100 episode length | 6.8      |
| mean 100 episode reward | 2.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1393   |
| steps                   | 980424   |
| td_erros                | -0.2312  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 139200   |
| lives                   | 139200   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 7.14     |
| mean 100 episode reward | 3.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0696   |
| steps                   | 981038   |
| td_erros                | -0.2637  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 139300   |
| lives                   | 139300   |
| mean 100 episode ei     | 4.33     |
| mean 100 episode length | 7.66     |
| mean 100 episode reward | 3.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.043    |
| steps                   | 981704   |
| td_erros                | -0.2616  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 139400   |
| lives                   | 139400   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 6.99     |
| mean 100 episode reward | 3.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0653   |
| steps                   | 982303   |
| td_erros                | -0.2623  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 139500   |
| lives                   | 139500   |
| mean 100 episode ei     | 4.47     |
| mean 100 episode length | 8.25     |
| mean 100 episode reward | 3.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.084    |
| steps                   | 983028   |
| td_erros                | -0.256   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 139600   |
| lives                   | 139600   |
| mean 100 episode ei     | 3.63     |
| mean 100 episode length | 7.23     |
| mean 100 episode reward | 3.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0745   |
| steps                   | 983651   |
| td_erros                | -0.2502  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 139700   |
| lives                   | 139700   |
| mean 100 episode ei     | 3.49     |
| mean 100 episode length | 6.75     |
| mean 100 episode reward | 2.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0679   |
| steps                   | 984226   |
| td_erros                | -0.2578  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 139800   |
| lives                   | 139800   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 6.93     |
| mean 100 episode reward | 2.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0443   |
| steps                   | 984819   |
| td_erros                | -0.2438  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 39       |
| episodes                | 139900   |
| lives                   | 139900   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 6.93     |
| mean 100 episode reward | 2.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0424   |
| steps                   | 985412   |
| td_erros                | -0.264   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 140000   |
| lives                   | 140000   |
| mean 100 episode ei     | 4.23     |
| mean 100 episode length | 7        |
| mean 100 episode reward | 2.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0593   |
| steps                   | 986012   |
| td_erros                | -0.2336  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 140100   |
| lives                   | 140100   |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 7.47     |
| mean 100 episode reward | 3.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0836   |
| steps                   | 986659   |
| td_erros                | -0.2417  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 140200   |
| lives                   | 140200   |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 7.1      |
| mean 100 episode reward | 3.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1042   |
| steps                   | 987269   |
| td_erros                | -0.2236  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 140300   |
| lives                   | 140300   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 7.46     |
| mean 100 episode reward | 3.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1174   |
| steps                   | 987915   |
| td_erros                | -0.1999  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 140400   |
| lives                   | 140400   |
| mean 100 episode ei     | 3.65     |
| mean 100 episode length | 6.95     |
| mean 100 episode reward | 3.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1387   |
| steps                   | 988510   |
| td_erros                | -0.1816  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 140500   |
| lives                   | 140500   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 6.59     |
| mean 100 episode reward | 4.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1045   |
| steps                   | 989069   |
| td_erros                | -0.186   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 140600   |
| lives                   | 140600   |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 7.49     |
| mean 100 episode reward | 3.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0804   |
| steps                   | 989718   |
| td_erros                | -0.1945  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 140700   |
| lives                   | 140700   |
| mean 100 episode ei     | 4.33     |
| mean 100 episode length | 6.95     |
| mean 100 episode reward | 3.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1288   |
| steps                   | 990313   |
| td_erros                | -0.1826  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 140800   |
| lives                   | 140800   |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 7        |
| mean 100 episode reward | 3.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1676   |
| steps                   | 990913   |
| td_erros                | -0.1751  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 140900   |
| lives                   | 140900   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 6.34     |
| mean 100 episode reward | 3        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1935   |
| steps                   | 991447   |
| td_erros                | -0.1869  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 141000   |
| lives                   | 141000   |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 6.96     |
| mean 100 episode reward | 3.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1249   |
| steps                   | 992043   |
| td_erros                | -0.2018  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 141100   |
| lives                   | 141100   |
| mean 100 episode ei     | 3.67     |
| mean 100 episode length | 6.21     |
| mean 100 episode reward | 3.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1191   |
| steps                   | 992564   |
| td_erros                | -0.2171  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 141200   |
| lives                   | 141200   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 6.53     |
| mean 100 episode reward | 4.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1112   |
| steps                   | 993117   |
| td_erros                | -0.2171  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 141300   |
| lives                   | 141300   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 6.7      |
| mean 100 episode reward | 3.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1472   |
| steps                   | 993687   |
| td_erros                | -0.2052  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 141400   |
| lives                   | 141400   |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 6.65     |
| mean 100 episode reward | 3.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1535   |
| steps                   | 994252   |
| td_erros                | -0.2372  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 141500   |
| lives                   | 141500   |
| mean 100 episode ei     | 4.24     |
| mean 100 episode length | 7.16     |
| mean 100 episode reward | 3.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1816   |
| steps                   | 994868   |
| td_erros                | -0.2087  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 141600   |
| lives                   | 141600   |
| mean 100 episode ei     | 3.3      |
| mean 100 episode length | 6.15     |
| mean 100 episode reward | 3.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1733   |
| steps                   | 995383   |
| td_erros                | -0.1788  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 141700   |
| lives                   | 141700   |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 7.18     |
| mean 100 episode reward | 4.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1006   |
| steps                   | 996001   |
| td_erros                | -0.1949  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 141800   |
| lives                   | 141800   |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 6.92     |
| mean 100 episode reward | 4.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0412   |
| steps                   | 996593   |
| td_erros                | -0.1921  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 141900   |
| lives                   | 141900   |
| mean 100 episode ei     | 3.79     |
| mean 100 episode length | 6.25     |
| mean 100 episode reward | 3.96     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0325   |
| steps                   | 997118   |
| td_erros                | -0.1891  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 142000   |
| lives                   | 142000   |
| mean 100 episode ei     | 3.79     |
| mean 100 episode length | 6.68     |
| mean 100 episode reward | 3.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0456   |
| steps                   | 997686   |
| td_erros                | -0.2264  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 142100   |
| lives                   | 142100   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 6.34     |
| mean 100 episode reward | 3.57     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0436   |
| steps                   | 998220   |
| td_erros                | -0.2215  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 142200   |
| lives                   | 142200   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 6.92     |
| mean 100 episode reward | 3.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0343   |
| steps                   | 998812   |
| td_erros                | -0.218   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 142300   |
| lives                   | 142300   |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 6.51     |
| mean 100 episode reward | 3.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.988    |
| steps                   | 999363   |
| td_erros                | -0.2341  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 142400   |
| lives                   | 142400   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 6.43     |
| mean 100 episode reward | 3.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0285   |
| steps                   | 999906   |
| td_erros                | -0.2212  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 142500   |
| lives                   | 142500   |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 6.54     |
| mean 100 episode reward | 3.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0012   |
| steps                   | 1000460  |
| td_erros                | -0.2249  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 142600   |
| lives                   | 142600   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 6.72     |
| mean 100 episode reward | 3.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0028   |
| steps                   | 1001032  |
| td_erros                | -0.2299  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 38       |
| episodes                | 142700   |
| lives                   | 142700   |
| mean 100 episode ei     | 4.4      |
| mean 100 episode length | 7.08     |
| mean 100 episode reward | 3.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0301   |
| steps                   | 1001640  |
| td_erros                | -0.2238  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 142800   |
| lives                   | 142800   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 7.04     |
| mean 100 episode reward | 3.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0488   |
| steps                   | 1002244  |
| td_erros                | -0.2123  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 142900   |
| lives                   | 142900   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 7.06     |
| mean 100 episode reward | 3.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.049    |
| steps                   | 1002850  |
| td_erros                | -0.2144  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 143000   |
| lives                   | 143000   |
| mean 100 episode ei     | 3.57     |
| mean 100 episode length | 6.75     |
| mean 100 episode reward | 3.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0414   |
| steps                   | 1003425  |
| td_erros                | -0.2267  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 143100   |
| lives                   | 143100   |
| mean 100 episode ei     | 3.6      |
| mean 100 episode length | 6.63     |
| mean 100 episode reward | 3.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9836   |
| steps                   | 1003988  |
| td_erros                | -0.2188  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 143200   |
| lives                   | 143200   |
| mean 100 episode ei     | 3.45     |
| mean 100 episode length | 6.64     |
| mean 100 episode reward | 3.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9802   |
| steps                   | 1004552  |
| td_erros                | -0.2214  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 143300   |
| lives                   | 143300   |
| mean 100 episode ei     | 3.54     |
| mean 100 episode length | 6.71     |
| mean 100 episode reward | 3.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9702   |
| steps                   | 1005123  |
| td_erros                | -0.222   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 143400   |
| lives                   | 143400   |
| mean 100 episode ei     | 3.54     |
| mean 100 episode length | 7.01     |
| mean 100 episode reward | 3.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.933    |
| steps                   | 1005724  |
| td_erros                | -0.2118  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 143500   |
| lives                   | 143500   |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 7.29     |
| mean 100 episode reward | 3.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8886   |
| steps                   | 1006353  |
| td_erros                | -0.2436  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 143600   |
| lives                   | 143600   |
| mean 100 episode ei     | 3.6      |
| mean 100 episode length | 6.58     |
| mean 100 episode reward | 3.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8468   |
| steps                   | 1006911  |
| td_erros                | -0.2516  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 143700   |
| lives                   | 143700   |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 6.67     |
| mean 100 episode reward | 3.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8292   |
| steps                   | 1007478  |
| td_erros                | -0.2523  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 143800   |
| lives                   | 143800   |
| mean 100 episode ei     | 4.57     |
| mean 100 episode length | 7.07     |
| mean 100 episode reward | 3.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8641   |
| steps                   | 1008085  |
| td_erros                | -0.2472  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 143900   |
| lives                   | 143900   |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 6.59     |
| mean 100 episode reward | 3.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.901    |
| steps                   | 1008644  |
| td_erros                | -0.2325  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 144000   |
| lives                   | 144000   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 6.35     |
| mean 100 episode reward | 2.96     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9218   |
| steps                   | 1009179  |
| td_erros                | -0.2385  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 144100   |
| lives                   | 144100   |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 6.36     |
| mean 100 episode reward | 3.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.949    |
| steps                   | 1009715  |
| td_erros                | -0.2678  |
--------------------------------------
Saving model due to running mean reward increase: 3.0796 -> 3.6678
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 144200   |
| lives                   | 144200   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 6.34     |
| mean 100 episode reward | 4.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9954   |
| steps                   | 1010249  |
| td_erros                | -0.2704  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 144300   |
| lives                   | 144300   |
| mean 100 episode ei     | 3.58     |
| mean 100 episode length | 6.47     |
| mean 100 episode reward | 3.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0135   |
| steps                   | 1010796  |
| td_erros                | -0.2645  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 144400   |
| lives                   | 144400   |
| mean 100 episode ei     | 3.25     |
| mean 100 episode length | 5.86     |
| mean 100 episode reward | 3.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0213   |
| steps                   | 1011282  |
| td_erros                | -0.2693  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 144500   |
| lives                   | 144500   |
| mean 100 episode ei     | 3.69     |
| mean 100 episode length | 6.51     |
| mean 100 episode reward | 4.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0347   |
| steps                   | 1011833  |
| td_erros                | -0.2641  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 144600   |
| lives                   | 144600   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 6.54     |
| mean 100 episode reward | 3.69     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0553   |
| steps                   | 1012387  |
| td_erros                | -0.2685  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 144700   |
| lives                   | 144700   |
| mean 100 episode ei     | 3.68     |
| mean 100 episode length | 6.39     |
| mean 100 episode reward | 3.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0584   |
| steps                   | 1012926  |
| td_erros                | -0.2448  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 144800   |
| lives                   | 144800   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 6.71     |
| mean 100 episode reward | 4.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0251   |
| steps                   | 1013497  |
| td_erros                | -0.2534  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 144900   |
| lives                   | 144900   |
| mean 100 episode ei     | 4.42     |
| mean 100 episode length | 7.41     |
| mean 100 episode reward | 3.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0102   |
| steps                   | 1014138  |
| td_erros                | -0.2525  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 145000   |
| lives                   | 145000   |
| mean 100 episode ei     | 4.42     |
| mean 100 episode length | 7.71     |
| mean 100 episode reward | 3.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9985   |
| steps                   | 1014809  |
| td_erros                | -0.2541  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 145100   |
| lives                   | 145100   |
| mean 100 episode ei     | 4.43     |
| mean 100 episode length | 7.44     |
| mean 100 episode reward | 3.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9741   |
| steps                   | 1015453  |
| td_erros                | -0.2534  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 145200   |
| lives                   | 145200   |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 7.21     |
| mean 100 episode reward | 4.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0088   |
| steps                   | 1016074  |
| td_erros                | -0.2648  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 145300   |
| lives                   | 145300   |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 7.05     |
| mean 100 episode reward | 3.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0737   |
| steps                   | 1016679  |
| td_erros                | -0.2489  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 145400   |
| lives                   | 145400   |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 6.52     |
| mean 100 episode reward | 3.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1084   |
| steps                   | 1017231  |
| td_erros                | -0.2281  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 37       |
| episodes                | 145500   |
| lives                   | 145500   |
| mean 100 episode ei     | 3.72     |
| mean 100 episode length | 6.04     |
| mean 100 episode reward | 3.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1489   |
| steps                   | 1017735  |
| td_erros                | -0.2228  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 145600   |
| lives                   | 145600   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 6.48     |
| mean 100 episode reward | 4.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1838   |
| steps                   | 1018283  |
| td_erros                | -0.2146  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 145700   |
| lives                   | 145700   |
| mean 100 episode ei     | 4.33     |
| mean 100 episode length | 6.88     |
| mean 100 episode reward | 4.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2107   |
| steps                   | 1018871  |
| td_erros                | -0.2047  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 145800   |
| lives                   | 145800   |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 7.24     |
| mean 100 episode reward | 3.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2274   |
| steps                   | 1019495  |
| td_erros                | -0.2107  |
--------------------------------------
Saving model due to mean reward increase: 3.727 -> 4.0931
Saving model due to running mean reward increase: 4.074 -> 4.0931
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 145900   |
| lives                   | 145900   |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 6.96     |
| mean 100 episode reward | 4.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2621   |
| steps                   | 1020091  |
| td_erros                | -0.1922  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 146000   |
| lives                   | 146000   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 7.15     |
| mean 100 episode reward | 3.96     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2718   |
| steps                   | 1020706  |
| td_erros                | -0.1677  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 146100   |
| lives                   | 146100   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 6.4      |
| mean 100 episode reward | 3.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2826   |
| steps                   | 1021246  |
| td_erros                | -0.1535  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 146200   |
| lives                   | 146200   |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 6.41     |
| mean 100 episode reward | 3.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2328   |
| steps                   | 1021787  |
| td_erros                | -0.1542  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 146300   |
| lives                   | 146300   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 6.85     |
| mean 100 episode reward | 4.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2147   |
| steps                   | 1022372  |
| td_erros                | -0.1588  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 146400   |
| lives                   | 146400   |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 6.77     |
| mean 100 episode reward | 4.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1851   |
| steps                   | 1022949  |
| td_erros                | -0.1736  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 146500   |
| lives                   | 146500   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 6.72     |
| mean 100 episode reward | 3.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1774   |
| steps                   | 1023521  |
| td_erros                | -0.1708  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 146600   |
| lives                   | 146600   |
| mean 100 episode ei     | 3.66     |
| mean 100 episode length | 6.76     |
| mean 100 episode reward | 4        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1471   |
| steps                   | 1024097  |
| td_erros                | -0.16    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 146700   |
| lives                   | 146700   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 6.98     |
| mean 100 episode reward | 4.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1152   |
| steps                   | 1024695  |
| td_erros                | -0.1579  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 146800   |
| lives                   | 146800   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 6.48     |
| mean 100 episode reward | 3.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0951   |
| steps                   | 1025243  |
| td_erros                | -0.1691  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 146900   |
| lives                   | 146900   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 6.23     |
| mean 100 episode reward | 4.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0865   |
| steps                   | 1025766  |
| td_erros                | -0.1801  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 147000   |
| lives                   | 147000   |
| mean 100 episode ei     | 4.45     |
| mean 100 episode length | 7.29     |
| mean 100 episode reward | 4.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0931   |
| steps                   | 1026395  |
| td_erros                | -0.163   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 147100   |
| lives                   | 147100   |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 7.48     |
| mean 100 episode reward | 3.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0486   |
| steps                   | 1027043  |
| td_erros                | -0.184   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 147200   |
| lives                   | 147200   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 6.94     |
| mean 100 episode reward | 3.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0395   |
| steps                   | 1027637  |
| td_erros                | -0.1765  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 147300   |
| lives                   | 147300   |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 6.98     |
| mean 100 episode reward | 4.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0344   |
| steps                   | 1028235  |
| td_erros                | -0.1911  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 147400   |
| lives                   | 147400   |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 7.04     |
| mean 100 episode reward | 3.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0746   |
| steps                   | 1028839  |
| td_erros                | -0.19    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 147500   |
| lives                   | 147500   |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 6.69     |
| mean 100 episode reward | 4.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1234   |
| steps                   | 1029408  |
| td_erros                | -0.1742  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 147600   |
| lives                   | 147600   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 6.69     |
| mean 100 episode reward | 4.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1792   |
| steps                   | 1029977  |
| td_erros                | -0.1484  |
--------------------------------------
Saving model due to mean reward increase: 4.0931 -> 4.307
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 147700   |
| lives                   | 147700   |
| mean 100 episode ei     | 4.5      |
| mean 100 episode length | 7.27     |
| mean 100 episode reward | 4.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1757   |
| steps                   | 1030604  |
| td_erros                | -0.1695  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 147800   |
| lives                   | 147800   |
| mean 100 episode ei     | 4.45     |
| mean 100 episode length | 7.67     |
| mean 100 episode reward | 3.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2249   |
| steps                   | 1031271  |
| td_erros                | -0.1377  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 147900   |
| lives                   | 147900   |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 6.55     |
| mean 100 episode reward | 3.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2189   |
| steps                   | 1031826  |
| td_erros                | -0.1518  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 148000   |
| lives                   | 148000   |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 6.05     |
| mean 100 episode reward | 3.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2744   |
| steps                   | 1032331  |
| td_erros                | -0.128   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 148100   |
| lives                   | 148100   |
| mean 100 episode ei     | 3.69     |
| mean 100 episode length | 6.03     |
| mean 100 episode reward | 3.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.295    |
| steps                   | 1032834  |
| td_erros                | -0.1363  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 148200   |
| lives                   | 148200   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 6.7      |
| mean 100 episode reward | 4.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.32     |
| steps                   | 1033404  |
| td_erros                | -0.1059  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 36       |
| episodes                | 148300   |
| lives                   | 148300   |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 7.1      |
| mean 100 episode reward | 4.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.3165   |
| steps                   | 1034014  |
| td_erros                | -0.1037  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 148400   |
| lives                   | 148400   |
| mean 100 episode ei     | 3.61     |
| mean 100 episode length | 6.63     |
| mean 100 episode reward | 3.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.309    |
| steps                   | 1034577  |
| td_erros                | -0.105   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 148500   |
| lives                   | 148500   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 7.06     |
| mean 100 episode reward | 3.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2628   |
| steps                   | 1035183  |
| td_erros                | -0.1323  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 148600   |
| lives                   | 148600   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 6.93     |
| mean 100 episode reward | 4.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1719   |
| steps                   | 1035776  |
| td_erros                | -0.1636  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 148700   |
| lives                   | 148700   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 6.76     |
| mean 100 episode reward | 4.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0921   |
| steps                   | 1036352  |
| td_erros                | -0.2094  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 148800   |
| lives                   | 148800   |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 6.24     |
| mean 100 episode reward | 4.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0678   |
| steps                   | 1036876  |
| td_erros                | -0.2058  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 148900   |
| lives                   | 148900   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 6.89     |
| mean 100 episode reward | 3.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0105   |
| steps                   | 1037465  |
| td_erros                | -0.2415  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 149000   |
| lives                   | 149000   |
| mean 100 episode ei     | 3.46     |
| mean 100 episode length | 6.42     |
| mean 100 episode reward | 3.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9897   |
| steps                   | 1038007  |
| td_erros                | -0.2369  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 149100   |
| lives                   | 149100   |
| mean 100 episode ei     | 3.35     |
| mean 100 episode length | 6.19     |
| mean 100 episode reward | 3.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9469   |
| steps                   | 1038526  |
| td_erros                | -0.2343  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 149200   |
| lives                   | 149200   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 7.06     |
| mean 100 episode reward | 3.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9069   |
| steps                   | 1039132  |
| td_erros                | -0.2392  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 149300   |
| lives                   | 149300   |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 6.78     |
| mean 100 episode reward | 3.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8421   |
| steps                   | 1039710  |
| td_erros                | -0.2595  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 149400   |
| lives                   | 149400   |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 7.11     |
| mean 100 episode reward | 3.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8529   |
| steps                   | 1040321  |
| td_erros                | -0.2807  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 149500   |
| lives                   | 149500   |
| mean 100 episode ei     | 4.48     |
| mean 100 episode length | 6.79     |
| mean 100 episode reward | 3.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9225   |
| steps                   | 1040900  |
| td_erros                | -0.2768  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 149600   |
| lives                   | 149600   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 6.47     |
| mean 100 episode reward | 2.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9757   |
| steps                   | 1041447  |
| td_erros                | -0.2691  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 149700   |
| lives                   | 149700   |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 6.4      |
| mean 100 episode reward | 4.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0239   |
| steps                   | 1041987  |
| td_erros                | -0.2645  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 149800   |
| lives                   | 149800   |
| mean 100 episode ei     | 3.68     |
| mean 100 episode length | 6.11     |
| mean 100 episode reward | 3.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0291   |
| steps                   | 1042498  |
| td_erros                | -0.2606  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 149900   |
| lives                   | 149900   |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 6.55     |
| mean 100 episode reward | 4.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0858   |
| steps                   | 1043053  |
| td_erros                | -0.2357  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 150000   |
| lives                   | 150000   |
| mean 100 episode ei     | 3.55     |
| mean 100 episode length | 6.55     |
| mean 100 episode reward | 3.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0875   |
| steps                   | 1043608  |
| td_erros                | -0.2404  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 150100   |
| lives                   | 150100   |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 6.48     |
| mean 100 episode reward | 3.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1112   |
| steps                   | 1044156  |
| td_erros                | -0.2218  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 150200   |
| lives                   | 150200   |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 6.9      |
| mean 100 episode reward | 3.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1583   |
| steps                   | 1044746  |
| td_erros                | -0.2276  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 150300   |
| lives                   | 150300   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 6.89     |
| mean 100 episode reward | 3.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1449   |
| steps                   | 1045335  |
| td_erros                | -0.2079  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 150400   |
| lives                   | 150400   |
| mean 100 episode ei     | 3.25     |
| mean 100 episode length | 6.32     |
| mean 100 episode reward | 3.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1378   |
| steps                   | 1045867  |
| td_erros                | -0.2075  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 150500   |
| lives                   | 150500   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 7.12     |
| mean 100 episode reward | 4.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0924   |
| steps                   | 1046479  |
| td_erros                | -0.2134  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 150600   |
| lives                   | 150600   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 7.05     |
| mean 100 episode reward | 3.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0405   |
| steps                   | 1047084  |
| td_erros                | -0.2085  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 150700   |
| lives                   | 150700   |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 7.18     |
| mean 100 episode reward | 3.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9543   |
| steps                   | 1047702  |
| td_erros                | -0.2442  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 150800   |
| lives                   | 150800   |
| mean 100 episode ei     | 3.72     |
| mean 100 episode length | 6.34     |
| mean 100 episode reward | 3.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9494   |
| steps                   | 1048236  |
| td_erros                | -0.2566  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 150900   |
| lives                   | 150900   |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 6.86     |
| mean 100 episode reward | 4.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9624   |
| steps                   | 1048822  |
| td_erros                | -0.2358  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 151000   |
| lives                   | 151000   |
| mean 100 episode ei     | 3.71     |
| mean 100 episode length | 6.28     |
| mean 100 episode reward | 4.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9677   |
| steps                   | 1049350  |
| td_erros                | -0.2234  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 151100   |
| lives                   | 151100   |
| mean 100 episode ei     | 3.83     |
| mean 100 episode length | 6.78     |
| mean 100 episode reward | 3.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9919   |
| steps                   | 1049928  |
| td_erros                | -0.2292  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 35       |
| episodes                | 151200   |
| lives                   | 151200   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 6.43     |
| mean 100 episode reward | 4.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0378   |
| steps                   | 1050471  |
| td_erros                | -0.2228  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 151300   |
| lives                   | 151300   |
| mean 100 episode ei     | 3.61     |
| mean 100 episode length | 6.5      |
| mean 100 episode reward | 3.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9969   |
| steps                   | 1051021  |
| td_erros                | -0.2231  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 151400   |
| lives                   | 151400   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 6.51     |
| mean 100 episode reward | 3.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0067   |
| steps                   | 1051572  |
| td_erros                | -0.2141  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 151500   |
| lives                   | 151500   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 6.51     |
| mean 100 episode reward | 3.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9828   |
| steps                   | 1052123  |
| td_erros                | -0.2109  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 151600   |
| lives                   | 151600   |
| mean 100 episode ei     | 3.13     |
| mean 100 episode length | 5.79     |
| mean 100 episode reward | 2.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.962    |
| steps                   | 1052602  |
| td_erros                | -0.1939  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 151700   |
| lives                   | 151700   |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 6.79     |
| mean 100 episode reward | 4.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9489   |
| steps                   | 1053181  |
| td_erros                | -0.2289  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 151800   |
| lives                   | 151800   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 6.9      |
| mean 100 episode reward | 4.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9513   |
| steps                   | 1053771  |
| td_erros                | -0.1881  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 151900   |
| lives                   | 151900   |
| mean 100 episode ei     | 4.32     |
| mean 100 episode length | 6.38     |
| mean 100 episode reward | 4.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.969    |
| steps                   | 1054309  |
| td_erros                | -0.2036  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 152000   |
| lives                   | 152000   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 6.32     |
| mean 100 episode reward | 4.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0044   |
| steps                   | 1054841  |
| td_erros                | -0.1851  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 152100   |
| lives                   | 152100   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 6.52     |
| mean 100 episode reward | 4.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0505   |
| steps                   | 1055393  |
| td_erros                | -0.1741  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 152200   |
| lives                   | 152200   |
| mean 100 episode ei     | 3.79     |
| mean 100 episode length | 6.98     |
| mean 100 episode reward | 3.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0701   |
| steps                   | 1055991  |
| td_erros                | -0.1564  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 152300   |
| lives                   | 152300   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 6.46     |
| mean 100 episode reward | 3.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0586   |
| steps                   | 1056537  |
| td_erros                | -0.1808  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 152400   |
| lives                   | 152400   |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 6.37     |
| mean 100 episode reward | 3.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0541   |
| steps                   | 1057074  |
| td_erros                | -0.1548  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 152500   |
| lives                   | 152500   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 6.62     |
| mean 100 episode reward | 4.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0626   |
| steps                   | 1057636  |
| td_erros                | -0.1806  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 152600   |
| lives                   | 152600   |
| mean 100 episode ei     | 3.75     |
| mean 100 episode length | 6.63     |
| mean 100 episode reward | 4.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1103   |
| steps                   | 1058199  |
| td_erros                | -0.1859  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 152700   |
| lives                   | 152700   |
| mean 100 episode ei     | 3.68     |
| mean 100 episode length | 6.32     |
| mean 100 episode reward | 3.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0522   |
| steps                   | 1058731  |
| td_erros                | -0.1899  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 152800   |
| lives                   | 152800   |
| mean 100 episode ei     | 3.48     |
| mean 100 episode length | 6.18     |
| mean 100 episode reward | 3.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9997   |
| steps                   | 1059249  |
| td_erros                | -0.2297  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 152900   |
| lives                   | 152900   |
| mean 100 episode ei     | 3.8      |
| mean 100 episode length | 6.63     |
| mean 100 episode reward | 4.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9508   |
| steps                   | 1059812  |
| td_erros                | -0.2305  |
--------------------------------------
Saving model due to running mean reward increase: 3.6667 -> 4.2561
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 153000   |
| lives                   | 153000   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 6.89     |
| mean 100 episode reward | 4.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8966   |
| steps                   | 1060401  |
| td_erros                | -0.2493  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 153100   |
| lives                   | 153100   |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 6.45     |
| mean 100 episode reward | 4.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9091   |
| steps                   | 1060946  |
| td_erros                | -0.2488  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 153200   |
| lives                   | 153200   |
| mean 100 episode ei     | 3.62     |
| mean 100 episode length | 6.28     |
| mean 100 episode reward | 3.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8997   |
| steps                   | 1061474  |
| td_erros                | -0.2343  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 153300   |
| lives                   | 153300   |
| mean 100 episode ei     | 3.74     |
| mean 100 episode length | 6.27     |
| mean 100 episode reward | 4.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8797   |
| steps                   | 1062001  |
| td_erros                | -0.2303  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 153400   |
| lives                   | 153400   |
| mean 100 episode ei     | 3.68     |
| mean 100 episode length | 6.13     |
| mean 100 episode reward | 4.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9176   |
| steps                   | 1062514  |
| td_erros                | -0.2143  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 153500   |
| lives                   | 153500   |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 6.39     |
| mean 100 episode reward | 4.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8942   |
| steps                   | 1063053  |
| td_erros                | -0.2177  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 153600   |
| lives                   | 153600   |
| mean 100 episode ei     | 3.67     |
| mean 100 episode length | 6.31     |
| mean 100 episode reward | 3.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8934   |
| steps                   | 1063584  |
| td_erros                | -0.2332  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 153700   |
| lives                   | 153700   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 7.03     |
| mean 100 episode reward | 4.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8711   |
| steps                   | 1064187  |
| td_erros                | -0.2476  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 153800   |
| lives                   | 153800   |
| mean 100 episode ei     | 4.36     |
| mean 100 episode length | 7.01     |
| mean 100 episode reward | 3.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8437   |
| steps                   | 1064788  |
| td_erros                | -0.2474  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 153900   |
| lives                   | 153900   |
| mean 100 episode ei     | 3.68     |
| mean 100 episode length | 5.78     |
| mean 100 episode reward | 3.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8852   |
| steps                   | 1065266  |
| td_erros                | -0.2388  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 154000   |
| lives                   | 154000   |
| mean 100 episode ei     | 3.8      |
| mean 100 episode length | 6.56     |
| mean 100 episode reward | 3.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8687   |
| steps                   | 1065822  |
| td_erros                | -0.244   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 34       |
| episodes                | 154100   |
| lives                   | 154100   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 6.74     |
| mean 100 episode reward | 4.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8825   |
| steps                   | 1066396  |
| td_erros                | -0.2533  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 154200   |
| lives                   | 154200   |
| mean 100 episode ei     | 4.24     |
| mean 100 episode length | 6.42     |
| mean 100 episode reward | 4.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9158   |
| steps                   | 1066938  |
| td_erros                | -0.2329  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 154300   |
| lives                   | 154300   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 6.64     |
| mean 100 episode reward | 4.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9108   |
| steps                   | 1067502  |
| td_erros                | -0.2376  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 154400   |
| lives                   | 154400   |
| mean 100 episode ei     | 3.6      |
| mean 100 episode length | 6.25     |
| mean 100 episode reward | 3.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9194   |
| steps                   | 1068027  |
| td_erros                | -0.2386  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 154500   |
| lives                   | 154500   |
| mean 100 episode ei     | 3.34     |
| mean 100 episode length | 5.75     |
| mean 100 episode reward | 3.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9583   |
| steps                   | 1068502  |
| td_erros                | -0.2056  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 154600   |
| lives                   | 154600   |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 6.84     |
| mean 100 episode reward | 3.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0147   |
| steps                   | 1069086  |
| td_erros                | -0.1871  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 154700   |
| lives                   | 154700   |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 6.97     |
| mean 100 episode reward | 3.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0527   |
| steps                   | 1069683  |
| td_erros                | -0.192   |
--------------------------------------
Saving model due to running mean reward increase: 3.3343 -> 3.6878
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 154800   |
| lives                   | 154800   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 6.89     |
| mean 100 episode reward | 3.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0462   |
| steps                   | 1070272  |
| td_erros                | -0.1776  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 154900   |
| lives                   | 154900   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 6.53     |
| mean 100 episode reward | 3.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0308   |
| steps                   | 1070825  |
| td_erros                | -0.1699  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 155000   |
| lives                   | 155000   |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 6.65     |
| mean 100 episode reward | 4.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0745   |
| steps                   | 1071390  |
| td_erros                | -0.1644  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 155100   |
| lives                   | 155100   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 6.28     |
| mean 100 episode reward | 3.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1229   |
| steps                   | 1071918  |
| td_erros                | -0.1365  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 155200   |
| lives                   | 155200   |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 6.6      |
| mean 100 episode reward | 4.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1313   |
| steps                   | 1072478  |
| td_erros                | -0.1259  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 155300   |
| lives                   | 155300   |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 7        |
| mean 100 episode reward | 3.99     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1178   |
| steps                   | 1073078  |
| td_erros                | -0.0933  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 155400   |
| lives                   | 155400   |
| mean 100 episode ei     | 4.67     |
| mean 100 episode length | 7.68     |
| mean 100 episode reward | 4.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1037   |
| steps                   | 1073746  |
| td_erros                | -0.1381  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 155500   |
| lives                   | 155500   |
| mean 100 episode ei     | 4.49     |
| mean 100 episode length | 7.16     |
| mean 100 episode reward | 4.57     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1335   |
| steps                   | 1074362  |
| td_erros                | -0.1263  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 155600   |
| lives                   | 155600   |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 7.06     |
| mean 100 episode reward | 4.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.148    |
| steps                   | 1074968  |
| td_erros                | -0.1169  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 155700   |
| lives                   | 155700   |
| mean 100 episode ei     | 4.24     |
| mean 100 episode length | 7.25     |
| mean 100 episode reward | 4.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1854   |
| steps                   | 1075593  |
| td_erros                | -0.124   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 155800   |
| lives                   | 155800   |
| mean 100 episode ei     | 4.48     |
| mean 100 episode length | 7.33     |
| mean 100 episode reward | 4.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1715   |
| steps                   | 1076226  |
| td_erros                | -0.1233  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 155900   |
| lives                   | 155900   |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 7.17     |
| mean 100 episode reward | 3.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1649   |
| steps                   | 1076843  |
| td_erros                | -0.1754  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 156000   |
| lives                   | 156000   |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 6.92     |
| mean 100 episode reward | 3.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1973   |
| steps                   | 1077435  |
| td_erros                | -0.1527  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 156100   |
| lives                   | 156100   |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 6.48     |
| mean 100 episode reward | 3.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2189   |
| steps                   | 1077983  |
| td_erros                | -0.1883  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 156200   |
| lives                   | 156200   |
| mean 100 episode ei     | 3.6      |
| mean 100 episode length | 5.99     |
| mean 100 episode reward | 3.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.2753   |
| steps                   | 1078482  |
| td_erros                | -0.1322  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 156300   |
| lives                   | 156300   |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 6.57     |
| mean 100 episode reward | 4.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.21     |
| steps                   | 1079039  |
| td_erros                | -0.1765  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 156400   |
| lives                   | 156400   |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 7.08     |
| mean 100 episode reward | 4.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1995   |
| steps                   | 1079647  |
| td_erros                | -0.1907  |
--------------------------------------
Saving model due to mean reward increase: 4.307 -> 4.3804
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 156500   |
| lives                   | 156500   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 7.57     |
| mean 100 episode reward | 4.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1378   |
| steps                   | 1080304  |
| td_erros                | -0.2272  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 156600   |
| lives                   | 156600   |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 7.76     |
| mean 100 episode reward | 4.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0688   |
| steps                   | 1080980  |
| td_erros                | -0.2434  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 156700   |
| lives                   | 156700   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 7        |
| mean 100 episode reward | 4.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0314   |
| steps                   | 1081580  |
| td_erros                | -0.2316  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 156800   |
| lives                   | 156800   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 6.94     |
| mean 100 episode reward | 3.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9878   |
| steps                   | 1082174  |
| td_erros                | -0.2477  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 33       |
| episodes                | 156900   |
| lives                   | 156900   |
| mean 100 episode ei     | 3.58     |
| mean 100 episode length | 6.62     |
| mean 100 episode reward | 3.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9253   |
| steps                   | 1082736  |
| td_erros                | -0.2573  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 157000   |
| lives                   | 157000   |
| mean 100 episode ei     | 3.64     |
| mean 100 episode length | 6.89     |
| mean 100 episode reward | 3.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.887    |
| steps                   | 1083325  |
| td_erros                | -0.2749  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 157100   |
| lives                   | 157100   |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 7.29     |
| mean 100 episode reward | 4.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.833    |
| steps                   | 1083954  |
| td_erros                | -0.2821  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 157200   |
| lives                   | 157200   |
| mean 100 episode ei     | 3.72     |
| mean 100 episode length | 7.05     |
| mean 100 episode reward | 4.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7942   |
| steps                   | 1084559  |
| td_erros                | -0.2906  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 157300   |
| lives                   | 157300   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 7.17     |
| mean 100 episode reward | 4.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7894   |
| steps                   | 1085176  |
| td_erros                | -0.3029  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 157400   |
| lives                   | 157400   |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 6.93     |
| mean 100 episode reward | 3.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7719   |
| steps                   | 1085769  |
| td_erros                | -0.3103  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 157500   |
| lives                   | 157500   |
| mean 100 episode ei     | 3.55     |
| mean 100 episode length | 6.64     |
| mean 100 episode reward | 4.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.77     |
| steps                   | 1086333  |
| td_erros                | -0.2944  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 157600   |
| lives                   | 157600   |
| mean 100 episode ei     | 2.68     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 2.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7303   |
| steps                   | 1086792  |
| td_erros                | -0.2678  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 157700   |
| lives                   | 157700   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 6.69     |
| mean 100 episode reward | 4.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7429   |
| steps                   | 1087361  |
| td_erros                | -0.2476  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 157800   |
| lives                   | 157800   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 7        |
| mean 100 episode reward | 4.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7371   |
| steps                   | 1087961  |
| td_erros                | -0.2517  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 157900   |
| lives                   | 157900   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 7.13     |
| mean 100 episode reward | 3.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7419   |
| steps                   | 1088574  |
| td_erros                | -0.2556  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 158000   |
| lives                   | 158000   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 7.17     |
| mean 100 episode reward | 3.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7671   |
| steps                   | 1089191  |
| td_erros                | -0.2481  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 158100   |
| lives                   | 158100   |
| mean 100 episode ei     | 4.53     |
| mean 100 episode length | 7.11     |
| mean 100 episode reward | 3.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8226   |
| steps                   | 1089802  |
| td_erros                | -0.2331  |
--------------------------------------
Saving model due to running mean reward increase: 3.5667 -> 3.7543
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 158200   |
| lives                   | 158200   |
| mean 100 episode ei     | 4.41     |
| mean 100 episode length | 6.65     |
| mean 100 episode reward | 4.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8449   |
| steps                   | 1090367  |
| td_erros                | -0.2399  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 158300   |
| lives                   | 158300   |
| mean 100 episode ei     | 3.69     |
| mean 100 episode length | 6.15     |
| mean 100 episode reward | 4.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9023   |
| steps                   | 1090882  |
| td_erros                | -0.2339  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 158400   |
| lives                   | 158400   |
| mean 100 episode ei     | 3.71     |
| mean 100 episode length | 6.04     |
| mean 100 episode reward | 3.99     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9285   |
| steps                   | 1091386  |
| td_erros                | -0.2415  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 158500   |
| lives                   | 158500   |
| mean 100 episode ei     | 3.58     |
| mean 100 episode length | 6.24     |
| mean 100 episode reward | 3.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9313   |
| steps                   | 1091910  |
| td_erros                | -0.2511  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 158600   |
| lives                   | 158600   |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 6.9      |
| mean 100 episode reward | 4.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9279   |
| steps                   | 1092500  |
| td_erros                | -0.2691  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 158700   |
| lives                   | 158700   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 6.28     |
| mean 100 episode reward | 4.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9595   |
| steps                   | 1093028  |
| td_erros                | -0.2559  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 158800   |
| lives                   | 158800   |
| mean 100 episode ei     | 4.39     |
| mean 100 episode length | 6.72     |
| mean 100 episode reward | 4.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0263   |
| steps                   | 1093600  |
| td_erros                | -0.2542  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 158900   |
| lives                   | 158900   |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 6.72     |
| mean 100 episode reward | 4.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0969   |
| steps                   | 1094172  |
| td_erros                | -0.2169  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 159000   |
| lives                   | 159000   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 6.12     |
| mean 100 episode reward | 3.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.135    |
| steps                   | 1094684  |
| td_erros                | -0.1967  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 159100   |
| lives                   | 159100   |
| mean 100 episode ei     | 4.47     |
| mean 100 episode length | 6.62     |
| mean 100 episode reward | 3.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1474   |
| steps                   | 1095246  |
| td_erros                | -0.2002  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 159200   |
| lives                   | 159200   |
| mean 100 episode ei     | 3.51     |
| mean 100 episode length | 6.12     |
| mean 100 episode reward | 3.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.122    |
| steps                   | 1095758  |
| td_erros                | -0.1889  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 159300   |
| lives                   | 159300   |
| mean 100 episode ei     | 3.65     |
| mean 100 episode length | 5.93     |
| mean 100 episode reward | 3.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.129    |
| steps                   | 1096251  |
| td_erros                | -0.1624  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 159400   |
| lives                   | 159400   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 6.38     |
| mean 100 episode reward | 4.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.1099   |
| steps                   | 1096789  |
| td_erros                | -0.1677  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 159500   |
| lives                   | 159500   |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 6.79     |
| mean 100 episode reward | 4.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0495   |
| steps                   | 1097368  |
| td_erros                | -0.2034  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 159600   |
| lives                   | 159600   |
| mean 100 episode ei     | 3.59     |
| mean 100 episode length | 6.18     |
| mean 100 episode reward | 3.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.0187   |
| steps                   | 1097886  |
| td_erros                | -0.2043  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 159700   |
| lives                   | 159700   |
| mean 100 episode ei     | 3.8      |
| mean 100 episode length | 6.38     |
| mean 100 episode reward | 4.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 2.02     |
| steps                   | 1098424  |
| td_erros                | -0.2288  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 32       |
| episodes                | 159800   |
| lives                   | 159800   |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 6.27     |
| mean 100 episode reward | 3.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.954    |
| steps                   | 1098951  |
| td_erros                | -0.2442  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 159900   |
| lives                   | 159900   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 6.51     |
| mean 100 episode reward | 4.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9052   |
| steps                   | 1099502  |
| td_erros                | -0.2648  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 160000   |
| lives                   | 160000   |
| mean 100 episode ei     | 2.96     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 3.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8736   |
| steps                   | 1099923  |
| td_erros                | -0.2644  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 160100   |
| lives                   | 160100   |
| mean 100 episode ei     | 3.68     |
| mean 100 episode length | 6.04     |
| mean 100 episode reward | 3.57     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8096   |
| steps                   | 1100427  |
| td_erros                | -0.2611  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 160200   |
| lives                   | 160200   |
| mean 100 episode ei     | 3.55     |
| mean 100 episode length | 6.33     |
| mean 100 episode reward | 4.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7476   |
| steps                   | 1100960  |
| td_erros                | -0.2525  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 160300   |
| lives                   | 160300   |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 6.53     |
| mean 100 episode reward | 4.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6901   |
| steps                   | 1101513  |
| td_erros                | -0.2742  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 160400   |
| lives                   | 160400   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 6.78     |
| mean 100 episode reward | 4.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6889   |
| steps                   | 1102091  |
| td_erros                | -0.2819  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 160500   |
| lives                   | 160500   |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 6.83     |
| mean 100 episode reward | 4.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7221   |
| steps                   | 1102674  |
| td_erros                | -0.248   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 160600   |
| lives                   | 160600   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 6.75     |
| mean 100 episode reward | 4.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7475   |
| steps                   | 1103249  |
| td_erros                | -0.2674  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 160700   |
| lives                   | 160700   |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 6.61     |
| mean 100 episode reward | 3.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7466   |
| steps                   | 1103810  |
| td_erros                | -0.2577  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 160800   |
| lives                   | 160800   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 6.45     |
| mean 100 episode reward | 3.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7572   |
| steps                   | 1104355  |
| td_erros                | -0.2631  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 160900   |
| lives                   | 160900   |
| mean 100 episode ei     | 3.52     |
| mean 100 episode length | 6.38     |
| mean 100 episode reward | 3.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7521   |
| steps                   | 1104893  |
| td_erros                | -0.269   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 161000   |
| lives                   | 161000   |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 6.43     |
| mean 100 episode reward | 3.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7365   |
| steps                   | 1105436  |
| td_erros                | -0.2819  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 161100   |
| lives                   | 161100   |
| mean 100 episode ei     | 3.69     |
| mean 100 episode length | 6.22     |
| mean 100 episode reward | 3.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7314   |
| steps                   | 1105958  |
| td_erros                | -0.285   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 161200   |
| lives                   | 161200   |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 6.19     |
| mean 100 episode reward | 3.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7283   |
| steps                   | 1106477  |
| td_erros                | -0.2987  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 161300   |
| lives                   | 161300   |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 6.69     |
| mean 100 episode reward | 4.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7183   |
| steps                   | 1107046  |
| td_erros                | -0.33    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 161400   |
| lives                   | 161400   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 6.52     |
| mean 100 episode reward | 3.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7816   |
| steps                   | 1107598  |
| td_erros                | -0.3286  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 161500   |
| lives                   | 161500   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 6.75     |
| mean 100 episode reward | 3.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8689   |
| steps                   | 1108173  |
| td_erros                | -0.3288  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 161600   |
| lives                   | 161600   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 6.89     |
| mean 100 episode reward | 3.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8688   |
| steps                   | 1108762  |
| td_erros                | -0.318   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 161700   |
| lives                   | 161700   |
| mean 100 episode ei     | 3.6      |
| mean 100 episode length | 6.72     |
| mean 100 episode reward | 3.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8439   |
| steps                   | 1109334  |
| td_erros                | -0.2934  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 161800   |
| lives                   | 161800   |
| mean 100 episode ei     | 3.29     |
| mean 100 episode length | 6.15     |
| mean 100 episode reward | 3.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8653   |
| steps                   | 1109849  |
| td_erros                | -0.2815  |
--------------------------------------
Saving model due to running mean reward increase: 3.3837 -> 4.0324
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 161900   |
| lives                   | 161900   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 6.58     |
| mean 100 episode reward | 4.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8776   |
| steps                   | 1110407  |
| td_erros                | -0.301   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 162000   |
| lives                   | 162000   |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 6.72     |
| mean 100 episode reward | 3.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8879   |
| steps                   | 1110979  |
| td_erros                | -0.2743  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 162100   |
| lives                   | 162100   |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 6.73     |
| mean 100 episode reward | 3.99     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.92     |
| steps                   | 1111552  |
| td_erros                | -0.2658  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 162200   |
| lives                   | 162200   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 6.61     |
| mean 100 episode reward | 4.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9214   |
| steps                   | 1112113  |
| td_erros                | -0.2414  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 162300   |
| lives                   | 162300   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 6.57     |
| mean 100 episode reward | 4.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9274   |
| steps                   | 1112670  |
| td_erros                | -0.243   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 162400   |
| lives                   | 162400   |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 6.71     |
| mean 100 episode reward | 4.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9281   |
| steps                   | 1113241  |
| td_erros                | -0.2395  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 162500   |
| lives                   | 162500   |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 6.3      |
| mean 100 episode reward | 4        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9362   |
| steps                   | 1113771  |
| td_erros                | -0.2396  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 162600   |
| lives                   | 162600   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 6.57     |
| mean 100 episode reward | 3.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9227   |
| steps                   | 1114328  |
| td_erros                | -0.2494  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 31       |
| episodes                | 162700   |
| lives                   | 162700   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 6.75     |
| mean 100 episode reward | 3.99     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9092   |
| steps                   | 1114903  |
| td_erros                | -0.2683  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 162800   |
| lives                   | 162800   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 6.79     |
| mean 100 episode reward | 4.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8553   |
| steps                   | 1115482  |
| td_erros                | -0.2694  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 162900   |
| lives                   | 162900   |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 7        |
| mean 100 episode reward | 3.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8177   |
| steps                   | 1116082  |
| td_erros                | -0.2842  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 163000   |
| lives                   | 163000   |
| mean 100 episode ei     | 4.48     |
| mean 100 episode length | 7.14     |
| mean 100 episode reward | 4.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8249   |
| steps                   | 1116696  |
| td_erros                | -0.2938  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 163100   |
| lives                   | 163100   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 6.37     |
| mean 100 episode reward | 4.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8572   |
| steps                   | 1117233  |
| td_erros                | -0.2912  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 163200   |
| lives                   | 163200   |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 6.85     |
| mean 100 episode reward | 4.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.878    |
| steps                   | 1117818  |
| td_erros                | -0.2782  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 163300   |
| lives                   | 163300   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 6.14     |
| mean 100 episode reward | 4.96     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9115   |
| steps                   | 1118332  |
| td_erros                | -0.2664  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 163400   |
| lives                   | 163400   |
| mean 100 episode ei     | 3.6      |
| mean 100 episode length | 6.53     |
| mean 100 episode reward | 4.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9076   |
| steps                   | 1118885  |
| td_erros                | -0.2553  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 163500   |
| lives                   | 163500   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 6.67     |
| mean 100 episode reward | 4.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9247   |
| steps                   | 1119452  |
| td_erros                | -0.2577  |
--------------------------------------
Saving model due to mean reward increase: 4.3804 -> 4.5257
Saving model due to running mean reward increase: 4.2756 -> 4.5257
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 163600   |
| lives                   | 163600   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 7.07     |
| mean 100 episode reward | 4.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9249   |
| steps                   | 1120059  |
| td_erros                | -0.2466  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 163700   |
| lives                   | 163700   |
| mean 100 episode ei     | 3.36     |
| mean 100 episode length | 6.4      |
| mean 100 episode reward | 3.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9573   |
| steps                   | 1120599  |
| td_erros                | -0.2304  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 163800   |
| lives                   | 163800   |
| mean 100 episode ei     | 2.77     |
| mean 100 episode length | 5.46     |
| mean 100 episode reward | 2.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9489   |
| steps                   | 1121045  |
| td_erros                | -0.2264  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 163900   |
| lives                   | 163900   |
| mean 100 episode ei     | 3.01     |
| mean 100 episode length | 5.91     |
| mean 100 episode reward | 3.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9242   |
| steps                   | 1121536  |
| td_erros                | -0.2134  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 164000   |
| lives                   | 164000   |
| mean 100 episode ei     | 3.71     |
| mean 100 episode length | 7.18     |
| mean 100 episode reward | 3.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8303   |
| steps                   | 1122154  |
| td_erros                | -0.2262  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 164100   |
| lives                   | 164100   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 7.1      |
| mean 100 episode reward | 4.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7722   |
| steps                   | 1122764  |
| td_erros                | -0.2591  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 164200   |
| lives                   | 164200   |
| mean 100 episode ei     | 3.36     |
| mean 100 episode length | 5.99     |
| mean 100 episode reward | 4.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.712    |
| steps                   | 1123263  |
| td_erros                | -0.2671  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 164300   |
| lives                   | 164300   |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 6.35     |
| mean 100 episode reward | 4.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6701   |
| steps                   | 1123798  |
| td_erros                | -0.2757  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 164400   |
| lives                   | 164400   |
| mean 100 episode ei     | 3.68     |
| mean 100 episode length | 6.42     |
| mean 100 episode reward | 4.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6231   |
| steps                   | 1124340  |
| td_erros                | -0.3053  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 164500   |
| lives                   | 164500   |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 6.4      |
| mean 100 episode reward | 4.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.585    |
| steps                   | 1124880  |
| td_erros                | -0.3138  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 164600   |
| lives                   | 164600   |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 6.51     |
| mean 100 episode reward | 4.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5633   |
| steps                   | 1125431  |
| td_erros                | -0.324   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 164700   |
| lives                   | 164700   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 7.04     |
| mean 100 episode reward | 4.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5817   |
| steps                   | 1126035  |
| td_erros                | -0.3225  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 164800   |
| lives                   | 164800   |
| mean 100 episode ei     | 3.61     |
| mean 100 episode length | 6.16     |
| mean 100 episode reward | 3.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.603    |
| steps                   | 1126551  |
| td_erros                | -0.3703  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 164900   |
| lives                   | 164900   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 6.35     |
| mean 100 episode reward | 3.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6473   |
| steps                   | 1127086  |
| td_erros                | -0.3746  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 165000   |
| lives                   | 165000   |
| mean 100 episode ei     | 3.7      |
| mean 100 episode length | 6.05     |
| mean 100 episode reward | 3.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6783   |
| steps                   | 1127591  |
| td_erros                | -0.3524  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 165100   |
| lives                   | 165100   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 6.35     |
| mean 100 episode reward | 4.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6878   |
| steps                   | 1128126  |
| td_erros                | -0.3651  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 165200   |
| lives                   | 165200   |
| mean 100 episode ei     | 3.07     |
| mean 100 episode length | 5.81     |
| mean 100 episode reward | 3.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7027   |
| steps                   | 1128607  |
| td_erros                | -0.3493  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 165300   |
| lives                   | 165300   |
| mean 100 episode ei     | 3.63     |
| mean 100 episode length | 5.92     |
| mean 100 episode reward | 4.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6888   |
| steps                   | 1129099  |
| td_erros                | -0.3309  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 165400   |
| lives                   | 165400   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 6.19     |
| mean 100 episode reward | 4.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6839   |
| steps                   | 1129618  |
| td_erros                | -0.3431  |
--------------------------------------
Saving model due to running mean reward increase: 4.409 -> 4.4866
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 165500   |
| lives                   | 165500   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 6.25     |
| mean 100 episode reward | 4.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6924   |
| steps                   | 1130143  |
| td_erros                | -0.3452  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 165600   |
| lives                   | 165600   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 6.25     |
| mean 100 episode reward | 4.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6802   |
| steps                   | 1130668  |
| td_erros                | -0.3229  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 30       |
| episodes                | 165700   |
| lives                   | 165700   |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 6.13     |
| mean 100 episode reward | 4.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7022   |
| steps                   | 1131181  |
| td_erros                | -0.3297  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 165800   |
| lives                   | 165800   |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 5.82     |
| mean 100 episode reward | 4.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7271   |
| steps                   | 1131663  |
| td_erros                | -0.351   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 165900   |
| lives                   | 165900   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 6.3      |
| mean 100 episode reward | 4.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.722    |
| steps                   | 1132193  |
| td_erros                | -0.3532  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 166000   |
| lives                   | 166000   |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 7.11     |
| mean 100 episode reward | 4.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7235   |
| steps                   | 1132804  |
| td_erros                | -0.3347  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 166100   |
| lives                   | 166100   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 6.61     |
| mean 100 episode reward | 4.69     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7617   |
| steps                   | 1133365  |
| td_erros                | -0.3114  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 166200   |
| lives                   | 166200   |
| mean 100 episode ei     | 3.74     |
| mean 100 episode length | 6.75     |
| mean 100 episode reward | 4.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7837   |
| steps                   | 1133940  |
| td_erros                | -0.2978  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 166300   |
| lives                   | 166300   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 6.59     |
| mean 100 episode reward | 4.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7833   |
| steps                   | 1134499  |
| td_erros                | -0.2975  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 166400   |
| lives                   | 166400   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 6.87     |
| mean 100 episode reward | 3.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.813    |
| steps                   | 1135086  |
| td_erros                | -0.2748  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 166500   |
| lives                   | 166500   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 6.58     |
| mean 100 episode reward | 4.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8273   |
| steps                   | 1135644  |
| td_erros                | -0.2889  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 166600   |
| lives                   | 166600   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 6.76     |
| mean 100 episode reward | 4.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8713   |
| steps                   | 1136220  |
| td_erros                | -0.2739  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 166700   |
| lives                   | 166700   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 6.5      |
| mean 100 episode reward | 4.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8843   |
| steps                   | 1136770  |
| td_erros                | -0.2736  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 166800   |
| lives                   | 166800   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 6.62     |
| mean 100 episode reward | 3.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9041   |
| steps                   | 1137332  |
| td_erros                | -0.2556  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 166900   |
| lives                   | 166900   |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 6.9      |
| mean 100 episode reward | 3.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8948   |
| steps                   | 1137922  |
| td_erros                | -0.2722  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 167000   |
| lives                   | 167000   |
| mean 100 episode ei     | 4.35     |
| mean 100 episode length | 6.94     |
| mean 100 episode reward | 3.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8993   |
| steps                   | 1138516  |
| td_erros                | -0.3014  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 167100   |
| lives                   | 167100   |
| mean 100 episode ei     | 4.41     |
| mean 100 episode length | 6.95     |
| mean 100 episode reward | 4.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9578   |
| steps                   | 1139111  |
| td_erros                | -0.3015  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 167200   |
| lives                   | 167200   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 6.51     |
| mean 100 episode reward | 5.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9397   |
| steps                   | 1139662  |
| td_erros                | -0.3066  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 167300   |
| lives                   | 167300   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 6.54     |
| mean 100 episode reward | 4.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9659   |
| steps                   | 1140216  |
| td_erros                | -0.3107  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 167400   |
| lives                   | 167400   |
| mean 100 episode ei     | 3.6      |
| mean 100 episode length | 6.48     |
| mean 100 episode reward | 4.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9874   |
| steps                   | 1140764  |
| td_erros                | -0.289   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 167500   |
| lives                   | 167500   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 6.56     |
| mean 100 episode reward | 4.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9784   |
| steps                   | 1141320  |
| td_erros                | -0.2939  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 167600   |
| lives                   | 167600   |
| mean 100 episode ei     | 3.7      |
| mean 100 episode length | 6.39     |
| mean 100 episode reward | 4.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9596   |
| steps                   | 1141859  |
| td_erros                | -0.298   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 167700   |
| lives                   | 167700   |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 7.26     |
| mean 100 episode reward | 3.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9019   |
| steps                   | 1142485  |
| td_erros                | -0.2919  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 167800   |
| lives                   | 167800   |
| mean 100 episode ei     | 3.59     |
| mean 100 episode length | 6.55     |
| mean 100 episode reward | 3.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9104   |
| steps                   | 1143040  |
| td_erros                | -0.2805  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 167900   |
| lives                   | 167900   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 6.79     |
| mean 100 episode reward | 4.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8652   |
| steps                   | 1143619  |
| td_erros                | -0.28    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 168000   |
| lives                   | 168000   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 7.02     |
| mean 100 episode reward | 4.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8061   |
| steps                   | 1144221  |
| td_erros                | -0.3036  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 168100   |
| lives                   | 168100   |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 6.95     |
| mean 100 episode reward | 4.57     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.78     |
| steps                   | 1144816  |
| td_erros                | -0.322   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 168200   |
| lives                   | 168200   |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 6.5      |
| mean 100 episode reward | 4.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8167   |
| steps                   | 1145366  |
| td_erros                | -0.3105  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 168300   |
| lives                   | 168300   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 6.52     |
| mean 100 episode reward | 4.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8215   |
| steps                   | 1145918  |
| td_erros                | -0.3007  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 168400   |
| lives                   | 168400   |
| mean 100 episode ei     | 3.8      |
| mean 100 episode length | 6.03     |
| mean 100 episode reward | 4.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8467   |
| steps                   | 1146421  |
| td_erros                | -0.306   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 29       |
| episodes                | 168500   |
| lives                   | 168500   |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 7.08     |
| mean 100 episode reward | 4.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8574   |
| steps                   | 1147029  |
| td_erros                | -0.3005  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 168600   |
| lives                   | 168600   |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 6.88     |
| mean 100 episode reward | 4.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.803    |
| steps                   | 1147617  |
| td_erros                | -0.3078  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 168700   |
| lives                   | 168700   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 6.84     |
| mean 100 episode reward | 4        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7697   |
| steps                   | 1148201  |
| td_erros                | -0.3207  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 168800   |
| lives                   | 168800   |
| mean 100 episode ei     | 3.79     |
| mean 100 episode length | 6.71     |
| mean 100 episode reward | 3.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7361   |
| steps                   | 1148772  |
| td_erros                | -0.3268  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 168900   |
| lives                   | 168900   |
| mean 100 episode ei     | 4.37     |
| mean 100 episode length | 7.02     |
| mean 100 episode reward | 3.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7397   |
| steps                   | 1149374  |
| td_erros                | -0.3185  |
--------------------------------------
Saving model due to running mean reward increase: 3.7301 -> 3.8987
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 169000   |
| lives                   | 169000   |
| mean 100 episode ei     | 4.49     |
| mean 100 episode length | 7.55     |
| mean 100 episode reward | 3.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6915   |
| steps                   | 1150029  |
| td_erros                | -0.3171  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 169100   |
| lives                   | 169100   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 6.8      |
| mean 100 episode reward | 4.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7174   |
| steps                   | 1150609  |
| td_erros                | -0.3261  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 169200   |
| lives                   | 169200   |
| mean 100 episode ei     | 3.75     |
| mean 100 episode length | 6.44     |
| mean 100 episode reward | 4.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7404   |
| steps                   | 1151153  |
| td_erros                | -0.3184  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 169300   |
| lives                   | 169300   |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 6.58     |
| mean 100 episode reward | 3.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.769    |
| steps                   | 1151711  |
| td_erros                | -0.3267  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 169400   |
| lives                   | 169400   |
| mean 100 episode ei     | 3.83     |
| mean 100 episode length | 6.28     |
| mean 100 episode reward | 4.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7681   |
| steps                   | 1152239  |
| td_erros                | -0.3145  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 169500   |
| lives                   | 169500   |
| mean 100 episode ei     | 4.21     |
| mean 100 episode length | 6.54     |
| mean 100 episode reward | 4.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7691   |
| steps                   | 1152793  |
| td_erros                | -0.3228  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 169600   |
| lives                   | 169600   |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 6.69     |
| mean 100 episode reward | 4.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7652   |
| steps                   | 1153362  |
| td_erros                | -0.33    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 169700   |
| lives                   | 169700   |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 6.34     |
| mean 100 episode reward | 4.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7799   |
| steps                   | 1153896  |
| td_erros                | -0.3187  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 169800   |
| lives                   | 169800   |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 6.16     |
| mean 100 episode reward | 4.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7957   |
| steps                   | 1154412  |
| td_erros                | -0.2923  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 169900   |
| lives                   | 169900   |
| mean 100 episode ei     | 3.23     |
| mean 100 episode length | 5.91     |
| mean 100 episode reward | 3.96     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7729   |
| steps                   | 1154903  |
| td_erros                | -0.3194  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 170000   |
| lives                   | 170000   |
| mean 100 episode ei     | 3.7      |
| mean 100 episode length | 6.13     |
| mean 100 episode reward | 4.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7356   |
| steps                   | 1155416  |
| td_erros                | -0.3159  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 170100   |
| lives                   | 170100   |
| mean 100 episode ei     | 3.46     |
| mean 100 episode length | 5.92     |
| mean 100 episode reward | 3.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7241   |
| steps                   | 1155908  |
| td_erros                | -0.316   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 170200   |
| lives                   | 170200   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 6.92     |
| mean 100 episode reward | 3.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7342   |
| steps                   | 1156500  |
| td_erros                | -0.3245  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 170300   |
| lives                   | 170300   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 6        |
| mean 100 episode reward | 3.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7495   |
| steps                   | 1157000  |
| td_erros                | -0.3301  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 170400   |
| lives                   | 170400   |
| mean 100 episode ei     | 3.4      |
| mean 100 episode length | 5.48     |
| mean 100 episode reward | 3.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7385   |
| steps                   | 1157448  |
| td_erros                | -0.3169  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 170500   |
| lives                   | 170500   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 6.64     |
| mean 100 episode reward | 3.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7405   |
| steps                   | 1158012  |
| td_erros                | -0.3185  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 170600   |
| lives                   | 170600   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 6.76     |
| mean 100 episode reward | 3.96     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7067   |
| steps                   | 1158588  |
| td_erros                | -0.3246  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 170700   |
| lives                   | 170700   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 6.73     |
| mean 100 episode reward | 4.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7051   |
| steps                   | 1159161  |
| td_erros                | -0.3325  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 170800   |
| lives                   | 170800   |
| mean 100 episode ei     | 4.4      |
| mean 100 episode length | 6.96     |
| mean 100 episode reward | 4.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6957   |
| steps                   | 1159757  |
| td_erros                | -0.3409  |
--------------------------------------
Saving model due to mean reward increase: 4.5257 -> 4.61
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 170900   |
| lives                   | 170900   |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 6.75     |
| mean 100 episode reward | 4.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7505   |
| steps                   | 1160332  |
| td_erros                | -0.3249  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 171000   |
| lives                   | 171000   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 6.76     |
| mean 100 episode reward | 4.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7644   |
| steps                   | 1160908  |
| td_erros                | -0.3352  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 171100   |
| lives                   | 171100   |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 6.54     |
| mean 100 episode reward | 4.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8073   |
| steps                   | 1161462  |
| td_erros                | -0.3167  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 171200   |
| lives                   | 171200   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 6.27     |
| mean 100 episode reward | 4.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.827    |
| steps                   | 1161989  |
| td_erros                | -0.3202  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 171300   |
| lives                   | 171300   |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 6.91     |
| mean 100 episode reward | 4.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8283   |
| steps                   | 1162580  |
| td_erros                | -0.3105  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 28       |
| episodes                | 171400   |
| lives                   | 171400   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 6.59     |
| mean 100 episode reward | 4.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8279   |
| steps                   | 1163139  |
| td_erros                | -0.3078  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 171500   |
| lives                   | 171500   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 7.08     |
| mean 100 episode reward | 4.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7902   |
| steps                   | 1163747  |
| td_erros                | -0.3142  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 171600   |
| lives                   | 171600   |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 6.91     |
| mean 100 episode reward | 4.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8027   |
| steps                   | 1164338  |
| td_erros                | -0.3143  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 171700   |
| lives                   | 171700   |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 7        |
| mean 100 episode reward | 4.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7555   |
| steps                   | 1164938  |
| td_erros                | -0.2952  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 171800   |
| lives                   | 171800   |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 6.67     |
| mean 100 episode reward | 4.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7642   |
| steps                   | 1165505  |
| td_erros                | -0.3032  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 171900   |
| lives                   | 171900   |
| mean 100 episode ei     | 3.49     |
| mean 100 episode length | 6.48     |
| mean 100 episode reward | 4.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7395   |
| steps                   | 1166053  |
| td_erros                | -0.3177  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 172000   |
| lives                   | 172000   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 6.79     |
| mean 100 episode reward | 4.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7262   |
| steps                   | 1166632  |
| td_erros                | -0.3003  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 172100   |
| lives                   | 172100   |
| mean 100 episode ei     | 3.75     |
| mean 100 episode length | 6.38     |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7087   |
| steps                   | 1167170  |
| td_erros                | -0.3174  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 172200   |
| lives                   | 172200   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 6.65     |
| mean 100 episode reward | 4.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7009   |
| steps                   | 1167735  |
| td_erros                | -0.2972  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 172300   |
| lives                   | 172300   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 6.69     |
| mean 100 episode reward | 4.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6784   |
| steps                   | 1168304  |
| td_erros                | -0.3227  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 172400   |
| lives                   | 172400   |
| mean 100 episode ei     | 3.54     |
| mean 100 episode length | 6.7      |
| mean 100 episode reward | 3.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6425   |
| steps                   | 1168874  |
| td_erros                | -0.326   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 172500   |
| lives                   | 172500   |
| mean 100 episode ei     | 3.59     |
| mean 100 episode length | 6.49     |
| mean 100 episode reward | 4.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6317   |
| steps                   | 1169423  |
| td_erros                | -0.3218  |
--------------------------------------
Saving model due to running mean reward increase: 4.0474 -> 4.5585
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 172600   |
| lives                   | 172600   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 7.12     |
| mean 100 episode reward | 4.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6224   |
| steps                   | 1170035  |
| td_erros                | -0.3462  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 172700   |
| lives                   | 172700   |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 7.13     |
| mean 100 episode reward | 4.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6301   |
| steps                   | 1170648  |
| td_erros                | -0.3433  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 172800   |
| lives                   | 172800   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 7.18     |
| mean 100 episode reward | 4.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6394   |
| steps                   | 1171266  |
| td_erros                | -0.3358  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 172900   |
| lives                   | 172900   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 6.9      |
| mean 100 episode reward | 4.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6245   |
| steps                   | 1171856  |
| td_erros                | -0.3386  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 173000   |
| lives                   | 173000   |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 6.76     |
| mean 100 episode reward | 4.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.662    |
| steps                   | 1172432  |
| td_erros                | -0.3431  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 173100   |
| lives                   | 173100   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 6.36     |
| mean 100 episode reward | 4.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6752   |
| steps                   | 1172968  |
| td_erros                | -0.328   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 173200   |
| lives                   | 173200   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 6.6      |
| mean 100 episode reward | 4.99     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6975   |
| steps                   | 1173528  |
| td_erros                | -0.3146  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 173300   |
| lives                   | 173300   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 6.46     |
| mean 100 episode reward | 4.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7436   |
| steps                   | 1174074  |
| td_erros                | -0.2976  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 173400   |
| lives                   | 173400   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 6.55     |
| mean 100 episode reward | 4.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7484   |
| steps                   | 1174629  |
| td_erros                | -0.3     |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 173500   |
| lives                   | 173500   |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 6.33     |
| mean 100 episode reward | 4.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7908   |
| steps                   | 1175162  |
| td_erros                | -0.2886  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 173600   |
| lives                   | 173600   |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 6.28     |
| mean 100 episode reward | 4.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7968   |
| steps                   | 1175690  |
| td_erros                | -0.2615  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 173700   |
| lives                   | 173700   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 6.58     |
| mean 100 episode reward | 4.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8068   |
| steps                   | 1176248  |
| td_erros                | -0.2682  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 173800   |
| lives                   | 173800   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 6.42     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8152   |
| steps                   | 1176790  |
| td_erros                | -0.2858  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 173900   |
| lives                   | 173900   |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 6.92     |
| mean 100 episode reward | 4.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8101   |
| steps                   | 1177382  |
| td_erros                | -0.2776  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 174000   |
| lives                   | 174000   |
| mean 100 episode ei     | 3.75     |
| mean 100 episode length | 6.32     |
| mean 100 episode reward | 3.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.769    |
| steps                   | 1177914  |
| td_erros                | -0.2888  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 174100   |
| lives                   | 174100   |
| mean 100 episode ei     | 3.56     |
| mean 100 episode length | 6.24     |
| mean 100 episode reward | 4.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7358   |
| steps                   | 1178438  |
| td_erros                | -0.3014  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 174200   |
| lives                   | 174200   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 6.4      |
| mean 100 episode reward | 4.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7011   |
| steps                   | 1178978  |
| td_erros                | -0.2898  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 27       |
| episodes                | 174300   |
| lives                   | 174300   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 6.53     |
| mean 100 episode reward | 4.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6785   |
| steps                   | 1179531  |
| td_erros                | -0.3033  |
--------------------------------------
Saving model due to mean reward increase: 4.61 -> 5.0881
Saving model due to running mean reward increase: 4.2214 -> 5.0881
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 174400   |
| lives                   | 174400   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 6.89     |
| mean 100 episode reward | 5.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6662   |
| steps                   | 1180120  |
| td_erros                | -0.3164  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 174500   |
| lives                   | 174500   |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 6.59     |
| mean 100 episode reward | 4.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6499   |
| steps                   | 1180679  |
| td_erros                | -0.3309  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 174600   |
| lives                   | 174600   |
| mean 100 episode ei     | 3.72     |
| mean 100 episode length | 6.22     |
| mean 100 episode reward | 3.99     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.691    |
| steps                   | 1181201  |
| td_erros                | -0.3272  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 174700   |
| lives                   | 174700   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 6.48     |
| mean 100 episode reward | 4.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7001   |
| steps                   | 1181749  |
| td_erros                | -0.3197  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 174800   |
| lives                   | 174800   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 6.23     |
| mean 100 episode reward | 4.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7179   |
| steps                   | 1182272  |
| td_erros                | -0.3318  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 174900   |
| lives                   | 174900   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 6.62     |
| mean 100 episode reward | 3.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7256   |
| steps                   | 1182834  |
| td_erros                | -0.3436  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 175000   |
| lives                   | 175000   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 6.8      |
| mean 100 episode reward | 3.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6725   |
| steps                   | 1183414  |
| td_erros                | -0.3658  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 175100   |
| lives                   | 175100   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 6.93     |
| mean 100 episode reward | 3.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6785   |
| steps                   | 1184007  |
| td_erros                | -0.353   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 175200   |
| lives                   | 175200   |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 6.61     |
| mean 100 episode reward | 3.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6425   |
| steps                   | 1184568  |
| td_erros                | -0.3592  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 175300   |
| lives                   | 175300   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 6.58     |
| mean 100 episode reward | 4.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6249   |
| steps                   | 1185126  |
| td_erros                | -0.3573  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 175400   |
| lives                   | 175400   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 6.75     |
| mean 100 episode reward | 4.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6121   |
| steps                   | 1185701  |
| td_erros                | -0.365   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 175500   |
| lives                   | 175500   |
| mean 100 episode ei     | 3.59     |
| mean 100 episode length | 6.57     |
| mean 100 episode reward | 3.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5972   |
| steps                   | 1186258  |
| td_erros                | -0.3557  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 175600   |
| lives                   | 175600   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 6.58     |
| mean 100 episode reward | 3.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5911   |
| steps                   | 1186816  |
| td_erros                | -0.3652  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 175700   |
| lives                   | 175700   |
| mean 100 episode ei     | 4.32     |
| mean 100 episode length | 7.04     |
| mean 100 episode reward | 3.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5937   |
| steps                   | 1187420  |
| td_erros                | -0.3515  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 175800   |
| lives                   | 175800   |
| mean 100 episode ei     | 4.39     |
| mean 100 episode length | 7.24     |
| mean 100 episode reward | 3.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.63     |
| steps                   | 1188044  |
| td_erros                | -0.3608  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 175900   |
| lives                   | 175900   |
| mean 100 episode ei     | 4.43     |
| mean 100 episode length | 6.76     |
| mean 100 episode reward | 3.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7067   |
| steps                   | 1188620  |
| td_erros                | -0.3368  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 176000   |
| lives                   | 176000   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 6.1      |
| mean 100 episode reward | 4.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7537   |
| steps                   | 1189130  |
| td_erros                | -0.3154  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 176100   |
| lives                   | 176100   |
| mean 100 episode ei     | 4.72     |
| mean 100 episode length | 6.82     |
| mean 100 episode reward | 3.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8226   |
| steps                   | 1189712  |
| td_erros                | -0.2975  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 176200   |
| lives                   | 176200   |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 6.38     |
| mean 100 episode reward | 3.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8512   |
| steps                   | 1190250  |
| td_erros                | -0.3061  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 176300   |
| lives                   | 176300   |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 6.51     |
| mean 100 episode reward | 4.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.875    |
| steps                   | 1190801  |
| td_erros                | -0.3059  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 176400   |
| lives                   | 176400   |
| mean 100 episode ei     | 4.33     |
| mean 100 episode length | 6.39     |
| mean 100 episode reward | 4.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9347   |
| steps                   | 1191340  |
| td_erros                | -0.2949  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 176500   |
| lives                   | 176500   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 6.38     |
| mean 100 episode reward | 4.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9539   |
| steps                   | 1191878  |
| td_erros                | -0.2756  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 176600   |
| lives                   | 176600   |
| mean 100 episode ei     | 3.58     |
| mean 100 episode length | 5.85     |
| mean 100 episode reward | 3.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.977    |
| steps                   | 1192363  |
| td_erros                | -0.2554  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 176700   |
| lives                   | 176700   |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 6.67     |
| mean 100 episode reward | 3.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.941    |
| steps                   | 1192930  |
| td_erros                | -0.242   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 176800   |
| lives                   | 176800   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 6.79     |
| mean 100 episode reward | 3.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9279   |
| steps                   | 1193509  |
| td_erros                | -0.2793  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 176900   |
| lives                   | 176900   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 6.29     |
| mean 100 episode reward | 4.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9422   |
| steps                   | 1194038  |
| td_erros                | -0.2517  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 177000   |
| lives                   | 177000   |
| mean 100 episode ei     | 3.75     |
| mean 100 episode length | 6.6      |
| mean 100 episode reward | 3.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9176   |
| steps                   | 1194598  |
| td_erros                | -0.2327  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 177100   |
| lives                   | 177100   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 6.87     |
| mean 100 episode reward | 3.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8973   |
| steps                   | 1195185  |
| td_erros                | -0.2611  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 26       |
| episodes                | 177200   |
| lives                   | 177200   |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 7.02     |
| mean 100 episode reward | 4.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8694   |
| steps                   | 1195787  |
| td_erros                | -0.2738  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 177300   |
| lives                   | 177300   |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 6.95     |
| mean 100 episode reward | 4.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8414   |
| steps                   | 1196382  |
| td_erros                | -0.2748  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 177400   |
| lives                   | 177400   |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 5.73     |
| mean 100 episode reward | 4.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7965   |
| steps                   | 1196855  |
| td_erros                | -0.2859  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 177500   |
| lives                   | 177500   |
| mean 100 episode ei     | 3.67     |
| mean 100 episode length | 5.87     |
| mean 100 episode reward | 3.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.765    |
| steps                   | 1197342  |
| td_erros                | -0.3144  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 177600   |
| lives                   | 177600   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 5.94     |
| mean 100 episode reward | 4.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7473   |
| steps                   | 1197836  |
| td_erros                | -0.3347  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 177700   |
| lives                   | 177700   |
| mean 100 episode ei     | 3.07     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 3.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7463   |
| steps                   | 1198275  |
| td_erros                | -0.3442  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 177800   |
| lives                   | 177800   |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 6.04     |
| mean 100 episode reward | 4.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7364   |
| steps                   | 1198779  |
| td_erros                | -0.3269  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 177900   |
| lives                   | 177900   |
| mean 100 episode ei     | 3.74     |
| mean 100 episode length | 5.85     |
| mean 100 episode reward | 4.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6952   |
| steps                   | 1199264  |
| td_erros                | -0.342   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 178000   |
| lives                   | 178000   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 6.36     |
| mean 100 episode reward | 4.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6743   |
| steps                   | 1199800  |
| td_erros                | -0.3396  |
--------------------------------------
Saving model due to running mean reward increase: 4.2048 -> 4.5239
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 178100   |
| lives                   | 178100   |
| mean 100 episode ei     | 3.36     |
| mean 100 episode length | 5.76     |
| mean 100 episode reward | 4.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6541   |
| steps                   | 1200276  |
| td_erros                | -0.3161  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 178200   |
| lives                   | 178200   |
| mean 100 episode ei     | 3.36     |
| mean 100 episode length | 6.03     |
| mean 100 episode reward | 4.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6299   |
| steps                   | 1200779  |
| td_erros                | -0.3319  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 178300   |
| lives                   | 178300   |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 6.26     |
| mean 100 episode reward | 4.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6339   |
| steps                   | 1201305  |
| td_erros                | -0.3261  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 178400   |
| lives                   | 178400   |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 6.64     |
| mean 100 episode reward | 3.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6386   |
| steps                   | 1201869  |
| td_erros                | -0.3111  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 178500   |
| lives                   | 178500   |
| mean 100 episode ei     | 3.61     |
| mean 100 episode length | 6.03     |
| mean 100 episode reward | 4.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6443   |
| steps                   | 1202372  |
| td_erros                | -0.3235  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 178600   |
| lives                   | 178600   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 6.1      |
| mean 100 episode reward | 4.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.646    |
| steps                   | 1202882  |
| td_erros                | -0.3102  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 178700   |
| lives                   | 178700   |
| mean 100 episode ei     | 4.32     |
| mean 100 episode length | 6.76     |
| mean 100 episode reward | 4.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6502   |
| steps                   | 1203458  |
| td_erros                | -0.3253  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 178800   |
| lives                   | 178800   |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 6.31     |
| mean 100 episode reward | 4.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6675   |
| steps                   | 1203989  |
| td_erros                | -0.3315  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 178900   |
| lives                   | 178900   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 6.55     |
| mean 100 episode reward | 4.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6831   |
| steps                   | 1204544  |
| td_erros                | -0.3395  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 179000   |
| lives                   | 179000   |
| mean 100 episode ei     | 3.63     |
| mean 100 episode length | 5.91     |
| mean 100 episode reward | 4.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7098   |
| steps                   | 1205035  |
| td_erros                | -0.3094  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 179100   |
| lives                   | 179100   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 6.3      |
| mean 100 episode reward | 4.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7065   |
| steps                   | 1205565  |
| td_erros                | -0.3173  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 179200   |
| lives                   | 179200   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 6.42     |
| mean 100 episode reward | 4.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7337   |
| steps                   | 1206107  |
| td_erros                | -0.3224  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 179300   |
| lives                   | 179300   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 6.18     |
| mean 100 episode reward | 4.57     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.754    |
| steps                   | 1206625  |
| td_erros                | -0.2974  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 179400   |
| lives                   | 179400   |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 6.83     |
| mean 100 episode reward | 4.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7544   |
| steps                   | 1207208  |
| td_erros                | -0.2987  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 179500   |
| lives                   | 179500   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 6.91     |
| mean 100 episode reward | 4.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.807    |
| steps                   | 1207799  |
| td_erros                | -0.259   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 179600   |
| lives                   | 179600   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 6.31     |
| mean 100 episode reward | 4.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8242   |
| steps                   | 1208330  |
| td_erros                | -0.2488  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 179700   |
| lives                   | 179700   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 6.54     |
| mean 100 episode reward | 4.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8049   |
| steps                   | 1208884  |
| td_erros                | -0.2605  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 179800   |
| lives                   | 179800   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 6.94     |
| mean 100 episode reward | 4.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8239   |
| steps                   | 1209478  |
| td_erros                | -0.2397  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 179900   |
| lives                   | 179900   |
| mean 100 episode ei     | 4.23     |
| mean 100 episode length | 7.33     |
| mean 100 episode reward | 4.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.798    |
| steps                   | 1210111  |
| td_erros                | -0.2754  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 180000   |
| lives                   | 180000   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 6.84     |
| mean 100 episode reward | 3.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8567   |
| steps                   | 1210695  |
| td_erros                | -0.2459  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 180100   |
| lives                   | 180100   |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 6.94     |
| mean 100 episode reward | 4.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8708   |
| steps                   | 1211289  |
| td_erros                | -0.2403  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 25       |
| episodes                | 180200   |
| lives                   | 180200   |
| mean 100 episode ei     | 4.32     |
| mean 100 episode length | 7        |
| mean 100 episode reward | 4.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8863   |
| steps                   | 1211889  |
| td_erros                | -0.2424  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 180300   |
| lives                   | 180300   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 6.47     |
| mean 100 episode reward | 4.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.927    |
| steps                   | 1212436  |
| td_erros                | -0.2297  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 180400   |
| lives                   | 180400   |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 6.6      |
| mean 100 episode reward | 4.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.973    |
| steps                   | 1212996  |
| td_erros                | -0.217   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 180500   |
| lives                   | 180500   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 6.65     |
| mean 100 episode reward | 4.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9674   |
| steps                   | 1213561  |
| td_erros                | -0.2198  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 180600   |
| lives                   | 180600   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 7.19     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.952    |
| steps                   | 1214180  |
| td_erros                | -0.2058  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 180700   |
| lives                   | 180700   |
| mean 100 episode ei     | 4.21     |
| mean 100 episode length | 6.87     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9583   |
| steps                   | 1214767  |
| td_erros                | -0.2184  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 180800   |
| lives                   | 180800   |
| mean 100 episode ei     | 3.8      |
| mean 100 episode length | 6.45     |
| mean 100 episode reward | 4.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.9468   |
| steps                   | 1215312  |
| td_erros                | -0.2186  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 180900   |
| lives                   | 180900   |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 6.64     |
| mean 100 episode reward | 4.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.932    |
| steps                   | 1215876  |
| td_erros                | -0.2309  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 181000   |
| lives                   | 181000   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 6.95     |
| mean 100 episode reward | 4.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8874   |
| steps                   | 1216471  |
| td_erros                | -0.2519  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 181100   |
| lives                   | 181100   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 6.92     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.855    |
| steps                   | 1217063  |
| td_erros                | -0.2519  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 181200   |
| lives                   | 181200   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 6.65     |
| mean 100 episode reward | 4.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.8256   |
| steps                   | 1217628  |
| td_erros                | -0.2731  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 181300   |
| lives                   | 181300   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 7        |
| mean 100 episode reward | 4.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.78     |
| steps                   | 1218228  |
| td_erros                | -0.2892  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 181400   |
| lives                   | 181400   |
| mean 100 episode ei     | 3.75     |
| mean 100 episode length | 6.51     |
| mean 100 episode reward | 4.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7692   |
| steps                   | 1218779  |
| td_erros                | -0.2962  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 181500   |
| lives                   | 181500   |
| mean 100 episode ei     | 3.67     |
| mean 100 episode length | 6.14     |
| mean 100 episode reward | 4.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7363   |
| steps                   | 1219293  |
| td_erros                | -0.3042  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 181600   |
| lives                   | 181600   |
| mean 100 episode ei     | 3.57     |
| mean 100 episode length | 5.98     |
| mean 100 episode reward | 4.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7107   |
| steps                   | 1219791  |
| td_erros                | -0.2905  |
--------------------------------------
Saving model due to running mean reward increase: 4.3316 -> 4.8083
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 181700   |
| lives                   | 181700   |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 6.42     |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6528   |
| steps                   | 1220333  |
| td_erros                | -0.3234  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 181800   |
| lives                   | 181800   |
| mean 100 episode ei     | 3.58     |
| mean 100 episode length | 6.48     |
| mean 100 episode reward | 4.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6265   |
| steps                   | 1220881  |
| td_erros                | -0.3202  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 181900   |
| lives                   | 181900   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 7.1      |
| mean 100 episode reward | 4.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5925   |
| steps                   | 1221491  |
| td_erros                | -0.316   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 182000   |
| lives                   | 182000   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 6.56     |
| mean 100 episode reward | 4.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5537   |
| steps                   | 1222047  |
| td_erros                | -0.3415  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 182100   |
| lives                   | 182100   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 6.61     |
| mean 100 episode reward | 4.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5369   |
| steps                   | 1222608  |
| td_erros                | -0.3523  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 182200   |
| lives                   | 182200   |
| mean 100 episode ei     | 3.63     |
| mean 100 episode length | 6.46     |
| mean 100 episode reward | 4.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5227   |
| steps                   | 1223154  |
| td_erros                | -0.3734  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 182300   |
| lives                   | 182300   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 6.63     |
| mean 100 episode reward | 4.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5569   |
| steps                   | 1223717  |
| td_erros                | -0.3554  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 182400   |
| lives                   | 182400   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 6.72     |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5637   |
| steps                   | 1224289  |
| td_erros                | -0.3693  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 182500   |
| lives                   | 182500   |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 6.7      |
| mean 100 episode reward | 3.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5644   |
| steps                   | 1224859  |
| td_erros                | -0.3568  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 182600   |
| lives                   | 182600   |
| mean 100 episode ei     | 3.36     |
| mean 100 episode length | 6.23     |
| mean 100 episode reward | 4.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5569   |
| steps                   | 1225382  |
| td_erros                | -0.3542  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 182700   |
| lives                   | 182700   |
| mean 100 episode ei     | 3.58     |
| mean 100 episode length | 6.49     |
| mean 100 episode reward | 4.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5105   |
| steps                   | 1225931  |
| td_erros                | -0.3439  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 182800   |
| lives                   | 182800   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 6.65     |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4921   |
| steps                   | 1226496  |
| td_erros                | -0.3593  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 182900   |
| lives                   | 182900   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 6.51     |
| mean 100 episode reward | 4.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4956   |
| steps                   | 1227047  |
| td_erros                | -0.375   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 183000   |
| lives                   | 183000   |
| mean 100 episode ei     | 3.63     |
| mean 100 episode length | 6.09     |
| mean 100 episode reward | 4.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5027   |
| steps                   | 1227556  |
| td_erros                | -0.3581  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 24       |
| episodes                | 183100   |
| lives                   | 183100   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 6.31     |
| mean 100 episode reward | 4.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4875   |
| steps                   | 1228087  |
| td_erros                | -0.3609  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 183200   |
| lives                   | 183200   |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 6.31     |
| mean 100 episode reward | 4.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4881   |
| steps                   | 1228618  |
| td_erros                | -0.3842  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 183300   |
| lives                   | 183300   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 6.79     |
| mean 100 episode reward | 4.69     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5027   |
| steps                   | 1229197  |
| td_erros                | -0.3762  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 183400   |
| lives                   | 183400   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 7.17     |
| mean 100 episode reward | 4.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4758   |
| steps                   | 1229814  |
| td_erros                | -0.3881  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 183500   |
| lives                   | 183500   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 7.11     |
| mean 100 episode reward | 5.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4669   |
| steps                   | 1230425  |
| td_erros                | -0.3946  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 183600   |
| lives                   | 183600   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 6.81     |
| mean 100 episode reward | 4.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5168   |
| steps                   | 1231006  |
| td_erros                | -0.3723  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 183700   |
| lives                   | 183700   |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 6.76     |
| mean 100 episode reward | 4.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5484   |
| steps                   | 1231582  |
| td_erros                | -0.3684  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 183800   |
| lives                   | 183800   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 6.42     |
| mean 100 episode reward | 4.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5372   |
| steps                   | 1232124  |
| td_erros                | -0.3477  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 183900   |
| lives                   | 183900   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 6.52     |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5761   |
| steps                   | 1232676  |
| td_erros                | -0.3659  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 184000   |
| lives                   | 184000   |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 6.8      |
| mean 100 episode reward | 4.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6252   |
| steps                   | 1233256  |
| td_erros                | -0.3391  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 184100   |
| lives                   | 184100   |
| mean 100 episode ei     | 3.54     |
| mean 100 episode length | 6.68     |
| mean 100 episode reward | 4.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6414   |
| steps                   | 1233824  |
| td_erros                | -0.318   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 184200   |
| lives                   | 184200   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 6.61     |
| mean 100 episode reward | 4.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6672   |
| steps                   | 1234385  |
| td_erros                | -0.3166  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 184300   |
| lives                   | 184300   |
| mean 100 episode ei     | 3.83     |
| mean 100 episode length | 6.85     |
| mean 100 episode reward | 4.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6947   |
| steps                   | 1234970  |
| td_erros                | -0.3253  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 184400   |
| lives                   | 184400   |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 6.96     |
| mean 100 episode reward | 4.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6867   |
| steps                   | 1235566  |
| td_erros                | -0.3363  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 184500   |
| lives                   | 184500   |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 7.07     |
| mean 100 episode reward | 4.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6601   |
| steps                   | 1236173  |
| td_erros                | -0.3441  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 184600   |
| lives                   | 184600   |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 7.28     |
| mean 100 episode reward | 4.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6236   |
| steps                   | 1236801  |
| td_erros                | -0.3523  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 184700   |
| lives                   | 184700   |
| mean 100 episode ei     | 3.08     |
| mean 100 episode length | 5.47     |
| mean 100 episode reward | 3.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6301   |
| steps                   | 1237248  |
| td_erros                | -0.3258  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 184800   |
| lives                   | 184800   |
| mean 100 episode ei     | 3.56     |
| mean 100 episode length | 5.8      |
| mean 100 episode reward | 4.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6117   |
| steps                   | 1237728  |
| td_erros                | -0.3132  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 184900   |
| lives                   | 184900   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 6.57     |
| mean 100 episode reward | 4        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5686   |
| steps                   | 1238285  |
| td_erros                | -0.3164  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 185000   |
| lives                   | 185000   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 6.58     |
| mean 100 episode reward | 4.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5687   |
| steps                   | 1238843  |
| td_erros                | -0.3489  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 185100   |
| lives                   | 185100   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 6.61     |
| mean 100 episode reward | 3.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5511   |
| steps                   | 1239404  |
| td_erros                | -0.3286  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 185200   |
| lives                   | 185200   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 6.56     |
| mean 100 episode reward | 3.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5697   |
| steps                   | 1239960  |
| td_erros                | -0.3408  |
--------------------------------------
Saving model due to running mean reward increase: 3.7792 -> 3.9016
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 185300   |
| lives                   | 185300   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 6.32     |
| mean 100 episode reward | 4.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6212   |
| steps                   | 1240492  |
| td_erros                | -0.3287  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 185400   |
| lives                   | 185400   |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 6.47     |
| mean 100 episode reward | 4.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6313   |
| steps                   | 1241039  |
| td_erros                | -0.329   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 185500   |
| lives                   | 185500   |
| mean 100 episode ei     | 4.47     |
| mean 100 episode length | 7.05     |
| mean 100 episode reward | 4.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6211   |
| steps                   | 1241644  |
| td_erros                | -0.3332  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 185600   |
| lives                   | 185600   |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 6.6      |
| mean 100 episode reward | 4.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6249   |
| steps                   | 1242204  |
| td_erros                | -0.3449  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 185700   |
| lives                   | 185700   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 6.87     |
| mean 100 episode reward | 4.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6328   |
| steps                   | 1242791  |
| td_erros                | -0.3815  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 185800   |
| lives                   | 185800   |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 7.06     |
| mean 100 episode reward | 5.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6188   |
| steps                   | 1243397  |
| td_erros                | -0.3698  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 23       |
| episodes                | 185900   |
| lives                   | 185900   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 7.26     |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6178   |
| steps                   | 1244023  |
| td_erros                | -0.3772  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 186000   |
| lives                   | 186000   |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 6.65     |
| mean 100 episode reward | 4.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6348   |
| steps                   | 1244588  |
| td_erros                | -0.3483  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 186100   |
| lives                   | 186100   |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 6.89     |
| mean 100 episode reward | 4.99     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6369   |
| steps                   | 1245177  |
| td_erros                | -0.3484  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 186200   |
| lives                   | 186200   |
| mean 100 episode ei     | 3.53     |
| mean 100 episode length | 5.87     |
| mean 100 episode reward | 4.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.644    |
| steps                   | 1245664  |
| td_erros                | -0.3444  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 186300   |
| lives                   | 186300   |
| mean 100 episode ei     | 4.42     |
| mean 100 episode length | 7.13     |
| mean 100 episode reward | 4.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6341   |
| steps                   | 1246277  |
| td_erros                | -0.3413  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 186400   |
| lives                   | 186400   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 6.5      |
| mean 100 episode reward | 4.57     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6511   |
| steps                   | 1246827  |
| td_erros                | -0.3412  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 186500   |
| lives                   | 186500   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 6.54     |
| mean 100 episode reward | 4.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6349   |
| steps                   | 1247381  |
| td_erros                | -0.3359  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 186600   |
| lives                   | 186600   |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 6.76     |
| mean 100 episode reward | 4.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6227   |
| steps                   | 1247957  |
| td_erros                | -0.3313  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 186700   |
| lives                   | 186700   |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 6.89     |
| mean 100 episode reward | 4.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6182   |
| steps                   | 1248546  |
| td_erros                | -0.3299  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 186800   |
| lives                   | 186800   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 6.47     |
| mean 100 episode reward | 4.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6306   |
| steps                   | 1249093  |
| td_erros                | -0.3246  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 186900   |
| lives                   | 186900   |
| mean 100 episode ei     | 4.73     |
| mean 100 episode length | 6.57     |
| mean 100 episode reward | 5.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6486   |
| steps                   | 1249650  |
| td_erros                | -0.351   |
--------------------------------------
Saving model due to mean reward increase: 5.0881 -> 5.2055
Saving model due to running mean reward increase: 4.9541 -> 5.2055
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 187000   |
| lives                   | 187000   |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 6.66     |
| mean 100 episode reward | 5.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6805   |
| steps                   | 1250216  |
| td_erros                | -0.3454  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 187100   |
| lives                   | 187100   |
| mean 100 episode ei     | 3.83     |
| mean 100 episode length | 6.26     |
| mean 100 episode reward | 4.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6723   |
| steps                   | 1250742  |
| td_erros                | -0.3213  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 187200   |
| lives                   | 187200   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 6.14     |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6882   |
| steps                   | 1251256  |
| td_erros                | -0.3267  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 187300   |
| lives                   | 187300   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.92     |
| mean 100 episode reward | 5.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7174   |
| steps                   | 1251748  |
| td_erros                | -0.3399  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 187400   |
| lives                   | 187400   |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 6.51     |
| mean 100 episode reward | 5.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7187   |
| steps                   | 1252299  |
| td_erros                | -0.3271  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 187500   |
| lives                   | 187500   |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 6.64     |
| mean 100 episode reward | 5.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.7228   |
| steps                   | 1252863  |
| td_erros                | -0.3225  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 187600   |
| lives                   | 187600   |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 6.71     |
| mean 100 episode reward | 4.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.716    |
| steps                   | 1253434  |
| td_erros                | -0.3287  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 187700   |
| lives                   | 187700   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 6.81     |
| mean 100 episode reward | 4.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6903   |
| steps                   | 1254015  |
| td_erros                | -0.34    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 187800   |
| lives                   | 187800   |
| mean 100 episode ei     | 3.65     |
| mean 100 episode length | 6.03     |
| mean 100 episode reward | 4.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6849   |
| steps                   | 1254518  |
| td_erros                | -0.3518  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 187900   |
| lives                   | 187900   |
| mean 100 episode ei     | 3.69     |
| mean 100 episode length | 6.34     |
| mean 100 episode reward | 4.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6564   |
| steps                   | 1255052  |
| td_erros                | -0.3283  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 188000   |
| lives                   | 188000   |
| mean 100 episode ei     | 3.52     |
| mean 100 episode length | 6.41     |
| mean 100 episode reward | 4.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6079   |
| steps                   | 1255593  |
| td_erros                | -0.3302  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 188100   |
| lives                   | 188100   |
| mean 100 episode ei     | 3.22     |
| mean 100 episode length | 5.98     |
| mean 100 episode reward | 4.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5733   |
| steps                   | 1256091  |
| td_erros                | -0.3254  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 188200   |
| lives                   | 188200   |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 6.88     |
| mean 100 episode reward | 4.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5284   |
| steps                   | 1256679  |
| td_erros                | -0.3394  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 188300   |
| lives                   | 188300   |
| mean 100 episode ei     | 3.05     |
| mean 100 episode length | 6.49     |
| mean 100 episode reward | 2.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4918   |
| steps                   | 1257228  |
| td_erros                | -0.3639  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 188400   |
| lives                   | 188400   |
| mean 100 episode ei     | 2.93     |
| mean 100 episode length | 5.48     |
| mean 100 episode reward | 3.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4854   |
| steps                   | 1257676  |
| td_erros                | -0.3214  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 188500   |
| lives                   | 188500   |
| mean 100 episode ei     | 3.29     |
| mean 100 episode length | 5.97     |
| mean 100 episode reward | 3.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4295   |
| steps                   | 1258173  |
| td_erros                | -0.3435  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 188600   |
| lives                   | 188600   |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 6.56     |
| mean 100 episode reward | 4.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4151   |
| steps                   | 1258729  |
| td_erros                | -0.3575  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 188700   |
| lives                   | 188700   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 6.38     |
| mean 100 episode reward | 4.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4389   |
| steps                   | 1259267  |
| td_erros                | -0.3468  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 188800   |
| lives                   | 188800   |
| mean 100 episode ei     | 3.62     |
| mean 100 episode length | 6.2      |
| mean 100 episode reward | 4.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4471   |
| steps                   | 1259787  |
| td_erros                | -0.3745  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 22       |
| episodes                | 188900   |
| lives                   | 188900   |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 6.4      |
| mean 100 episode reward | 4.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.492    |
| steps                   | 1260327  |
| td_erros                | -0.3746  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 189000   |
| lives                   | 189000   |
| mean 100 episode ei     | 3.48     |
| mean 100 episode length | 6.8      |
| mean 100 episode reward | 4.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.467    |
| steps                   | 1260907  |
| td_erros                | -0.3441  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 189100   |
| lives                   | 189100   |
| mean 100 episode ei     | 3.28     |
| mean 100 episode length | 6.01     |
| mean 100 episode reward | 3.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4697   |
| steps                   | 1261408  |
| td_erros                | -0.3456  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 189200   |
| lives                   | 189200   |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 6.9      |
| mean 100 episode reward | 4.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4701   |
| steps                   | 1261998  |
| td_erros                | -0.3253  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 189300   |
| lives                   | 189300   |
| mean 100 episode ei     | 2.45     |
| mean 100 episode length | 5.05     |
| mean 100 episode reward | 2.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4713   |
| steps                   | 1262403  |
| td_erros                | -0.3131  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 189400   |
| lives                   | 189400   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 6.46     |
| mean 100 episode reward | 4.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4617   |
| steps                   | 1262949  |
| td_erros                | -0.3319  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 189500   |
| lives                   | 189500   |
| mean 100 episode ei     | 3.62     |
| mean 100 episode length | 6.73     |
| mean 100 episode reward | 4.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4817   |
| steps                   | 1263522  |
| td_erros                | -0.3386  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 189600   |
| lives                   | 189600   |
| mean 100 episode ei     | 4.24     |
| mean 100 episode length | 6.95     |
| mean 100 episode reward | 4.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4999   |
| steps                   | 1264117  |
| td_erros                | -0.3353  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 189700   |
| lives                   | 189700   |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 6.63     |
| mean 100 episode reward | 4.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4844   |
| steps                   | 1264680  |
| td_erros                | -0.3208  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 189800   |
| lives                   | 189800   |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 7.14     |
| mean 100 episode reward | 4.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5084   |
| steps                   | 1265294  |
| td_erros                | -0.3387  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 189900   |
| lives                   | 189900   |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 6.91     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5132   |
| steps                   | 1265885  |
| td_erros                | -0.3386  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 190000   |
| lives                   | 190000   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 6.63     |
| mean 100 episode reward | 4.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5283   |
| steps                   | 1266448  |
| td_erros                | -0.3401  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 190100   |
| lives                   | 190100   |
| mean 100 episode ei     | 3.56     |
| mean 100 episode length | 6.72     |
| mean 100 episode reward | 4.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5188   |
| steps                   | 1267020  |
| td_erros                | -0.3528  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 190200   |
| lives                   | 190200   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 6.96     |
| mean 100 episode reward | 4.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5398   |
| steps                   | 1267616  |
| td_erros                | -0.3822  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 190300   |
| lives                   | 190300   |
| mean 100 episode ei     | 4.44     |
| mean 100 episode length | 7.21     |
| mean 100 episode reward | 4.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5935   |
| steps                   | 1268237  |
| td_erros                | -0.3536  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 190400   |
| lives                   | 190400   |
| mean 100 episode ei     | 3.7      |
| mean 100 episode length | 6.21     |
| mean 100 episode reward | 4.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6029   |
| steps                   | 1268758  |
| td_erros                | -0.3349  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 190500   |
| lives                   | 190500   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 6.12     |
| mean 100 episode reward | 4.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6215   |
| steps                   | 1269270  |
| td_erros                | -0.327   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 190600   |
| lives                   | 190600   |
| mean 100 episode ei     | 3.69     |
| mean 100 episode length | 6.81     |
| mean 100 episode reward | 4.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6276   |
| steps                   | 1269851  |
| td_erros                | -0.3146  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 190700   |
| lives                   | 190700   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 7        |
| mean 100 episode reward | 4.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6127   |
| steps                   | 1270451  |
| td_erros                | -0.313   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 190800   |
| lives                   | 190800   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 6.6      |
| mean 100 episode reward | 4.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6183   |
| steps                   | 1271011  |
| td_erros                | -0.3154  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 190900   |
| lives                   | 190900   |
| mean 100 episode ei     | 4.43     |
| mean 100 episode length | 6.98     |
| mean 100 episode reward | 5.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6137   |
| steps                   | 1271609  |
| td_erros                | -0.3055  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 191000   |
| lives                   | 191000   |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 6.86     |
| mean 100 episode reward | 5.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5979   |
| steps                   | 1272195  |
| td_erros                | -0.3334  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 191100   |
| lives                   | 191100   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 6.52     |
| mean 100 episode reward | 5.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6174   |
| steps                   | 1272747  |
| td_erros                | -0.3493  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 191200   |
| lives                   | 191200   |
| mean 100 episode ei     | 3.75     |
| mean 100 episode length | 6.37     |
| mean 100 episode reward | 4.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6468   |
| steps                   | 1273284  |
| td_erros                | -0.3253  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 191300   |
| lives                   | 191300   |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 6.58     |
| mean 100 episode reward | 4.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6546   |
| steps                   | 1273842  |
| td_erros                | -0.3372  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 191400   |
| lives                   | 191400   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 6.86     |
| mean 100 episode reward | 4.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6413   |
| steps                   | 1274428  |
| td_erros                | -0.3228  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 191500   |
| lives                   | 191500   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 6.59     |
| mean 100 episode reward | 4.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6498   |
| steps                   | 1274987  |
| td_erros                | -0.3197  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 191600   |
| lives                   | 191600   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 6.18     |
| mean 100 episode reward | 4.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6698   |
| steps                   | 1275505  |
| td_erros                | -0.3203  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 191700   |
| lives                   | 191700   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 6.33     |
| mean 100 episode reward | 4.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6729   |
| steps                   | 1276038  |
| td_erros                | -0.3116  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 21       |
| episodes                | 191800   |
| lives                   | 191800   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 6.59     |
| mean 100 episode reward | 4.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6731   |
| steps                   | 1276597  |
| td_erros                | -0.3159  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 191900   |
| lives                   | 191900   |
| mean 100 episode ei     | 3.67     |
| mean 100 episode length | 6.26     |
| mean 100 episode reward | 4.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6666   |
| steps                   | 1277123  |
| td_erros                | -0.3066  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 192000   |
| lives                   | 192000   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 6.53     |
| mean 100 episode reward | 4.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6609   |
| steps                   | 1277676  |
| td_erros                | -0.3032  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 192100   |
| lives                   | 192100   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 6.29     |
| mean 100 episode reward | 4.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6573   |
| steps                   | 1278205  |
| td_erros                | -0.3257  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 192200   |
| lives                   | 192200   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 6.45     |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6646   |
| steps                   | 1278750  |
| td_erros                | -0.3284  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 192300   |
| lives                   | 192300   |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 6.92     |
| mean 100 episode reward | 4.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6418   |
| steps                   | 1279342  |
| td_erros                | -0.3378  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 192400   |
| lives                   | 192400   |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 6.79     |
| mean 100 episode reward | 4.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6535   |
| steps                   | 1279921  |
| td_erros                | -0.3448  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 192500   |
| lives                   | 192500   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 6.64     |
| mean 100 episode reward | 5.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6487   |
| steps                   | 1280485  |
| td_erros                | -0.3399  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 192600   |
| lives                   | 192600   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 6.6      |
| mean 100 episode reward | 5.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6401   |
| steps                   | 1281045  |
| td_erros                | -0.3449  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 192700   |
| lives                   | 192700   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 6.76     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6464   |
| steps                   | 1281621  |
| td_erros                | -0.3415  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 192800   |
| lives                   | 192800   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 6.68     |
| mean 100 episode reward | 4.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6302   |
| steps                   | 1282189  |
| td_erros                | -0.3476  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 192900   |
| lives                   | 192900   |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 6.6      |
| mean 100 episode reward | 4.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6053   |
| steps                   | 1282749  |
| td_erros                | -0.3412  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 193000   |
| lives                   | 193000   |
| mean 100 episode ei     | 3.74     |
| mean 100 episode length | 6.56     |
| mean 100 episode reward | 4.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5992   |
| steps                   | 1283305  |
| td_erros                | -0.3298  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 193100   |
| lives                   | 193100   |
| mean 100 episode ei     | 3.45     |
| mean 100 episode length | 6.32     |
| mean 100 episode reward | 4.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6017   |
| steps                   | 1283837  |
| td_erros                | -0.3182  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 193200   |
| lives                   | 193200   |
| mean 100 episode ei     | 4.3      |
| mean 100 episode length | 7.56     |
| mean 100 episode reward | 4.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.586    |
| steps                   | 1284493  |
| td_erros                | -0.3209  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 193300   |
| lives                   | 193300   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 7.14     |
| mean 100 episode reward | 4.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5424   |
| steps                   | 1285107  |
| td_erros                | -0.3149  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 193400   |
| lives                   | 193400   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 6.98     |
| mean 100 episode reward | 4.69     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.529    |
| steps                   | 1285705  |
| td_erros                | -0.3084  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 193500   |
| lives                   | 193500   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 7.15     |
| mean 100 episode reward | 4.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5132   |
| steps                   | 1286320  |
| td_erros                | -0.3162  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 193600   |
| lives                   | 193600   |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 6.93     |
| mean 100 episode reward | 4.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5058   |
| steps                   | 1286913  |
| td_erros                | -0.3413  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 193700   |
| lives                   | 193700   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 7.03     |
| mean 100 episode reward | 4.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5151   |
| steps                   | 1287516  |
| td_erros                | -0.3211  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 193800   |
| lives                   | 193800   |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 6.49     |
| mean 100 episode reward | 4.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5471   |
| steps                   | 1288065  |
| td_erros                | -0.3206  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 193900   |
| lives                   | 193900   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 6.59     |
| mean 100 episode reward | 4.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5437   |
| steps                   | 1288624  |
| td_erros                | -0.3424  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 194000   |
| lives                   | 194000   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 6.49     |
| mean 100 episode reward | 4.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5544   |
| steps                   | 1289173  |
| td_erros                | -0.3504  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 194100   |
| lives                   | 194100   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 6.38     |
| mean 100 episode reward | 4.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5812   |
| steps                   | 1289711  |
| td_erros                | -0.3271  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 194200   |
| lives                   | 194200   |
| mean 100 episode ei     | 2.63     |
| mean 100 episode length | 4.91     |
| mean 100 episode reward | 2.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6015   |
| steps                   | 1290102  |
| td_erros                | -0.3166  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 194300   |
| lives                   | 194300   |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 6.11     |
| mean 100 episode reward | 4.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5924   |
| steps                   | 1290613  |
| td_erros                | -0.3078  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 194400   |
| lives                   | 194400   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 6.37     |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5906   |
| steps                   | 1291150  |
| td_erros                | -0.2999  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 194500   |
| lives                   | 194500   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 6.02     |
| mean 100 episode reward | 5.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.59     |
| steps                   | 1291652  |
| td_erros                | -0.3108  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 194600   |
| lives                   | 194600   |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 6.3      |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5833   |
| steps                   | 1292182  |
| td_erros                | -0.3176  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 20       |
| episodes                | 194700   |
| lives                   | 194700   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.67     |
| mean 100 episode reward | 4.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6213   |
| steps                   | 1292649  |
| td_erros                | -0.321   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 194800   |
| lives                   | 194800   |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 5.56     |
| mean 100 episode reward | 4.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6306   |
| steps                   | 1293105  |
| td_erros                | -0.3159  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 194900   |
| lives                   | 194900   |
| mean 100 episode ei     | 3.71     |
| mean 100 episode length | 6.11     |
| mean 100 episode reward | 3.96     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6019   |
| steps                   | 1293616  |
| td_erros                | -0.3203  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 195000   |
| lives                   | 195000   |
| mean 100 episode ei     | 3.71     |
| mean 100 episode length | 6.74     |
| mean 100 episode reward | 4.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.637    |
| steps                   | 1294190  |
| td_erros                | -0.3116  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 195100   |
| lives                   | 195100   |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 6.78     |
| mean 100 episode reward | 4.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6264   |
| steps                   | 1294768  |
| td_erros                | -0.3211  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 195200   |
| lives                   | 195200   |
| mean 100 episode ei     | 2.91     |
| mean 100 episode length | 6.06     |
| mean 100 episode reward | 3.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.626    |
| steps                   | 1295274  |
| td_erros                | -0.3364  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 195300   |
| lives                   | 195300   |
| mean 100 episode ei     | 3.24     |
| mean 100 episode length | 5.9      |
| mean 100 episode reward | 4.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6045   |
| steps                   | 1295764  |
| td_erros                | -0.3382  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 195400   |
| lives                   | 195400   |
| mean 100 episode ei     | 3.31     |
| mean 100 episode length | 5.46     |
| mean 100 episode reward | 4.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5845   |
| steps                   | 1296210  |
| td_erros                | -0.3216  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 195500   |
| lives                   | 195500   |
| mean 100 episode ei     | 3.63     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 4.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5295   |
| steps                   | 1296669  |
| td_erros                | -0.3466  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 195600   |
| lives                   | 195600   |
| mean 100 episode ei     | 3.41     |
| mean 100 episode length | 5.67     |
| mean 100 episode reward | 4.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5151   |
| steps                   | 1297136  |
| td_erros                | -0.3494  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 195700   |
| lives                   | 195700   |
| mean 100 episode ei     | 3.65     |
| mean 100 episode length | 5.88     |
| mean 100 episode reward | 4.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4802   |
| steps                   | 1297624  |
| td_erros                | -0.3323  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 195800   |
| lives                   | 195800   |
| mean 100 episode ei     | 3.67     |
| mean 100 episode length | 6.66     |
| mean 100 episode reward | 4.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4114   |
| steps                   | 1298190  |
| td_erros                | -0.3607  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 195900   |
| lives                   | 195900   |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 6.6      |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4019   |
| steps                   | 1298750  |
| td_erros                | -0.3782  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 196000   |
| lives                   | 196000   |
| mean 100 episode ei     | 4.32     |
| mean 100 episode length | 7.03     |
| mean 100 episode reward | 4.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3915   |
| steps                   | 1299353  |
| td_erros                | -0.3998  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 196100   |
| lives                   | 196100   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 6.91     |
| mean 100 episode reward | 4.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4062   |
| steps                   | 1299944  |
| td_erros                | -0.385   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 196200   |
| lives                   | 196200   |
| mean 100 episode ei     | 4.23     |
| mean 100 episode length | 6.63     |
| mean 100 episode reward | 4.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.403    |
| steps                   | 1300507  |
| td_erros                | -0.4247  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 196300   |
| lives                   | 196300   |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 6.55     |
| mean 100 episode reward | 4.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4427   |
| steps                   | 1301062  |
| td_erros                | -0.4321  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 196400   |
| lives                   | 196400   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 6.24     |
| mean 100 episode reward | 4.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4591   |
| steps                   | 1301586  |
| td_erros                | -0.4247  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 196500   |
| lives                   | 196500   |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 6.29     |
| mean 100 episode reward | 4.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4778   |
| steps                   | 1302115  |
| td_erros                | -0.4172  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 196600   |
| lives                   | 196600   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 6.17     |
| mean 100 episode reward | 4.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5212   |
| steps                   | 1302632  |
| td_erros                | -0.4198  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 196700   |
| lives                   | 196700   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 6.14     |
| mean 100 episode reward | 4.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5432   |
| steps                   | 1303146  |
| td_erros                | -0.4057  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 196800   |
| lives                   | 196800   |
| mean 100 episode ei     | 3.68     |
| mean 100 episode length | 6.24     |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5507   |
| steps                   | 1303670  |
| td_erros                | -0.3958  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 196900   |
| lives                   | 196900   |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 6.2      |
| mean 100 episode reward | 4.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.557    |
| steps                   | 1304190  |
| td_erros                | -0.3806  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 197000   |
| lives                   | 197000   |
| mean 100 episode ei     | 3.7      |
| mean 100 episode length | 6.02     |
| mean 100 episode reward | 4.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5504   |
| steps                   | 1304692  |
| td_erros                | -0.3722  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 197100   |
| lives                   | 197100   |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 5.83     |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5801   |
| steps                   | 1305175  |
| td_erros                | -0.3972  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 197200   |
| lives                   | 197200   |
| mean 100 episode ei     | 3.83     |
| mean 100 episode length | 6.04     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5621   |
| steps                   | 1305679  |
| td_erros                | -0.3855  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 197300   |
| lives                   | 197300   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 6.51     |
| mean 100 episode reward | 5.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5805   |
| steps                   | 1306230  |
| td_erros                | -0.3766  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 197400   |
| lives                   | 197400   |
| mean 100 episode ei     | 3.32     |
| mean 100 episode length | 5.64     |
| mean 100 episode reward | 4.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5752   |
| steps                   | 1306694  |
| td_erros                | -0.3813  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 197500   |
| lives                   | 197500   |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 6.05     |
| mean 100 episode reward | 4.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.569    |
| steps                   | 1307199  |
| td_erros                | -0.3705  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 197600   |
| lives                   | 197600   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 6.15     |
| mean 100 episode reward | 4.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5403   |
| steps                   | 1307714  |
| td_erros                | -0.3604  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 197700   |
| lives                   | 197700   |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 6.36     |
| mean 100 episode reward | 4.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.533    |
| steps                   | 1308250  |
| td_erros                | -0.3916  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 19       |
| episodes                | 197800   |
| lives                   | 197800   |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 6.41     |
| mean 100 episode reward | 4.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.512    |
| steps                   | 1308791  |
| td_erros                | -0.3885  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 197900   |
| lives                   | 197900   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 6.82     |
| mean 100 episode reward | 4.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4761   |
| steps                   | 1309373  |
| td_erros                | -0.3782  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 198000   |
| lives                   | 198000   |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 6.79     |
| mean 100 episode reward | 4.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4609   |
| steps                   | 1309952  |
| td_erros                | -0.4029  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 198100   |
| lives                   | 198100   |
| mean 100 episode ei     | 3.8      |
| mean 100 episode length | 6.85     |
| mean 100 episode reward | 4.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4639   |
| steps                   | 1310537  |
| td_erros                | -0.3692  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 198200   |
| lives                   | 198200   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 6.99     |
| mean 100 episode reward | 5.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4778   |
| steps                   | 1311136  |
| td_erros                | -0.3738  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 198300   |
| lives                   | 198300   |
| mean 100 episode ei     | 3.66     |
| mean 100 episode length | 6.87     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4689   |
| steps                   | 1311723  |
| td_erros                | -0.3552  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 198400   |
| lives                   | 198400   |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 7.08     |
| mean 100 episode reward | 5.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.45     |
| steps                   | 1312331  |
| td_erros                | -0.3695  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 198500   |
| lives                   | 198500   |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 7.15     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4899   |
| steps                   | 1312946  |
| td_erros                | -0.3539  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 198600   |
| lives                   | 198600   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 7.15     |
| mean 100 episode reward | 4.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5      |
| steps                   | 1313561  |
| td_erros                | -0.3482  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 198700   |
| lives                   | 198700   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 7        |
| mean 100 episode reward | 4.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5183   |
| steps                   | 1314161  |
| td_erros                | -0.3386  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 198800   |
| lives                   | 198800   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 7.25     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5239   |
| steps                   | 1314786  |
| td_erros                | -0.3208  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 198900   |
| lives                   | 198900   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 7.03     |
| mean 100 episode reward | 5.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5164   |
| steps                   | 1315389  |
| td_erros                | -0.3434  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 199000   |
| lives                   | 199000   |
| mean 100 episode ei     | 3.8      |
| mean 100 episode length | 6.7      |
| mean 100 episode reward | 5.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5422   |
| steps                   | 1315959  |
| td_erros                | -0.3305  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 199100   |
| lives                   | 199100   |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 6.88     |
| mean 100 episode reward | 5.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5261   |
| steps                   | 1316547  |
| td_erros                | -0.333   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 199200   |
| lives                   | 199200   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 7.27     |
| mean 100 episode reward | 4.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.558    |
| steps                   | 1317174  |
| td_erros                | -0.3048  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 199300   |
| lives                   | 199300   |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 7.09     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.591    |
| steps                   | 1317783  |
| td_erros                | -0.3052  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 199400   |
| lives                   | 199400   |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 6.65     |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5918   |
| steps                   | 1318348  |
| td_erros                | -0.2942  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 199500   |
| lives                   | 199500   |
| mean 100 episode ei     | 3.8      |
| mean 100 episode length | 6.55     |
| mean 100 episode reward | 4.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6111   |
| steps                   | 1318903  |
| td_erros                | -0.2958  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 199600   |
| lives                   | 199600   |
| mean 100 episode ei     | 3.64     |
| mean 100 episode length | 6.8      |
| mean 100 episode reward | 4.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6195   |
| steps                   | 1319483  |
| td_erros                | -0.289   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 199700   |
| lives                   | 199700   |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 7.1      |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6485   |
| steps                   | 1320093  |
| td_erros                | -0.2737  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 199800   |
| lives                   | 199800   |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 6.5      |
| mean 100 episode reward | 4.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6264   |
| steps                   | 1320643  |
| td_erros                | -0.2853  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 199900   |
| lives                   | 199900   |
| mean 100 episode ei     | 3.05     |
| mean 100 episode length | 5.35     |
| mean 100 episode reward | 3.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6283   |
| steps                   | 1321078  |
| td_erros                | -0.2537  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 200000   |
| lives                   | 200000   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 6.49     |
| mean 100 episode reward | 4.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6016   |
| steps                   | 1321627  |
| td_erros                | -0.2714  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 200100   |
| lives                   | 200100   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 6.17     |
| mean 100 episode reward | 4.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5817   |
| steps                   | 1322144  |
| td_erros                | -0.2927  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 200200   |
| lives                   | 200200   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 6.08     |
| mean 100 episode reward | 4.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5828   |
| steps                   | 1322652  |
| td_erros                | -0.3232  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 200300   |
| lives                   | 200300   |
| mean 100 episode ei     | 3.83     |
| mean 100 episode length | 6.24     |
| mean 100 episode reward | 4.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5574   |
| steps                   | 1323176  |
| td_erros                | -0.3285  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 200400   |
| lives                   | 200400   |
| mean 100 episode ei     | 3.3      |
| mean 100 episode length | 5.74     |
| mean 100 episode reward | 4.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5005   |
| steps                   | 1323650  |
| td_erros                | -0.3633  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 200500   |
| lives                   | 200500   |
| mean 100 episode ei     | 3.52     |
| mean 100 episode length | 5.94     |
| mean 100 episode reward | 4.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4951   |
| steps                   | 1324144  |
| td_erros                | -0.3788  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 200600   |
| lives                   | 200600   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 6.45     |
| mean 100 episode reward | 4.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.492    |
| steps                   | 1324689  |
| td_erros                | -0.3787  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 18       |
| episodes                | 200700   |
| lives                   | 200700   |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 6.32     |
| mean 100 episode reward | 4.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4772   |
| steps                   | 1325221  |
| td_erros                | -0.38    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 200800   |
| lives                   | 200800   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 6.43     |
| mean 100 episode reward | 4.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4876   |
| steps                   | 1325764  |
| td_erros                | -0.3944  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 200900   |
| lives                   | 200900   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 6.51     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5134   |
| steps                   | 1326315  |
| td_erros                | -0.4025  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 201000   |
| lives                   | 201000   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 6.62     |
| mean 100 episode reward | 5.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5136   |
| steps                   | 1326877  |
| td_erros                | -0.4095  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 201100   |
| lives                   | 201100   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 6.53     |
| mean 100 episode reward | 5.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5045   |
| steps                   | 1327430  |
| td_erros                | -0.3937  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 201200   |
| lives                   | 201200   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 6.31     |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4884   |
| steps                   | 1327961  |
| td_erros                | -0.3965  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 201300   |
| lives                   | 201300   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 6.38     |
| mean 100 episode reward | 5        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5022   |
| steps                   | 1328499  |
| td_erros                | -0.3777  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 201400   |
| lives                   | 201400   |
| mean 100 episode ei     | 4.21     |
| mean 100 episode length | 6        |
| mean 100 episode reward | 4.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5139   |
| steps                   | 1328999  |
| td_erros                | -0.4193  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 201500   |
| lives                   | 201500   |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 6.19     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5166   |
| steps                   | 1329518  |
| td_erros                | -0.4374  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 201600   |
| lives                   | 201600   |
| mean 100 episode ei     | 3.53     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 4.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5607   |
| steps                   | 1329980  |
| td_erros                | -0.4138  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 201700   |
| lives                   | 201700   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 6.28     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5617   |
| steps                   | 1330508  |
| td_erros                | -0.4138  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 201800   |
| lives                   | 201800   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 6.77     |
| mean 100 episode reward | 4.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5583   |
| steps                   | 1331085  |
| td_erros                | -0.3809  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 201900   |
| lives                   | 201900   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 6.72     |
| mean 100 episode reward | 4.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5339   |
| steps                   | 1331657  |
| td_erros                | -0.3973  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 202000   |
| lives                   | 202000   |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 6.88     |
| mean 100 episode reward | 4.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.542    |
| steps                   | 1332245  |
| td_erros                | -0.4036  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 202100   |
| lives                   | 202100   |
| mean 100 episode ei     | 4.47     |
| mean 100 episode length | 7.1      |
| mean 100 episode reward | 5.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5256   |
| steps                   | 1332855  |
| td_erros                | -0.4072  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 202200   |
| lives                   | 202200   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 6.86     |
| mean 100 episode reward | 4.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5562   |
| steps                   | 1333441  |
| td_erros                | -0.3893  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 202300   |
| lives                   | 202300   |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 6.78     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.584    |
| steps                   | 1334019  |
| td_erros                | -0.391   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 202400   |
| lives                   | 202400   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 6.88     |
| mean 100 episode reward | 4.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5843   |
| steps                   | 1334607  |
| td_erros                | -0.3881  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 202500   |
| lives                   | 202500   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 6.72     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5981   |
| steps                   | 1335179  |
| td_erros                | -0.3691  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 202600   |
| lives                   | 202600   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 6.46     |
| mean 100 episode reward | 5.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6021   |
| steps                   | 1335725  |
| td_erros                | -0.3608  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 202700   |
| lives                   | 202700   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 6.6      |
| mean 100 episode reward | 5.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5959   |
| steps                   | 1336285  |
| td_erros                | -0.3713  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 202800   |
| lives                   | 202800   |
| mean 100 episode ei     | 2.83     |
| mean 100 episode length | 5.67     |
| mean 100 episode reward | 3.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6219   |
| steps                   | 1336752  |
| td_erros                | -0.3316  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 202900   |
| lives                   | 202900   |
| mean 100 episode ei     | 4.23     |
| mean 100 episode length | 7.24     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.578    |
| steps                   | 1337376  |
| td_erros                | -0.3174  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 203000   |
| lives                   | 203000   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 7.06     |
| mean 100 episode reward | 5.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5664   |
| steps                   | 1337982  |
| td_erros                | -0.3153  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 203100   |
| lives                   | 203100   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 7.05     |
| mean 100 episode reward | 5.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5545   |
| steps                   | 1338587  |
| td_erros                | -0.3268  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 203200   |
| lives                   | 203200   |
| mean 100 episode ei     | 3.63     |
| mean 100 episode length | 6.84     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5276   |
| steps                   | 1339171  |
| td_erros                | -0.2825  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 203300   |
| lives                   | 203300   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 6.91     |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5182   |
| steps                   | 1339762  |
| td_erros                | -0.298   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 203400   |
| lives                   | 203400   |
| mean 100 episode ei     | 3.56     |
| mean 100 episode length | 6.57     |
| mean 100 episode reward | 4.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4905   |
| steps                   | 1340319  |
| td_erros                | -0.3105  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 17       |
| episodes                | 203500   |
| lives                   | 203500   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 7.27     |
| mean 100 episode reward | 5.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4577   |
| steps                   | 1340946  |
| td_erros                | -0.3082  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 203600   |
| lives                   | 203600   |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 7.09     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4457   |
| steps                   | 1341555  |
| td_erros                | -0.3229  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 203700   |
| lives                   | 203700   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 6.85     |
| mean 100 episode reward | 5.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4478   |
| steps                   | 1342140  |
| td_erros                | -0.3571  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 203800   |
| lives                   | 203800   |
| mean 100 episode ei     | 3.36     |
| mean 100 episode length | 6.11     |
| mean 100 episode reward | 4.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4742   |
| steps                   | 1342651  |
| td_erros                | -0.3475  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 203900   |
| lives                   | 203900   |
| mean 100 episode ei     | 2.6      |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 2.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4718   |
| steps                   | 1343071  |
| td_erros                | -0.3126  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 204000   |
| lives                   | 204000   |
| mean 100 episode ei     | 3.79     |
| mean 100 episode length | 6.57     |
| mean 100 episode reward | 4.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4528   |
| steps                   | 1343628  |
| td_erros                | -0.2837  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 204100   |
| lives                   | 204100   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 6.91     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4344   |
| steps                   | 1344219  |
| td_erros                | -0.3395  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 204200   |
| lives                   | 204200   |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 6.24     |
| mean 100 episode reward | 4.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4364   |
| steps                   | 1344743  |
| td_erros                | -0.3368  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 204300   |
| lives                   | 204300   |
| mean 100 episode ei     | 3.72     |
| mean 100 episode length | 5.73     |
| mean 100 episode reward | 4.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4604   |
| steps                   | 1345216  |
| td_erros                | -0.3328  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 204400   |
| lives                   | 204400   |
| mean 100 episode ei     | 3.65     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 4.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.492    |
| steps                   | 1345676  |
| td_erros                | -0.3179  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 204500   |
| lives                   | 204500   |
| mean 100 episode ei     | 3.79     |
| mean 100 episode length | 5.94     |
| mean 100 episode reward | 4.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4845   |
| steps                   | 1346170  |
| td_erros                | -0.3321  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 204600   |
| lives                   | 204600   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 6.03     |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4817   |
| steps                   | 1346673  |
| td_erros                | -0.3321  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 204700   |
| lives                   | 204700   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 6.24     |
| mean 100 episode reward | 4.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4804   |
| steps                   | 1347197  |
| td_erros                | -0.3859  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 204800   |
| lives                   | 204800   |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 6.63     |
| mean 100 episode reward | 4.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4941   |
| steps                   | 1347760  |
| td_erros                | -0.3638  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 204900   |
| lives                   | 204900   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 6.29     |
| mean 100 episode reward | 4.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5431   |
| steps                   | 1348289  |
| td_erros                | -0.3912  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 205000   |
| lives                   | 205000   |
| mean 100 episode ei     | 3.67     |
| mean 100 episode length | 6.01     |
| mean 100 episode reward | 3.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5908   |
| steps                   | 1348790  |
| td_erros                | -0.36    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 205100   |
| lives                   | 205100   |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 6.16     |
| mean 100 episode reward | 3.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5909   |
| steps                   | 1349306  |
| td_erros                | -0.34    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 205200   |
| lives                   | 205200   |
| mean 100 episode ei     | 3.7      |
| mean 100 episode length | 6.36     |
| mean 100 episode reward | 3.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5911   |
| steps                   | 1349842  |
| td_erros                | -0.34    |
--------------------------------------
Saving model due to running mean reward increase: 3.6015 -> 3.7823
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 205300   |
| lives                   | 205300   |
| mean 100 episode ei     | 3.56     |
| mean 100 episode length | 5.92     |
| mean 100 episode reward | 3.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5902   |
| steps                   | 1350334  |
| td_erros                | -0.3431  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 205400   |
| lives                   | 205400   |
| mean 100 episode ei     | 3.56     |
| mean 100 episode length | 5.95     |
| mean 100 episode reward | 4.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5798   |
| steps                   | 1350829  |
| td_erros                | -0.2952  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 205500   |
| lives                   | 205500   |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 6.29     |
| mean 100 episode reward | 4.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5754   |
| steps                   | 1351358  |
| td_erros                | -0.2976  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 205600   |
| lives                   | 205600   |
| mean 100 episode ei     | 3.7      |
| mean 100 episode length | 6.19     |
| mean 100 episode reward | 3.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5231   |
| steps                   | 1351877  |
| td_erros                | -0.3185  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 205700   |
| lives                   | 205700   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 6.62     |
| mean 100 episode reward | 3.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5065   |
| steps                   | 1352439  |
| td_erros                | -0.3183  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 205800   |
| lives                   | 205800   |
| mean 100 episode ei     | 3.62     |
| mean 100 episode length | 6.4      |
| mean 100 episode reward | 3.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4916   |
| steps                   | 1352979  |
| td_erros                | -0.3201  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 205900   |
| lives                   | 205900   |
| mean 100 episode ei     | 3.53     |
| mean 100 episode length | 5.9      |
| mean 100 episode reward | 3.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4878   |
| steps                   | 1353469  |
| td_erros                | -0.3193  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 206000   |
| lives                   | 206000   |
| mean 100 episode ei     | 3.4      |
| mean 100 episode length | 6.12     |
| mean 100 episode reward | 3.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4653   |
| steps                   | 1353981  |
| td_erros                | -0.2827  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 206100   |
| lives                   | 206100   |
| mean 100 episode ei     | 3.52     |
| mean 100 episode length | 6.67     |
| mean 100 episode reward | 3.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4155   |
| steps                   | 1354548  |
| td_erros                | -0.3011  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 206200   |
| lives                   | 206200   |
| mean 100 episode ei     | 3.67     |
| mean 100 episode length | 6.25     |
| mean 100 episode reward | 4.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.393    |
| steps                   | 1355073  |
| td_erros                | -0.3202  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 206300   |
| lives                   | 206300   |
| mean 100 episode ei     | 3.59     |
| mean 100 episode length | 6.32     |
| mean 100 episode reward | 4.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4258   |
| steps                   | 1355605  |
| td_erros                | -0.3181  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 206400   |
| lives                   | 206400   |
| mean 100 episode ei     | 3.83     |
| mean 100 episode length | 6.95     |
| mean 100 episode reward | 4.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3802   |
| steps                   | 1356200  |
| td_erros                | -0.3148  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 206500   |
| lives                   | 206500   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 7.08     |
| mean 100 episode reward | 4.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3877   |
| steps                   | 1356808  |
| td_erros                | -0.3145  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 16       |
| episodes                | 206600   |
| lives                   | 206600   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 6.85     |
| mean 100 episode reward | 4.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3844   |
| steps                   | 1357393  |
| td_erros                | -0.3174  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 206700   |
| lives                   | 206700   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 6.12     |
| mean 100 episode reward | 4.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4124   |
| steps                   | 1357905  |
| td_erros                | -0.2995  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 206800   |
| lives                   | 206800   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.73     |
| mean 100 episode reward | 4.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4466   |
| steps                   | 1358378  |
| td_erros                | -0.2744  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 206900   |
| lives                   | 206900   |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 5.73     |
| mean 100 episode reward | 4.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4724   |
| steps                   | 1358851  |
| td_erros                | -0.2814  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 207000   |
| lives                   | 207000   |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 5.97     |
| mean 100 episode reward | 3.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5047   |
| steps                   | 1359348  |
| td_erros                | -0.2652  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 207100   |
| lives                   | 207100   |
| mean 100 episode ei     | 3.8      |
| mean 100 episode length | 5.7      |
| mean 100 episode reward | 4.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5167   |
| steps                   | 1359818  |
| td_erros                | -0.262   |
--------------------------------------
Saving model due to running mean reward increase: 4.098 -> 4.2828
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 207200   |
| lives                   | 207200   |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 6.35     |
| mean 100 episode reward | 4.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5564   |
| steps                   | 1360353  |
| td_erros                | -0.2623  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 207300   |
| lives                   | 207300   |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 6.6      |
| mean 100 episode reward | 3.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5797   |
| steps                   | 1360913  |
| td_erros                | -0.2532  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 207400   |
| lives                   | 207400   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 6.43     |
| mean 100 episode reward | 3.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5687   |
| steps                   | 1361456  |
| td_erros                | -0.2549  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 207500   |
| lives                   | 207500   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.85     |
| mean 100 episode reward | 3.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5859   |
| steps                   | 1361941  |
| td_erros                | -0.2755  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 207600   |
| lives                   | 207600   |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 6.15     |
| mean 100 episode reward | 4.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6245   |
| steps                   | 1362456  |
| td_erros                | -0.2423  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 207700   |
| lives                   | 207700   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.95     |
| mean 100 episode reward | 3.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6232   |
| steps                   | 1362951  |
| td_erros                | -0.2484  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 207800   |
| lives                   | 207800   |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 5.7      |
| mean 100 episode reward | 4.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6419   |
| steps                   | 1363421  |
| td_erros                | -0.225   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 207900   |
| lives                   | 207900   |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 5.7      |
| mean 100 episode reward | 4.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6569   |
| steps                   | 1363891  |
| td_erros                | -0.2331  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 208000   |
| lives                   | 208000   |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 6.41     |
| mean 100 episode reward | 4.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6303   |
| steps                   | 1364432  |
| td_erros                | -0.2501  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 208100   |
| lives                   | 208100   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 6.43     |
| mean 100 episode reward | 4.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6334   |
| steps                   | 1364975  |
| td_erros                | -0.2292  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 208200   |
| lives                   | 208200   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 5.88     |
| mean 100 episode reward | 3.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6351   |
| steps                   | 1365463  |
| td_erros                | -0.2517  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 208300   |
| lives                   | 208300   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 6.01     |
| mean 100 episode reward | 3.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.637    |
| steps                   | 1365964  |
| td_erros                | -0.2314  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 208400   |
| lives                   | 208400   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.95     |
| mean 100 episode reward | 3.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6531   |
| steps                   | 1366459  |
| td_erros                | -0.2622  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 208500   |
| lives                   | 208500   |
| mean 100 episode ei     | 3.79     |
| mean 100 episode length | 5.72     |
| mean 100 episode reward | 3.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6628   |
| steps                   | 1366931  |
| td_erros                | -0.2604  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 208600   |
| lives                   | 208600   |
| mean 100 episode ei     | 3.49     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 3.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6608   |
| steps                   | 1367374  |
| td_erros                | -0.2659  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 208700   |
| lives                   | 208700   |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 5.97     |
| mean 100 episode reward | 4.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6682   |
| steps                   | 1367871  |
| td_erros                | -0.2607  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 208800   |
| lives                   | 208800   |
| mean 100 episode ei     | 3.74     |
| mean 100 episode length | 5.97     |
| mean 100 episode reward | 5.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6927   |
| steps                   | 1368368  |
| td_erros                | -0.2566  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 208900   |
| lives                   | 208900   |
| mean 100 episode ei     | 3.63     |
| mean 100 episode length | 5.71     |
| mean 100 episode reward | 4.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6947   |
| steps                   | 1368839  |
| td_erros                | -0.2715  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 209000   |
| lives                   | 209000   |
| mean 100 episode ei     | 3.65     |
| mean 100 episode length | 6        |
| mean 100 episode reward | 4.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6648   |
| steps                   | 1369339  |
| td_erros                | -0.305   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 209100   |
| lives                   | 209100   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 6.05     |
| mean 100 episode reward | 4.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6664   |
| steps                   | 1369844  |
| td_erros                | -0.3245  |
--------------------------------------
Saving model due to running mean reward increase: 4.3994 -> 4.6575
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 209200   |
| lives                   | 209200   |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 6.55     |
| mean 100 episode reward | 5.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6327   |
| steps                   | 1370399  |
| td_erros                | -0.3173  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 209300   |
| lives                   | 209300   |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 6.21     |
| mean 100 episode reward | 4.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6047   |
| steps                   | 1370920  |
| td_erros                | -0.3046  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 209400   |
| lives                   | 209400   |
| mean 100 episode ei     | 4.21     |
| mean 100 episode length | 6.57     |
| mean 100 episode reward | 4.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6065   |
| steps                   | 1371477  |
| td_erros                | -0.3153  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 209500   |
| lives                   | 209500   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 6.13     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6219   |
| steps                   | 1371990  |
| td_erros                | -0.3042  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 209600   |
| lives                   | 209600   |
| mean 100 episode ei     | 3.72     |
| mean 100 episode length | 6.18     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6085   |
| steps                   | 1372508  |
| td_erros                | -0.3099  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 209700   |
| lives                   | 209700   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 6.44     |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5865   |
| steps                   | 1373052  |
| td_erros                | -0.31    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 15       |
| episodes                | 209800   |
| lives                   | 209800   |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 6.79     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5712   |
| steps                   | 1373631  |
| td_erros                | -0.322   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 209900   |
| lives                   | 209900   |
| mean 100 episode ei     | 3.4      |
| mean 100 episode length | 6.4      |
| mean 100 episode reward | 4.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5302   |
| steps                   | 1374171  |
| td_erros                | -0.3213  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 210000   |
| lives                   | 210000   |
| mean 100 episode ei     | 3.37     |
| mean 100 episode length | 5.89     |
| mean 100 episode reward | 3.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5373   |
| steps                   | 1374660  |
| td_erros                | -0.2963  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 210100   |
| lives                   | 210100   |
| mean 100 episode ei     | 3.68     |
| mean 100 episode length | 6.26     |
| mean 100 episode reward | 4.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4763   |
| steps                   | 1375186  |
| td_erros                | -0.3047  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 210200   |
| lives                   | 210200   |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 6.63     |
| mean 100 episode reward | 5.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4556   |
| steps                   | 1375749  |
| td_erros                | -0.3311  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 210300   |
| lives                   | 210300   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 6.5      |
| mean 100 episode reward | 4.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4535   |
| steps                   | 1376299  |
| td_erros                | -0.3319  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 210400   |
| lives                   | 210400   |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 6.83     |
| mean 100 episode reward | 5.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4816   |
| steps                   | 1376882  |
| td_erros                | -0.3251  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 210500   |
| lives                   | 210500   |
| mean 100 episode ei     | 3.69     |
| mean 100 episode length | 6.35     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4645   |
| steps                   | 1377417  |
| td_erros                | -0.3135  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 210600   |
| lives                   | 210600   |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 6.43     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4824   |
| steps                   | 1377960  |
| td_erros                | -0.3265  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 210700   |
| lives                   | 210700   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 6.2      |
| mean 100 episode reward | 4.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4816   |
| steps                   | 1378480  |
| td_erros                | -0.3196  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 210800   |
| lives                   | 210800   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 6.24     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4751   |
| steps                   | 1379004  |
| td_erros                | -0.3319  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 210900   |
| lives                   | 210900   |
| mean 100 episode ei     | 3.62     |
| mean 100 episode length | 5.75     |
| mean 100 episode reward | 5.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5061   |
| steps                   | 1379479  |
| td_erros                | -0.3454  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 211000   |
| lives                   | 211000   |
| mean 100 episode ei     | 3.69     |
| mean 100 episode length | 5.95     |
| mean 100 episode reward | 4.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5266   |
| steps                   | 1379974  |
| td_erros                | -0.3302  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 211100   |
| lives                   | 211100   |
| mean 100 episode ei     | 3.83     |
| mean 100 episode length | 6.33     |
| mean 100 episode reward | 4.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5133   |
| steps                   | 1380507  |
| td_erros                | -0.3229  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 211200   |
| lives                   | 211200   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 6.41     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5024   |
| steps                   | 1381048  |
| td_erros                | -0.3122  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 211300   |
| lives                   | 211300   |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 6.32     |
| mean 100 episode reward | 4.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5034   |
| steps                   | 1381580  |
| td_erros                | -0.3262  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 211400   |
| lives                   | 211400   |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 6.37     |
| mean 100 episode reward | 4.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4853   |
| steps                   | 1382117  |
| td_erros                | -0.3222  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 211500   |
| lives                   | 211500   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 6.51     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4865   |
| steps                   | 1382668  |
| td_erros                | -0.3483  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 211600   |
| lives                   | 211600   |
| mean 100 episode ei     | 3.71     |
| mean 100 episode length | 6.5      |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4772   |
| steps                   | 1383218  |
| td_erros                | -0.3304  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 211700   |
| lives                   | 211700   |
| mean 100 episode ei     | 4.46     |
| mean 100 episode length | 7.04     |
| mean 100 episode reward | 5.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4544   |
| steps                   | 1383822  |
| td_erros                | -0.3306  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 211800   |
| lives                   | 211800   |
| mean 100 episode ei     | 4.24     |
| mean 100 episode length | 7.26     |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4646   |
| steps                   | 1384448  |
| td_erros                | -0.3371  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 211900   |
| lives                   | 211900   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 6.71     |
| mean 100 episode reward | 5.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4766   |
| steps                   | 1385019  |
| td_erros                | -0.328   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 212000   |
| lives                   | 212000   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 6.47     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5299   |
| steps                   | 1385566  |
| td_erros                | -0.3234  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 212100   |
| lives                   | 212100   |
| mean 100 episode ei     | 3.68     |
| mean 100 episode length | 5.86     |
| mean 100 episode reward | 4.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5217   |
| steps                   | 1386052  |
| td_erros                | -0.3119  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 212200   |
| lives                   | 212200   |
| mean 100 episode ei     | 3.72     |
| mean 100 episode length | 6.03     |
| mean 100 episode reward | 5.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5304   |
| steps                   | 1386555  |
| td_erros                | -0.3201  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 212300   |
| lives                   | 212300   |
| mean 100 episode ei     | 3.79     |
| mean 100 episode length | 6.18     |
| mean 100 episode reward | 4.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5189   |
| steps                   | 1387073  |
| td_erros                | -0.3263  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 212400   |
| lives                   | 212400   |
| mean 100 episode ei     | 3.38     |
| mean 100 episode length | 5.82     |
| mean 100 episode reward | 4.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5133   |
| steps                   | 1387555  |
| td_erros                | -0.3024  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 212500   |
| lives                   | 212500   |
| mean 100 episode ei     | 3.64     |
| mean 100 episode length | 6.48     |
| mean 100 episode reward | 5.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4814   |
| steps                   | 1388103  |
| td_erros                | -0.2941  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 212600   |
| lives                   | 212600   |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 6.96     |
| mean 100 episode reward | 5.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4546   |
| steps                   | 1388699  |
| td_erros                | -0.3     |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 212700   |
| lives                   | 212700   |
| mean 100 episode ei     | 3.75     |
| mean 100 episode length | 6.38     |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4352   |
| steps                   | 1389237  |
| td_erros                | -0.3086  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 14       |
| episodes                | 212800   |
| lives                   | 212800   |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 6.48     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4012   |
| steps                   | 1389785  |
| td_erros                | -0.3415  |
--------------------------------------
Saving model due to mean reward increase: 5.2055 -> 5.381
Saving model due to running mean reward increase: 5.1442 -> 5.381
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 212900   |
| lives                   | 212900   |
| mean 100 episode ei     | 3.58     |
| mean 100 episode length | 6        |
| mean 100 episode reward | 5.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4037   |
| steps                   | 1390285  |
| td_erros                | -0.3313  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 213000   |
| lives                   | 213000   |
| mean 100 episode ei     | 3.69     |
| mean 100 episode length | 6.37     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3842   |
| steps                   | 1390822  |
| td_erros                | -0.3209  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 213100   |
| lives                   | 213100   |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 6.17     |
| mean 100 episode reward | 5.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3915   |
| steps                   | 1391339  |
| td_erros                | -0.3415  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 213200   |
| lives                   | 213200   |
| mean 100 episode ei     | 3.71     |
| mean 100 episode length | 6.76     |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.349    |
| steps                   | 1391915  |
| td_erros                | -0.3391  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 213300   |
| lives                   | 213300   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 7.08     |
| mean 100 episode reward | 5.57     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3378   |
| steps                   | 1392523  |
| td_erros                | -0.3552  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 213400   |
| lives                   | 213400   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 6.96     |
| mean 100 episode reward | 5.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3493   |
| steps                   | 1393119  |
| td_erros                | -0.3545  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 213500   |
| lives                   | 213500   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 6.46     |
| mean 100 episode reward | 4.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3735   |
| steps                   | 1393665  |
| td_erros                | -0.3391  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 213600   |
| lives                   | 213600   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 6.58     |
| mean 100 episode reward | 4.96     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3927   |
| steps                   | 1394223  |
| td_erros                | -0.3313  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 213700   |
| lives                   | 213700   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 6.61     |
| mean 100 episode reward | 4.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4324   |
| steps                   | 1394784  |
| td_erros                | -0.3157  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 213800   |
| lives                   | 213800   |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 6.53     |
| mean 100 episode reward | 4.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4382   |
| steps                   | 1395337  |
| td_erros                | -0.3037  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 213900   |
| lives                   | 213900   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 6.62     |
| mean 100 episode reward | 4.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4628   |
| steps                   | 1395899  |
| td_erros                | -0.293   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 214000   |
| lives                   | 214000   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 6.53     |
| mean 100 episode reward | 4.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4797   |
| steps                   | 1396452  |
| td_erros                | -0.2877  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 214100   |
| lives                   | 214100   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 6.65     |
| mean 100 episode reward | 5.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5249   |
| steps                   | 1397017  |
| td_erros                | -0.2638  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 214200   |
| lives                   | 214200   |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 6.43     |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5559   |
| steps                   | 1397560  |
| td_erros                | -0.2634  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 214300   |
| lives                   | 214300   |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 6.44     |
| mean 100 episode reward | 5        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5561   |
| steps                   | 1398104  |
| td_erros                | -0.2645  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 214400   |
| lives                   | 214400   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 6.4      |
| mean 100 episode reward | 5.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.579    |
| steps                   | 1398644  |
| td_erros                | -0.2626  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 214500   |
| lives                   | 214500   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 6.55     |
| mean 100 episode reward | 5.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6015   |
| steps                   | 1399199  |
| td_erros                | -0.2209  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 214600   |
| lives                   | 214600   |
| mean 100 episode ei     | 3.5      |
| mean 100 episode length | 5.68     |
| mean 100 episode reward | 4.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5831   |
| steps                   | 1399667  |
| td_erros                | -0.2208  |
--------------------------------------
Saving model due to running mean reward increase: 4.0858 -> 5.1882
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 214700   |
| lives                   | 214700   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 6.43     |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.58     |
| steps                   | 1400210  |
| td_erros                | -0.2163  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 214800   |
| lives                   | 214800   |
| mean 100 episode ei     | 3.52     |
| mean 100 episode length | 6.09     |
| mean 100 episode reward | 4.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5841   |
| steps                   | 1400719  |
| td_erros                | -0.2177  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 214900   |
| lives                   | 214900   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 6.59     |
| mean 100 episode reward | 4.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5873   |
| steps                   | 1401278  |
| td_erros                | -0.2184  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 215000   |
| lives                   | 215000   |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 6.21     |
| mean 100 episode reward | 4.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5985   |
| steps                   | 1401799  |
| td_erros                | -0.2201  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 215100   |
| lives                   | 215100   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 6.53     |
| mean 100 episode reward | 4.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6143   |
| steps                   | 1402352  |
| td_erros                | -0.224   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 215200   |
| lives                   | 215200   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 6.57     |
| mean 100 episode reward | 4.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6356   |
| steps                   | 1402909  |
| td_erros                | -0.2282  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 215300   |
| lives                   | 215300   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 6.17     |
| mean 100 episode reward | 4.96     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6295   |
| steps                   | 1403426  |
| td_erros                | -0.2496  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 215400   |
| lives                   | 215400   |
| mean 100 episode ei     | 3.7      |
| mean 100 episode length | 6.3      |
| mean 100 episode reward | 4.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6476   |
| steps                   | 1403956  |
| td_erros                | -0.2594  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 215500   |
| lives                   | 215500   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 6.24     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.624    |
| steps                   | 1404480  |
| td_erros                | -0.2716  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 215600   |
| lives                   | 215600   |
| mean 100 episode ei     | 2.72     |
| mean 100 episode length | 4.48     |
| mean 100 episode reward | 3.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6371   |
| steps                   | 1404828  |
| td_erros                | -0.2615  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 215700   |
| lives                   | 215700   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.92     |
| mean 100 episode reward | 4.69     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5984   |
| steps                   | 1405320  |
| td_erros                | -0.2586  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 13       |
| episodes                | 215800   |
| lives                   | 215800   |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 6.76     |
| mean 100 episode reward | 4.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5638   |
| steps                   | 1405896  |
| td_erros                | -0.266   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 215900   |
| lives                   | 215900   |
| mean 100 episode ei     | 3.29     |
| mean 100 episode length | 6.36     |
| mean 100 episode reward | 4.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5375   |
| steps                   | 1406432  |
| td_erros                | -0.2415  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 216000   |
| lives                   | 216000   |
| mean 100 episode ei     | 3.51     |
| mean 100 episode length | 6.27     |
| mean 100 episode reward | 4        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5319   |
| steps                   | 1406959  |
| td_erros                | -0.2584  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 216100   |
| lives                   | 216100   |
| mean 100 episode ei     | 3.6      |
| mean 100 episode length | 6.56     |
| mean 100 episode reward | 3.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5151   |
| steps                   | 1407515  |
| td_erros                | -0.2548  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 216200   |
| lives                   | 216200   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 6.85     |
| mean 100 episode reward | 4.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.488    |
| steps                   | 1408100  |
| td_erros                | -0.2485  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 216300   |
| lives                   | 216300   |
| mean 100 episode ei     | 3.72     |
| mean 100 episode length | 7.02     |
| mean 100 episode reward | 4.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4582   |
| steps                   | 1408702  |
| td_erros                | -0.2473  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 216400   |
| lives                   | 216400   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 7.18     |
| mean 100 episode reward | 4.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4101   |
| steps                   | 1409320  |
| td_erros                | -0.2632  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 216500   |
| lives                   | 216500   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 6.7      |
| mean 100 episode reward | 4.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3825   |
| steps                   | 1409890  |
| td_erros                | -0.292   |
--------------------------------------
Saving model due to running mean reward increase: 4.4766 -> 5.023
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 216600   |
| lives                   | 216600   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 6.72     |
| mean 100 episode reward | 4.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3613   |
| steps                   | 1410462  |
| td_erros                | -0.3276  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 216700   |
| lives                   | 216700   |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 6.88     |
| mean 100 episode reward | 4.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3772   |
| steps                   | 1411050  |
| td_erros                | -0.3104  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 216800   |
| lives                   | 216800   |
| mean 100 episode ei     | 3.04     |
| mean 100 episode length | 5.84     |
| mean 100 episode reward | 3.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3835   |
| steps                   | 1411534  |
| td_erros                | -0.2983  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 216900   |
| lives                   | 216900   |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 6.89     |
| mean 100 episode reward | 5.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3743   |
| steps                   | 1412123  |
| td_erros                | -0.3094  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 217000   |
| lives                   | 217000   |
| mean 100 episode ei     | 3.74     |
| mean 100 episode length | 6.2      |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.406    |
| steps                   | 1412643  |
| td_erros                | -0.2826  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 217100   |
| lives                   | 217100   |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 6.22     |
| mean 100 episode reward | 5.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4375   |
| steps                   | 1413165  |
| td_erros                | -0.2869  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 217200   |
| lives                   | 217200   |
| mean 100 episode ei     | 3.8      |
| mean 100 episode length | 6.36     |
| mean 100 episode reward | 5.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4602   |
| steps                   | 1413701  |
| td_erros                | -0.2737  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 217300   |
| lives                   | 217300   |
| mean 100 episode ei     | 3.51     |
| mean 100 episode length | 6.24     |
| mean 100 episode reward | 4.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4574   |
| steps                   | 1414225  |
| td_erros                | -0.2934  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 217400   |
| lives                   | 217400   |
| mean 100 episode ei     | 3.72     |
| mean 100 episode length | 6.62     |
| mean 100 episode reward | 4.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4494   |
| steps                   | 1414787  |
| td_erros                | -0.2911  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 217500   |
| lives                   | 217500   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 7.1      |
| mean 100 episode reward | 4.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4485   |
| steps                   | 1415397  |
| td_erros                | -0.2911  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 217600   |
| lives                   | 217600   |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 7.03     |
| mean 100 episode reward | 4.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4136   |
| steps                   | 1416000  |
| td_erros                | -0.2866  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 217700   |
| lives                   | 217700   |
| mean 100 episode ei     | 3.14     |
| mean 100 episode length | 5.68     |
| mean 100 episode reward | 3.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3701   |
| steps                   | 1416468  |
| td_erros                | -0.2915  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 217800   |
| lives                   | 217800   |
| mean 100 episode ei     | 2.67     |
| mean 100 episode length | 5.48     |
| mean 100 episode reward | 2.96     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.359    |
| steps                   | 1416916  |
| td_erros                | -0.3078  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 217900   |
| lives                   | 217900   |
| mean 100 episode ei     | 3.71     |
| mean 100 episode length | 6.14     |
| mean 100 episode reward | 4.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3284   |
| steps                   | 1417430  |
| td_erros                | -0.3145  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 218000   |
| lives                   | 218000   |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 6.09     |
| mean 100 episode reward | 4.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3124   |
| steps                   | 1417939  |
| td_erros                | -0.3314  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 218100   |
| lives                   | 218100   |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 6.1      |
| mean 100 episode reward | 5        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2873   |
| steps                   | 1418449  |
| td_erros                | -0.3385  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 218200   |
| lives                   | 218200   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 5.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2695   |
| steps                   | 1418907  |
| td_erros                | -0.3409  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 218300   |
| lives                   | 218300   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 5.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3019   |
| steps                   | 1419369  |
| td_erros                | -0.3758  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 218400   |
| lives                   | 218400   |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 6.1      |
| mean 100 episode reward | 4.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.285    |
| steps                   | 1419879  |
| td_erros                | -0.3753  |
--------------------------------------
Saving model due to running mean reward increase: 4.6738 -> 4.6742
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 218500   |
| lives                   | 218500   |
| mean 100 episode ei     | 3.64     |
| mean 100 episode length | 5.99     |
| mean 100 episode reward | 4.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3126   |
| steps                   | 1420378  |
| td_erros                | -0.3999  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 218600   |
| lives                   | 218600   |
| mean 100 episode ei     | 3.57     |
| mean 100 episode length | 6.3      |
| mean 100 episode reward | 4.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3295   |
| steps                   | 1420908  |
| td_erros                | -0.3752  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 218700   |
| lives                   | 218700   |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 6.23     |
| mean 100 episode reward | 5.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3493   |
| steps                   | 1421431  |
| td_erros                | -0.4181  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 12       |
| episodes                | 218800   |
| lives                   | 218800   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 6.18     |
| mean 100 episode reward | 5.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3606   |
| steps                   | 1421949  |
| td_erros                | -0.3993  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 218900   |
| lives                   | 218900   |
| mean 100 episode ei     | 3.26     |
| mean 100 episode length | 4.72     |
| mean 100 episode reward | 4.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4265   |
| steps                   | 1422321  |
| td_erros                | -0.3743  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 219000   |
| lives                   | 219000   |
| mean 100 episode ei     | 3.59     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 4.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4765   |
| steps                   | 1422745  |
| td_erros                | -0.3248  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 219100   |
| lives                   | 219100   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.81     |
| mean 100 episode reward | 4.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4429   |
| steps                   | 1423226  |
| td_erros                | -0.3264  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 219200   |
| lives                   | 219200   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 6.21     |
| mean 100 episode reward | 4.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4716   |
| steps                   | 1423747  |
| td_erros                | -0.3322  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 219300   |
| lives                   | 219300   |
| mean 100 episode ei     | 3.74     |
| mean 100 episode length | 6        |
| mean 100 episode reward | 4.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4776   |
| steps                   | 1424247  |
| td_erros                | -0.3113  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 219400   |
| lives                   | 219400   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 5.89     |
| mean 100 episode reward | 4.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4999   |
| steps                   | 1424736  |
| td_erros                | -0.3064  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 219500   |
| lives                   | 219500   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.9      |
| mean 100 episode reward | 4.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.51     |
| steps                   | 1425226  |
| td_erros                | -0.2965  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 219600   |
| lives                   | 219600   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.73     |
| mean 100 episode reward | 4.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5351   |
| steps                   | 1425699  |
| td_erros                | -0.2761  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 219700   |
| lives                   | 219700   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.71     |
| mean 100 episode reward | 4.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5595   |
| steps                   | 1426170  |
| td_erros                | -0.28    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 219800   |
| lives                   | 219800   |
| mean 100 episode ei     | 3.63     |
| mean 100 episode length | 5.52     |
| mean 100 episode reward | 4.57     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5861   |
| steps                   | 1426622  |
| td_erros                | -0.2722  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 219900   |
| lives                   | 219900   |
| mean 100 episode ei     | 4.23     |
| mean 100 episode length | 5.72     |
| mean 100 episode reward | 4.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.602    |
| steps                   | 1427094  |
| td_erros                | -0.2633  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 220000   |
| lives                   | 220000   |
| mean 100 episode ei     | 4.54     |
| mean 100 episode length | 6.14     |
| mean 100 episode reward | 4.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5982   |
| steps                   | 1427608  |
| td_erros                | -0.3017  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 220100   |
| lives                   | 220100   |
| mean 100 episode ei     | 3.58     |
| mean 100 episode length | 5.75     |
| mean 100 episode reward | 4.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.597    |
| steps                   | 1428083  |
| td_erros                | -0.2934  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 220200   |
| lives                   | 220200   |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 6.03     |
| mean 100 episode reward | 4.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6102   |
| steps                   | 1428586  |
| td_erros                | -0.3087  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 220300   |
| lives                   | 220300   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 6.26     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6288   |
| steps                   | 1429112  |
| td_erros                | -0.2987  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 220400   |
| lives                   | 220400   |
| mean 100 episode ei     | 3.2      |
| mean 100 episode length | 5.35     |
| mean 100 episode reward | 4.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6244   |
| steps                   | 1429547  |
| td_erros                | -0.2866  |
--------------------------------------
Saving model due to running mean reward increase: 4.6338 -> 4.857
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 220500   |
| lives                   | 220500   |
| mean 100 episode ei     | 3.57     |
| mean 100 episode length | 5.67     |
| mean 100 episode reward | 4.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6279   |
| steps                   | 1430014  |
| td_erros                | -0.2746  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 220600   |
| lives                   | 220600   |
| mean 100 episode ei     | 3.4      |
| mean 100 episode length | 5.72     |
| mean 100 episode reward | 4.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6365   |
| steps                   | 1430486  |
| td_erros                | -0.2696  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 220700   |
| lives                   | 220700   |
| mean 100 episode ei     | 3.55     |
| mean 100 episode length | 5.85     |
| mean 100 episode reward | 4.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5953   |
| steps                   | 1430971  |
| td_erros                | -0.2613  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 220800   |
| lives                   | 220800   |
| mean 100 episode ei     | 3.41     |
| mean 100 episode length | 5.82     |
| mean 100 episode reward | 4.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5762   |
| steps                   | 1431453  |
| td_erros                | -0.2703  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 220900   |
| lives                   | 220900   |
| mean 100 episode ei     | 3.52     |
| mean 100 episode length | 5.76     |
| mean 100 episode reward | 5.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5723   |
| steps                   | 1431929  |
| td_erros                | -0.2506  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 221000   |
| lives                   | 221000   |
| mean 100 episode ei     | 3.6      |
| mean 100 episode length | 5.77     |
| mean 100 episode reward | 5.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5629   |
| steps                   | 1432406  |
| td_erros                | -0.2526  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 221100   |
| lives                   | 221100   |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 5.79     |
| mean 100 episode reward | 5.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5579   |
| steps                   | 1432885  |
| td_erros                | -0.2323  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 221200   |
| lives                   | 221200   |
| mean 100 episode ei     | 3.74     |
| mean 100 episode length | 5.74     |
| mean 100 episode reward | 4.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5007   |
| steps                   | 1433359  |
| td_erros                | -0.2459  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 221300   |
| lives                   | 221300   |
| mean 100 episode ei     | 3.6      |
| mean 100 episode length | 5.68     |
| mean 100 episode reward | 4.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.499    |
| steps                   | 1433827  |
| td_erros                | -0.2846  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 221400   |
| lives                   | 221400   |
| mean 100 episode ei     | 3.56     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 4.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5085   |
| steps                   | 1434269  |
| td_erros                | -0.2722  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 221500   |
| lives                   | 221500   |
| mean 100 episode ei     | 2.74     |
| mean 100 episode length | 4.8      |
| mean 100 episode reward | 3.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5114   |
| steps                   | 1434649  |
| td_erros                | -0.2829  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 221600   |
| lives                   | 221600   |
| mean 100 episode ei     | 2.9      |
| mean 100 episode length | 5.27     |
| mean 100 episode reward | 4.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4325   |
| steps                   | 1435076  |
| td_erros                | -0.296   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 221700   |
| lives                   | 221700   |
| mean 100 episode ei     | 2.93     |
| mean 100 episode length | 5.18     |
| mean 100 episode reward | 4.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3569   |
| steps                   | 1435494  |
| td_erros                | -0.3206  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 221800   |
| lives                   | 221800   |
| mean 100 episode ei     | 2.83     |
| mean 100 episode length | 5.02     |
| mean 100 episode reward | 4.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3178   |
| steps                   | 1435896  |
| td_erros                | -0.3227  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 221900   |
| lives                   | 221900   |
| mean 100 episode ei     | 2.8      |
| mean 100 episode length | 5.03     |
| mean 100 episode reward | 4.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2596   |
| steps                   | 1436299  |
| td_erros                | -0.3311  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 222000   |
| lives                   | 222000   |
| mean 100 episode ei     | 2.84     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 3.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2096   |
| steps                   | 1436718  |
| td_erros                | -0.3274  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 222100   |
| lives                   | 222100   |
| mean 100 episode ei     | 2.52     |
| mean 100 episode length | 4.58     |
| mean 100 episode reward | 3.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2069   |
| steps                   | 1437076  |
| td_erros                | -0.3411  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 222200   |
| lives                   | 222200   |
| mean 100 episode ei     | 2.89     |
| mean 100 episode length | 4.89     |
| mean 100 episode reward | 3.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1907   |
| steps                   | 1437465  |
| td_erros                | -0.3169  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 222300   |
| lives                   | 222300   |
| mean 100 episode ei     | 3.01     |
| mean 100 episode length | 4.94     |
| mean 100 episode reward | 4.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1449   |
| steps                   | 1437859  |
| td_erros                | -0.3012  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 11       |
| episodes                | 222400   |
| lives                   | 222400   |
| mean 100 episode ei     | 3.38     |
| mean 100 episode length | 5.09     |
| mean 100 episode reward | 4.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1164   |
| steps                   | 1438268  |
| td_erros                | -0.3117  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 222500   |
| lives                   | 222500   |
| mean 100 episode ei     | 3.28     |
| mean 100 episode length | 4.97     |
| mean 100 episode reward | 4.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1232   |
| steps                   | 1438665  |
| td_erros                | -0.3425  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 222600   |
| lives                   | 222600   |
| mean 100 episode ei     | 3.37     |
| mean 100 episode length | 4.82     |
| mean 100 episode reward | 4.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1094   |
| steps                   | 1439047  |
| td_erros                | -0.3258  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 222700   |
| lives                   | 222700   |
| mean 100 episode ei     | 3.48     |
| mean 100 episode length | 4.89     |
| mean 100 episode reward | 4.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.0855   |
| steps                   | 1439436  |
| td_erros                | -0.3663  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 222800   |
| lives                   | 222800   |
| mean 100 episode ei     | 3.47     |
| mean 100 episode length | 4.89     |
| mean 100 episode reward | 4.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1086   |
| steps                   | 1439825  |
| td_erros                | -0.3907  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 222900   |
| lives                   | 222900   |
| mean 100 episode ei     | 3.32     |
| mean 100 episode length | 4.84     |
| mean 100 episode reward | 4.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1127   |
| steps                   | 1440209  |
| td_erros                | -0.3908  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 223000   |
| lives                   | 223000   |
| mean 100 episode ei     | 3.41     |
| mean 100 episode length | 4.7      |
| mean 100 episode reward | 4.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1389   |
| steps                   | 1440579  |
| td_erros                | -0.4125  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 223100   |
| lives                   | 223100   |
| mean 100 episode ei     | 3.45     |
| mean 100 episode length | 5.14     |
| mean 100 episode reward | 4.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1329   |
| steps                   | 1440993  |
| td_erros                | -0.4594  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 223200   |
| lives                   | 223200   |
| mean 100 episode ei     | 3.52     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 4.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1569   |
| steps                   | 1441418  |
| td_erros                | -0.4842  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 223300   |
| lives                   | 223300   |
| mean 100 episode ei     | 3.65     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 3.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1561   |
| steps                   | 1441842  |
| td_erros                | -0.4976  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 223400   |
| lives                   | 223400   |
| mean 100 episode ei     | 2.97     |
| mean 100 episode length | 4.86     |
| mean 100 episode reward | 3.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.168    |
| steps                   | 1442228  |
| td_erros                | -0.5112  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 223500   |
| lives                   | 223500   |
| mean 100 episode ei     | 2.67     |
| mean 100 episode length | 4.76     |
| mean 100 episode reward | 3.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1763   |
| steps                   | 1442604  |
| td_erros                | -0.4875  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 223600   |
| lives                   | 223600   |
| mean 100 episode ei     | 2.61     |
| mean 100 episode length | 4.61     |
| mean 100 episode reward | 3.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2212   |
| steps                   | 1442965  |
| td_erros                | -0.4459  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 223700   |
| lives                   | 223700   |
| mean 100 episode ei     | 2.96     |
| mean 100 episode length | 4.73     |
| mean 100 episode reward | 3.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2117   |
| steps                   | 1443338  |
| td_erros                | -0.4096  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 223800   |
| lives                   | 223800   |
| mean 100 episode ei     | 3.39     |
| mean 100 episode length | 4.95     |
| mean 100 episode reward | 3.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1822   |
| steps                   | 1443733  |
| td_erros                | -0.3847  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 223900   |
| lives                   | 223900   |
| mean 100 episode ei     | 3.26     |
| mean 100 episode length | 4.79     |
| mean 100 episode reward | 3.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1902   |
| steps                   | 1444112  |
| td_erros                | -0.382   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 224000   |
| lives                   | 224000   |
| mean 100 episode ei     | 3.5      |
| mean 100 episode length | 4.93     |
| mean 100 episode reward | 4.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1921   |
| steps                   | 1444505  |
| td_erros                | -0.4026  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 224100   |
| lives                   | 224100   |
| mean 100 episode ei     | 3.31     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 3.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1803   |
| steps                   | 1444945  |
| td_erros                | -0.3973  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 224200   |
| lives                   | 224200   |
| mean 100 episode ei     | 3.23     |
| mean 100 episode length | 5.12     |
| mean 100 episode reward | 3.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1793   |
| steps                   | 1445357  |
| td_erros                | -0.3995  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 224300   |
| lives                   | 224300   |
| mean 100 episode ei     | 3.28     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 3.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1932   |
| steps                   | 1445780  |
| td_erros                | -0.3804  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 224400   |
| lives                   | 224400   |
| mean 100 episode ei     | 3.31     |
| mean 100 episode length | 5.16     |
| mean 100 episode reward | 3.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2023   |
| steps                   | 1446196  |
| td_erros                | -0.3842  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 224500   |
| lives                   | 224500   |
| mean 100 episode ei     | 3.33     |
| mean 100 episode length | 5.28     |
| mean 100 episode reward | 3.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2121   |
| steps                   | 1446624  |
| td_erros                | -0.381   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 224600   |
| lives                   | 224600   |
| mean 100 episode ei     | 3.63     |
| mean 100 episode length | 5.53     |
| mean 100 episode reward | 3.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2102   |
| steps                   | 1447077  |
| td_erros                | -0.3589  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 224700   |
| lives                   | 224700   |
| mean 100 episode ei     | 3.55     |
| mean 100 episode length | 5.47     |
| mean 100 episode reward | 3.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2149   |
| steps                   | 1447524  |
| td_erros                | -0.3682  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 224800   |
| lives                   | 224800   |
| mean 100 episode ei     | 3.5      |
| mean 100 episode length | 5.45     |
| mean 100 episode reward | 3.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2231   |
| steps                   | 1447969  |
| td_erros                | -0.3757  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 224900   |
| lives                   | 224900   |
| mean 100 episode ei     | 3.42     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 3.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2249   |
| steps                   | 1448391  |
| td_erros                | -0.4249  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 225000   |
| lives                   | 225000   |
| mean 100 episode ei     | 3.66     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 3.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2695   |
| steps                   | 1448831  |
| td_erros                | -0.4025  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 225100   |
| lives                   | 225100   |
| mean 100 episode ei     | 3.43     |
| mean 100 episode length | 5.15     |
| mean 100 episode reward | 3.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2844   |
| steps                   | 1449246  |
| td_erros                | -0.3763  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 225200   |
| lives                   | 225200   |
| mean 100 episode ei     | 3.62     |
| mean 100 episode length | 5.53     |
| mean 100 episode reward | 3.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3014   |
| steps                   | 1449699  |
| td_erros                | -0.3457  |
--------------------------------------
Saving model due to running mean reward increase: 3.5099 -> 4.561
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 225300   |
| lives                   | 225300   |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 5.49     |
| mean 100 episode reward | 4.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3319   |
| steps                   | 1450148  |
| td_erros                | -0.3449  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 225400   |
| lives                   | 225400   |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 5.45     |
| mean 100 episode reward | 4.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3593   |
| steps                   | 1450593  |
| td_erros                | -0.3519  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 225500   |
| lives                   | 225500   |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 5.91     |
| mean 100 episode reward | 3.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3705   |
| steps                   | 1451084  |
| td_erros                | -0.3564  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 225600   |
| lives                   | 225600   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.78     |
| mean 100 episode reward | 4.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3958   |
| steps                   | 1451562  |
| td_erros                | -0.3518  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 225700   |
| lives                   | 225700   |
| mean 100 episode ei     | 3.71     |
| mean 100 episode length | 5.38     |
| mean 100 episode reward | 3.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4217   |
| steps                   | 1452000  |
| td_erros                | -0.3581  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 225800   |
| lives                   | 225800   |
| mean 100 episode ei     | 3.44     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 3.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4563   |
| steps                   | 1452439  |
| td_erros                | -0.3348  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 225900   |
| lives                   | 225900   |
| mean 100 episode ei     | 3.41     |
| mean 100 episode length | 5.01     |
| mean 100 episode reward | 4.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4436   |
| steps                   | 1452840  |
| td_erros                | -0.3546  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 226000   |
| lives                   | 226000   |
| mean 100 episode ei     | 2.67     |
| mean 100 episode length | 4.5      |
| mean 100 episode reward | 2.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4234   |
| steps                   | 1453190  |
| td_erros                | -0.3392  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 226100   |
| lives                   | 226100   |
| mean 100 episode ei     | 2.99     |
| mean 100 episode length | 4.41     |
| mean 100 episode reward | 4.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4163   |
| steps                   | 1453531  |
| td_erros                | -0.3496  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 226200   |
| lives                   | 226200   |
| mean 100 episode ei     | 3.24     |
| mean 100 episode length | 4.66     |
| mean 100 episode reward | 4.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4025   |
| steps                   | 1453897  |
| td_erros                | -0.3364  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 10       |
| episodes                | 226300   |
| lives                   | 226300   |
| mean 100 episode ei     | 3.42     |
| mean 100 episode length | 4.87     |
| mean 100 episode reward | 4.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.376    |
| steps                   | 1454284  |
| td_erros                | -0.3517  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 226400   |
| lives                   | 226400   |
| mean 100 episode ei     | 3.68     |
| mean 100 episode length | 5.3      |
| mean 100 episode reward | 5.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3539   |
| steps                   | 1454714  |
| td_erros                | -0.3962  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 226500   |
| lives                   | 226500   |
| mean 100 episode ei     | 3.69     |
| mean 100 episode length | 5.5      |
| mean 100 episode reward | 4.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.341    |
| steps                   | 1455164  |
| td_erros                | -0.3991  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 226600   |
| lives                   | 226600   |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 5.69     |
| mean 100 episode reward | 4.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3342   |
| steps                   | 1455633  |
| td_erros                | -0.3926  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 226700   |
| lives                   | 226700   |
| mean 100 episode ei     | 3.55     |
| mean 100 episode length | 5.29     |
| mean 100 episode reward | 4.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3264   |
| steps                   | 1456062  |
| td_erros                | -0.3904  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 226800   |
| lives                   | 226800   |
| mean 100 episode ei     | 3.63     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3723   |
| steps                   | 1456482  |
| td_erros                | -0.3629  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 226900   |
| lives                   | 226900   |
| mean 100 episode ei     | 3.5      |
| mean 100 episode length | 5.28     |
| mean 100 episode reward | 4.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3745   |
| steps                   | 1456910  |
| td_erros                | -0.3436  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 227000   |
| lives                   | 227000   |
| mean 100 episode ei     | 3.13     |
| mean 100 episode length | 5.64     |
| mean 100 episode reward | 4.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3388   |
| steps                   | 1457374  |
| td_erros                | -0.3422  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 227100   |
| lives                   | 227100   |
| mean 100 episode ei     | 2.7      |
| mean 100 episode length | 5.55     |
| mean 100 episode reward | 4.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3349   |
| steps                   | 1457829  |
| td_erros                | -0.3369  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 227200   |
| lives                   | 227200   |
| mean 100 episode ei     | 2.41     |
| mean 100 episode length | 5.3      |
| mean 100 episode reward | 3.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3187   |
| steps                   | 1458259  |
| td_erros                | -0.3368  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 227300   |
| lives                   | 227300   |
| mean 100 episode ei     | 2.8      |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 3.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.326    |
| steps                   | 1458722  |
| td_erros                | -0.2981  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 227400   |
| lives                   | 227400   |
| mean 100 episode ei     | 3.2      |
| mean 100 episode length | 5.67     |
| mean 100 episode reward | 3.69     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3178   |
| steps                   | 1459189  |
| td_erros                | -0.265   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 227500   |
| lives                   | 227500   |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 6.05     |
| mean 100 episode reward | 3.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2873   |
| steps                   | 1459694  |
| td_erros                | -0.2676  |
--------------------------------------
Saving model due to running mean reward increase: 3.6191 -> 3.6916
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 227600   |
| lives                   | 227600   |
| mean 100 episode ei     | 3.45     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 3.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3108   |
| steps                   | 1460159  |
| td_erros                | -0.28    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 227700   |
| lives                   | 227700   |
| mean 100 episode ei     | 3.56     |
| mean 100 episode length | 5.46     |
| mean 100 episode reward | 3.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3299   |
| steps                   | 1460605  |
| td_erros                | -0.2675  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 227800   |
| lives                   | 227800   |
| mean 100 episode ei     | 3.62     |
| mean 100 episode length | 5.56     |
| mean 100 episode reward | 3.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3358   |
| steps                   | 1461061  |
| td_erros                | -0.2507  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 227900   |
| lives                   | 227900   |
| mean 100 episode ei     | 3.75     |
| mean 100 episode length | 5.47     |
| mean 100 episode reward | 3.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3146   |
| steps                   | 1461508  |
| td_erros                | -0.2533  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 228000   |
| lives                   | 228000   |
| mean 100 episode ei     | 3.83     |
| mean 100 episode length | 5.48     |
| mean 100 episode reward | 3.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3092   |
| steps                   | 1461956  |
| td_erros                | -0.2509  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 228100   |
| lives                   | 228100   |
| mean 100 episode ei     | 3.6      |
| mean 100 episode length | 5.36     |
| mean 100 episode reward | 4.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3076   |
| steps                   | 1462392  |
| td_erros                | -0.2618  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 228200   |
| lives                   | 228200   |
| mean 100 episode ei     | 3.65     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 4.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3244   |
| steps                   | 1462832  |
| td_erros                | -0.2843  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 228300   |
| lives                   | 228300   |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 4.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3523   |
| steps                   | 1463273  |
| td_erros                | -0.2903  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 228400   |
| lives                   | 228400   |
| mean 100 episode ei     | 3.71     |
| mean 100 episode length | 5.46     |
| mean 100 episode reward | 4.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3742   |
| steps                   | 1463719  |
| td_erros                | -0.3259  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 228500   |
| lives                   | 228500   |
| mean 100 episode ei     | 3.55     |
| mean 100 episode length | 5.52     |
| mean 100 episode reward | 4.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3733   |
| steps                   | 1464171  |
| td_erros                | -0.3596  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 228600   |
| lives                   | 228600   |
| mean 100 episode ei     | 3.61     |
| mean 100 episode length | 5.71     |
| mean 100 episode reward | 3.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4096   |
| steps                   | 1464642  |
| td_erros                | -0.3526  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 228700   |
| lives                   | 228700   |
| mean 100 episode ei     | 3.55     |
| mean 100 episode length | 5.76     |
| mean 100 episode reward | 3.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4302   |
| steps                   | 1465118  |
| td_erros                | -0.3692  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 228800   |
| lives                   | 228800   |
| mean 100 episode ei     | 2.95     |
| mean 100 episode length | 5.33     |
| mean 100 episode reward | 3.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4283   |
| steps                   | 1465551  |
| td_erros                | -0.3213  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 228900   |
| lives                   | 228900   |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 5.89     |
| mean 100 episode reward | 4.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4135   |
| steps                   | 1466040  |
| td_erros                | -0.3301  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 229000   |
| lives                   | 229000   |
| mean 100 episode ei     | 3.52     |
| mean 100 episode length | 5.52     |
| mean 100 episode reward | 4.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4298   |
| steps                   | 1466492  |
| td_erros                | -0.3133  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 229100   |
| lives                   | 229100   |
| mean 100 episode ei     | 3.42     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 4.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4096   |
| steps                   | 1466953  |
| td_erros                | -0.3118  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 229200   |
| lives                   | 229200   |
| mean 100 episode ei     | 3.67     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4058   |
| steps                   | 1467414  |
| td_erros                | -0.3118  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 229300   |
| lives                   | 229300   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.73     |
| mean 100 episode reward | 4.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4083   |
| steps                   | 1467887  |
| td_erros                | -0.3152  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 229400   |
| lives                   | 229400   |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 5.94     |
| mean 100 episode reward | 3.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4151   |
| steps                   | 1468381  |
| td_erros                | -0.3321  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 229500   |
| lives                   | 229500   |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 5.95     |
| mean 100 episode reward | 3.99     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3965   |
| steps                   | 1468876  |
| td_erros                | -0.3239  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 229600   |
| lives                   | 229600   |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 4.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4089   |
| steps                   | 1469341  |
| td_erros                | -0.3225  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 229700   |
| lives                   | 229700   |
| mean 100 episode ei     | 3.62     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 4.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4191   |
| steps                   | 1469800  |
| td_erros                | -0.3344  |
--------------------------------------
Saving model due to running mean reward increase: 4.3405 -> 4.591
--------------------------------------
| % time spent exploring  | 9        |
| episodes                | 229800   |
| lives                   | 229800   |
| mean 100 episode ei     | 3.63     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 4.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4361   |
| steps                   | 1470242  |
| td_erros                | -0.3368  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 229900   |
| lives                   | 229900   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.69     |
| mean 100 episode reward | 4.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4187   |
| steps                   | 1470711  |
| td_erros                | -0.3712  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 230000   |
| lives                   | 230000   |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 5.94     |
| mean 100 episode reward | 4.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4118   |
| steps                   | 1471205  |
| td_erros                | -0.3889  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 230100   |
| lives                   | 230100   |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 5.86     |
| mean 100 episode reward | 4.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4566   |
| steps                   | 1471691  |
| td_erros                | -0.3971  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 230200   |
| lives                   | 230200   |
| mean 100 episode ei     | 3.58     |
| mean 100 episode length | 5.75     |
| mean 100 episode reward | 4.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4636   |
| steps                   | 1472166  |
| td_erros                | -0.3963  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 230300   |
| lives                   | 230300   |
| mean 100 episode ei     | 3.57     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 4.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4669   |
| steps                   | 1472628  |
| td_erros                | -0.38    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 230400   |
| lives                   | 230400   |
| mean 100 episode ei     | 3.52     |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4515   |
| steps                   | 1473086  |
| td_erros                | -0.3687  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 230500   |
| lives                   | 230500   |
| mean 100 episode ei     | 3.53     |
| mean 100 episode length | 5.56     |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4441   |
| steps                   | 1473542  |
| td_erros                | -0.3712  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 230600   |
| lives                   | 230600   |
| mean 100 episode ei     | 3.71     |
| mean 100 episode length | 5.52     |
| mean 100 episode reward | 5.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4572   |
| steps                   | 1473994  |
| td_erros                | -0.3607  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 230700   |
| lives                   | 230700   |
| mean 100 episode ei     | 3.6      |
| mean 100 episode length | 5.57     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4438   |
| steps                   | 1474451  |
| td_erros                | -0.3488  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 230800   |
| lives                   | 230800   |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 5.74     |
| mean 100 episode reward | 5.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4413   |
| steps                   | 1474925  |
| td_erros                | -0.3533  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 230900   |
| lives                   | 230900   |
| mean 100 episode ei     | 3.8      |
| mean 100 episode length | 5.87     |
| mean 100 episode reward | 5.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4211   |
| steps                   | 1475412  |
| td_erros                | -0.3756  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 231000   |
| lives                   | 231000   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 6.74     |
| mean 100 episode reward | 4.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3854   |
| steps                   | 1475986  |
| td_erros                | -0.3417  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 231100   |
| lives                   | 231100   |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 6.85     |
| mean 100 episode reward | 5.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.348    |
| steps                   | 1476571  |
| td_erros                | -0.3562  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 231200   |
| lives                   | 231200   |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 6.05     |
| mean 100 episode reward | 5.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3462   |
| steps                   | 1477076  |
| td_erros                | -0.3488  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 231300   |
| lives                   | 231300   |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 5.94     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3687   |
| steps                   | 1477570  |
| td_erros                | -0.3495  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 231400   |
| lives                   | 231400   |
| mean 100 episode ei     | 3.57     |
| mean 100 episode length | 5.75     |
| mean 100 episode reward | 5.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.356    |
| steps                   | 1478045  |
| td_erros                | -0.3436  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 231500   |
| lives                   | 231500   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 6.08     |
| mean 100 episode reward | 5.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3598   |
| steps                   | 1478553  |
| td_erros                | -0.3563  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 231600   |
| lives                   | 231600   |
| mean 100 episode ei     | 3.71     |
| mean 100 episode length | 6.14     |
| mean 100 episode reward | 5.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3755   |
| steps                   | 1479067  |
| td_erros                | -0.3586  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 231700   |
| lives                   | 231700   |
| mean 100 episode ei     | 3.36     |
| mean 100 episode length | 5.91     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3971   |
| steps                   | 1479558  |
| td_erros                | -0.3129  |
--------------------------------------
Saving model due to mean reward increase: 5.381 -> 5.3944
Saving model due to running mean reward increase: 5.1065 -> 5.3944
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 231800   |
| lives                   | 231800   |
| mean 100 episode ei     | 3.51     |
| mean 100 episode length | 5.9      |
| mean 100 episode reward | 5.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3745   |
| steps                   | 1480048  |
| td_erros                | -0.2988  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 231900   |
| lives                   | 231900   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 6.06     |
| mean 100 episode reward | 5.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3785   |
| steps                   | 1480554  |
| td_erros                | -0.3124  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 232000   |
| lives                   | 232000   |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 5.95     |
| mean 100 episode reward | 5.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3702   |
| steps                   | 1481049  |
| td_erros                | -0.2985  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 232100   |
| lives                   | 232100   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.94     |
| mean 100 episode reward | 5.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4098   |
| steps                   | 1481543  |
| td_erros                | -0.2943  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 232200   |
| lives                   | 232200   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.423    |
| steps                   | 1482004  |
| td_erros                | -0.2856  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 232300   |
| lives                   | 232300   |
| mean 100 episode ei     | 3.3      |
| mean 100 episode length | 4.86     |
| mean 100 episode reward | 4.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4552   |
| steps                   | 1482390  |
| td_erros                | -0.2755  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 232400   |
| lives                   | 232400   |
| mean 100 episode ei     | 3.42     |
| mean 100 episode length | 5.09     |
| mean 100 episode reward | 4.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4503   |
| steps                   | 1482799  |
| td_erros                | -0.2716  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 232500   |
| lives                   | 232500   |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 5.74     |
| mean 100 episode reward | 4.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.434    |
| steps                   | 1483273  |
| td_erros                | -0.2752  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 232600   |
| lives                   | 232600   |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 5.76     |
| mean 100 episode reward | 4.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4298   |
| steps                   | 1483749  |
| td_erros                | -0.2749  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 232700   |
| lives                   | 232700   |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 6.12     |
| mean 100 episode reward | 4.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4418   |
| steps                   | 1484261  |
| td_erros                | -0.2873  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 232800   |
| lives                   | 232800   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 5.92     |
| mean 100 episode reward | 4.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4402   |
| steps                   | 1484753  |
| td_erros                | -0.3126  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 232900   |
| lives                   | 232900   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 6.05     |
| mean 100 episode reward | 4.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4496   |
| steps                   | 1485258  |
| td_erros                | -0.323   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 233000   |
| lives                   | 233000   |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 6.01     |
| mean 100 episode reward | 4.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4449   |
| steps                   | 1485759  |
| td_erros                | -0.3451  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 233100   |
| lives                   | 233100   |
| mean 100 episode ei     | 4.34     |
| mean 100 episode length | 6.46     |
| mean 100 episode reward | 5.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4318   |
| steps                   | 1486305  |
| td_erros                | -0.3314  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 8        |
| episodes                | 233200   |
| lives                   | 233200   |
| mean 100 episode ei     | 4.73     |
| mean 100 episode length | 6.5      |
| mean 100 episode reward | 5.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4111   |
| steps                   | 1486855  |
| td_erros                | -0.3553  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 233300   |
| lives                   | 233300   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.79     |
| mean 100 episode reward | 5.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4372   |
| steps                   | 1487334  |
| td_erros                | -0.3691  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 233400   |
| lives                   | 233400   |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 5.57     |
| mean 100 episode reward | 5.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4372   |
| steps                   | 1487791  |
| td_erros                | -0.3835  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 233500   |
| lives                   | 233500   |
| mean 100 episode ei     | 4.22     |
| mean 100 episode length | 5.86     |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4647   |
| steps                   | 1488277  |
| td_erros                | -0.3939  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 233600   |
| lives                   | 233600   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.86     |
| mean 100 episode reward | 4.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.474    |
| steps                   | 1488763  |
| td_erros                | -0.412   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 233700   |
| lives                   | 233700   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.71     |
| mean 100 episode reward | 4.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5342   |
| steps                   | 1489234  |
| td_erros                | -0.3703  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 233800   |
| lives                   | 233800   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.73     |
| mean 100 episode reward | 4.69     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5523   |
| steps                   | 1489707  |
| td_erros                | -0.3421  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 233900   |
| lives                   | 233900   |
| mean 100 episode ei     | 3.69     |
| mean 100 episode length | 5.7      |
| mean 100 episode reward | 4.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5447   |
| steps                   | 1490177  |
| td_erros                | -0.3447  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 234000   |
| lives                   | 234000   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.86     |
| mean 100 episode reward | 4.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5499   |
| steps                   | 1490663  |
| td_erros                | -0.3298  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 234100   |
| lives                   | 234100   |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 6.3      |
| mean 100 episode reward | 4.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5601   |
| steps                   | 1491193  |
| td_erros                | -0.3291  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 234200   |
| lives                   | 234200   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 5.79     |
| mean 100 episode reward | 4.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5581   |
| steps                   | 1491672  |
| td_erros                | -0.3003  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 234300   |
| lives                   | 234300   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.84     |
| mean 100 episode reward | 4.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5669   |
| steps                   | 1492156  |
| td_erros                | -0.3034  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 234400   |
| lives                   | 234400   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.76     |
| mean 100 episode reward | 4        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5785   |
| steps                   | 1492632  |
| td_erros                | -0.3146  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 234500   |
| lives                   | 234500   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.68     |
| mean 100 episode reward | 4.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5728   |
| steps                   | 1493100  |
| td_erros                | -0.332   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 234600   |
| lives                   | 234600   |
| mean 100 episode ei     | 3.63     |
| mean 100 episode length | 5.51     |
| mean 100 episode reward | 4.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5739   |
| steps                   | 1493551  |
| td_erros                | -0.3072  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 234700   |
| lives                   | 234700   |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 5.85     |
| mean 100 episode reward | 4.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5697   |
| steps                   | 1494036  |
| td_erros                | -0.3317  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 234800   |
| lives                   | 234800   |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 5.91     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5766   |
| steps                   | 1494527  |
| td_erros                | -0.3298  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 234900   |
| lives                   | 234900   |
| mean 100 episode ei     | 3.66     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.569    |
| steps                   | 1494987  |
| td_erros                | -0.333   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 235000   |
| lives                   | 235000   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 5.8      |
| mean 100 episode reward | 5.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5594   |
| steps                   | 1495467  |
| td_erros                | -0.3267  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 235100   |
| lives                   | 235100   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.94     |
| mean 100 episode reward | 5.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.563    |
| steps                   | 1495961  |
| td_erros                | -0.3424  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 235200   |
| lives                   | 235200   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 6.25     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5357   |
| steps                   | 1496486  |
| td_erros                | -0.3395  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 235300   |
| lives                   | 235300   |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 6.37     |
| mean 100 episode reward | 5.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5321   |
| steps                   | 1497023  |
| td_erros                | -0.3269  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 235400   |
| lives                   | 235400   |
| mean 100 episode ei     | 3.55     |
| mean 100 episode length | 6.32     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5172   |
| steps                   | 1497555  |
| td_erros                | -0.3261  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 235500   |
| lives                   | 235500   |
| mean 100 episode ei     | 3.83     |
| mean 100 episode length | 6.48     |
| mean 100 episode reward | 5.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4636   |
| steps                   | 1498103  |
| td_erros                | -0.3198  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 235600   |
| lives                   | 235600   |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 6.17     |
| mean 100 episode reward | 5.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4411   |
| steps                   | 1498620  |
| td_erros                | -0.3224  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 235700   |
| lives                   | 235700   |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 6.57     |
| mean 100 episode reward | 5.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.418    |
| steps                   | 1499177  |
| td_erros                | -0.3227  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 235800   |
| lives                   | 235800   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 6.52     |
| mean 100 episode reward | 4.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4197   |
| steps                   | 1499729  |
| td_erros                | -0.3074  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 235900   |
| lives                   | 235900   |
| mean 100 episode ei     | 4.24     |
| mean 100 episode length | 6.77     |
| mean 100 episode reward | 4.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3954   |
| steps                   | 1500306  |
| td_erros                | -0.2947  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 236000   |
| lives                   | 236000   |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 6.46     |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3968   |
| steps                   | 1500852  |
| td_erros                | -0.3027  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 236100   |
| lives                   | 236100   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 6.15     |
| mean 100 episode reward | 4.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4021   |
| steps                   | 1501367  |
| td_erros                | -0.2976  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 236200   |
| lives                   | 236200   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 6.01     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4284   |
| steps                   | 1501868  |
| td_erros                | -0.2951  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 236300   |
| lives                   | 236300   |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 6.43     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4464   |
| steps                   | 1502411  |
| td_erros                | -0.2886  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 7        |
| episodes                | 236400   |
| lives                   | 236400   |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 6.46     |
| mean 100 episode reward | 5.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.482    |
| steps                   | 1502957  |
| td_erros                | -0.2794  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 236500   |
| lives                   | 236500   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 6.12     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5157   |
| steps                   | 1503469  |
| td_erros                | -0.2757  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 236600   |
| lives                   | 236600   |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 6.3      |
| mean 100 episode reward | 5.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.541    |
| steps                   | 1503999  |
| td_erros                | -0.2654  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 236700   |
| lives                   | 236700   |
| mean 100 episode ei     | 3.63     |
| mean 100 episode length | 6.21     |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5513   |
| steps                   | 1504520  |
| td_erros                | -0.2543  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 236800   |
| lives                   | 236800   |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 6.4      |
| mean 100 episode reward | 3.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.589    |
| steps                   | 1505060  |
| td_erros                | -0.2382  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 236900   |
| lives                   | 236900   |
| mean 100 episode ei     | 3.37     |
| mean 100 episode length | 5.95     |
| mean 100 episode reward | 4.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.592    |
| steps                   | 1505555  |
| td_erros                | -0.2275  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 237000   |
| lives                   | 237000   |
| mean 100 episode ei     | 3.52     |
| mean 100 episode length | 5.88     |
| mean 100 episode reward | 5.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.567    |
| steps                   | 1506043  |
| td_erros                | -0.2285  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 237100   |
| lives                   | 237100   |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 6.12     |
| mean 100 episode reward | 5.63     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5354   |
| steps                   | 1506555  |
| td_erros                | -0.2313  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 237200   |
| lives                   | 237200   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 6.18     |
| mean 100 episode reward | 5.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5133   |
| steps                   | 1507073  |
| td_erros                | -0.2171  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 237300   |
| lives                   | 237300   |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 5.92     |
| mean 100 episode reward | 5.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5132   |
| steps                   | 1507565  |
| td_erros                | -0.2364  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 237400   |
| lives                   | 237400   |
| mean 100 episode ei     | 3.4      |
| mean 100 episode length | 5.76     |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5134   |
| steps                   | 1508041  |
| td_erros                | -0.2315  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 237500   |
| lives                   | 237500   |
| mean 100 episode ei     | 3.66     |
| mean 100 episode length | 5.71     |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4963   |
| steps                   | 1508512  |
| td_erros                | -0.2244  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 237600   |
| lives                   | 237600   |
| mean 100 episode ei     | 3.49     |
| mean 100 episode length | 6.08     |
| mean 100 episode reward | 4.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4877   |
| steps                   | 1509020  |
| td_erros                | -0.2029  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 237700   |
| lives                   | 237700   |
| mean 100 episode ei     | 3.52     |
| mean 100 episode length | 5.96     |
| mean 100 episode reward | 4.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4825   |
| steps                   | 1509516  |
| td_erros                | -0.2263  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 237800   |
| lives                   | 237800   |
| mean 100 episode ei     | 3.34     |
| mean 100 episode length | 6.27     |
| mean 100 episode reward | 3.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4461   |
| steps                   | 1510043  |
| td_erros                | -0.2396  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 237900   |
| lives                   | 237900   |
| mean 100 episode ei     | 3.41     |
| mean 100 episode length | 6.03     |
| mean 100 episode reward | 3.57     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4411   |
| steps                   | 1510546  |
| td_erros                | -0.2338  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 238000   |
| lives                   | 238000   |
| mean 100 episode ei     | 3.43     |
| mean 100 episode length | 5.77     |
| mean 100 episode reward | 3.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.405    |
| steps                   | 1511023  |
| td_erros                | -0.2508  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 238100   |
| lives                   | 238100   |
| mean 100 episode ei     | 3.69     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 3.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3732   |
| steps                   | 1511483  |
| td_erros                | -0.2633  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 238200   |
| lives                   | 238200   |
| mean 100 episode ei     | 3.5      |
| mean 100 episode length | 5.16     |
| mean 100 episode reward | 4.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3678   |
| steps                   | 1511899  |
| td_erros                | -0.2947  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 238300   |
| lives                   | 238300   |
| mean 100 episode ei     | 3.5      |
| mean 100 episode length | 4.79     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3902   |
| steps                   | 1512278  |
| td_erros                | -0.2779  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 238400   |
| lives                   | 238400   |
| mean 100 episode ei     | 3.38     |
| mean 100 episode length | 4.94     |
| mean 100 episode reward | 5.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4071   |
| steps                   | 1512672  |
| td_erros                | -0.2687  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 238500   |
| lives                   | 238500   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.12     |
| mean 100 episode reward | 4.6      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3762   |
| steps                   | 1513084  |
| td_erros                | -0.2887  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 238600   |
| lives                   | 238600   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 5.13     |
| mean 100 episode reward | 4.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3625   |
| steps                   | 1513497  |
| td_erros                | -0.3029  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 238700   |
| lives                   | 238700   |
| mean 100 episode ei     | 3.5      |
| mean 100 episode length | 4.91     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3454   |
| steps                   | 1513888  |
| td_erros                | -0.3258  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 238800   |
| lives                   | 238800   |
| mean 100 episode ei     | 3.59     |
| mean 100 episode length | 5.1      |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3641   |
| steps                   | 1514298  |
| td_erros                | -0.3112  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 238900   |
| lives                   | 238900   |
| mean 100 episode ei     | 3.63     |
| mean 100 episode length | 5.05     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3457   |
| steps                   | 1514703  |
| td_erros                | -0.3119  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 239000   |
| lives                   | 239000   |
| mean 100 episode ei     | 2.98     |
| mean 100 episode length | 4.48     |
| mean 100 episode reward | 4.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.351    |
| steps                   | 1515051  |
| td_erros                | -0.3458  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 239100   |
| lives                   | 239100   |
| mean 100 episode ei     | 3.38     |
| mean 100 episode length | 4.79     |
| mean 100 episode reward | 3.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3266   |
| steps                   | 1515430  |
| td_erros                | -0.342   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 239200   |
| lives                   | 239200   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.11     |
| mean 100 episode reward | 4.74     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3394   |
| steps                   | 1515841  |
| td_erros                | -0.3403  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 239300   |
| lives                   | 239300   |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 5.47     |
| mean 100 episode reward | 4.87     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3539   |
| steps                   | 1516288  |
| td_erros                | -0.3892  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 239400   |
| lives                   | 239400   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.358    |
| steps                   | 1516751  |
| td_erros                | -0.4206  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 239500   |
| lives                   | 239500   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 5.72     |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3701   |
| steps                   | 1517223  |
| td_erros                | -0.4119  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 239600   |
| lives                   | 239600   |
| mean 100 episode ei     | 4.23     |
| mean 100 episode length | 6.18     |
| mean 100 episode reward | 5.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3802   |
| steps                   | 1517741  |
| td_erros                | -0.432   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 239700   |
| lives                   | 239700   |
| mean 100 episode ei     | 3.67     |
| mean 100 episode length | 5.62     |
| mean 100 episode reward | 4.84     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3873   |
| steps                   | 1518203  |
| td_erros                | -0.4446  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 239800   |
| lives                   | 239800   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 5.45     |
| mean 100 episode reward | 4.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4085   |
| steps                   | 1518648  |
| td_erros                | -0.3768  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 6        |
| episodes                | 239900   |
| lives                   | 239900   |
| mean 100 episode ei     | 3.79     |
| mean 100 episode length | 5.83     |
| mean 100 episode reward | 3.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4129   |
| steps                   | 1519131  |
| td_erros                | -0.3789  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 240000   |
| lives                   | 240000   |
| mean 100 episode ei     | 3.71     |
| mean 100 episode length | 5.77     |
| mean 100 episode reward | 3.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4408   |
| steps                   | 1519608  |
| td_erros                | -0.3885  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 240100   |
| lives                   | 240100   |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 5.97     |
| mean 100 episode reward | 3.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4329   |
| steps                   | 1520105  |
| td_erros                | -0.3753  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 240200   |
| lives                   | 240200   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 6.23     |
| mean 100 episode reward | 3.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4325   |
| steps                   | 1520628  |
| td_erros                | -0.3864  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 240300   |
| lives                   | 240300   |
| mean 100 episode ei     | 4.32     |
| mean 100 episode length | 6.32     |
| mean 100 episode reward | 4.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4335   |
| steps                   | 1521160  |
| td_erros                | -0.3881  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 240400   |
| lives                   | 240400   |
| mean 100 episode ei     | 4.4      |
| mean 100 episode length | 6.05     |
| mean 100 episode reward | 4.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.439    |
| steps                   | 1521665  |
| td_erros                | -0.3612  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 240500   |
| lives                   | 240500   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.84     |
| mean 100 episode reward | 4.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4493   |
| steps                   | 1522149  |
| td_erros                | -0.3455  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 240600   |
| lives                   | 240600   |
| mean 100 episode ei     | 3.75     |
| mean 100 episode length | 5.48     |
| mean 100 episode reward | 5.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4631   |
| steps                   | 1522597  |
| td_erros                | -0.337   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 240700   |
| lives                   | 240700   |
| mean 100 episode ei     | 3.65     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 4.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4862   |
| steps                   | 1523062  |
| td_erros                | -0.3101  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 240800   |
| lives                   | 240800   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 5.94     |
| mean 100 episode reward | 3.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4671   |
| steps                   | 1523556  |
| td_erros                | -0.3432  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 240900   |
| lives                   | 240900   |
| mean 100 episode ei     | 3.83     |
| mean 100 episode length | 6.11     |
| mean 100 episode reward | 3.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.51     |
| steps                   | 1524067  |
| td_erros                | -0.3179  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 241000   |
| lives                   | 241000   |
| mean 100 episode ei     | 3.75     |
| mean 100 episode length | 6.23     |
| mean 100 episode reward | 2.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5092   |
| steps                   | 1524590  |
| td_erros                | -0.3058  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 241100   |
| lives                   | 241100   |
| mean 100 episode ei     | 3.48     |
| mean 100 episode length | 6.09     |
| mean 100 episode reward | 2.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.503    |
| steps                   | 1525099  |
| td_erros                | -0.2948  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 241200   |
| lives                   | 241200   |
| mean 100 episode ei     | 3.52     |
| mean 100 episode length | 6.28     |
| mean 100 episode reward | 2.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5031   |
| steps                   | 1525627  |
| td_erros                | -0.2987  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 241300   |
| lives                   | 241300   |
| mean 100 episode ei     | 3.24     |
| mean 100 episode length | 6.04     |
| mean 100 episode reward | 2.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5181   |
| steps                   | 1526131  |
| td_erros                | -0.2747  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 241400   |
| lives                   | 241400   |
| mean 100 episode ei     | 3.22     |
| mean 100 episode length | 5.97     |
| mean 100 episode reward | 1.99     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.504    |
| steps                   | 1526628  |
| td_erros                | -0.2785  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 241500   |
| lives                   | 241500   |
| mean 100 episode ei     | 3.34     |
| mean 100 episode length | 6.04     |
| mean 100 episode reward | 2.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4728   |
| steps                   | 1527132  |
| td_erros                | -0.286   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 241600   |
| lives                   | 241600   |
| mean 100 episode ei     | 3.32     |
| mean 100 episode length | 5.76     |
| mean 100 episode reward | 2.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4323   |
| steps                   | 1527608  |
| td_erros                | -0.2972  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 241700   |
| lives                   | 241700   |
| mean 100 episode ei     | 3.23     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 2.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3876   |
| steps                   | 1528069  |
| td_erros                | -0.2884  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 241800   |
| lives                   | 241800   |
| mean 100 episode ei     | 3.4      |
| mean 100 episode length | 5.95     |
| mean 100 episode reward | 3.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3372   |
| steps                   | 1528564  |
| td_erros                | -0.2675  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 241900   |
| lives                   | 241900   |
| mean 100 episode ei     | 3.13     |
| mean 100 episode length | 5.72     |
| mean 100 episode reward | 3.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3125   |
| steps                   | 1529036  |
| td_erros                | -0.2466  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 242000   |
| lives                   | 242000   |
| mean 100 episode ei     | 3.25     |
| mean 100 episode length | 5.87     |
| mean 100 episode reward | 3.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3072   |
| steps                   | 1529523  |
| td_erros                | -0.2288  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 242100   |
| lives                   | 242100   |
| mean 100 episode ei     | 3.28     |
| mean 100 episode length | 5.67     |
| mean 100 episode reward | 3.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2577   |
| steps                   | 1529990  |
| td_erros                | -0.2084  |
--------------------------------------
Saving model due to running mean reward increase: 3.1735 -> 3.2208
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 242200   |
| lives                   | 242200   |
| mean 100 episode ei     | 3.29     |
| mean 100 episode length | 5.68     |
| mean 100 episode reward | 3.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2213   |
| steps                   | 1530458  |
| td_erros                | -0.2262  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 242300   |
| lives                   | 242300   |
| mean 100 episode ei     | 3.31     |
| mean 100 episode length | 5.78     |
| mean 100 episode reward | 3.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2211   |
| steps                   | 1530936  |
| td_erros                | -0.2254  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 242400   |
| lives                   | 242400   |
| mean 100 episode ei     | 3.43     |
| mean 100 episode length | 5.82     |
| mean 100 episode reward | 3.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1551   |
| steps                   | 1531418  |
| td_erros                | -0.2414  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 242500   |
| lives                   | 242500   |
| mean 100 episode ei     | 3.3      |
| mean 100 episode length | 5.47     |
| mean 100 episode reward | 3.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1457   |
| steps                   | 1531865  |
| td_erros                | -0.245   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 242600   |
| lives                   | 242600   |
| mean 100 episode ei     | 3.17     |
| mean 100 episode length | 5.45     |
| mean 100 episode reward | 3.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1559   |
| steps                   | 1532310  |
| td_erros                | -0.2447  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 242700   |
| lives                   | 242700   |
| mean 100 episode ei     | 3.26     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 3.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1711   |
| steps                   | 1532735  |
| td_erros                | -0.2594  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 242800   |
| lives                   | 242800   |
| mean 100 episode ei     | 3.3      |
| mean 100 episode length | 5.35     |
| mean 100 episode reward | 3.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1819   |
| steps                   | 1533170  |
| td_erros                | -0.2526  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 242900   |
| lives                   | 242900   |
| mean 100 episode ei     | 3.41     |
| mean 100 episode length | 5.15     |
| mean 100 episode reward | 4.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2003   |
| steps                   | 1533585  |
| td_erros                | -0.2557  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 243000   |
| lives                   | 243000   |
| mean 100 episode ei     | 3.31     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 4.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2138   |
| steps                   | 1534026  |
| td_erros                | -0.2495  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 243100   |
| lives                   | 243100   |
| mean 100 episode ei     | 3.43     |
| mean 100 episode length | 5.12     |
| mean 100 episode reward | 4.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2147   |
| steps                   | 1534438  |
| td_erros                | -0.2474  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 243200   |
| lives                   | 243200   |
| mean 100 episode ei     | 3.42     |
| mean 100 episode length | 5.09     |
| mean 100 episode reward | 4.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.227    |
| steps                   | 1534847  |
| td_erros                | -0.2569  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 5        |
| episodes                | 243300   |
| lives                   | 243300   |
| mean 100 episode ei     | 3.34     |
| mean 100 episode length | 5.1      |
| mean 100 episode reward | 4.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2417   |
| steps                   | 1535257  |
| td_erros                | -0.2619  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 243400   |
| lives                   | 243400   |
| mean 100 episode ei     | 3.34     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 4        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.252    |
| steps                   | 1535698  |
| td_erros                | -0.2579  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 243500   |
| lives                   | 243500   |
| mean 100 episode ei     | 3.27     |
| mean 100 episode length | 5.45     |
| mean 100 episode reward | 4.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2472   |
| steps                   | 1536143  |
| td_erros                | -0.2664  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 243600   |
| lives                   | 243600   |
| mean 100 episode ei     | 3.34     |
| mean 100 episode length | 5.29     |
| mean 100 episode reward | 4.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2497   |
| steps                   | 1536572  |
| td_erros                | -0.2429  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 243700   |
| lives                   | 243700   |
| mean 100 episode ei     | 3.08     |
| mean 100 episode length | 4.87     |
| mean 100 episode reward | 3.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2338   |
| steps                   | 1536959  |
| td_erros                | -0.2619  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 243800   |
| lives                   | 243800   |
| mean 100 episode ei     | 2.56     |
| mean 100 episode length | 4.24     |
| mean 100 episode reward | 3.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2107   |
| steps                   | 1537283  |
| td_erros                | -0.2348  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 243900   |
| lives                   | 243900   |
| mean 100 episode ei     | 3.34     |
| mean 100 episode length | 5.37     |
| mean 100 episode reward | 3.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1339   |
| steps                   | 1537720  |
| td_erros                | -0.2727  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 244000   |
| lives                   | 244000   |
| mean 100 episode ei     | 3.43     |
| mean 100 episode length | 5.38     |
| mean 100 episode reward | 3.91     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.104    |
| steps                   | 1538158  |
| td_erros                | -0.2992  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 244100   |
| lives                   | 244100   |
| mean 100 episode ei     | 3.32     |
| mean 100 episode length | 5.49     |
| mean 100 episode reward | 3.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1419   |
| steps                   | 1538607  |
| td_erros                | -0.3093  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 244200   |
| lives                   | 244200   |
| mean 100 episode ei     | 3.42     |
| mean 100 episode length | 5.47     |
| mean 100 episode reward | 4.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1647   |
| steps                   | 1539054  |
| td_erros                | -0.3283  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 244300   |
| lives                   | 244300   |
| mean 100 episode ei     | 3.45     |
| mean 100 episode length | 5.51     |
| mean 100 episode reward | 4.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1526   |
| steps                   | 1539505  |
| td_erros                | -0.3177  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 244400   |
| lives                   | 244400   |
| mean 100 episode ei     | 3.56     |
| mean 100 episode length | 5.46     |
| mean 100 episode reward | 5.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1298   |
| steps                   | 1539951  |
| td_erros                | -0.3253  |
--------------------------------------
Saving model due to running mean reward increase: 4.7497 -> 5.0221
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 244500   |
| lives                   | 244500   |
| mean 100 episode ei     | 3.59     |
| mean 100 episode length | 5.53     |
| mean 100 episode reward | 5.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1586   |
| steps                   | 1540404  |
| td_erros                | -0.3054  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 244600   |
| lives                   | 244600   |
| mean 100 episode ei     | 3.04     |
| mean 100 episode length | 4.77     |
| mean 100 episode reward | 4.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1682   |
| steps                   | 1540781  |
| td_erros                | -0.3004  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 244700   |
| lives                   | 244700   |
| mean 100 episode ei     | 3.44     |
| mean 100 episode length | 4.98     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1573   |
| steps                   | 1541179  |
| td_erros                | -0.3087  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 244800   |
| lives                   | 244800   |
| mean 100 episode ei     | 2.96     |
| mean 100 episode length | 4.65     |
| mean 100 episode reward | 4.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1357   |
| steps                   | 1541544  |
| td_erros                | -0.3083  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 244900   |
| lives                   | 244900   |
| mean 100 episode ei     | 3.65     |
| mean 100 episode length | 5.17     |
| mean 100 episode reward | 5.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1347   |
| steps                   | 1541961  |
| td_erros                | -0.3322  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 245000   |
| lives                   | 245000   |
| mean 100 episode ei     | 3.63     |
| mean 100 episode length | 5.15     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1326   |
| steps                   | 1542376  |
| td_erros                | -0.358   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 245100   |
| lives                   | 245100   |
| mean 100 episode ei     | 3.55     |
| mean 100 episode length | 5.02     |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.176    |
| steps                   | 1542778  |
| td_erros                | -0.3605  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 245200   |
| lives                   | 245200   |
| mean 100 episode ei     | 3.14     |
| mean 100 episode length | 4.63     |
| mean 100 episode reward | 4.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.1941   |
| steps                   | 1543141  |
| td_erros                | -0.3418  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 245300   |
| lives                   | 245300   |
| mean 100 episode ei     | 3.52     |
| mean 100 episode length | 5        |
| mean 100 episode reward | 5.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.212    |
| steps                   | 1543541  |
| td_erros                | -0.3537  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 245400   |
| lives                   | 245400   |
| mean 100 episode ei     | 3.46     |
| mean 100 episode length | 4.96     |
| mean 100 episode reward | 4.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2109   |
| steps                   | 1543937  |
| td_erros                | -0.3576  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 245500   |
| lives                   | 245500   |
| mean 100 episode ei     | 3.56     |
| mean 100 episode length | 5.03     |
| mean 100 episode reward | 5.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2151   |
| steps                   | 1544340  |
| td_erros                | -0.3418  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 245600   |
| lives                   | 245600   |
| mean 100 episode ei     | 3.37     |
| mean 100 episode length | 5.07     |
| mean 100 episode reward | 4.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2285   |
| steps                   | 1544747  |
| td_erros                | -0.3622  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 245700   |
| lives                   | 245700   |
| mean 100 episode ei     | 3.47     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 4.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2343   |
| steps                   | 1545191  |
| td_erros                | -0.3396  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 245800   |
| lives                   | 245800   |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 4.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2025   |
| steps                   | 1545634  |
| td_erros                | -0.3743  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 245900   |
| lives                   | 245900   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 5.45     |
| mean 100 episode reward | 4.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2105   |
| steps                   | 1546079  |
| td_erros                | -0.4085  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 246000   |
| lives                   | 246000   |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 4.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2317   |
| steps                   | 1546518  |
| td_erros                | -0.4035  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 246100   |
| lives                   | 246100   |
| mean 100 episode ei     | 3.45     |
| mean 100 episode length | 5.3      |
| mean 100 episode reward | 4.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2285   |
| steps                   | 1546948  |
| td_erros                | -0.4085  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 246200   |
| lives                   | 246200   |
| mean 100 episode ei     | 3.82     |
| mean 100 episode length | 5.34     |
| mean 100 episode reward | 4.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.229    |
| steps                   | 1547382  |
| td_erros                | -0.393   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 246300   |
| lives                   | 246300   |
| mean 100 episode ei     | 3.85     |
| mean 100 episode length | 5.35     |
| mean 100 episode reward | 4.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2329   |
| steps                   | 1547817  |
| td_erros                | -0.4224  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 246400   |
| lives                   | 246400   |
| mean 100 episode ei     | 3.56     |
| mean 100 episode length | 5.32     |
| mean 100 episode reward | 4.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2513   |
| steps                   | 1548249  |
| td_erros                | -0.4444  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 246500   |
| lives                   | 246500   |
| mean 100 episode ei     | 3.42     |
| mean 100 episode length | 5.3      |
| mean 100 episode reward | 4.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2787   |
| steps                   | 1548679  |
| td_erros                | -0.4399  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 246600   |
| lives                   | 246600   |
| mean 100 episode ei     | 3.38     |
| mean 100 episode length | 5.3      |
| mean 100 episode reward | 5.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2705   |
| steps                   | 1549109  |
| td_erros                | -0.4145  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 246700   |
| lives                   | 246700   |
| mean 100 episode ei     | 3.51     |
| mean 100 episode length | 5.26     |
| mean 100 episode reward | 5.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2854   |
| steps                   | 1549535  |
| td_erros                | -0.3941  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 246800   |
| lives                   | 246800   |
| mean 100 episode ei     | 3.46     |
| mean 100 episode length | 5.05     |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2905   |
| steps                   | 1549940  |
| td_erros                | -0.3912  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 246900   |
| lives                   | 246900   |
| mean 100 episode ei     | 3.59     |
| mean 100 episode length | 4.77     |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3149   |
| steps                   | 1550317  |
| td_erros                | -0.3694  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 247000   |
| lives                   | 247000   |
| mean 100 episode ei     | 3.54     |
| mean 100 episode length | 4.69     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.35     |
| steps                   | 1550686  |
| td_erros                | -0.3525  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 247100   |
| lives                   | 247100   |
| mean 100 episode ei     | 3.5      |
| mean 100 episode length | 4.76     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3687   |
| steps                   | 1551062  |
| td_erros                | -0.3231  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 4        |
| episodes                | 247200   |
| lives                   | 247200   |
| mean 100 episode ei     | 3.51     |
| mean 100 episode length | 4.82     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3612   |
| steps                   | 1551444  |
| td_erros                | -0.3071  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 247300   |
| lives                   | 247300   |
| mean 100 episode ei     | 3.65     |
| mean 100 episode length | 4.86     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3715   |
| steps                   | 1551830  |
| td_erros                | -0.2897  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 247400   |
| lives                   | 247400   |
| mean 100 episode ei     | 3.72     |
| mean 100 episode length | 4.79     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4      |
| steps                   | 1552209  |
| td_erros                | -0.3047  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 247500   |
| lives                   | 247500   |
| mean 100 episode ei     | 3.55     |
| mean 100 episode length | 4.81     |
| mean 100 episode reward | 5.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4065   |
| steps                   | 1552590  |
| td_erros                | -0.2594  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 247600   |
| lives                   | 247600   |
| mean 100 episode ei     | 3.54     |
| mean 100 episode length | 4.82     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4165   |
| steps                   | 1552972  |
| td_erros                | -0.2594  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 247700   |
| lives                   | 247700   |
| mean 100 episode ei     | 3.56     |
| mean 100 episode length | 4.97     |
| mean 100 episode reward | 5.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4246   |
| steps                   | 1553369  |
| td_erros                | -0.2766  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 247800   |
| lives                   | 247800   |
| mean 100 episode ei     | 3.59     |
| mean 100 episode length | 4.94     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4341   |
| steps                   | 1553763  |
| td_erros                | -0.2852  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 247900   |
| lives                   | 247900   |
| mean 100 episode ei     | 3.58     |
| mean 100 episode length | 5.14     |
| mean 100 episode reward | 5.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4486   |
| steps                   | 1554177  |
| td_erros                | -0.2952  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 248000   |
| lives                   | 248000   |
| mean 100 episode ei     | 3.49     |
| mean 100 episode length | 5.04     |
| mean 100 episode reward | 5.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4398   |
| steps                   | 1554581  |
| td_erros                | -0.2742  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 248100   |
| lives                   | 248100   |
| mean 100 episode ei     | 3.54     |
| mean 100 episode length | 5.11     |
| mean 100 episode reward | 5.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.433    |
| steps                   | 1554992  |
| td_erros                | -0.2829  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 248200   |
| lives                   | 248200   |
| mean 100 episode ei     | 3.46     |
| mean 100 episode length | 5.14     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4378   |
| steps                   | 1555406  |
| td_erros                | -0.26    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 248300   |
| lives                   | 248300   |
| mean 100 episode ei     | 3.58     |
| mean 100 episode length | 5.1      |
| mean 100 episode reward | 5.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4166   |
| steps                   | 1555816  |
| td_erros                | -0.2874  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 248400   |
| lives                   | 248400   |
| mean 100 episode ei     | 3.54     |
| mean 100 episode length | 4.98     |
| mean 100 episode reward | 5.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4213   |
| steps                   | 1556214  |
| td_erros                | -0.2969  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 248500   |
| lives                   | 248500   |
| mean 100 episode ei     | 3.61     |
| mean 100 episode length | 4.83     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4386   |
| steps                   | 1556597  |
| td_erros                | -0.3062  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 248600   |
| lives                   | 248600   |
| mean 100 episode ei     | 3.62     |
| mean 100 episode length | 4.86     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4487   |
| steps                   | 1556983  |
| td_erros                | -0.2985  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 248700   |
| lives                   | 248700   |
| mean 100 episode ei     | 3.53     |
| mean 100 episode length | 4.87     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4492   |
| steps                   | 1557370  |
| td_erros                | -0.2893  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 248800   |
| lives                   | 248800   |
| mean 100 episode ei     | 3.51     |
| mean 100 episode length | 4.62     |
| mean 100 episode reward | 5.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4484   |
| steps                   | 1557732  |
| td_erros                | -0.2922  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 248900   |
| lives                   | 248900   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 4.66     |
| mean 100 episode reward | 4.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.441    |
| steps                   | 1558098  |
| td_erros                | -0.3089  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 249000   |
| lives                   | 249000   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 4.66     |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4267   |
| steps                   | 1558464  |
| td_erros                | -0.3226  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 249100   |
| lives                   | 249100   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.03     |
| mean 100 episode reward | 4.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4265   |
| steps                   | 1558867  |
| td_erros                | -0.3485  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 249200   |
| lives                   | 249200   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.04     |
| mean 100 episode reward | 4.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4179   |
| steps                   | 1559271  |
| td_erros                | -0.3758  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 249300   |
| lives                   | 249300   |
| mean 100 episode ei     | 3.7      |
| mean 100 episode length | 5.15     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.433    |
| steps                   | 1559686  |
| td_erros                | -0.3837  |
--------------------------------------
Saving model due to running mean reward increase: 5.0649 -> 5.2916
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 249400   |
| lives                   | 249400   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4381   |
| steps                   | 1560109  |
| td_erros                | -0.3956  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 249500   |
| lives                   | 249500   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4409   |
| steps                   | 1560532  |
| td_erros                | -0.3785  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 249600   |
| lives                   | 249600   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 5.26     |
| mean 100 episode reward | 5.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.446    |
| steps                   | 1560958  |
| td_erros                | -0.3644  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 249700   |
| lives                   | 249700   |
| mean 100 episode ei     | 3.68     |
| mean 100 episode length | 4.97     |
| mean 100 episode reward | 5.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4244   |
| steps                   | 1561355  |
| td_erros                | -0.359   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 249800   |
| lives                   | 249800   |
| mean 100 episode ei     | 3.45     |
| mean 100 episode length | 4.78     |
| mean 100 episode reward | 4.81     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4289   |
| steps                   | 1561733  |
| td_erros                | -0.3544  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 249900   |
| lives                   | 249900   |
| mean 100 episode ei     | 3.35     |
| mean 100 episode length | 4.77     |
| mean 100 episode reward | 4.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4082   |
| steps                   | 1562110  |
| td_erros                | -0.3598  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 250000   |
| lives                   | 250000   |
| mean 100 episode ei     | 3.45     |
| mean 100 episode length | 5.08     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4229   |
| steps                   | 1562518  |
| td_erros                | -0.3348  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 250100   |
| lives                   | 250100   |
| mean 100 episode ei     | 3.49     |
| mean 100 episode length | 5.28     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4216   |
| steps                   | 1562946  |
| td_erros                | -0.3307  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 250200   |
| lives                   | 250200   |
| mean 100 episode ei     | 3.44     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 5.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4146   |
| steps                   | 1563390  |
| td_erros                | -0.3124  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 250300   |
| lives                   | 250300   |
| mean 100 episode ei     | 3.58     |
| mean 100 episode length | 5.32     |
| mean 100 episode reward | 4.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4222   |
| steps                   | 1563822  |
| td_erros                | -0.2926  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 250400   |
| lives                   | 250400   |
| mean 100 episode ei     | 3.72     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4198   |
| steps                   | 1564245  |
| td_erros                | -0.3007  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 250500   |
| lives                   | 250500   |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 5.31     |
| mean 100 episode reward | 4.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4332   |
| steps                   | 1564676  |
| td_erros                | -0.2888  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 250600   |
| lives                   | 250600   |
| mean 100 episode ei     | 3.41     |
| mean 100 episode length | 5.49     |
| mean 100 episode reward | 3.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4371   |
| steps                   | 1565125  |
| td_erros                | -0.2773  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 250700   |
| lives                   | 250700   |
| mean 100 episode ei     | 3.28     |
| mean 100 episode length | 5.37     |
| mean 100 episode reward | 3.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4503   |
| steps                   | 1565562  |
| td_erros                | -0.2643  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 250800   |
| lives                   | 250800   |
| mean 100 episode ei     | 3.46     |
| mean 100 episode length | 5.37     |
| mean 100 episode reward | 3.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4512   |
| steps                   | 1565999  |
| td_erros                | -0.2668  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 250900   |
| lives                   | 250900   |
| mean 100 episode ei     | 3.39     |
| mean 100 episode length | 5.29     |
| mean 100 episode reward | 3.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.451    |
| steps                   | 1566428  |
| td_erros                | -0.2515  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 251000   |
| lives                   | 251000   |
| mean 100 episode ei     | 3.47     |
| mean 100 episode length | 5.31     |
| mean 100 episode reward | 3.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4527   |
| steps                   | 1566859  |
| td_erros                | -0.2533  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 3        |
| episodes                | 251100   |
| lives                   | 251100   |
| mean 100 episode ei     | 3.4      |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 4.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4221   |
| steps                   | 1567300  |
| td_erros                | -0.2438  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 251200   |
| lives                   | 251200   |
| mean 100 episode ei     | 3.37     |
| mean 100 episode length | 5.35     |
| mean 100 episode reward | 4.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3902   |
| steps                   | 1567735  |
| td_erros                | -0.233   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 251300   |
| lives                   | 251300   |
| mean 100 episode ei     | 3.44     |
| mean 100 episode length | 5.28     |
| mean 100 episode reward | 4.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3808   |
| steps                   | 1568163  |
| td_erros                | -0.2463  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 251400   |
| lives                   | 251400   |
| mean 100 episode ei     | 3.58     |
| mean 100 episode length | 5.18     |
| mean 100 episode reward | 5.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3561   |
| steps                   | 1568581  |
| td_erros                | -0.2549  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 251500   |
| lives                   | 251500   |
| mean 100 episode ei     | 3.47     |
| mean 100 episode length | 4.89     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3558   |
| steps                   | 1568970  |
| td_erros                | -0.253   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 251600   |
| lives                   | 251600   |
| mean 100 episode ei     | 3.35     |
| mean 100 episode length | 4.89     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.353    |
| steps                   | 1569359  |
| td_erros                | -0.256   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 251700   |
| lives                   | 251700   |
| mean 100 episode ei     | 3.47     |
| mean 100 episode length | 4.86     |
| mean 100 episode reward | 5.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3373   |
| steps                   | 1569745  |
| td_erros                | -0.2281  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 251800   |
| lives                   | 251800   |
| mean 100 episode ei     | 2.72     |
| mean 100 episode length | 4.21     |
| mean 100 episode reward | 4.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.356    |
| steps                   | 1570066  |
| td_erros                | -0.195   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 251900   |
| lives                   | 251900   |
| mean 100 episode ei     | 3.13     |
| mean 100 episode length | 4.58     |
| mean 100 episode reward | 4.79     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3354   |
| steps                   | 1570424  |
| td_erros                | -0.1817  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 252000   |
| lives                   | 252000   |
| mean 100 episode ei     | 3.41     |
| mean 100 episode length | 4.88     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3346   |
| steps                   | 1570812  |
| td_erros                | -0.1954  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 252100   |
| lives                   | 252100   |
| mean 100 episode ei     | 3.58     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2728   |
| steps                   | 1571253  |
| td_erros                | -0.2278  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 252200   |
| lives                   | 252200   |
| mean 100 episode ei     | 3.53     |
| mean 100 episode length | 5.32     |
| mean 100 episode reward | 5.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.245    |
| steps                   | 1571685  |
| td_erros                | -0.2638  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 252300   |
| lives                   | 252300   |
| mean 100 episode ei     | 3.57     |
| mean 100 episode length | 5.45     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2573   |
| steps                   | 1572130  |
| td_erros                | -0.2765  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 252400   |
| lives                   | 252400   |
| mean 100 episode ei     | 3.54     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 5.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.262    |
| steps                   | 1572574  |
| td_erros                | -0.2839  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 252500   |
| lives                   | 252500   |
| mean 100 episode ei     | 3.55     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2713   |
| steps                   | 1573018  |
| td_erros                | -0.2987  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 252600   |
| lives                   | 252600   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 5.49     |
| mean 100 episode reward | 4.61     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2759   |
| steps                   | 1573467  |
| td_erros                | -0.303   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 252700   |
| lives                   | 252700   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.48     |
| mean 100 episode reward | 4.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2922   |
| steps                   | 1573915  |
| td_erros                | -0.3431  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 252800   |
| lives                   | 252800   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 4.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2834   |
| steps                   | 1574357  |
| td_erros                | -0.3615  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 252900   |
| lives                   | 252900   |
| mean 100 episode ei     | 4.31     |
| mean 100 episode length | 5.57     |
| mean 100 episode reward | 4.69     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.304    |
| steps                   | 1574814  |
| td_erros                | -0.3897  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 253000   |
| lives                   | 253000   |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 5.68     |
| mean 100 episode reward | 4.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2909   |
| steps                   | 1575282  |
| td_erros                | -0.4335  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 253100   |
| lives                   | 253100   |
| mean 100 episode ei     | 4.33     |
| mean 100 episode length | 5.49     |
| mean 100 episode reward | 4.72     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3101   |
| steps                   | 1575731  |
| td_erros                | -0.4722  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 253200   |
| lives                   | 253200   |
| mean 100 episode ei     | 3.61     |
| mean 100 episode length | 4.93     |
| mean 100 episode reward | 4.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.343    |
| steps                   | 1576124  |
| td_erros                | -0.4473  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 253300   |
| lives                   | 253300   |
| mean 100 episode ei     | 3.46     |
| mean 100 episode length | 4.83     |
| mean 100 episode reward | 5.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.367    |
| steps                   | 1576507  |
| td_erros                | -0.4133  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 253400   |
| lives                   | 253400   |
| mean 100 episode ei     | 3.4      |
| mean 100 episode length | 4.74     |
| mean 100 episode reward | 4.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.38     |
| steps                   | 1576881  |
| td_erros                | -0.4115  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 253500   |
| lives                   | 253500   |
| mean 100 episode ei     | 3.6      |
| mean 100 episode length | 4.81     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3912   |
| steps                   | 1577262  |
| td_erros                | -0.3742  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 253600   |
| lives                   | 253600   |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 4.74     |
| mean 100 episode reward | 4.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.404    |
| steps                   | 1577636  |
| td_erros                | -0.3943  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 253700   |
| lives                   | 253700   |
| mean 100 episode ei     | 3.51     |
| mean 100 episode length | 4.56     |
| mean 100 episode reward | 4.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4177   |
| steps                   | 1577992  |
| td_erros                | -0.368   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 253800   |
| lives                   | 253800   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 4.68     |
| mean 100 episode reward | 4.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4248   |
| steps                   | 1578360  |
| td_erros                | -0.3753  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 253900   |
| lives                   | 253900   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 4.72     |
| mean 100 episode reward | 4.7      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4212   |
| steps                   | 1578732  |
| td_erros                | -0.3647  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 254000   |
| lives                   | 254000   |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 4.74     |
| mean 100 episode reward | 4.99     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4178   |
| steps                   | 1579106  |
| td_erros                | -0.3733  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 254100   |
| lives                   | 254100   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 4.66     |
| mean 100 episode reward | 4.77     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.423    |
| steps                   | 1579472  |
| td_erros                | -0.3342  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 254200   |
| lives                   | 254200   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 4.66     |
| mean 100 episode reward | 4.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4322   |
| steps                   | 1579838  |
| td_erros                | -0.3504  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 254300   |
| lives                   | 254300   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 4.9      |
| mean 100 episode reward | 4.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4321   |
| steps                   | 1580228  |
| td_erros                | -0.3362  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 254400   |
| lives                   | 254400   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.26     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4424   |
| steps                   | 1580654  |
| td_erros                | -0.3402  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 254500   |
| lives                   | 254500   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4433   |
| steps                   | 1581094  |
| td_erros                | -0.3193  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 254600   |
| lives                   | 254600   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.45     |
| mean 100 episode reward | 5        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4371   |
| steps                   | 1581539  |
| td_erros                | -0.3036  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 254700   |
| lives                   | 254700   |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 5.33     |
| mean 100 episode reward | 4.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4515   |
| steps                   | 1581972  |
| td_erros                | -0.3179  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 254800   |
| lives                   | 254800   |
| mean 100 episode ei     | 3.55     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 3.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.485    |
| steps                   | 1582411  |
| td_erros                | -0.308   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 254900   |
| lives                   | 254900   |
| mean 100 episode ei     | 3.39     |
| mean 100 episode length | 5.46     |
| mean 100 episode reward | 3.76     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.461    |
| steps                   | 1582857  |
| td_erros                | -0.2941  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 255000   |
| lives                   | 255000   |
| mean 100 episode ei     | 3.47     |
| mean 100 episode length | 5.53     |
| mean 100 episode reward | 3.57     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4793   |
| steps                   | 1583310  |
| td_erros                | -0.2858  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 2        |
| episodes                | 255100   |
| lives                   | 255100   |
| mean 100 episode ei     | 3.78     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 4.8      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4695   |
| steps                   | 1583770  |
| td_erros                | -0.2873  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 255200   |
| lives                   | 255200   |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 5.56     |
| mean 100 episode reward | 5.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4822   |
| steps                   | 1584226  |
| td_erros                | -0.3037  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 255300   |
| lives                   | 255300   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4892   |
| steps                   | 1584667  |
| td_erros                | -0.28    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 255400   |
| lives                   | 255400   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 4.94     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4864   |
| steps                   | 1585111  |
| td_erros                | -0.2536  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 255500   |
| lives                   | 255500   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4785   |
| steps                   | 1585552  |
| td_erros                | -0.265   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 255600   |
| lives                   | 255600   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4824   |
| steps                   | 1585995  |
| td_erros                | -0.2801  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 255700   |
| lives                   | 255700   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 4.97     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5073   |
| steps                   | 1586436  |
| td_erros                | -0.2532  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 255800   |
| lives                   | 255800   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5018   |
| steps                   | 1586879  |
| td_erros                | -0.2482  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 255900   |
| lives                   | 255900   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.57     |
| mean 100 episode reward | 5.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5333   |
| steps                   | 1587336  |
| td_erros                | -0.244   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 256000   |
| lives                   | 256000   |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5665   |
| steps                   | 1587799  |
| td_erros                | -0.2288  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 256100   |
| lives                   | 256100   |
| mean 100 episode ei     | 3.76     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 4.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6006   |
| steps                   | 1588238  |
| td_erros                | -0.2268  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 256200   |
| lives                   | 256200   |
| mean 100 episode ei     | 3.59     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6063   |
| steps                   | 1588660  |
| td_erros                | -0.2049  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 256300   |
| lives                   | 256300   |
| mean 100 episode ei     | 3.65     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6288   |
| steps                   | 1589082  |
| td_erros                | -0.2132  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 256400   |
| lives                   | 256400   |
| mean 100 episode ei     | 3.57     |
| mean 100 episode length | 5.3      |
| mean 100 episode reward | 4.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5878   |
| steps                   | 1589512  |
| td_erros                | -0.2468  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 256500   |
| lives                   | 256500   |
| mean 100 episode ei     | 3.79     |
| mean 100 episode length | 5.31     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5254   |
| steps                   | 1589943  |
| td_erros                | -0.2544  |
--------------------------------------
Saving model due to running mean reward increase: 4.6566 -> 5.2681
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 256600   |
| lives                   | 256600   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.28     |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.529    |
| steps                   | 1590371  |
| td_erros                | -0.2693  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 256700   |
| lives                   | 256700   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5246   |
| steps                   | 1590791  |
| td_erros                | -0.2462  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 256800   |
| lives                   | 256800   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5141   |
| steps                   | 1591214  |
| td_erros                | -0.2647  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 256900   |
| lives                   | 256900   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5049   |
| steps                   | 1591657  |
| td_erros                | -0.2567  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 257000   |
| lives                   | 257000   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.49     |
| mean 100 episode reward | 5.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5105   |
| steps                   | 1592106  |
| td_erros                | -0.2575  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 257100   |
| lives                   | 257100   |
| mean 100 episode ei     | 3.69     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 4.93     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4866   |
| steps                   | 1592547  |
| td_erros                | -0.2616  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 257200   |
| lives                   | 257200   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.46     |
| mean 100 episode reward | 5.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4794   |
| steps                   | 1592993  |
| td_erros                | -0.2619  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 257300   |
| lives                   | 257300   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4523   |
| steps                   | 1593435  |
| td_erros                | -0.2802  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 257400   |
| lives                   | 257400   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4772   |
| steps                   | 1593878  |
| td_erros                | -0.2682  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 257500   |
| lives                   | 257500   |
| mean 100 episode ei     | 3.84     |
| mean 100 episode length | 5.38     |
| mean 100 episode reward | 5.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4935   |
| steps                   | 1594316  |
| td_erros                | -0.2704  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 257600   |
| lives                   | 257600   |
| mean 100 episode ei     | 3.29     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5145   |
| steps                   | 1594740  |
| td_erros                | -0.2553  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 257700   |
| lives                   | 257700   |
| mean 100 episode ei     | 3.42     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5185   |
| steps                   | 1595179  |
| td_erros                | -0.2864  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 257800   |
| lives                   | 257800   |
| mean 100 episode ei     | 3.47     |
| mean 100 episode length | 5.65     |
| mean 100 episode reward | 5.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5176   |
| steps                   | 1595644  |
| td_erros                | -0.2796  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 257900   |
| lives                   | 257900   |
| mean 100 episode ei     | 3.8      |
| mean 100 episode length | 5.49     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4956   |
| steps                   | 1596093  |
| td_erros                | -0.2592  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 258000   |
| lives                   | 258000   |
| mean 100 episode ei     | 3.5      |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 5.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4628   |
| steps                   | 1596518  |
| td_erros                | -0.2666  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 258100   |
| lives                   | 258100   |
| mean 100 episode ei     | 3.25     |
| mean 100 episode length | 5.02     |
| mean 100 episode reward | 4.64     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4461   |
| steps                   | 1596920  |
| td_erros                | -0.2871  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 258200   |
| lives                   | 258200   |
| mean 100 episode ei     | 2.53     |
| mean 100 episode length | 4.34     |
| mean 100 episode reward | 3.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4273   |
| steps                   | 1597254  |
| td_erros                | -0.2414  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 258300   |
| lives                   | 258300   |
| mean 100 episode ei     | 4.19     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3659   |
| steps                   | 1597694  |
| td_erros                | -0.2693  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 258400   |
| lives                   | 258400   |
| mean 100 episode ei     | 3.45     |
| mean 100 episode length | 4.73     |
| mean 100 episode reward | 4.73     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2988   |
| steps                   | 1598067  |
| td_erros                | -0.2801  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 258500   |
| lives                   | 258500   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.04     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2822   |
| steps                   | 1598471  |
| td_erros                | -0.3093  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 258600   |
| lives                   | 258600   |
| mean 100 episode ei     | 3.5      |
| mean 100 episode length | 4.56     |
| mean 100 episode reward | 4.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2634   |
| steps                   | 1598827  |
| td_erros                | -0.3117  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 258700   |
| lives                   | 258700   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.02     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2716   |
| steps                   | 1599229  |
| td_erros                | -0.3185  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 258800   |
| lives                   | 258800   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.05     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.234    |
| steps                   | 1599634  |
| td_erros                | -0.3393  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 258900   |
| lives                   | 258900   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.01     |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2224   |
| steps                   | 1600035  |
| td_erros                | -0.349   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 259000   |
| lives                   | 259000   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.2543   |
| steps                   | 1600459  |
| td_erros                | -0.3566  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 259100   |
| lives                   | 259100   |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3165   |
| steps                   | 1600882  |
| td_erros                | -0.3747  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 259200   |
| lives                   | 259200   |
| mean 100 episode ei     | 4.42     |
| mean 100 episode length | 5.5      |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3598   |
| steps                   | 1601332  |
| td_erros                | -0.3532  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 259300   |
| lives                   | 259300   |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 5.34     |
| mean 100 episode reward | 5.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3645   |
| steps                   | 1601766  |
| td_erros                | -0.3262  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 259400   |
| lives                   | 259400   |
| mean 100 episode ei     | 3.54     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3883   |
| steps                   | 1602189  |
| td_erros                | -0.3636  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 259500   |
| lives                   | 259500   |
| mean 100 episode ei     | 3.64     |
| mean 100 episode length | 5.33     |
| mean 100 episode reward | 6.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4212   |
| steps                   | 1602622  |
| td_erros                | -0.3463  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 259600   |
| lives                   | 259600   |
| mean 100 episode ei     | 3.56     |
| mean 100 episode length | 5.58     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4646   |
| steps                   | 1603080  |
| td_erros                | -0.324   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 259700   |
| lives                   | 259700   |
| mean 100 episode ei     | 2.81     |
| mean 100 episode length | 5.11     |
| mean 100 episode reward | 4.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4753   |
| steps                   | 1603491  |
| td_erros                | -0.307   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 259800   |
| lives                   | 259800   |
| mean 100 episode ei     | 3.31     |
| mean 100 episode length | 5        |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4829   |
| steps                   | 1603891  |
| td_erros                | -0.2911  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 259900   |
| lives                   | 259900   |
| mean 100 episode ei     | 3.51     |
| mean 100 episode length | 4.79     |
| mean 100 episode reward | 5.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4484   |
| steps                   | 1604270  |
| td_erros                | -0.2358  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 260000   |
| lives                   | 260000   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 4.8      |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4223   |
| steps                   | 1604650  |
| td_erros                | -0.2722  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 260100   |
| lives                   | 260100   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 4.87     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4194   |
| steps                   | 1605037  |
| td_erros                | -0.2536  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 260200   |
| lives                   | 260200   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 4.85     |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4008   |
| steps                   | 1605422  |
| td_erros                | -0.2553  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 260300   |
| lives                   | 260300   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 4.83     |
| mean 100 episode reward | 5.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3989   |
| steps                   | 1605805  |
| td_erros                | -0.2413  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 260400   |
| lives                   | 260400   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 4.87     |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3826   |
| steps                   | 1606192  |
| td_erros                | -0.2473  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 260500   |
| lives                   | 260500   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 4.83     |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4175   |
| steps                   | 1606575  |
| td_erros                | -0.2258  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 260600   |
| lives                   | 260600   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 4.74     |
| mean 100 episode reward | 4.92     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4213   |
| steps                   | 1606949  |
| td_erros                | -0.2385  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 260700   |
| lives                   | 260700   |
| mean 100 episode ei     | 3.19     |
| mean 100 episode length | 4.01     |
| mean 100 episode reward | 4.07     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4535   |
| steps                   | 1607250  |
| td_erros                | -0.2281  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 260800   |
| lives                   | 260800   |
| mean 100 episode ei     | 3.24     |
| mean 100 episode length | 4.02     |
| mean 100 episode reward | 4.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4626   |
| steps                   | 1607552  |
| td_erros                | -0.216   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 260900   |
| lives                   | 260900   |
| mean 100 episode ei     | 3.27     |
| mean 100 episode length | 4.07     |
| mean 100 episode reward | 4.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4746   |
| steps                   | 1607859  |
| td_erros                | -0.2048  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 261000   |
| lives                   | 261000   |
| mean 100 episode ei     | 3.87     |
| mean 100 episode length | 4.84     |
| mean 100 episode reward | 4.86     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4867   |
| steps                   | 1608243  |
| td_erros                | -0.2241  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 261100   |
| lives                   | 261100   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4789   |
| steps                   | 1608663  |
| td_erros                | -0.2819  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 261200   |
| lives                   | 261200   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4903   |
| steps                   | 1609083  |
| td_erros                | -0.2978  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 261300   |
| lives                   | 261300   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.26     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.536    |
| steps                   | 1609509  |
| td_erros                | -0.3141  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 261400   |
| lives                   | 261400   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.575    |
| steps                   | 1609949  |
| td_erros                | -0.312   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 261500   |
| lives                   | 261500   |
| mean 100 episode ei     | 3.77     |
| mean 100 episode length | 5.35     |
| mean 100 episode reward | 4.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6302   |
| steps                   | 1610384  |
| td_erros                | -0.2945  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 261600   |
| lives                   | 261600   |
| mean 100 episode ei     | 3.27     |
| mean 100 episode length | 4.83     |
| mean 100 episode reward | 4.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6668   |
| steps                   | 1610767  |
| td_erros                | -0.3138  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 261700   |
| lives                   | 261700   |
| mean 100 episode ei     | 3.37     |
| mean 100 episode length | 5.38     |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6609   |
| steps                   | 1611205  |
| td_erros                | -0.3407  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 261800   |
| lives                   | 261800   |
| mean 100 episode ei     | 3.6      |
| mean 100 episode length | 5.89     |
| mean 100 episode reward | 4.75     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6475   |
| steps                   | 1611694  |
| td_erros                | -0.3649  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 261900   |
| lives                   | 261900   |
| mean 100 episode ei     | 3.31     |
| mean 100 episode length | 5.09     |
| mean 100 episode reward | 4.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6239   |
| steps                   | 1612103  |
| td_erros                | -0.3836  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 262000   |
| lives                   | 262000   |
| mean 100 episode ei     | 3.73     |
| mean 100 episode length | 5.33     |
| mean 100 episode reward | 4.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5829   |
| steps                   | 1612536  |
| td_erros                | -0.3666  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 262100   |
| lives                   | 262100   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 4.88     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5426   |
| steps                   | 1612977  |
| td_erros                | -0.3599  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 262200   |
| lives                   | 262200   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 4.95     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5232   |
| steps                   | 1613402  |
| td_erros                | -0.3399  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 262300   |
| lives                   | 262300   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4947   |
| steps                   | 1613825  |
| td_erros                | -0.3457  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 262400   |
| lives                   | 262400   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.28     |
| mean 100 episode reward | 5.57     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.477    |
| steps                   | 1614253  |
| td_erros                | -0.3397  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 262500   |
| lives                   | 262500   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.78     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4663   |
| steps                   | 1614694  |
| td_erros                | -0.3693  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 262600   |
| lives                   | 262600   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 5.71     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4919   |
| steps                   | 1615138  |
| td_erros                | -0.3678  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 262700   |
| lives                   | 262700   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4605   |
| steps                   | 1615563  |
| td_erros                | -0.3416  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 262800   |
| lives                   | 262800   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4623   |
| steps                   | 1616004  |
| td_erros                | -0.312   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 262900   |
| lives                   | 262900   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5      |
| steps                   | 1616446  |
| td_erros                | -0.3009  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 263000   |
| lives                   | 263000   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5526   |
| steps                   | 1616886  |
| td_erros                | -0.3165  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 263100   |
| lives                   | 263100   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.26     |
| mean 100 episode reward | 5.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5947   |
| steps                   | 1617312  |
| td_erros                | -0.3038  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 263200   |
| lives                   | 263200   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6511   |
| steps                   | 1617732  |
| td_erros                | -0.325   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 263300   |
| lives                   | 263300   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6545   |
| steps                   | 1618154  |
| td_erros                | -0.2903  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 263400   |
| lives                   | 263400   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.26     |
| mean 100 episode reward | 5.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6493   |
| steps                   | 1618580  |
| td_erros                | -0.3127  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 263500   |
| lives                   | 263500   |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6232   |
| steps                   | 1619021  |
| td_erros                | -0.3032  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 263600   |
| lives                   | 263600   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6006   |
| steps                   | 1619464  |
| td_erros                | -0.308   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 263700   |
| lives                   | 263700   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5883   |
| steps                   | 1619905  |
| td_erros                | -0.3449  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 263800   |
| lives                   | 263800   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.593    |
| steps                   | 1620347  |
| td_erros                | -0.3345  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 263900   |
| lives                   | 263900   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.13     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6003   |
| steps                   | 1620760  |
| td_erros                | -0.3339  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 264000   |
| lives                   | 264000   |
| mean 100 episode ei     | 3.15     |
| mean 100 episode length | 4.44     |
| mean 100 episode reward | 4.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6111   |
| steps                   | 1621104  |
| td_erros                | -0.3024  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 264100   |
| lives                   | 264100   |
| mean 100 episode ei     | 2.13     |
| mean 100 episode length | 3.82     |
| mean 100 episode reward | 3.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5799   |
| steps                   | 1621386  |
| td_erros                | -0.2621  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 264200   |
| lives                   | 264200   |
| mean 100 episode ei     | 3.71     |
| mean 100 episode length | 5.06     |
| mean 100 episode reward | 5.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.514    |
| steps                   | 1621792  |
| td_erros                | -0.2846  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 264300   |
| lives                   | 264300   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.36     |
| mean 100 episode reward | 5.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4703   |
| steps                   | 1622228  |
| td_erros                | -0.3025  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 264400   |
| lives                   | 264400   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4403   |
| steps                   | 1622670  |
| td_erros                | -0.3292  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 264500   |
| lives                   | 264500   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4262   |
| steps                   | 1623111  |
| td_erros                | -0.3143  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 264600   |
| lives                   | 264600   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.413    |
| steps                   | 1623552  |
| td_erros                | -0.3484  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 264700   |
| lives                   | 264700   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.37     |
| mean 100 episode reward | 5.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3904   |
| steps                   | 1623989  |
| td_erros                | -0.3697  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 264800   |
| lives                   | 264800   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.38     |
| mean 100 episode reward | 5.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3802   |
| steps                   | 1624427  |
| td_erros                | -0.4099  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 264900   |
| lives                   | 264900   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.373    |
| steps                   | 1624868  |
| td_erros                | -0.3889  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 265000   |
| lives                   | 265000   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 5.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3487   |
| steps                   | 1625312  |
| td_erros                | -0.4219  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 265100   |
| lives                   | 265100   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3432   |
| steps                   | 1625753  |
| td_erros                | -0.4172  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 265200   |
| lives                   | 265200   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.47     |
| mean 100 episode reward | 5.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3506   |
| steps                   | 1626200  |
| td_erros                | -0.4628  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 265300   |
| lives                   | 265300   |
| mean 100 episode ei     | 3.79     |
| mean 100 episode length | 5.45     |
| mean 100 episode reward | 5.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3877   |
| steps                   | 1626645  |
| td_erros                | -0.4973  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 265400   |
| lives                   | 265400   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4074   |
| steps                   | 1627105  |
| td_erros                | -0.4867  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 265500   |
| lives                   | 265500   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.57     |
| mean 100 episode reward | 4.9      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4392   |
| steps                   | 1627562  |
| td_erros                | -0.4615  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 265600   |
| lives                   | 265600   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.53     |
| mean 100 episode reward | 4.67     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.472    |
| steps                   | 1628015  |
| td_erros                | -0.4497  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 265700   |
| lives                   | 265700   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.56     |
| mean 100 episode reward | 4.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4493   |
| steps                   | 1628471  |
| td_erros                | -0.4373  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 265800   |
| lives                   | 265800   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.59     |
| mean 100 episode reward | 4.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4591   |
| steps                   | 1628930  |
| td_erros                | -0.4452  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 265900   |
| lives                   | 265900   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.55     |
| mean 100 episode reward | 4.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4441   |
| steps                   | 1629385  |
| td_erros                | -0.4446  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 266000   |
| lives                   | 266000   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.17     |
| mean 100 episode reward | 5.06     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4863   |
| steps                   | 1629802  |
| td_erros                | -0.4351  |
--------------------------------------
Saving model due to running mean reward increase: 4.9295 -> 5.1083
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 266100   |
| lives                   | 266100   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.06     |
| mean 100 episode reward | 5.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4897   |
| steps                   | 1630208  |
| td_erros                | -0.4333  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 266200   |
| lives                   | 266200   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.04     |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4967   |
| steps                   | 1630612  |
| td_erros                | -0.4131  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 266300   |
| lives                   | 266300   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4938   |
| steps                   | 1631032  |
| td_erros                | -0.4118  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 266400   |
| lives                   | 266400   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5043   |
| steps                   | 1631452  |
| td_erros                | -0.4325  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 266500   |
| lives                   | 266500   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5258   |
| steps                   | 1631874  |
| td_erros                | -0.457   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 266600   |
| lives                   | 266600   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5292   |
| steps                   | 1632295  |
| td_erros                | -0.4621  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 266700   |
| lives                   | 266700   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5205   |
| steps                   | 1632717  |
| td_erros                | -0.4413  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 266800   |
| lives                   | 266800   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5413   |
| steps                   | 1633137  |
| td_erros                | -0.4693  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 266900   |
| lives                   | 266900   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5464   |
| steps                   | 1633557  |
| td_erros                | -0.4603  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 267000   |
| lives                   | 267000   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5643   |
| steps                   | 1633979  |
| td_erros                | -0.4726  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 267100   |
| lives                   | 267100   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5966   |
| steps                   | 1634401  |
| td_erros                | -0.4843  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 267200   |
| lives                   | 267200   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 4.89     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5876   |
| steps                   | 1634826  |
| td_erros                | -0.4893  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 267300   |
| lives                   | 267300   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 4.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5978   |
| steps                   | 1635265  |
| td_erros                | -0.5089  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 267400   |
| lives                   | 267400   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.56     |
| mean 100 episode reward | 4.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6024   |
| steps                   | 1635721  |
| td_erros                | -0.4945  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 267500   |
| lives                   | 267500   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 4.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5813   |
| steps                   | 1636181  |
| td_erros                | -0.4822  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 267600   |
| lives                   | 267600   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.63     |
| mean 100 episode reward | 4.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5691   |
| steps                   | 1636644  |
| td_erros                | -0.5076  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 267700   |
| lives                   | 267700   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.27     |
| mean 100 episode reward | 5.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5535   |
| steps                   | 1637071  |
| td_erros                | -0.5115  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 267800   |
| lives                   | 267800   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.17     |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5805   |
| steps                   | 1637488  |
| td_erros                | -0.4884  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 267900   |
| lives                   | 267900   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.06     |
| mean 100 episode reward | 5.01     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5601   |
| steps                   | 1637894  |
| td_erros                | -0.5065  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 268000   |
| lives                   | 268000   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 4.99     |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5674   |
| steps                   | 1638293  |
| td_erros                | -0.4867  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 268100   |
| lives                   | 268100   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.03     |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5464   |
| steps                   | 1638696  |
| td_erros                | -0.5366  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 268200   |
| lives                   | 268200   |
| mean 100 episode ei     | 4.25     |
| mean 100 episode length | 5.13     |
| mean 100 episode reward | 5.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5137   |
| steps                   | 1639109  |
| td_erros                | -0.5061  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 268300   |
| lives                   | 268300   |
| mean 100 episode ei     | 4.4      |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4931   |
| steps                   | 1639550  |
| td_erros                | -0.5451  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 268400   |
| lives                   | 268400   |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.494    |
| steps                   | 1639975  |
| td_erros                | -0.5574  |
--------------------------------------
Saving model due to running mean reward increase: 5.1113 -> 5.3545
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 268500   |
| lives                   | 268500   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4992   |
| steps                   | 1640396  |
| td_erros                | -0.5666  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 268600   |
| lives                   | 268600   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5008   |
| steps                   | 1640816  |
| td_erros                | -0.5587  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 268700   |
| lives                   | 268700   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5199   |
| steps                   | 1641238  |
| td_erros                | -0.5848  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 268800   |
| lives                   | 268800   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5417   |
| steps                   | 1641659  |
| td_erros                | -0.5864  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 268900   |
| lives                   | 268900   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5512   |
| steps                   | 1642080  |
| td_erros                | -0.5841  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 269000   |
| lives                   | 269000   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5508   |
| steps                   | 1642501  |
| td_erros                | -0.6003  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 269100   |
| lives                   | 269100   |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 5.33     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5392   |
| steps                   | 1642934  |
| td_erros                | -0.5647  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 269200   |
| lives                   | 269200   |
| mean 100 episode ei     | 4.39     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.03     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5027   |
| steps                   | 1643374  |
| td_erros                | -0.5909  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 269300   |
| lives                   | 269300   |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 5.27     |
| mean 100 episode reward | 4.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4944   |
| steps                   | 1643801  |
| td_erros                | -0.6024  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 269400   |
| lives                   | 269400   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 4.62     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4827   |
| steps                   | 1644223  |
| td_erros                | -0.5896  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 269500   |
| lives                   | 269500   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 4.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.513    |
| steps                   | 1644644  |
| td_erros                | -0.5934  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 269600   |
| lives                   | 269600   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5166   |
| steps                   | 1645064  |
| td_erros                | -0.6155  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 269700   |
| lives                   | 269700   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.31     |
| mean 100 episode reward | 4.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5208   |
| steps                   | 1645495  |
| td_erros                | -0.5682  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 269800   |
| lives                   | 269800   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.34     |
| mean 100 episode reward | 4.65     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5301   |
| steps                   | 1645929  |
| td_erros                | -0.6045  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 269900   |
| lives                   | 269900   |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 4.68     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5177   |
| steps                   | 1646370  |
| td_erros                | -0.6073  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 270000   |
| lives                   | 270000   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.55     |
| mean 100 episode reward | 4.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5238   |
| steps                   | 1646825  |
| td_erros                | -0.5716  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 270100   |
| lives                   | 270100   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 4.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5089   |
| steps                   | 1647268  |
| td_erros                | -0.5744  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 270200   |
| lives                   | 270200   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.28     |
| mean 100 episode reward | 4.66     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5223   |
| steps                   | 1647696  |
| td_erros                | -0.5985  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 270300   |
| lives                   | 270300   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 4.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5135   |
| steps                   | 1648116  |
| td_erros                | -0.6068  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 270400   |
| lives                   | 270400   |
| mean 100 episode ei     | 4.38     |
| mean 100 episode length | 5.38     |
| mean 100 episode reward | 4.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5373   |
| steps                   | 1648554  |
| td_erros                | -0.5735  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 270500   |
| lives                   | 270500   |
| mean 100 episode ei     | 4.39     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4942   |
| steps                   | 1648994  |
| td_erros                | -0.5932  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 270600   |
| lives                   | 270600   |
| mean 100 episode ei     | 4.33     |
| mean 100 episode length | 5.32     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4939   |
| steps                   | 1649426  |
| td_erros                | -0.5983  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 270700   |
| lives                   | 270700   |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 5.26     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4794   |
| steps                   | 1649852  |
| td_erros                | -0.6077  |
--------------------------------------
Saving model due to running mean reward increase: 5.2159 -> 5.3329
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 270800   |
| lives                   | 270800   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4827   |
| steps                   | 1650273  |
| td_erros                | -0.6085  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 270900   |
| lives                   | 270900   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.481    |
| steps                   | 1650693  |
| td_erros                | -0.6379  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 271000   |
| lives                   | 271000   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5119   |
| steps                   | 1651113  |
| td_erros                | -0.6332  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 271100   |
| lives                   | 271100   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5049   |
| steps                   | 1651533  |
| td_erros                | -0.6335  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 271200   |
| lives                   | 271200   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5109   |
| steps                   | 1651954  |
| td_erros                | -0.6514  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 271300   |
| lives                   | 271300   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5071   |
| steps                   | 1652376  |
| td_erros                | -0.655   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 271400   |
| lives                   | 271400   |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 5.26     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5024   |
| steps                   | 1652802  |
| td_erros                | -0.6382  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 271500   |
| lives                   | 271500   |
| mean 100 episode ei     | 4.35     |
| mean 100 episode length | 5.45     |
| mean 100 episode reward | 5.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4911   |
| steps                   | 1653247  |
| td_erros                | -0.648   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 271600   |
| lives                   | 271600   |
| mean 100 episode ei     | 4.28     |
| mean 100 episode length | 5.55     |
| mean 100 episode reward | 4.98     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4779   |
| steps                   | 1653702  |
| td_erros                | -0.6678  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 271700   |
| lives                   | 271700   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.38     |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4915   |
| steps                   | 1654140  |
| td_erros                | -0.6609  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 271800   |
| lives                   | 271800   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4965   |
| steps                   | 1654579  |
| td_erros                | -0.6778  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 271900   |
| lives                   | 271900   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5138   |
| steps                   | 1655021  |
| td_erros                | -0.6797  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 272000   |
| lives                   | 272000   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5029   |
| steps                   | 1655463  |
| td_erros                | -0.6726  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 272100   |
| lives                   | 272100   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4842   |
| steps                   | 1655886  |
| td_erros                | -0.6673  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 272200   |
| lives                   | 272200   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5021   |
| steps                   | 1656311  |
| td_erros                | -0.6714  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 272300   |
| lives                   | 272300   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4877   |
| steps                   | 1656732  |
| td_erros                | -0.6566  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 272400   |
| lives                   | 272400   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5054   |
| steps                   | 1657153  |
| td_erros                | -0.6895  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 272500   |
| lives                   | 272500   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4977   |
| steps                   | 1657574  |
| td_erros                | -0.7072  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 272600   |
| lives                   | 272600   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4704   |
| steps                   | 1657998  |
| td_erros                | -0.6836  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 272700   |
| lives                   | 272700   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4823   |
| steps                   | 1658417  |
| td_erros                | -0.6688  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 272800   |
| lives                   | 272800   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5127   |
| steps                   | 1658841  |
| td_erros                | -0.6813  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 272900   |
| lives                   | 272900   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5145   |
| steps                   | 1659262  |
| td_erros                | -0.6819  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 273000   |
| lives                   | 273000   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5252   |
| steps                   | 1659686  |
| td_erros                | -0.7171  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 273100   |
| lives                   | 273100   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5304   |
| steps                   | 1660107  |
| td_erros                | -0.6726  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 273200   |
| lives                   | 273200   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5305   |
| steps                   | 1660528  |
| td_erros                | -0.689   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 273300   |
| lives                   | 273300   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5416   |
| steps                   | 1660948  |
| td_erros                | -0.7195  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 273400   |
| lives                   | 273400   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5486   |
| steps                   | 1661370  |
| td_erros                | -0.7143  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 273500   |
| lives                   | 273500   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5469   |
| steps                   | 1661791  |
| td_erros                | -0.7243  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 273600   |
| lives                   | 273600   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.3      |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5564   |
| steps                   | 1662221  |
| td_erros                | -0.7141  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 273700   |
| lives                   | 273700   |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 5.57     |
| mean 100 episode reward | 4.82     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5497   |
| steps                   | 1662678  |
| td_erros                | -0.7039  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 273800   |
| lives                   | 273800   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.55     |
| mean 100 episode reward | 4.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5355   |
| steps                   | 1663133  |
| td_erros                | -0.7174  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 273900   |
| lives                   | 273900   |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 5.57     |
| mean 100 episode reward | 4.85     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5036   |
| steps                   | 1663590  |
| td_erros                | -0.7093  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 274000   |
| lives                   | 274000   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.32     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4823   |
| steps                   | 1664022  |
| td_erros                | -0.7129  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 274100   |
| lives                   | 274100   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4757   |
| steps                   | 1664445  |
| td_erros                | -0.745   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 274200   |
| lives                   | 274200   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4932   |
| steps                   | 1664865  |
| td_erros                | -0.7533  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 274300   |
| lives                   | 274300   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5041   |
| steps                   | 1665285  |
| td_erros                | -0.7366  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 274400   |
| lives                   | 274400   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.26     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4894   |
| steps                   | 1665711  |
| td_erros                | -0.757   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 274500   |
| lives                   | 274500   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5      |
| steps                   | 1666134  |
| td_erros                | -0.7583  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 274600   |
| lives                   | 274600   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4861   |
| steps                   | 1666556  |
| td_erros                | -0.7382  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 274700   |
| lives                   | 274700   |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4768   |
| steps                   | 1666980  |
| td_erros                | -0.7576  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 274800   |
| lives                   | 274800   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4604   |
| steps                   | 1667400  |
| td_erros                | -0.7627  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 274900   |
| lives                   | 274900   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4823   |
| steps                   | 1667821  |
| td_erros                | -0.7741  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 275000   |
| lives                   | 275000   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5188   |
| steps                   | 1668242  |
| td_erros                | -0.7728  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 275100   |
| lives                   | 275100   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5198   |
| steps                   | 1668662  |
| td_erros                | -0.7758  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 275200   |
| lives                   | 275200   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5331   |
| steps                   | 1669084  |
| td_erros                | -0.7848  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 275300   |
| lives                   | 275300   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5736   |
| steps                   | 1669505  |
| td_erros                | -0.7812  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 275400   |
| lives                   | 275400   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5615   |
| steps                   | 1669927  |
| td_erros                | -0.7885  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 275500   |
| lives                   | 275500   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.3      |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5634   |
| steps                   | 1670357  |
| td_erros                | -0.7654  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 275600   |
| lives                   | 275600   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5642   |
| steps                   | 1670799  |
| td_erros                | -0.7857  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 275700   |
| lives                   | 275700   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5543   |
| steps                   | 1671241  |
| td_erros                | -0.7488  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 275800   |
| lives                   | 275800   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5687   |
| steps                   | 1671681  |
| td_erros                | -0.7776  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 275900   |
| lives                   | 275900   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5492   |
| steps                   | 1672121  |
| td_erros                | -0.7697  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 276000   |
| lives                   | 276000   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.34     |
| mean 100 episode reward | 5.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5525   |
| steps                   | 1672555  |
| td_erros                | -0.7828  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 276100   |
| lives                   | 276100   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5297   |
| steps                   | 1672978  |
| td_erros                | -0.7862  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 276200   |
| lives                   | 276200   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5223   |
| steps                   | 1673398  |
| td_erros                | -0.794   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 276300   |
| lives                   | 276300   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5157   |
| steps                   | 1673819  |
| td_erros                | -0.7563  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 276400   |
| lives                   | 276400   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4957   |
| steps                   | 1674240  |
| td_erros                | -0.786   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 276500   |
| lives                   | 276500   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4867   |
| steps                   | 1674662  |
| td_erros                | -0.7669  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 276600   |
| lives                   | 276600   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4847   |
| steps                   | 1675082  |
| td_erros                | -0.7836  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 276700   |
| lives                   | 276700   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4778   |
| steps                   | 1675503  |
| td_erros                | -0.7862  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 276800   |
| lives                   | 276800   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4505   |
| steps                   | 1675924  |
| td_erros                | -0.7925  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 276900   |
| lives                   | 276900   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4789   |
| steps                   | 1676348  |
| td_erros                | -0.8263  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 277000   |
| lives                   | 277000   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4854   |
| steps                   | 1676772  |
| td_erros                | -0.8113  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 277100   |
| lives                   | 277100   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5123   |
| steps                   | 1677192  |
| td_erros                | -0.8234  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 277200   |
| lives                   | 277200   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5184   |
| steps                   | 1677614  |
| td_erros                | -0.819   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 277300   |
| lives                   | 277300   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5382   |
| steps                   | 1678037  |
| td_erros                | -0.8187  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 277400   |
| lives                   | 277400   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5518   |
| steps                   | 1678457  |
| td_erros                | -0.8276  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 277500   |
| lives                   | 277500   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5709   |
| steps                   | 1678877  |
| td_erros                | -0.8767  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 277600   |
| lives                   | 277600   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5666   |
| steps                   | 1679297  |
| td_erros                | -0.8544  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 277700   |
| lives                   | 277700   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.35     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5773   |
| steps                   | 1679732  |
| td_erros                | -0.8403  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 277800   |
| lives                   | 277800   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5629   |
| steps                   | 1680173  |
| td_erros                | -0.8473  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 277900   |
| lives                   | 277900   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5577   |
| steps                   | 1680614  |
| td_erros                | -0.821   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 278000   |
| lives                   | 278000   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5298   |
| steps                   | 1681053  |
| td_erros                | -0.795   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 278100   |
| lives                   | 278100   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5172   |
| steps                   | 1681493  |
| td_erros                | -0.8232  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 278200   |
| lives                   | 278200   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5056   |
| steps                   | 1681936  |
| td_erros                | -0.7958  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 278300   |
| lives                   | 278300   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.08     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.487    |
| steps                   | 1682375  |
| td_erros                | -0.8192  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 278400   |
| lives                   | 278400   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4732   |
| steps                   | 1682799  |
| td_erros                | -0.7995  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 278500   |
| lives                   | 278500   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4505   |
| steps                   | 1683222  |
| td_erros                | -0.7899  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 278600   |
| lives                   | 278600   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4419   |
| steps                   | 1683641  |
| td_erros                | -0.7758  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 278700   |
| lives                   | 278700   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4174   |
| steps                   | 1684061  |
| td_erros                | -0.8084  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 278800   |
| lives                   | 278800   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4197   |
| steps                   | 1684484  |
| td_erros                | -0.8318  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 278900   |
| lives                   | 278900   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4164   |
| steps                   | 1684905  |
| td_erros                | -0.7582  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 279000   |
| lives                   | 279000   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4137   |
| steps                   | 1685324  |
| td_erros                | -0.7767  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 279100   |
| lives                   | 279100   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4315   |
| steps                   | 1685745  |
| td_erros                | -0.7974  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 279200   |
| lives                   | 279200   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4268   |
| steps                   | 1686167  |
| td_erros                | -0.8229  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 279300   |
| lives                   | 279300   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4464   |
| steps                   | 1686590  |
| td_erros                | -0.8188  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 279400   |
| lives                   | 279400   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4459   |
| steps                   | 1687011  |
| td_erros                | -0.8183  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 279500   |
| lives                   | 279500   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4908   |
| steps                   | 1687430  |
| td_erros                | -0.8385  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 279600   |
| lives                   | 279600   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4824   |
| steps                   | 1687852  |
| td_erros                | -0.8435  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 279700   |
| lives                   | 279700   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4807   |
| steps                   | 1688272  |
| td_erros                | -0.8396  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 279800   |
| lives                   | 279800   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5017   |
| steps                   | 1688693  |
| td_erros                | -0.8825  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 279900   |
| lives                   | 279900   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5233   |
| steps                   | 1689114  |
| td_erros                | -0.811   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 280000   |
| lives                   | 280000   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5308   |
| steps                   | 1689536  |
| td_erros                | -0.8404  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 280100   |
| lives                   | 280100   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5372   |
| steps                   | 1689956  |
| td_erros                | -0.8106  |
--------------------------------------
Saving model due to running mean reward increase: 5.3221 -> 5.3518
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 280200   |
| lives                   | 280200   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5441   |
| steps                   | 1690379  |
| td_erros                | -0.8428  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 280300   |
| lives                   | 280300   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5251   |
| steps                   | 1690803  |
| td_erros                | -0.8113  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 280400   |
| lives                   | 280400   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5378   |
| steps                   | 1691227  |
| td_erros                | -0.8682  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 280500   |
| lives                   | 280500   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5403   |
| steps                   | 1691649  |
| td_erros                | -0.8347  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 280600   |
| lives                   | 280600   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5454   |
| steps                   | 1692068  |
| td_erros                | -0.8405  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 280700   |
| lives                   | 280700   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5499   |
| steps                   | 1692490  |
| td_erros                | -0.855   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 280800   |
| lives                   | 280800   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5602   |
| steps                   | 1692931  |
| td_erros                | -0.86    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 280900   |
| lives                   | 280900   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5468   |
| steps                   | 1693373  |
| td_erros                | -0.8615  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 281000   |
| lives                   | 281000   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 4.99     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5349   |
| steps                   | 1693815  |
| td_erros                | -0.8432  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 281100   |
| lives                   | 281100   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5354   |
| steps                   | 1694258  |
| td_erros                | -0.8478  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 281200   |
| lives                   | 281200   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5207   |
| steps                   | 1694700  |
| td_erros                | -0.8439  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 281300   |
| lives                   | 281300   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5102   |
| steps                   | 1695139  |
| td_erros                | -0.7934  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 281400   |
| lives                   | 281400   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.38     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.482    |
| steps                   | 1695577  |
| td_erros                | -0.8142  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 281500   |
| lives                   | 281500   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4727   |
| steps                   | 1695997  |
| td_erros                | -0.7805  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 281600   |
| lives                   | 281600   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4467   |
| steps                   | 1696419  |
| td_erros                | -0.7688  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 281700   |
| lives                   | 281700   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4471   |
| steps                   | 1696844  |
| td_erros                | -0.8285  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 281800   |
| lives                   | 281800   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.43     |
| steps                   | 1697266  |
| td_erros                | -0.7932  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 281900   |
| lives                   | 281900   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4046   |
| steps                   | 1697687  |
| td_erros                | -0.845   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 282000   |
| lives                   | 282000   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 5.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4153   |
| steps                   | 1698112  |
| td_erros                | -0.8593  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 282100   |
| lives                   | 282100   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4158   |
| steps                   | 1698532  |
| td_erros                | -0.8462  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 282200   |
| lives                   | 282200   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4299   |
| steps                   | 1698952  |
| td_erros                | -0.8754  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 282300   |
| lives                   | 282300   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.458    |
| steps                   | 1699373  |
| td_erros                | -0.8931  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 282400   |
| lives                   | 282400   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4778   |
| steps                   | 1699794  |
| td_erros                | -0.8874  |
--------------------------------------
Saving model due to running mean reward increase: 5.2882 -> 5.2887
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 282500   |
| lives                   | 282500   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4928   |
| steps                   | 1700219  |
| td_erros                | -0.8822  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 282600   |
| lives                   | 282600   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5038   |
| steps                   | 1700640  |
| td_erros                | -0.8907  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 282700   |
| lives                   | 282700   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4928   |
| steps                   | 1701063  |
| td_erros                | -0.8647  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 282800   |
| lives                   | 282800   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5056   |
| steps                   | 1701485  |
| td_erros                | -0.9077  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 282900   |
| lives                   | 282900   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5366   |
| steps                   | 1701905  |
| td_erros                | -0.9018  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 283000   |
| lives                   | 283000   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5319   |
| steps                   | 1702326  |
| td_erros                | -0.8744  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 283100   |
| lives                   | 283100   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5471   |
| steps                   | 1702749  |
| td_erros                | -0.8877  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 283200   |
| lives                   | 283200   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5455   |
| steps                   | 1703169  |
| td_erros                | -0.8484  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 283300   |
| lives                   | 283300   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5642   |
| steps                   | 1703591  |
| td_erros                | -0.8836  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 283400   |
| lives                   | 283400   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5665   |
| steps                   | 1704015  |
| td_erros                | -0.8851  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 283500   |
| lives                   | 283500   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5653   |
| steps                   | 1704457  |
| td_erros                | -0.8772  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 283600   |
| lives                   | 283600   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5546   |
| steps                   | 1704898  |
| td_erros                | -0.8204  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 283700   |
| lives                   | 283700   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5399   |
| steps                   | 1705338  |
| td_erros                | -0.8443  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 283800   |
| lives                   | 283800   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5362   |
| steps                   | 1705780  |
| td_erros                | -0.8598  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 283900   |
| lives                   | 283900   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4996   |
| steps                   | 1706221  |
| td_erros                | -0.8592  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 284000   |
| lives                   | 284000   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.34     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4963   |
| steps                   | 1706655  |
| td_erros                | -0.8424  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 284100   |
| lives                   | 284100   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5017   |
| steps                   | 1707075  |
| td_erros                | -0.8281  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 284200   |
| lives                   | 284200   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.47     |
| steps                   | 1707495  |
| td_erros                | -0.8371  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 284300   |
| lives                   | 284300   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.482    |
| steps                   | 1707916  |
| td_erros                | -0.8658  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 284400   |
| lives                   | 284400   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4608   |
| steps                   | 1708337  |
| td_erros                | -0.8433  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 284500   |
| lives                   | 284500   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4439   |
| steps                   | 1708761  |
| td_erros                | -0.8482  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 284600   |
| lives                   | 284600   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4518   |
| steps                   | 1709184  |
| td_erros                | -0.8681  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 284700   |
| lives                   | 284700   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4561   |
| steps                   | 1709605  |
| td_erros                | -0.8465  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 284800   |
| lives                   | 284800   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.18     |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4485   |
| steps                   | 1710023  |
| td_erros                | -0.8654  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 284900   |
| lives                   | 284900   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.459    |
| steps                   | 1710444  |
| td_erros                | -0.8684  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 285000   |
| lives                   | 285000   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.485    |
| steps                   | 1710864  |
| td_erros                | -0.8513  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 285100   |
| lives                   | 285100   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4815   |
| steps                   | 1711286  |
| td_erros                | -0.8833  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 285200   |
| lives                   | 285200   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5028   |
| steps                   | 1711707  |
| td_erros                | -0.8889  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 285300   |
| lives                   | 285300   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5173   |
| steps                   | 1712128  |
| td_erros                | -0.8722  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 285400   |
| lives                   | 285400   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5229   |
| steps                   | 1712549  |
| td_erros                | -0.8907  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 285500   |
| lives                   | 285500   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.525    |
| steps                   | 1712971  |
| td_erros                | -0.8788  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 285600   |
| lives                   | 285600   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5365   |
| steps                   | 1713392  |
| td_erros                | -0.87    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 285700   |
| lives                   | 285700   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5375   |
| steps                   | 1713813  |
| td_erros                | -0.9029  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 285800   |
| lives                   | 285800   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5469   |
| steps                   | 1714234  |
| td_erros                | -0.8717  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 285900   |
| lives                   | 285900   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5432   |
| steps                   | 1714656  |
| td_erros                | -0.8612  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 286000   |
| lives                   | 286000   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5406   |
| steps                   | 1715078  |
| td_erros                | -0.9049  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 286100   |
| lives                   | 286100   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5345   |
| steps                   | 1715500  |
| td_erros                | -0.8909  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 286200   |
| lives                   | 286200   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 5.18     |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5531   |
| steps                   | 1715918  |
| td_erros                | -0.8764  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 286300   |
| lives                   | 286300   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5593   |
| steps                   | 1716339  |
| td_erros                | -0.8687  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 286400   |
| lives                   | 286400   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5545   |
| steps                   | 1716763  |
| td_erros                | -0.8646  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 286500   |
| lives                   | 286500   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5706   |
| steps                   | 1717184  |
| td_erros                | -0.8669  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 286600   |
| lives                   | 286600   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5471   |
| steps                   | 1717605  |
| td_erros                | -0.8605  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 286700   |
| lives                   | 286700   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5583   |
| steps                   | 1718025  |
| td_erros                | -0.894   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 286800   |
| lives                   | 286800   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5566   |
| steps                   | 1718449  |
| td_erros                | -0.8954  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 286900   |
| lives                   | 286900   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5576   |
| steps                   | 1718870  |
| td_erros                | -0.8935  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 287000   |
| lives                   | 287000   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.27     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5619   |
| steps                   | 1719297  |
| td_erros                | -0.891   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 287100   |
| lives                   | 287100   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5535   |
| steps                   | 1719737  |
| td_erros                | -0.8761  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 287200   |
| lives                   | 287200   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5457   |
| steps                   | 1720179  |
| td_erros                | -0.8991  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 287300   |
| lives                   | 287300   |
| mean 100 episode ei     | 3.81     |
| mean 100 episode length | 5.37     |
| mean 100 episode reward | 4.96     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5376   |
| steps                   | 1720616  |
| td_erros                | -0.8524  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 287400   |
| lives                   | 287400   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.521    |
| steps                   | 1721056  |
| td_erros                | -0.8763  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 287500   |
| lives                   | 287500   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.33     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5118   |
| steps                   | 1721489  |
| td_erros                | -0.8422  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 287600   |
| lives                   | 287600   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4798   |
| steps                   | 1721909  |
| td_erros                | -0.8579  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 287700   |
| lives                   | 287700   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4915   |
| steps                   | 1722330  |
| td_erros                | -0.8794  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 287800   |
| lives                   | 287800   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4723   |
| steps                   | 1722750  |
| td_erros                | -0.8615  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 287900   |
| lives                   | 287900   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4584   |
| steps                   | 1723171  |
| td_erros                | -0.8668  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 288000   |
| lives                   | 288000   |
| mean 100 episode ei     | 3.61     |
| mean 100 episode length | 5.02     |
| mean 100 episode reward | 4.83     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4326   |
| steps                   | 1723573  |
| td_erros                | -0.8711  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 288100   |
| lives                   | 288100   |
| mean 100 episode ei     | 3.27     |
| mean 100 episode length | 4.87     |
| mean 100 episode reward | 4.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3858   |
| steps                   | 1723960  |
| td_erros                | -0.8041  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 288200   |
| lives                   | 288200   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3591   |
| steps                   | 1724382  |
| td_erros                | -0.8396  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 288300   |
| lives                   | 288300   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3409   |
| steps                   | 1724801  |
| td_erros                | -0.8527  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 288400   |
| lives                   | 288400   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3447   |
| steps                   | 1725221  |
| td_erros                | -0.8837  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 288500   |
| lives                   | 288500   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3632   |
| steps                   | 1725642  |
| td_erros                | -0.8888  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 288600   |
| lives                   | 288600   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.18     |
| mean 100 episode reward | 5.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3784   |
| steps                   | 1726060  |
| td_erros                | -0.93    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 288700   |
| lives                   | 288700   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3982   |
| steps                   | 1726482  |
| td_erros                | -0.9143  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 288800   |
| lives                   | 288800   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3946   |
| steps                   | 1726902  |
| td_erros                | -0.898   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 288900   |
| lives                   | 288900   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4025   |
| steps                   | 1727327  |
| td_erros                | -0.9036  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 289000   |
| lives                   | 289000   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4012   |
| steps                   | 1727748  |
| td_erros                | -0.927   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 289100   |
| lives                   | 289100   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.3992   |
| steps                   | 1728167  |
| td_erros                | -0.9155  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 289200   |
| lives                   | 289200   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4087   |
| steps                   | 1728587  |
| td_erros                | -0.9314  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 289300   |
| lives                   | 289300   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4192   |
| steps                   | 1729008  |
| td_erros                | -0.959   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 289400   |
| lives                   | 289400   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4436   |
| steps                   | 1729429  |
| td_erros                | -0.97    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 289500   |
| lives                   | 289500   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4472   |
| steps                   | 1729850  |
| td_erros                | -0.9781  |
--------------------------------------
Saving model due to running mean reward increase: 5.2649 -> 5.2727
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 289600   |
| lives                   | 289600   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4713   |
| steps                   | 1730270  |
| td_erros                | -1.0077  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 289700   |
| lives                   | 289700   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4733   |
| steps                   | 1730690  |
| td_erros                | -0.9928  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 289800   |
| lives                   | 289800   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5053   |
| steps                   | 1731112  |
| td_erros                | -1.0167  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 289900   |
| lives                   | 289900   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5144   |
| steps                   | 1731535  |
| td_erros                | -0.9818  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 290000   |
| lives                   | 290000   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5143   |
| steps                   | 1731958  |
| td_erros                | -0.9792  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 290100   |
| lives                   | 290100   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5181   |
| steps                   | 1732378  |
| td_erros                | -0.9783  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 290200   |
| lives                   | 290200   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5398   |
| steps                   | 1732799  |
| td_erros                | -1.0132  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 290300   |
| lives                   | 290300   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5592   |
| steps                   | 1733221  |
| td_erros                | -1.0113  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 290400   |
| lives                   | 290400   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5589   |
| steps                   | 1733641  |
| td_erros                | -0.9752  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 290500   |
| lives                   | 290500   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5388   |
| steps                   | 1734061  |
| td_erros                | -0.9749  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 290600   |
| lives                   | 290600   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5519   |
| steps                   | 1734481  |
| td_erros                | -0.9976  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 290700   |
| lives                   | 290700   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5636   |
| steps                   | 1734902  |
| td_erros                | -0.9962  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 290800   |
| lives                   | 290800   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5541   |
| steps                   | 1735325  |
| td_erros                | -0.9825  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 290900   |
| lives                   | 290900   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5641   |
| steps                   | 1735748  |
| td_erros                | -1.0224  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 291000   |
| lives                   | 291000   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.569    |
| steps                   | 1736169  |
| td_erros                | -1.0053  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 291100   |
| lives                   | 291100   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.571    |
| steps                   | 1736592  |
| td_erros                | -0.961   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 291200   |
| lives                   | 291200   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5615   |
| steps                   | 1737014  |
| td_erros                | -1.0195  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 291300   |
| lives                   | 291300   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.28     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5565   |
| steps                   | 1737442  |
| td_erros                | -0.9848  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 291400   |
| lives                   | 291400   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.3      |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5678   |
| steps                   | 1737872  |
| td_erros                | -0.9858  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 291500   |
| lives                   | 291500   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5552   |
| steps                   | 1738313  |
| td_erros                | -0.9614  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 291600   |
| lives                   | 291600   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.3      |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5512   |
| steps                   | 1738743  |
| td_erros                | -0.9437  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 291700   |
| lives                   | 291700   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5511   |
| steps                   | 1739163  |
| td_erros                | -0.9739  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 291800   |
| lives                   | 291800   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5574   |
| steps                   | 1739583  |
| td_erros                | -0.9405  |
--------------------------------------
Saving model due to running mean reward increase: 5.238 -> 5.3631
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 291900   |
| lives                   | 291900   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5622   |
| steps                   | 1740003  |
| td_erros                | -0.9502  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 292000   |
| lives                   | 292000   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5476   |
| steps                   | 1740425  |
| td_erros                | -0.9617  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 292100   |
| lives                   | 292100   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5409   |
| steps                   | 1740846  |
| td_erros                | -0.918   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 292200   |
| lives                   | 292200   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5057   |
| steps                   | 1741269  |
| td_erros                | -0.8474  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 292300   |
| lives                   | 292300   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4948   |
| steps                   | 1741692  |
| td_erros                | -0.9216  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 292400   |
| lives                   | 292400   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4852   |
| steps                   | 1742116  |
| td_erros                | -0.9162  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 292500   |
| lives                   | 292500   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4953   |
| steps                   | 1742539  |
| td_erros                | -0.9418  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 292600   |
| lives                   | 292600   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5111   |
| steps                   | 1742958  |
| td_erros                | -0.9278  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 292700   |
| lives                   | 292700   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.18     |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5059   |
| steps                   | 1743376  |
| td_erros                | -0.9149  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 292800   |
| lives                   | 292800   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5263   |
| steps                   | 1743795  |
| td_erros                | -0.9515  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 292900   |
| lives                   | 292900   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5217   |
| steps                   | 1744215  |
| td_erros                | -0.9432  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 293000   |
| lives                   | 293000   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.15     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5184   |
| steps                   | 1744630  |
| td_erros                | -0.9291  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 293100   |
| lives                   | 293100   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5289   |
| steps                   | 1745052  |
| td_erros                | -0.9623  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 293200   |
| lives                   | 293200   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5577   |
| steps                   | 1745472  |
| td_erros                | -0.9108  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 293300   |
| lives                   | 293300   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5449   |
| steps                   | 1745893  |
| td_erros                | -0.9244  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 293400   |
| lives                   | 293400   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5576   |
| steps                   | 1746315  |
| td_erros                | -0.8986  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 293500   |
| lives                   | 293500   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5656   |
| steps                   | 1746735  |
| td_erros                | -0.94    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 293600   |
| lives                   | 293600   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.571    |
| steps                   | 1747158  |
| td_erros                | -0.9369  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 293700   |
| lives                   | 293700   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5671   |
| steps                   | 1747580  |
| td_erros                | -1.0044  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 293800   |
| lives                   | 293800   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.579    |
| steps                   | 1747999  |
| td_erros                | -0.9267  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 293900   |
| lives                   | 293900   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5911   |
| steps                   | 1748421  |
| td_erros                | -0.925   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 294000   |
| lives                   | 294000   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5869   |
| steps                   | 1748841  |
| td_erros                | -0.951   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 294100   |
| lives                   | 294100   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5952   |
| steps                   | 1749265  |
| td_erros                | -0.933   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 294200   |
| lives                   | 294200   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5937   |
| steps                   | 1749686  |
| td_erros                | -0.9885  |
--------------------------------------
Saving model due to running mean reward increase: 5.3181 -> 5.3689
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 294300   |
| lives                   | 294300   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.17     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5854   |
| steps                   | 1750103  |
| td_erros                | -0.9682  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 294400   |
| lives                   | 294400   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5887   |
| steps                   | 1750524  |
| td_erros                | -0.9589  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 294500   |
| lives                   | 294500   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5972   |
| steps                   | 1750947  |
| td_erros                | -0.9663  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 294600   |
| lives                   | 294600   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6034   |
| steps                   | 1751368  |
| td_erros                | -0.9534  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 294700   |
| lives                   | 294700   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.33     |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6091   |
| steps                   | 1751801  |
| td_erros                | -0.958   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 294800   |
| lives                   | 294800   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.46     |
| mean 100 episode reward | 5.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6021   |
| steps                   | 1752247  |
| td_erros                | -0.9342  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 294900   |
| lives                   | 294900   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.49     |
| mean 100 episode reward | 5.1      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5795   |
| steps                   | 1752696  |
| td_erros                | -0.8903  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 295000   |
| lives                   | 295000   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5811   |
| steps                   | 1753137  |
| td_erros                | -0.9112  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 295100   |
| lives                   | 295100   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 5.38     |
| mean 100 episode reward | 5.04     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5575   |
| steps                   | 1753575  |
| td_erros                | -0.8719  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 295200   |
| lives                   | 295200   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.34     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5207   |
| steps                   | 1754009  |
| td_erros                | -0.8851  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 295300   |
| lives                   | 295300   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5215   |
| steps                   | 1754430  |
| td_erros                | -0.8838  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 295400   |
| lives                   | 295400   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4991   |
| steps                   | 1754851  |
| td_erros                | -0.9045  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 295500   |
| lives                   | 295500   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4853   |
| steps                   | 1755272  |
| td_erros                | -0.8712  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 295600   |
| lives                   | 295600   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4619   |
| steps                   | 1755692  |
| td_erros                | -0.8998  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 295700   |
| lives                   | 295700   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4466   |
| steps                   | 1756112  |
| td_erros                | -0.8992  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 295800   |
| lives                   | 295800   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4483   |
| steps                   | 1756531  |
| td_erros                | -0.8994  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 295900   |
| lives                   | 295900   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4333   |
| steps                   | 1756954  |
| td_erros                | -0.9244  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 296000   |
| lives                   | 296000   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4382   |
| steps                   | 1757374  |
| td_erros                | -0.8901  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 296100   |
| lives                   | 296100   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4547   |
| steps                   | 1757794  |
| td_erros                | -0.9293  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 296200   |
| lives                   | 296200   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4572   |
| steps                   | 1758215  |
| td_erros                | -0.9133  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 296300   |
| lives                   | 296300   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4707   |
| steps                   | 1758636  |
| td_erros                | -0.9007  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 296400   |
| lives                   | 296400   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4763   |
| steps                   | 1759058  |
| td_erros                | -0.918   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 296500   |
| lives                   | 296500   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4664   |
| steps                   | 1759477  |
| td_erros                | -0.9102  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 296600   |
| lives                   | 296600   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4933   |
| steps                   | 1759898  |
| td_erros                | -0.957   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 296700   |
| lives                   | 296700   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5078   |
| steps                   | 1760318  |
| td_erros                | -0.9531  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 296800   |
| lives                   | 296800   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5255   |
| steps                   | 1760741  |
| td_erros                | -0.9472  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 296900   |
| lives                   | 296900   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5301   |
| steps                   | 1761162  |
| td_erros                | -0.8973  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 297000   |
| lives                   | 297000   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5312   |
| steps                   | 1761583  |
| td_erros                | -0.9547  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 297100   |
| lives                   | 297100   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5395   |
| steps                   | 1762003  |
| td_erros                | -0.9411  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 297200   |
| lives                   | 297200   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5488   |
| steps                   | 1762423  |
| td_erros                | -0.935   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 297300   |
| lives                   | 297300   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 5.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5586   |
| steps                   | 1762842  |
| td_erros                | -0.9292  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 297400   |
| lives                   | 297400   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5552   |
| steps                   | 1763261  |
| td_erros                | -0.9201  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 297500   |
| lives                   | 297500   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5737   |
| steps                   | 1763682  |
| td_erros                | -0.9398  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 297600   |
| lives                   | 297600   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5782   |
| steps                   | 1764103  |
| td_erros                | -0.9251  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 297700   |
| lives                   | 297700   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5598   |
| steps                   | 1764526  |
| td_erros                | -0.8906  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 297800   |
| lives                   | 297800   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5622   |
| steps                   | 1764948  |
| td_erros                | -0.9406  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 297900   |
| lives                   | 297900   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5569   |
| steps                   | 1765370  |
| td_erros                | -0.9107  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 298000   |
| lives                   | 298000   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.566    |
| steps                   | 1765791  |
| td_erros                | -0.935   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 298100   |
| lives                   | 298100   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5715   |
| steps                   | 1766210  |
| td_erros                | -0.9124  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 298200   |
| lives                   | 298200   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5744   |
| steps                   | 1766632  |
| td_erros                | -0.9233  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 298300   |
| lives                   | 298300   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5607   |
| steps                   | 1767053  |
| td_erros                | -0.9063  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 298400   |
| lives                   | 298400   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5698   |
| steps                   | 1767474  |
| td_erros                | -0.9289  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 298500   |
| lives                   | 298500   |
| mean 100 episode ei     | 3.86     |
| mean 100 episode length | 5.18     |
| mean 100 episode reward | 5.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5396   |
| steps                   | 1767892  |
| td_erros                | -0.9399  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 298600   |
| lives                   | 298600   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5683   |
| steps                   | 1768311  |
| td_erros                | -0.9355  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 298700   |
| lives                   | 298700   |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 5.26     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5498   |
| steps                   | 1768737  |
| td_erros                | -0.9357  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 298800   |
| lives                   | 298800   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.545    |
| steps                   | 1769160  |
| td_erros                | -0.9516  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 298900   |
| lives                   | 298900   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5424   |
| steps                   | 1769583  |
| td_erros                | -0.9331  |
--------------------------------------
Saving model due to running mean reward increase: 5.2536 -> 5.3242
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 299000   |
| lives                   | 299000   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5393   |
| steps                   | 1770003  |
| td_erros                | -0.9207  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 299100   |
| lives                   | 299100   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5586   |
| steps                   | 1770424  |
| td_erros                | -0.9229  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 299200   |
| lives                   | 299200   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5566   |
| steps                   | 1770844  |
| td_erros                | -0.9304  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 299300   |
| lives                   | 299300   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5553   |
| steps                   | 1771266  |
| td_erros                | -0.9102  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 299400   |
| lives                   | 299400   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5461   |
| steps                   | 1771688  |
| td_erros                | -0.9704  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 299500   |
| lives                   | 299500   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5702   |
| steps                   | 1772109  |
| td_erros                | -0.9282  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 299600   |
| lives                   | 299600   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5651   |
| steps                   | 1772528  |
| td_erros                | -0.9744  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 299700   |
| lives                   | 299700   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5783   |
| steps                   | 1772949  |
| td_erros                | -0.9655  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 299800   |
| lives                   | 299800   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 5.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5718   |
| steps                   | 1773374  |
| td_erros                | -0.9563  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 299900   |
| lives                   | 299900   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5789   |
| steps                   | 1773795  |
| td_erros                | -0.9316  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 300000   |
| lives                   | 300000   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5652   |
| steps                   | 1774236  |
| td_erros                | -0.9575  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 300100   |
| lives                   | 300100   |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5        |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5768   |
| steps                   | 1774678  |
| td_erros                | -0.8945  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 300200   |
| lives                   | 300200   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5611   |
| steps                   | 1775120  |
| td_erros                | -0.8837  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 300300   |
| lives                   | 300300   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5677   |
| steps                   | 1775559  |
| td_erros                | -0.9297  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 300400   |
| lives                   | 300400   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.31     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5402   |
| steps                   | 1775990  |
| td_erros                | -0.8995  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 300500   |
| lives                   | 300500   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.27     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5207   |
| steps                   | 1776417  |
| td_erros                | -0.9029  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 300600   |
| lives                   | 300600   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5069   |
| steps                   | 1776838  |
| td_erros                | -0.8705  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 300700   |
| lives                   | 300700   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5067   |
| steps                   | 1777259  |
| td_erros                | -0.8908  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 300800   |
| lives                   | 300800   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.479    |
| steps                   | 1777680  |
| td_erros                | -0.907   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 300900   |
| lives                   | 300900   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4853   |
| steps                   | 1778103  |
| td_erros                | -0.8983  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 301000   |
| lives                   | 301000   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4867   |
| steps                   | 1778525  |
| td_erros                | -0.9041  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 301100   |
| lives                   | 301100   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4797   |
| steps                   | 1778947  |
| td_erros                | -0.9082  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 301200   |
| lives                   | 301200   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4767   |
| steps                   | 1779370  |
| td_erros                | -0.9352  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 301300   |
| lives                   | 301300   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4939   |
| steps                   | 1779792  |
| td_erros                | -0.9306  |
--------------------------------------
Saving model due to running mean reward increase: 5.2298 -> 5.2766
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 301400   |
| lives                   | 301400   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5068   |
| steps                   | 1780213  |
| td_erros                | -0.9232  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 301500   |
| lives                   | 301500   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5186   |
| steps                   | 1780636  |
| td_erros                | -0.9288  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 301600   |
| lives                   | 301600   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5179   |
| steps                   | 1781056  |
| td_erros                | -0.9407  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 301700   |
| lives                   | 301700   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5254   |
| steps                   | 1781476  |
| td_erros                | -0.9659  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 301800   |
| lives                   | 301800   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.18     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.544    |
| steps                   | 1781894  |
| td_erros                | -0.9747  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 301900   |
| lives                   | 301900   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5448   |
| steps                   | 1782316  |
| td_erros                | -0.9546  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 302000   |
| lives                   | 302000   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.555    |
| steps                   | 1782738  |
| td_erros                | -0.9597  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 302100   |
| lives                   | 302100   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5712   |
| steps                   | 1783159  |
| td_erros                | -0.9443  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 302200   |
| lives                   | 302200   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.57     |
| steps                   | 1783580  |
| td_erros                | -1.0126  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 302300   |
| lives                   | 302300   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5716   |
| steps                   | 1784001  |
| td_erros                | -0.9259  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 302400   |
| lives                   | 302400   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5791   |
| steps                   | 1784424  |
| td_erros                | -0.9518  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 302500   |
| lives                   | 302500   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5734   |
| steps                   | 1784845  |
| td_erros                | -0.9341  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 302600   |
| lives                   | 302600   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5841   |
| steps                   | 1785267  |
| td_erros                | -0.9619  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 302700   |
| lives                   | 302700   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5889   |
| steps                   | 1785690  |
| td_erros                | -0.9777  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 302800   |
| lives                   | 302800   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.583    |
| steps                   | 1786111  |
| td_erros                | -0.9166  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 302900   |
| lives                   | 302900   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5797   |
| steps                   | 1786534  |
| td_erros                | -0.961   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 303000   |
| lives                   | 303000   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5681   |
| steps                   | 1786957  |
| td_erros                | -0.9241  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 303100   |
| lives                   | 303100   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5637   |
| steps                   | 1787382  |
| td_erros                | -0.9725  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 303200   |
| lives                   | 303200   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5598   |
| steps                   | 1787805  |
| td_erros                | -0.9628  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 303300   |
| lives                   | 303300   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5612   |
| steps                   | 1788225  |
| td_erros                | -0.9572  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 303400   |
| lives                   | 303400   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5513   |
| steps                   | 1788648  |
| td_erros                | -0.9645  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 303500   |
| lives                   | 303500   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5487   |
| steps                   | 1789071  |
| td_erros                | -0.9829  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 303600   |
| lives                   | 303600   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5483   |
| steps                   | 1789492  |
| td_erros                | -0.9493  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 303700   |
| lives                   | 303700   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5473   |
| steps                   | 1789913  |
| td_erros                | -0.9336  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 303800   |
| lives                   | 303800   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.18     |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5567   |
| steps                   | 1790331  |
| td_erros                | -0.9389  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 303900   |
| lives                   | 303900   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5505   |
| steps                   | 1790750  |
| td_erros                | -0.9495  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 304000   |
| lives                   | 304000   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5598   |
| steps                   | 1791170  |
| td_erros                | -0.937   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 304100   |
| lives                   | 304100   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5538   |
| steps                   | 1791590  |
| td_erros                | -0.9444  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 304200   |
| lives                   | 304200   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5636   |
| steps                   | 1792011  |
| td_erros                | -0.9287  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 304300   |
| lives                   | 304300   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.574    |
| steps                   | 1792434  |
| td_erros                | -0.9671  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 304400   |
| lives                   | 304400   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5598   |
| steps                   | 1792858  |
| td_erros                | -0.9759  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 304500   |
| lives                   | 304500   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5761   |
| steps                   | 1793279  |
| td_erros                | -0.9628  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 304600   |
| lives                   | 304600   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5852   |
| steps                   | 1793702  |
| td_erros                | -0.9401  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 304700   |
| lives                   | 304700   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5734   |
| steps                   | 1794123  |
| td_erros                | -0.9576  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 304800   |
| lives                   | 304800   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5715   |
| steps                   | 1794546  |
| td_erros                | -0.9779  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 304900   |
| lives                   | 304900   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5792   |
| steps                   | 1794969  |
| td_erros                | -0.9479  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 305000   |
| lives                   | 305000   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.18     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5778   |
| steps                   | 1795387  |
| td_erros                | -0.9975  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 305100   |
| lives                   | 305100   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5812   |
| steps                   | 1795808  |
| td_erros                | -0.9473  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 305200   |
| lives                   | 305200   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5872   |
| steps                   | 1796229  |
| td_erros                | -0.9477  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 305300   |
| lives                   | 305300   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5952   |
| steps                   | 1796651  |
| td_erros                | -0.9686  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 305400   |
| lives                   | 305400   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 5.15     |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5847   |
| steps                   | 1797066  |
| td_erros                | -0.9671  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 305500   |
| lives                   | 305500   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5957   |
| steps                   | 1797488  |
| td_erros                | -0.9153  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 305600   |
| lives                   | 305600   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5855   |
| steps                   | 1797909  |
| td_erros                | -0.9413  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 305700   |
| lives                   | 305700   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5883   |
| steps                   | 1798330  |
| td_erros                | -0.9486  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 305800   |
| lives                   | 305800   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5929   |
| steps                   | 1798750  |
| td_erros                | -0.9236  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 305900   |
| lives                   | 305900   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.6001   |
| steps                   | 1799174  |
| td_erros                | -0.9253  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 306000   |
| lives                   | 306000   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5889   |
| steps                   | 1799615  |
| td_erros                | -0.9348  |
--------------------------------------
Saving model due to running mean reward increase: 5.0822 -> 5.2686
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 306100   |
| lives                   | 306100   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5595   |
| steps                   | 1800037  |
| td_erros                | -0.9362  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 306200   |
| lives                   | 306200   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.581    |
| steps                   | 1800460  |
| td_erros                | -0.9847  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 306300   |
| lives                   | 306300   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5849   |
| steps                   | 1800880  |
| td_erros                | -0.9633  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 306400   |
| lives                   | 306400   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5882   |
| steps                   | 1801302  |
| td_erros                | -0.9448  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 306500   |
| lives                   | 306500   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5685   |
| steps                   | 1801724  |
| td_erros                | -0.933   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 306600   |
| lives                   | 306600   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.563    |
| steps                   | 1802145  |
| td_erros                | -0.9645  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 306700   |
| lives                   | 306700   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5554   |
| steps                   | 1802567  |
| td_erros                | -0.9797  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 306800   |
| lives                   | 306800   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.27     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5616   |
| steps                   | 1802994  |
| td_erros                | -0.9487  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 306900   |
| lives                   | 306900   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5755   |
| steps                   | 1803416  |
| td_erros                | -0.9752  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 307000   |
| lives                   | 307000   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5688   |
| steps                   | 1803835  |
| td_erros                | -0.9696  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 307100   |
| lives                   | 307100   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5589   |
| steps                   | 1804256  |
| td_erros                | -0.9561  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 307200   |
| lives                   | 307200   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5771   |
| steps                   | 1804678  |
| td_erros                | -0.9626  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 307300   |
| lives                   | 307300   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5671   |
| steps                   | 1805100  |
| td_erros                | -0.9574  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 307400   |
| lives                   | 307400   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5638   |
| steps                   | 1805519  |
| td_erros                | -0.9423  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 307500   |
| lives                   | 307500   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5676   |
| steps                   | 1805941  |
| td_erros                | -0.9405  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 307600   |
| lives                   | 307600   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5607   |
| steps                   | 1806361  |
| td_erros                | -0.9893  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 307700   |
| lives                   | 307700   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5579   |
| steps                   | 1806783  |
| td_erros                | -0.9568  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 307800   |
| lives                   | 307800   |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5458   |
| steps                   | 1807208  |
| td_erros                | -0.9897  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 307900   |
| lives                   | 307900   |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5385   |
| steps                   | 1807632  |
| td_erros                | -0.9999  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 308000   |
| lives                   | 308000   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5459   |
| steps                   | 1808055  |
| td_erros                | -0.9944  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 308100   |
| lives                   | 308100   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5481   |
| steps                   | 1808475  |
| td_erros                | -0.9455  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 308200   |
| lives                   | 308200   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.553    |
| steps                   | 1808898  |
| td_erros                | -0.9732  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 308300   |
| lives                   | 308300   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5486   |
| steps                   | 1809317  |
| td_erros                | -0.9821  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 308400   |
| lives                   | 308400   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5526   |
| steps                   | 1809739  |
| td_erros                | -0.9892  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 308500   |
| lives                   | 308500   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5378   |
| steps                   | 1810161  |
| td_erros                | -0.972   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 308600   |
| lives                   | 308600   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5429   |
| steps                   | 1810583  |
| td_erros                | -0.9879  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 308700   |
| lives                   | 308700   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.18     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5484   |
| steps                   | 1811001  |
| td_erros                | -0.9738  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 308800   |
| lives                   | 308800   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5672   |
| steps                   | 1811423  |
| td_erros                | -0.9927  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 308900   |
| lives                   | 308900   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5569   |
| steps                   | 1811842  |
| td_erros                | -0.9973  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 309000   |
| lives                   | 309000   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5413   |
| steps                   | 1812264  |
| td_erros                | -1.0183  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 309100   |
| lives                   | 309100   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.3      |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5532   |
| steps                   | 1812694  |
| td_erros                | -1.0058  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 309200   |
| lives                   | 309200   |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 5.02     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.545    |
| steps                   | 1813138  |
| td_erros                | -1.0102  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 309300   |
| lives                   | 309300   |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.11     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5452   |
| steps                   | 1813577  |
| td_erros                | -0.9719  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 309400   |
| lives                   | 309400   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.12     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5345   |
| steps                   | 1814016  |
| td_erros                | -0.9546  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 309500   |
| lives                   | 309500   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5453   |
| steps                   | 1814437  |
| td_erros                | -0.9736  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 309600   |
| lives                   | 309600   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5045   |
| steps                   | 1814858  |
| td_erros                | -0.9491  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 309700   |
| lives                   | 309700   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5182   |
| steps                   | 1815281  |
| td_erros                | -0.9733  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 309800   |
| lives                   | 309800   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5175   |
| steps                   | 1815702  |
| td_erros                | -0.9691  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 309900   |
| lives                   | 309900   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5149   |
| steps                   | 1816122  |
| td_erros                | -0.9607  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 310000   |
| lives                   | 310000   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5203   |
| steps                   | 1816544  |
| td_erros                | -0.9587  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 310100   |
| lives                   | 310100   |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4892   |
| steps                   | 1816968  |
| td_erros                | -0.9202  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 310200   |
| lives                   | 310200   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.479    |
| steps                   | 1817389  |
| td_erros                | -0.9644  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 310300   |
| lives                   | 310300   |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4824   |
| steps                   | 1817811  |
| td_erros                | -0.9482  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 310400   |
| lives                   | 310400   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4841   |
| steps                   | 1818236  |
| td_erros                | -0.9819  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 310500   |
| lives                   | 310500   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4779   |
| steps                   | 1818659  |
| td_erros                | -0.969   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 310600   |
| lives                   | 310600   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4923   |
| steps                   | 1819083  |
| td_erros                | -1.0201  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 310700   |
| lives                   | 310700   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.24     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5144   |
| steps                   | 1819503  |
| td_erros                | -0.9975  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 310800   |
| lives                   | 310800   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5206   |
| steps                   | 1819926  |
| td_erros                | -0.9818  |
--------------------------------------
Saving model due to running mean reward increase: 5.2667 -> 5.3592
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 310900   |
| lives                   | 310900   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5328   |
| steps                   | 1820349  |
| td_erros                | -0.9425  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 311000   |
| lives                   | 311000   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 5.09     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5234   |
| steps                   | 1820768  |
| td_erros                | -0.9916  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 311100   |
| lives                   | 311100   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5348   |
| steps                   | 1821190  |
| td_erros                | -0.9321  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 311200   |
| lives                   | 311200   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.17     |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5323   |
| steps                   | 1821607  |
| td_erros                | -1.0012  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 311300   |
| lives                   | 311300   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5505   |
| steps                   | 1822028  |
| td_erros                | -0.9872  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 311400   |
| lives                   | 311400   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5342   |
| steps                   | 1822448  |
| td_erros                | -0.9725  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 311500   |
| lives                   | 311500   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5363   |
| steps                   | 1822870  |
| td_erros                | -0.9816  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 311600   |
| lives                   | 311600   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5512   |
| steps                   | 1823289  |
| td_erros                | -0.9748  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 311700   |
| lives                   | 311700   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5509   |
| steps                   | 1823711  |
| td_erros                | -1.0007  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 311800   |
| lives                   | 311800   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.27     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.545    |
| steps                   | 1824138  |
| td_erros                | -0.9512  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 311900   |
| lives                   | 311900   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5418   |
| steps                   | 1824557  |
| td_erros                | -0.989   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 312000   |
| lives                   | 312000   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5549   |
| steps                   | 1824977  |
| td_erros                | -1.0128  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 312100   |
| lives                   | 312100   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5284   |
| steps                   | 1825401  |
| td_erros                | -0.9519  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 312200   |
| lives                   | 312200   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5397   |
| steps                   | 1825822  |
| td_erros                | -1.0198  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 312300   |
| lives                   | 312300   |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5241   |
| steps                   | 1826245  |
| td_erros                | -1.0361  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 312400   |
| lives                   | 312400   |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5477   |
| steps                   | 1826669  |
| td_erros                | -0.9895  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 312500   |
| lives                   | 312500   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5404   |
| steps                   | 1827089  |
| td_erros                | -1.0129  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 312600   |
| lives                   | 312600   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5526   |
| steps                   | 1827514  |
| td_erros                | -0.999   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 312700   |
| lives                   | 312700   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5503   |
| steps                   | 1827939  |
| td_erros                | -0.9752  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 312800   |
| lives                   | 312800   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5231   |
| steps                   | 1828362  |
| td_erros                | -0.9837  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 312900   |
| lives                   | 312900   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.28     |
| mean 100 episode reward | 5.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5259   |
| steps                   | 1828790  |
| td_erros                | -0.9521  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 313000   |
| lives                   | 313000   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.52     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5426   |
| steps                   | 1829242  |
| td_erros                | -0.9652  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 313100   |
| lives                   | 313100   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 5.29     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5339   |
| steps                   | 1829671  |
| td_erros                | -0.9916  |
--------------------------------------
Saving model due to mean reward increase: 5.3944 -> 5.4229
Saving model due to running mean reward increase: 5.3463 -> 5.4229
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 313200   |
| lives                   | 313200   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.38     |
| mean 100 episode reward | 5.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5271   |
| steps                   | 1830109  |
| td_erros                | -0.9398  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 313300   |
| lives                   | 313300   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5286   |
| steps                   | 1830548  |
| td_erros                | -0.9574  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 313400   |
| lives                   | 313400   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5265   |
| steps                   | 1830987  |
| td_erros                | -0.9899  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 313500   |
| lives                   | 313500   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.57     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.528    |
| steps                   | 1831430  |
| td_erros                | -0.9697  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 313600   |
| lives                   | 313600   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.38     |
| mean 100 episode reward | 5.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5308   |
| steps                   | 1831868  |
| td_erros                | -0.9655  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 313700   |
| lives                   | 313700   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5286   |
| steps                   | 1832311  |
| td_erros                | -0.947   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 313800   |
| lives                   | 313800   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5282   |
| steps                   | 1832752  |
| td_erros                | -0.923   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 313900   |
| lives                   | 313900   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5227   |
| steps                   | 1833193  |
| td_erros                | -0.9186  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 314000   |
| lives                   | 314000   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5193   |
| steps                   | 1833634  |
| td_erros                | -0.9092  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 314100   |
| lives                   | 314100   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.509    |
| steps                   | 1834074  |
| td_erros                | -0.8997  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 314200   |
| lives                   | 314200   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5012   |
| steps                   | 1834514  |
| td_erros                | -0.9098  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 314300   |
| lives                   | 314300   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4983   |
| steps                   | 1834957  |
| td_erros                | -0.9356  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 314400   |
| lives                   | 314400   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5033   |
| steps                   | 1835397  |
| td_erros                | -0.9446  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 314500   |
| lives                   | 314500   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4977   |
| steps                   | 1835837  |
| td_erros                | -0.9596  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 314600   |
| lives                   | 314600   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.32     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5067   |
| steps                   | 1836269  |
| td_erros                | -0.9387  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 314700   |
| lives                   | 314700   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5171   |
| steps                   | 1836691  |
| td_erros                | -0.9404  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 314800   |
| lives                   | 314800   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.27     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5225   |
| steps                   | 1837118  |
| td_erros                | -0.9056  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 314900   |
| lives                   | 314900   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5235   |
| steps                   | 1837539  |
| td_erros                | -0.9612  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 315000   |
| lives                   | 315000   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5427   |
| steps                   | 1837959  |
| td_erros                | -0.9487  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 315100   |
| lives                   | 315100   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5583   |
| steps                   | 1838382  |
| td_erros                | -0.9404  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 315200   |
| lives                   | 315200   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5424   |
| steps                   | 1838801  |
| td_erros                | -0.9425  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 315300   |
| lives                   | 315300   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5504   |
| steps                   | 1839223  |
| td_erros                | -0.9632  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 315400   |
| lives                   | 315400   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5497   |
| steps                   | 1839644  |
| td_erros                | -0.9615  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 315500   |
| lives                   | 315500   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5577   |
| steps                   | 1840066  |
| td_erros                | -0.9952  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 315600   |
| lives                   | 315600   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.21     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5581   |
| steps                   | 1840486  |
| td_erros                | -0.9957  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 315700   |
| lives                   | 315700   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5611   |
| steps                   | 1840909  |
| td_erros                | -0.9433  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 315800   |
| lives                   | 315800   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.569    |
| steps                   | 1841329  |
| td_erros                | -1.0191  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 315900   |
| lives                   | 315900   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5706   |
| steps                   | 1841749  |
| td_erros                | -0.9836  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 316000   |
| lives                   | 316000   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5782   |
| steps                   | 1842172  |
| td_erros                | -0.9828  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 316100   |
| lives                   | 316100   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.37     |
| mean 100 episode reward | 5.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5651   |
| steps                   | 1842609  |
| td_erros                | -0.9901  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 316200   |
| lives                   | 316200   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.36     |
| mean 100 episode reward | 5.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5556   |
| steps                   | 1843045  |
| td_erros                | -0.992   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 316300   |
| lives                   | 316300   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.35     |
| mean 100 episode reward | 5.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5588   |
| steps                   | 1843480  |
| td_erros                | -0.9619  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 316400   |
| lives                   | 316400   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 5.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5375   |
| steps                   | 1843924  |
| td_erros                | -0.9806  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 316500   |
| lives                   | 316500   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.528    |
| steps                   | 1844363  |
| td_erros                | -1.0027  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 316600   |
| lives                   | 316600   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5243   |
| steps                   | 1844802  |
| td_erros                | -0.9806  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 316700   |
| lives                   | 316700   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.53     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5034   |
| steps                   | 1845255  |
| td_erros                | -0.9652  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 316800   |
| lives                   | 316800   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.51     |
| steps                   | 1845715  |
| td_erros                | -0.9348  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 316900   |
| lives                   | 316900   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 5.51     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.493    |
| steps                   | 1846166  |
| td_erros                | -0.9507  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 317000   |
| lives                   | 317000   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4997   |
| steps                   | 1846608  |
| td_erros                | -0.9579  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 317100   |
| lives                   | 317100   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.45     |
| mean 100 episode reward | 5.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4919   |
| steps                   | 1847053  |
| td_erros                | -0.9172  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 317200   |
| lives                   | 317200   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4765   |
| steps                   | 1847494  |
| td_erros                | -0.9458  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 317300   |
| lives                   | 317300   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4835   |
| steps                   | 1847935  |
| td_erros                | -0.898   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 317400   |
| lives                   | 317400   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 5.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4534   |
| steps                   | 1848379  |
| td_erros                | -0.9458  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 317500   |
| lives                   | 317500   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.34     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.456    |
| steps                   | 1848813  |
| td_erros                | -0.895   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 317600   |
| lives                   | 317600   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4675   |
| steps                   | 1849236  |
| td_erros                | -0.9351  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 317700   |
| lives                   | 317700   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4923   |
| steps                   | 1849656  |
| td_erros                | -0.927   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 317800   |
| lives                   | 317800   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4783   |
| steps                   | 1850081  |
| td_erros                | -0.9216  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 317900   |
| lives                   | 317900   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5023   |
| steps                   | 1850501  |
| td_erros                | -0.9523  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 318000   |
| lives                   | 318000   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5132   |
| steps                   | 1850923  |
| td_erros                | -0.9638  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 318100   |
| lives                   | 318100   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5278   |
| steps                   | 1851343  |
| td_erros                | -0.9578  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 318200   |
| lives                   | 318200   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5333   |
| steps                   | 1851766  |
| td_erros                | -0.9604  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 318300   |
| lives                   | 318300   |
| mean 100 episode ei     | 3.88     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.05     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5295   |
| steps                   | 1852190  |
| td_erros                | -0.9551  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 318400   |
| lives                   | 318400   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5236   |
| steps                   | 1852610  |
| td_erros                | -0.9593  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 318500   |
| lives                   | 318500   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5245   |
| steps                   | 1853030  |
| td_erros                | -0.9598  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 318600   |
| lives                   | 318600   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5381   |
| steps                   | 1853450  |
| td_erros                | -0.9696  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 318700   |
| lives                   | 318700   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5366   |
| steps                   | 1853872  |
| td_erros                | -0.9304  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 318800   |
| lives                   | 318800   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5357   |
| steps                   | 1854295  |
| td_erros                | -0.9552  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 318900   |
| lives                   | 318900   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5323   |
| steps                   | 1854716  |
| td_erros                | -0.9664  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 319000   |
| lives                   | 319000   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.17     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5375   |
| steps                   | 1855133  |
| td_erros                | -0.9797  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 319100   |
| lives                   | 319100   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5595   |
| steps                   | 1855556  |
| td_erros                | -0.9834  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 319200   |
| lives                   | 319200   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.545    |
| steps                   | 1855976  |
| td_erros                | -0.9805  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 319300   |
| lives                   | 319300   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5441   |
| steps                   | 1856400  |
| td_erros                | -0.999   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 319400   |
| lives                   | 319400   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5595   |
| steps                   | 1856821  |
| td_erros                | -0.9843  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 319500   |
| lives                   | 319500   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.571    |
| steps                   | 1857243  |
| td_erros                | -0.9838  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 319600   |
| lives                   | 319600   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5663   |
| steps                   | 1857667  |
| td_erros                | -1.0082  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 319700   |
| lives                   | 319700   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.28     |
| mean 100 episode reward | 5.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5724   |
| steps                   | 1858095  |
| td_erros                | -1.0014  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 319800   |
| lives                   | 319800   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.33     |
| mean 100 episode reward | 5.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5969   |
| steps                   | 1858528  |
| td_erros                | -0.9406  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 319900   |
| lives                   | 319900   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5804   |
| steps                   | 1858969  |
| td_erros                | -0.9647  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 320000   |
| lives                   | 320000   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.582    |
| steps                   | 1859412  |
| td_erros                | -0.9977  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 320100   |
| lives                   | 320100   |
| mean 100 episode ei     | 4.18     |
| mean 100 episode length | 5.48     |
| mean 100 episode reward | 5.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5708   |
| steps                   | 1859860  |
| td_erros                | -0.9683  |
--------------------------------------
Saving model due to mean reward increase: 5.4229 -> 5.5519
Saving model due to running mean reward increase: 5.5153 -> 5.5519
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 320200   |
| lives                   | 320200   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5632   |
| steps                   | 1860301  |
| td_erros                | -0.9904  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 320300   |
| lives                   | 320300   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5462   |
| steps                   | 1860743  |
| td_erros                | -0.9725  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 320400   |
| lives                   | 320400   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5485   |
| steps                   | 1861183  |
| td_erros                | -0.9821  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 320500   |
| lives                   | 320500   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5456   |
| steps                   | 1861624  |
| td_erros                | -0.9615  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 320600   |
| lives                   | 320600   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5365   |
| steps                   | 1862063  |
| td_erros                | -0.916   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 320700   |
| lives                   | 320700   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5157   |
| steps                   | 1862503  |
| td_erros                | -0.9243  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 320800   |
| lives                   | 320800   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5178   |
| steps                   | 1862946  |
| td_erros                | -0.9326  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 320900   |
| lives                   | 320900   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4969   |
| steps                   | 1863387  |
| td_erros                | -0.9658  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 321000   |
| lives                   | 321000   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.508    |
| steps                   | 1863830  |
| td_erros                | -0.938   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 321100   |
| lives                   | 321100   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4951   |
| steps                   | 1864270  |
| td_erros                | -0.9469  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 321200   |
| lives                   | 321200   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5044   |
| steps                   | 1864713  |
| td_erros                | -0.9576  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 321300   |
| lives                   | 321300   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.38     |
| mean 100 episode reward | 5.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5085   |
| steps                   | 1865151  |
| td_erros                | -0.9385  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 321400   |
| lives                   | 321400   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5137   |
| steps                   | 1865594  |
| td_erros                | -0.923   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 321500   |
| lives                   | 321500   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4966   |
| steps                   | 1866036  |
| td_erros                | -0.9241  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 321600   |
| lives                   | 321600   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5144   |
| steps                   | 1866479  |
| td_erros                | -0.9649  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 321700   |
| lives                   | 321700   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 5.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5049   |
| steps                   | 1866923  |
| td_erros                | -0.935   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 321800   |
| lives                   | 321800   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.51     |
| steps                   | 1867363  |
| td_erros                | -0.966   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 321900   |
| lives                   | 321900   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5179   |
| steps                   | 1867805  |
| td_erros                | -0.9962  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 322000   |
| lives                   | 322000   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5158   |
| steps                   | 1868247  |
| td_erros                | -0.9561  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 322100   |
| lives                   | 322100   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5135   |
| steps                   | 1868688  |
| td_erros                | -0.9577  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 322200   |
| lives                   | 322200   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5342   |
| steps                   | 1869129  |
| td_erros                | -0.951   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 322300   |
| lives                   | 322300   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5282   |
| steps                   | 1869569  |
| td_erros                | -0.9552  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 322400   |
| lives                   | 322400   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.525    |
| steps                   | 1870008  |
| td_erros                | -0.9749  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 322500   |
| lives                   | 322500   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5303   |
| steps                   | 1870450  |
| td_erros                | -0.9621  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 322600   |
| lives                   | 322600   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.517    |
| steps                   | 1870889  |
| td_erros                | -0.937   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 322700   |
| lives                   | 322700   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5294   |
| steps                   | 1871328  |
| td_erros                | -0.9683  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 322800   |
| lives                   | 322800   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5313   |
| steps                   | 1871771  |
| td_erros                | -0.9449  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 322900   |
| lives                   | 322900   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.59     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5306   |
| steps                   | 1872214  |
| td_erros                | -0.9566  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 323000   |
| lives                   | 323000   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5341   |
| steps                   | 1872655  |
| td_erros                | -0.9533  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 323100   |
| lives                   | 323100   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.527    |
| steps                   | 1873097  |
| td_erros                | -0.9809  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 323200   |
| lives                   | 323200   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5267   |
| steps                   | 1873538  |
| td_erros                | -0.9859  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 323300   |
| lives                   | 323300   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5313   |
| steps                   | 1873978  |
| td_erros                | -0.9663  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 323400   |
| lives                   | 323400   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5408   |
| steps                   | 1874419  |
| td_erros                | -0.9902  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 323500   |
| lives                   | 323500   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5284   |
| steps                   | 1874861  |
| td_erros                | -0.9685  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 323600   |
| lives                   | 323600   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5326   |
| steps                   | 1875303  |
| td_erros                | -0.9701  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 323700   |
| lives                   | 323700   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 5.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.529    |
| steps                   | 1875747  |
| td_erros                | -0.9774  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 323800   |
| lives                   | 323800   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.38     |
| mean 100 episode reward | 5.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5316   |
| steps                   | 1876185  |
| td_erros                | -0.956   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 323900   |
| lives                   | 323900   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5341   |
| steps                   | 1876628  |
| td_erros                | -0.9606  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 324000   |
| lives                   | 324000   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5253   |
| steps                   | 1877071  |
| td_erros                | -0.9611  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 324100   |
| lives                   | 324100   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5187   |
| steps                   | 1877513  |
| td_erros                | -0.9711  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 324200   |
| lives                   | 324200   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5335   |
| steps                   | 1877954  |
| td_erros                | -0.9664  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 324300   |
| lives                   | 324300   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.525    |
| steps                   | 1878397  |
| td_erros                | -0.9464  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 324400   |
| lives                   | 324400   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5341   |
| steps                   | 1878837  |
| td_erros                | -0.9815  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 324500   |
| lives                   | 324500   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5358   |
| steps                   | 1879280  |
| td_erros                | -0.9427  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 324600   |
| lives                   | 324600   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5192   |
| steps                   | 1879719  |
| td_erros                | -0.9551  |
--------------------------------------
Saving model due to running mean reward increase: 5.4091 -> 5.4936
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 324700   |
| lives                   | 324700   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.32     |
| mean 100 episode reward | 5.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5231   |
| steps                   | 1880151  |
| td_erros                | -0.9597  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 324800   |
| lives                   | 324800   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5326   |
| steps                   | 1880573  |
| td_erros                | -0.9608  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 324900   |
| lives                   | 324900   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5525   |
| steps                   | 1880995  |
| td_erros                | -0.9401  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 325000   |
| lives                   | 325000   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.36     |
| mean 100 episode reward | 5.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5362   |
| steps                   | 1881431  |
| td_erros                | -0.9492  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 325100   |
| lives                   | 325100   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5422   |
| steps                   | 1881850  |
| td_erros                | -0.9696  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 325200   |
| lives                   | 325200   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5538   |
| steps                   | 1882270  |
| td_erros                | -1.0155  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 325300   |
| lives                   | 325300   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5656   |
| steps                   | 1882691  |
| td_erros                | -0.9487  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 325400   |
| lives                   | 325400   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5628   |
| steps                   | 1883112  |
| td_erros                | -0.9411  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 325500   |
| lives                   | 325500   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.33     |
| mean 100 episode reward | 5.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5621   |
| steps                   | 1883545  |
| td_erros                | -0.9639  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 325600   |
| lives                   | 325600   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.32     |
| mean 100 episode reward | 5.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5722   |
| steps                   | 1883977  |
| td_erros                | -0.9708  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 325700   |
| lives                   | 325700   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.3      |
| mean 100 episode reward | 5.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5608   |
| steps                   | 1884407  |
| td_erros                | -1.0041  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 325800   |
| lives                   | 325800   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5777   |
| steps                   | 1884830  |
| td_erros                | -0.9709  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 325900   |
| lives                   | 325900   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.35     |
| mean 100 episode reward | 5.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5897   |
| steps                   | 1885265  |
| td_erros                | -0.9885  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 326000   |
| lives                   | 326000   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.32     |
| mean 100 episode reward | 5.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5976   |
| steps                   | 1885697  |
| td_erros                | -0.9975  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 326100   |
| lives                   | 326100   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.32     |
| mean 100 episode reward | 5.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5788   |
| steps                   | 1886129  |
| td_erros                | -0.9531  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 326200   |
| lives                   | 326200   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.28     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5821   |
| steps                   | 1886557  |
| td_erros                | -1.0191  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 326300   |
| lives                   | 326300   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5666   |
| steps                   | 1886979  |
| td_erros                | -0.9968  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 326400   |
| lives                   | 326400   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5732   |
| steps                   | 1887402  |
| td_erros                | -1.0184  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 326500   |
| lives                   | 326500   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5632   |
| steps                   | 1887822  |
| td_erros                | -1.0031  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 326600   |
| lives                   | 326600   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5712   |
| steps                   | 1888245  |
| td_erros                | -0.9721  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 326700   |
| lives                   | 326700   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.34     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5831   |
| steps                   | 1888679  |
| td_erros                | -0.983   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 326800   |
| lives                   | 326800   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5668   |
| steps                   | 1889121  |
| td_erros                | -1.0029  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 326900   |
| lives                   | 326900   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 5.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5593   |
| steps                   | 1889565  |
| td_erros                | -1.0042  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 327000   |
| lives                   | 327000   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.35     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5457   |
| steps                   | 1890000  |
| td_erros                | -0.9996  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 327100   |
| lives                   | 327100   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5651   |
| steps                   | 1890440  |
| td_erros                | -0.9738  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 327200   |
| lives                   | 327200   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 5.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5536   |
| steps                   | 1890884  |
| td_erros                | -0.9986  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 327300   |
| lives                   | 327300   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5429   |
| steps                   | 1891324  |
| td_erros                | -0.9796  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 327400   |
| lives                   | 327400   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5501   |
| steps                   | 1891765  |
| td_erros                | -0.9701  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 327500   |
| lives                   | 327500   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5489   |
| steps                   | 1892204  |
| td_erros                | -0.9599  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 327600   |
| lives                   | 327600   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5417   |
| steps                   | 1892646  |
| td_erros                | -0.9759  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 327700   |
| lives                   | 327700   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5336   |
| steps                   | 1893089  |
| td_erros                | -0.952   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 327800   |
| lives                   | 327800   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 5.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5204   |
| steps                   | 1893533  |
| td_erros                | -1.0222  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 327900   |
| lives                   | 327900   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5175   |
| steps                   | 1893973  |
| td_erros                | -0.9709  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 328000   |
| lives                   | 328000   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.35     |
| mean 100 episode reward | 5.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5413   |
| steps                   | 1894408  |
| td_erros                | -0.9698  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 328100   |
| lives                   | 328100   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5456   |
| steps                   | 1894830  |
| td_erros                | -0.9565  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 328200   |
| lives                   | 328200   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.541    |
| steps                   | 1895253  |
| td_erros                | -0.9396  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 328300   |
| lives                   | 328300   |
| mean 100 episode ei     | 3.9      |
| mean 100 episode length | 5.28     |
| mean 100 episode reward | 5.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5519   |
| steps                   | 1895681  |
| td_erros                | -0.987   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 328400   |
| lives                   | 328400   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.33     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5493   |
| steps                   | 1896114  |
| td_erros                | -0.9566  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 328500   |
| lives                   | 328500   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5475   |
| steps                   | 1896553  |
| td_erros                | -0.957   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 328600   |
| lives                   | 328600   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.32     |
| mean 100 episode reward | 5.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.558    |
| steps                   | 1896985  |
| td_erros                | -0.9837  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 328700   |
| lives                   | 328700   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.3      |
| mean 100 episode reward | 5.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5535   |
| steps                   | 1897415  |
| td_erros                | -0.9435  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 328800   |
| lives                   | 328800   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.31     |
| mean 100 episode reward | 5.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5571   |
| steps                   | 1897846  |
| td_erros                | -0.9401  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 328900   |
| lives                   | 328900   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5671   |
| steps                   | 1898266  |
| td_erros                | -0.9913  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 329000   |
| lives                   | 329000   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5721   |
| steps                   | 1898688  |
| td_erros                | -1.0074  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 329100   |
| lives                   | 329100   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5681   |
| steps                   | 1899110  |
| td_erros                | -0.968   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 329200   |
| lives                   | 329200   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5792   |
| steps                   | 1899530  |
| td_erros                | -1.0155  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 329300   |
| lives                   | 329300   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5739   |
| steps                   | 1899952  |
| td_erros                | -0.9458  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 329400   |
| lives                   | 329400   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5753   |
| steps                   | 1900372  |
| td_erros                | -0.997   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 329500   |
| lives                   | 329500   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5695   |
| steps                   | 1900794  |
| td_erros                | -1.0185  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 329600   |
| lives                   | 329600   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5565   |
| steps                   | 1901216  |
| td_erros                | -1.0171  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 329700   |
| lives                   | 329700   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.577    |
| steps                   | 1901639  |
| td_erros                | -1.0274  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 329800   |
| lives                   | 329800   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5887   |
| steps                   | 1902061  |
| td_erros                | -0.9698  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 329900   |
| lives                   | 329900   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 5.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5809   |
| steps                   | 1902486  |
| td_erros                | -0.9911  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 330000   |
| lives                   | 330000   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.593    |
| steps                   | 1902928  |
| td_erros                | -1.0023  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 330100   |
| lives                   | 330100   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5792   |
| steps                   | 1903370  |
| td_erros                | -0.9901  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 330200   |
| lives                   | 330200   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5854   |
| steps                   | 1903812  |
| td_erros                | -1.0079  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 330300   |
| lives                   | 330300   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 5.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.575    |
| steps                   | 1904256  |
| td_erros                | -0.995   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 330400   |
| lives                   | 330400   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.52     |
| mean 100 episode reward | 5.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5578   |
| steps                   | 1904708  |
| td_erros                | -0.9854  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 330500   |
| lives                   | 330500   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.56     |
| mean 100 episode reward | 5.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.533    |
| steps                   | 1905164  |
| td_erros                | -0.9888  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 330600   |
| lives                   | 330600   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5428   |
| steps                   | 1905624  |
| td_erros                | -0.971   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 330700   |
| lives                   | 330700   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.47     |
| mean 100 episode reward | 5.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5161   |
| steps                   | 1906071  |
| td_erros                | -0.9913  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 330800   |
| lives                   | 330800   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5148   |
| steps                   | 1906512  |
| td_erros                | -0.9859  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 330900   |
| lives                   | 330900   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 5.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5038   |
| steps                   | 1906956  |
| td_erros                | -0.9412  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 331000   |
| lives                   | 331000   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.484    |
| steps                   | 1907397  |
| td_erros                | -0.9392  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 331100   |
| lives                   | 331100   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4652   |
| steps                   | 1907836  |
| td_erros                | -0.9268  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 331200   |
| lives                   | 331200   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4715   |
| steps                   | 1908275  |
| td_erros                | -0.9144  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 331300   |
| lives                   | 331300   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4744   |
| steps                   | 1908717  |
| td_erros                | -0.9449  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 331400   |
| lives                   | 331400   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.31     |
| mean 100 episode reward | 5.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4783   |
| steps                   | 1909148  |
| td_erros                | -0.911   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 331500   |
| lives                   | 331500   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4848   |
| steps                   | 1909570  |
| td_erros                | -0.9304  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 331600   |
| lives                   | 331600   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4825   |
| steps                   | 1909991  |
| td_erros                | -0.964   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 331700   |
| lives                   | 331700   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4891   |
| steps                   | 1910411  |
| td_erros                | -0.9393  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 331800   |
| lives                   | 331800   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5022   |
| steps                   | 1910832  |
| td_erros                | -0.9489  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 331900   |
| lives                   | 331900   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.51     |
| steps                   | 1911255  |
| td_erros                | -0.9825  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 332000   |
| lives                   | 332000   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5157   |
| steps                   | 1911676  |
| td_erros                | -0.9919  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 332100   |
| lives                   | 332100   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5237   |
| steps                   | 1912097  |
| td_erros                | -0.9914  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 332200   |
| lives                   | 332200   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.18     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5397   |
| steps                   | 1912518  |
| td_erros                | -0.9891  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 332300   |
| lives                   | 332300   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5446   |
| steps                   | 1912938  |
| td_erros                | -0.95    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 332400   |
| lives                   | 332400   |
| mean 100 episode ei     | 3.91     |
| mean 100 episode length | 5.13     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5453   |
| steps                   | 1913351  |
| td_erros                | -0.9883  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 332500   |
| lives                   | 332500   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5598   |
| steps                   | 1913771  |
| td_erros                | -0.9857  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 332600   |
| lives                   | 332600   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5624   |
| steps                   | 1914194  |
| td_erros                | -1.0149  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 332700   |
| lives                   | 332700   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.17     |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.551    |
| steps                   | 1914611  |
| td_erros                | -0.9691  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 332800   |
| lives                   | 332800   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5527   |
| steps                   | 1915032  |
| td_erros                | -0.9771  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 332900   |
| lives                   | 332900   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5647   |
| steps                   | 1915454  |
| td_erros                | -0.9991  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 333000   |
| lives                   | 333000   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5682   |
| steps                   | 1915876  |
| td_erros                | -0.9943  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 333100   |
| lives                   | 333100   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5474   |
| steps                   | 1916297  |
| td_erros                | -0.9795  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 333200   |
| lives                   | 333200   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5594   |
| steps                   | 1916720  |
| td_erros                | -1.0166  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 333300   |
| lives                   | 333300   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5421   |
| steps                   | 1917142  |
| td_erros                | -1.0186  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 333400   |
| lives                   | 333400   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5567   |
| steps                   | 1917567  |
| td_erros                | -0.9809  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 333500   |
| lives                   | 333500   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5696   |
| steps                   | 1917990  |
| td_erros                | -1.0013  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 333600   |
| lives                   | 333600   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.13     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5622   |
| steps                   | 1918411  |
| td_erros                | -0.9909  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 333700   |
| lives                   | 333700   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5631   |
| steps                   | 1918832  |
| td_erros                | -0.9849  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 333800   |
| lives                   | 333800   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5648   |
| steps                   | 1919254  |
| td_erros                | -0.9903  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 333900   |
| lives                   | 333900   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5395   |
| steps                   | 1919675  |
| td_erros                | -1.022   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 334000   |
| lives                   | 334000   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5592   |
| steps                   | 1920095  |
| td_erros                | -1.017   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 334100   |
| lives                   | 334100   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5613   |
| steps                   | 1920516  |
| td_erros                | -1.0217  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 334200   |
| lives                   | 334200   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5675   |
| steps                   | 1920937  |
| td_erros                | -1.0362  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 334300   |
| lives                   | 334300   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5826   |
| steps                   | 1921359  |
| td_erros                | -1.0142  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 334400   |
| lives                   | 334400   |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5757   |
| steps                   | 1921781  |
| td_erros                | -0.9985  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 334500   |
| lives                   | 334500   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.577    |
| steps                   | 1922203  |
| td_erros                | -1.0383  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 334600   |
| lives                   | 334600   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5793   |
| steps                   | 1922625  |
| td_erros                | -1.0042  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 334700   |
| lives                   | 334700   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5825   |
| steps                   | 1923045  |
| td_erros                | -1.026   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 334800   |
| lives                   | 334800   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5845   |
| steps                   | 1923465  |
| td_erros                | -1.0351  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 334900   |
| lives                   | 334900   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5861   |
| steps                   | 1923885  |
| td_erros                | -1.0025  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 335000   |
| lives                   | 335000   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5826   |
| steps                   | 1924307  |
| td_erros                | -1.0196  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 335100   |
| lives                   | 335100   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5708   |
| steps                   | 1924729  |
| td_erros                | -1.03    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 335200   |
| lives                   | 335200   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5738   |
| steps                   | 1925150  |
| td_erros                | -1.0141  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 335300   |
| lives                   | 335300   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5746   |
| steps                   | 1925573  |
| td_erros                | -1.0287  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 335400   |
| lives                   | 335400   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5755   |
| steps                   | 1925994  |
| td_erros                | -0.9792  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 335500   |
| lives                   | 335500   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5731   |
| steps                   | 1926414  |
| td_erros                | -0.9939  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 335600   |
| lives                   | 335600   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5693   |
| steps                   | 1926836  |
| td_erros                | -1.0171  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 335700   |
| lives                   | 335700   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5775   |
| steps                   | 1927257  |
| td_erros                | -1.0169  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 335800   |
| lives                   | 335800   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5922   |
| steps                   | 1927677  |
| td_erros                | -1.0501  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 335900   |
| lives                   | 335900   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5862   |
| steps                   | 1928097  |
| td_erros                | -0.9908  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 336000   |
| lives                   | 336000   |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5765   |
| steps                   | 1928519  |
| td_erros                | -1.0355  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 336100   |
| lives                   | 336100   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5624   |
| steps                   | 1928940  |
| td_erros                | -1.0151  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 336200   |
| lives                   | 336200   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5595   |
| steps                   | 1929360  |
| td_erros                | -1.0115  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 336300   |
| lives                   | 336300   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.27     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5625   |
| steps                   | 1929787  |
| td_erros                | -1.0033  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 336400   |
| lives                   | 336400   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.29     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5703   |
| steps                   | 1930216  |
| td_erros                | -1.0339  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 336500   |
| lives                   | 336500   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.32     |
| mean 100 episode reward | 5.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5718   |
| steps                   | 1930648  |
| td_erros                | -1.0553  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 336600   |
| lives                   | 336600   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5782   |
| steps                   | 1931071  |
| td_erros                | -1.0351  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 336700   |
| lives                   | 336700   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.35     |
| mean 100 episode reward | 5.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5737   |
| steps                   | 1931506  |
| td_erros                | -1.0067  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 336800   |
| lives                   | 336800   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.28     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5603   |
| steps                   | 1931934  |
| td_erros                | -1.0107  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 336900   |
| lives                   | 336900   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5534   |
| steps                   | 1932376  |
| td_erros                | -0.9884  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 337000   |
| lives                   | 337000   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5304   |
| steps                   | 1932819  |
| td_erros                | -0.9964  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 337100   |
| lives                   | 337100   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5416   |
| steps                   | 1933259  |
| td_erros                | -1.0064  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 337200   |
| lives                   | 337200   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.46     |
| mean 100 episode reward | 5.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5357   |
| steps                   | 1933705  |
| td_erros                | -1.008   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 337300   |
| lives                   | 337300   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.37     |
| mean 100 episode reward | 5.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5285   |
| steps                   | 1934142  |
| td_erros                | -1.0121  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 337400   |
| lives                   | 337400   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.27     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5191   |
| steps                   | 1934569  |
| td_erros                | -0.9771  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 337500   |
| lives                   | 337500   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5202   |
| steps                   | 1935012  |
| td_erros                | -0.9822  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 337600   |
| lives                   | 337600   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5251   |
| steps                   | 1935453  |
| td_erros                | -0.9664  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 337700   |
| lives                   | 337700   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.45     |
| mean 100 episode reward | 5.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5108   |
| steps                   | 1935898  |
| td_erros                | -0.9641  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 337800   |
| lives                   | 337800   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4959   |
| steps                   | 1936340  |
| td_erros                | -0.9746  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 337900   |
| lives                   | 337900   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4947   |
| steps                   | 1936781  |
| td_erros                | -0.9801  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 338000   |
| lives                   | 338000   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5023   |
| steps                   | 1937222  |
| td_erros                | -0.9872  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 338100   |
| lives                   | 338100   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5068   |
| steps                   | 1937665  |
| td_erros                | -0.9442  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 338200   |
| lives                   | 338200   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4957   |
| steps                   | 1938106  |
| td_erros                | -0.9782  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 338300   |
| lives                   | 338300   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5091   |
| steps                   | 1938546  |
| td_erros                | -0.9956  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 338400   |
| lives                   | 338400   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 5.53     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5137   |
| steps                   | 1938999  |
| td_erros                | -0.957   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 338500   |
| lives                   | 338500   |
| mean 100 episode ei     | 3.95     |
| mean 100 episode length | 5.47     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4938   |
| steps                   | 1939446  |
| td_erros                | -0.9673  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 338600   |
| lives                   | 338600   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4931   |
| steps                   | 1939886  |
| td_erros                | -0.9418  |
--------------------------------------
Saving model due to running mean reward increase: 5.3822 -> 5.5383
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 338700   |
| lives                   | 338700   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4992   |
| steps                   | 1940328  |
| td_erros                | -0.9417  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 338800   |
| lives                   | 338800   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5147   |
| steps                   | 1940769  |
| td_erros                | -0.9554  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 338900   |
| lives                   | 338900   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 5.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4912   |
| steps                   | 1941213  |
| td_erros                | -0.9763  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 339000   |
| lives                   | 339000   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4935   |
| steps                   | 1941654  |
| td_erros                | -0.9532  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 339100   |
| lives                   | 339100   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5      |
| steps                   | 1942094  |
| td_erros                | -0.9934  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 339200   |
| lives                   | 339200   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.47     |
| mean 100 episode reward | 5.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5025   |
| steps                   | 1942541  |
| td_erros                | -1.0085  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 339300   |
| lives                   | 339300   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5048   |
| steps                   | 1942981  |
| td_erros                | -1.0042  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 339400   |
| lives                   | 339400   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4903   |
| steps                   | 1943421  |
| td_erros                | -1.0153  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 339500   |
| lives                   | 339500   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4946   |
| steps                   | 1943863  |
| td_erros                | -1.0022  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 339600   |
| lives                   | 339600   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.56     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5041   |
| steps                   | 1944304  |
| td_erros                | -1.0083  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 339700   |
| lives                   | 339700   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5132   |
| steps                   | 1944746  |
| td_erros                | -1.0328  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 339800   |
| lives                   | 339800   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5053   |
| steps                   | 1945186  |
| td_erros                | -1.0162  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 339900   |
| lives                   | 339900   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.38     |
| mean 100 episode reward | 5.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5139   |
| steps                   | 1945624  |
| td_erros                | -1.0368  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 340000   |
| lives                   | 340000   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5254   |
| steps                   | 1946065  |
| td_erros                | -0.9832  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 340100   |
| lives                   | 340100   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5209   |
| steps                   | 1946506  |
| td_erros                | -0.9713  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 340200   |
| lives                   | 340200   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5196   |
| steps                   | 1946948  |
| td_erros                | -1.0358  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 340300   |
| lives                   | 340300   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5212   |
| steps                   | 1947390  |
| td_erros                | -0.9794  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 340400   |
| lives                   | 340400   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5267   |
| steps                   | 1947831  |
| td_erros                | -0.9864  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 340500   |
| lives                   | 340500   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5156   |
| steps                   | 1948270  |
| td_erros                | -1.0134  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 340600   |
| lives                   | 340600   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.45     |
| mean 100 episode reward | 5.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5285   |
| steps                   | 1948715  |
| td_erros                | -0.9979  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 340700   |
| lives                   | 340700   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.539    |
| steps                   | 1949157  |
| td_erros                | -1.0234  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 340800   |
| lives                   | 340800   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5262   |
| steps                   | 1949597  |
| td_erros                | -0.9686  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 340900   |
| lives                   | 340900   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.45     |
| mean 100 episode reward | 5.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5178   |
| steps                   | 1950042  |
| td_erros                | -0.9843  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 341000   |
| lives                   | 341000   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.58     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5233   |
| steps                   | 1950482  |
| td_erros                | -0.9737  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 341100   |
| lives                   | 341100   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5384   |
| steps                   | 1950922  |
| td_erros                | -0.9821  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 341200   |
| lives                   | 341200   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5387   |
| steps                   | 1951347  |
| td_erros                | -1.0234  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 341300   |
| lives                   | 341300   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.32     |
| mean 100 episode reward | 5.45     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5379   |
| steps                   | 1951779  |
| td_erros                | -1.001   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 341400   |
| lives                   | 341400   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5357   |
| steps                   | 1952218  |
| td_erros                | -1.0173  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 341500   |
| lives                   | 341500   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5463   |
| steps                   | 1952659  |
| td_erros                | -1.0378  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 341600   |
| lives                   | 341600   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5464   |
| steps                   | 1953101  |
| td_erros                | -0.9825  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 341700   |
| lives                   | 341700   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5368   |
| steps                   | 1953542  |
| td_erros                | -0.9995  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 341800   |
| lives                   | 341800   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5512   |
| steps                   | 1953983  |
| td_erros                | -1.0002  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 341900   |
| lives                   | 341900   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5228   |
| steps                   | 1954423  |
| td_erros                | -0.9558  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 342000   |
| lives                   | 342000   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5343   |
| steps                   | 1954865  |
| td_erros                | -1.0085  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 342100   |
| lives                   | 342100   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5371   |
| steps                   | 1955305  |
| td_erros                | -0.996   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 342200   |
| lives                   | 342200   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5379   |
| steps                   | 1955745  |
| td_erros                | -1.0263  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 342300   |
| lives                   | 342300   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5253   |
| steps                   | 1956188  |
| td_erros                | -0.9666  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 342400   |
| lives                   | 342400   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5299   |
| steps                   | 1956627  |
| td_erros                | -1.0159  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 342500   |
| lives                   | 342500   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.49     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5298   |
| steps                   | 1957066  |
| td_erros                | -0.9929  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 342600   |
| lives                   | 342600   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5254   |
| steps                   | 1957507  |
| td_erros                | -1.0221  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 342700   |
| lives                   | 342700   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 5.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5104   |
| steps                   | 1957951  |
| td_erros                | -1.025   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 342800   |
| lives                   | 342800   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.527    |
| steps                   | 1958390  |
| td_erros                | -1.0247  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 342900   |
| lives                   | 342900   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.37     |
| mean 100 episode reward | 5.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5278   |
| steps                   | 1958827  |
| td_erros                | -0.9854  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 343000   |
| lives                   | 343000   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 5.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5453   |
| steps                   | 1959252  |
| td_erros                | -1.0269  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 343100   |
| lives                   | 343100   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5473   |
| steps                   | 1959672  |
| td_erros                | -1.0095  |
--------------------------------------
Saving model due to running mean reward increase: 5.325 -> 5.4228
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 343200   |
| lives                   | 343200   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.33     |
| mean 100 episode reward | 5.43     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5473   |
| steps                   | 1960105  |
| td_erros                | -1.0423  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 343300   |
| lives                   | 343300   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.52     |
| mean 100 episode reward | 5.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.554    |
| steps                   | 1960557  |
| td_erros                | -0.9998  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 343400   |
| lives                   | 343400   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.6      |
| mean 100 episode reward | 5.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5506   |
| steps                   | 1961017  |
| td_erros                | -0.9648  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 343500   |
| lives                   | 343500   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.61     |
| mean 100 episode reward | 5.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5415   |
| steps                   | 1961478  |
| td_erros                | -1.0039  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 343600   |
| lives                   | 343600   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.44     |
| mean 100 episode reward | 5.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5253   |
| steps                   | 1961922  |
| td_erros                | -0.953   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 343700   |
| lives                   | 343700   |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 5.46     |
| mean 100 episode reward | 5.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5241   |
| steps                   | 1962368  |
| td_erros                | -0.9914  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 343800   |
| lives                   | 343800   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5219   |
| steps                   | 1962810  |
| td_erros                | -0.9638  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 343900   |
| lives                   | 343900   |
| mean 100 episode ei     | 3.96     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4986   |
| steps                   | 1963250  |
| td_erros                | -0.9619  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 344000   |
| lives                   | 344000   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4997   |
| steps                   | 1963692  |
| td_erros                | -0.9937  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 344100   |
| lives                   | 344100   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4999   |
| steps                   | 1964133  |
| td_erros                | -0.9813  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 344200   |
| lives                   | 344200   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.48     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4988   |
| steps                   | 1964573  |
| td_erros                | -0.9501  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 344300   |
| lives                   | 344300   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.44     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.469    |
| steps                   | 1965014  |
| td_erros                | -0.9535  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 344400   |
| lives                   | 344400   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4744   |
| steps                   | 1965457  |
| td_erros                | -0.9809  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 344500   |
| lives                   | 344500   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4754   |
| steps                   | 1965897  |
| td_erros                | -0.9516  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 344600   |
| lives                   | 344600   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4932   |
| steps                   | 1966321  |
| td_erros                | -0.9557  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 344700   |
| lives                   | 344700   |
| mean 100 episode ei     | 3.94     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.16     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.4999   |
| steps                   | 1966741  |
| td_erros                | -0.9902  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 344800   |
| lives                   | 344800   |
| mean 100 episode ei     | 3.89     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.14     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5116   |
| steps                   | 1967161  |
| td_erros                | -0.9911  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 344900   |
| lives                   | 344900   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.514    |
| steps                   | 1967583  |
| td_erros                | -0.9762  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 345000   |
| lives                   | 345000   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 5.26     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5317   |
| steps                   | 1968008  |
| td_erros                | -1.0097  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 345100   |
| lives                   | 345100   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5392   |
| steps                   | 1968429  |
| td_erros                | -0.9936  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 345200   |
| lives                   | 345200   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5499   |
| steps                   | 1968850  |
| td_erros                | -0.9844  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 345300   |
| lives                   | 345300   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5602   |
| steps                   | 1969270  |
| td_erros                | -0.9993  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 345400   |
| lives                   | 345400   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5545   |
| steps                   | 1969691  |
| td_erros                | -0.9882  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 345500   |
| lives                   | 345500   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5562   |
| steps                   | 1970116  |
| td_erros                | -0.9625  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 345600   |
| lives                   | 345600   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5562   |
| steps                   | 1970538  |
| td_erros                | -1.0328  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 345700   |
| lives                   | 345700   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5557   |
| steps                   | 1970958  |
| td_erros                | -1.0302  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 345800   |
| lives                   | 345800   |
| mean 100 episode ei     | 3.92     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5775   |
| steps                   | 1971378  |
| td_erros                | -0.9999  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 345900   |
| lives                   | 345900   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.18     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5681   |
| steps                   | 1971796  |
| td_erros                | -1.0411  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 346000   |
| lives                   | 346000   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.37     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5778   |
| steps                   | 1972218  |
| td_erros                | -1.0574  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 346100   |
| lives                   | 346100   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5712   |
| steps                   | 1972639  |
| td_erros                | -1.0036  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 346200   |
| lives                   | 346200   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5749   |
| steps                   | 1973061  |
| td_erros                | -1.0122  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 346300   |
| lives                   | 346300   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5789   |
| steps                   | 1973480  |
| td_erros                | -1.0109  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 346400   |
| lives                   | 346400   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5844   |
| steps                   | 1973901  |
| td_erros                | -1.0011  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 346500   |
| lives                   | 346500   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5777   |
| steps                   | 1974323  |
| td_erros                | -1.0298  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 346600   |
| lives                   | 346600   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5738   |
| steps                   | 1974743  |
| td_erros                | -1.0068  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 346700   |
| lives                   | 346700   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5852   |
| steps                   | 1975163  |
| td_erros                | -1.0026  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 346800   |
| lives                   | 346800   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5705   |
| steps                   | 1975585  |
| td_erros                | -1.0448  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 346900   |
| lives                   | 346900   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5943   |
| steps                   | 1976005  |
| td_erros                | -1.0114  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 347000   |
| lives                   | 347000   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5942   |
| steps                   | 1976426  |
| td_erros                | -1.0161  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 347100   |
| lives                   | 347100   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5871   |
| steps                   | 1976850  |
| td_erros                | -1.0525  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 347200   |
| lives                   | 347200   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5855   |
| steps                   | 1977271  |
| td_erros                | -1.0343  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 347300   |
| lives                   | 347300   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.18     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5879   |
| steps                   | 1977689  |
| td_erros                | -1.0564  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 347400   |
| lives                   | 347400   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5952   |
| steps                   | 1978109  |
| td_erros                | -1.0116  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 347500   |
| lives                   | 347500   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.51     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5894   |
| steps                   | 1978549  |
| td_erros                | -1.0307  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 347600   |
| lives                   | 347600   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.28     |
| mean 100 episode reward | 5.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5857   |
| steps                   | 1978977  |
| td_erros                | -1.0388  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 347700   |
| lives                   | 347700   |
| mean 100 episode ei     | 4.06     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.52     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5708   |
| steps                   | 1979419  |
| td_erros                | -1.0259  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 347800   |
| lives                   | 347800   |
| mean 100 episode ei     | 4.03     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5805   |
| steps                   | 1979859  |
| td_erros                | -1.0379  |
--------------------------------------
Saving model due to mean reward increase: 5.5519 -> 5.5567
Saving model due to running mean reward increase: 5.4979 -> 5.5567
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 347900   |
| lives                   | 347900   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.54     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.57     |
| steps                   | 1980301  |
| td_erros                | -1.0108  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 348000   |
| lives                   | 348000   |
| mean 100 episode ei     | 3.98     |
| mean 100 episode length | 5.38     |
| mean 100 episode reward | 5.42     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.576    |
| steps                   | 1980739  |
| td_erros                | -1.0332  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 348100   |
| lives                   | 348100   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.38     |
| mean 100 episode reward | 5.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5778   |
| steps                   | 1981177  |
| td_erros                | -0.987   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 348200   |
| lives                   | 348200   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.46     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5613   |
| steps                   | 1981616  |
| td_erros                | -0.9875  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 348300   |
| lives                   | 348300   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.41     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5701   |
| steps                   | 1982056  |
| td_erros                | -1.0009  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 348400   |
| lives                   | 348400   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.47     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5556   |
| steps                   | 1982498  |
| td_erros                | -1.0176  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 348500   |
| lives                   | 348500   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5552   |
| steps                   | 1982940  |
| td_erros                | -1.0082  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 348600   |
| lives                   | 348600   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.41     |
| mean 100 episode reward | 5.5      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5485   |
| steps                   | 1983381  |
| td_erros                | -0.9999  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 348700   |
| lives                   | 348700   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5479   |
| steps                   | 1983823  |
| td_erros                | -0.9981  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 348800   |
| lives                   | 348800   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.4      |
| mean 100 episode reward | 5.55     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5488   |
| steps                   | 1984263  |
| td_erros                | -0.9864  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 348900   |
| lives                   | 348900   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.53     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5647   |
| steps                   | 1984702  |
| td_erros                | -0.9771  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 349000   |
| lives                   | 349000   |
| mean 100 episode ei     | 4.2      |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.4      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5362   |
| steps                   | 1985145  |
| td_erros                | -0.9929  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 349100   |
| lives                   | 349100   |
| mean 100 episode ei     | 4.29     |
| mean 100 episode length | 5.42     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5337   |
| steps                   | 1985587  |
| td_erros                | -1.0076  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 349200   |
| lives                   | 349200   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.27     |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5279   |
| steps                   | 1986014  |
| td_erros                | -1.0183  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 349300   |
| lives                   | 349300   |
| mean 100 episode ei     | 4.04     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.25     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5309   |
| steps                   | 1986435  |
| td_erros                | -0.9863  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 349400   |
| lives                   | 349400   |
| mean 100 episode ei     | 4        |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.2      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5376   |
| steps                   | 1986856  |
| td_erros                | -1.0239  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 349500   |
| lives                   | 349500   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5385   |
| steps                   | 1987277  |
| td_erros                | -0.9672  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 349600   |
| lives                   | 349600   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5326   |
| steps                   | 1987698  |
| td_erros                | -1.0072  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 349700   |
| lives                   | 349700   |
| mean 100 episode ei     | 4.13     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5548   |
| steps                   | 1988119  |
| td_erros                | -0.9638  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 349800   |
| lives                   | 349800   |
| mean 100 episode ei     | 3.93     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.15     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5348   |
| steps                   | 1988539  |
| td_erros                | -0.9616  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 349900   |
| lives                   | 349900   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5163   |
| steps                   | 1988963  |
| td_erros                | -0.9781  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 350000   |
| lives                   | 350000   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.29     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5231   |
| steps                   | 1989387  |
| td_erros                | -0.9739  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 350100   |
| lives                   | 350100   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5342   |
| steps                   | 1989808  |
| td_erros                | -0.9553  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 350200   |
| lives                   | 350200   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.28     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5325   |
| steps                   | 1990231  |
| td_erros                | -0.9546  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 350300   |
| lives                   | 350300   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.547    |
| steps                   | 1990651  |
| td_erros                | -1.0043  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 350400   |
| lives                   | 350400   |
| mean 100 episode ei     | 4.14     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5646   |
| steps                   | 1991075  |
| td_erros                | -1.0039  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 350500   |
| lives                   | 350500   |
| mean 100 episode ei     | 4.33     |
| mean 100 episode length | 5.43     |
| mean 100 episode reward | 5.3      |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5535   |
| steps                   | 1991518  |
| td_erros                | -1.0076  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 350600   |
| lives                   | 350600   |
| mean 100 episode ei     | 4.26     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.38     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5284   |
| steps                   | 1991957  |
| td_erros                | -1.0013  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 350700   |
| lives                   | 350700   |
| mean 100 episode ei     | 4.1      |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5185   |
| steps                   | 1992377  |
| td_erros                | -1.0198  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 350800   |
| lives                   | 350800   |
| mean 100 episode ei     | 4.17     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5198   |
| steps                   | 1992801  |
| td_erros                | -0.9777  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 350900   |
| lives                   | 350900   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.21     |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5271   |
| steps                   | 1993222  |
| td_erros                | -0.9782  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 351000   |
| lives                   | 351000   |
| mean 100 episode ei     | 4.07     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.39     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5198   |
| steps                   | 1993642  |
| td_erros                | -0.9788  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 351100   |
| lives                   | 351100   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.33     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5421   |
| steps                   | 1994062  |
| td_erros                | -0.9672  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 351200   |
| lives                   | 351200   |
| mean 100 episode ei     | 4.12     |
| mean 100 episode length | 5.2      |
| mean 100 episode reward | 5.34     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5335   |
| steps                   | 1994482  |
| td_erros                | -0.96    |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 351300   |
| lives                   | 351300   |
| mean 100 episode ei     | 4.09     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5403   |
| steps                   | 1994904  |
| td_erros                | -0.9769  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 351400   |
| lives                   | 351400   |
| mean 100 episode ei     | 4.11     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5404   |
| steps                   | 1995326  |
| td_erros                | -0.9633  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 351500   |
| lives                   | 351500   |
| mean 100 episode ei     | 4.05     |
| mean 100 episode length | 5.23     |
| mean 100 episode reward | 5.19     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5279   |
| steps                   | 1995749  |
| td_erros                | -0.9931  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 351600   |
| lives                   | 351600   |
| mean 100 episode ei     | 3.97     |
| mean 100 episode length | 5.22     |
| mean 100 episode reward | 5.22     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5298   |
| steps                   | 1996171  |
| td_erros                | -0.9775  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 351700   |
| lives                   | 351700   |
| mean 100 episode ei     | 4.16     |
| mean 100 episode length | 5.31     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5289   |
| steps                   | 1996602  |
| td_erros                | -0.9441  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 351800   |
| lives                   | 351800   |
| mean 100 episode ei     | 4.24     |
| mean 100 episode length | 5.37     |
| mean 100 episode reward | 5.32     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5447   |
| steps                   | 1997039  |
| td_erros                | -0.9671  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 351900   |
| lives                   | 351900   |
| mean 100 episode ei     | 4.27     |
| mean 100 episode length | 5.39     |
| mean 100 episode reward | 5.35     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.523    |
| steps                   | 1997478  |
| td_erros                | -0.9781  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 352000   |
| lives                   | 352000   |
| mean 100 episode ei     | 4.15     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 5.36     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5278   |
| steps                   | 1997903  |
| td_erros                | -0.951   |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 352100   |
| lives                   | 352100   |
| mean 100 episode ei     | 3.99     |
| mean 100 episode length | 5.19     |
| mean 100 episode reward | 5.31     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5221   |
| steps                   | 1998322  |
| td_erros                | -0.9835  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 352200   |
| lives                   | 352200   |
| mean 100 episode ei     | 4.02     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.23     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.506    |
| steps                   | 1998746  |
| td_erros                | -0.9856  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 352300   |
| lives                   | 352300   |
| mean 100 episode ei     | 4.01     |
| mean 100 episode length | 5.25     |
| mean 100 episode reward | 5.17     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.52     |
| steps                   | 1999171  |
| td_erros                | -0.9815  |
--------------------------------------
--------------------------------------
| % time spent exploring  | 1        |
| episodes                | 352400   |
| lives                   | 352400   |
| mean 100 episode ei     | 4.08     |
| mean 100 episode length | 5.24     |
| mean 100 episode reward | 5.27     |
| most_used_dataset       | 4        |
| number_of_used          | 21       |
| q_t                     | 1.5176   |
| steps                   | 1999595  |
| td_erros                | -0.9605  |
--------------------------------------
Restored model with mean reward: 5.5567
